I0523 19:28:11.005794      15 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-041930030
I0523 19:28:11.005952      15 e2e.go:240] Starting e2e run "e6484d5c-7d90-11e9-b22f-2a454b6ec3fe" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1558639690 - Will randomize all specs
Will run 204 of 3585 specs

May 23 19:28:11.127: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:28:11.129: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 23 19:28:18.262: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 23 19:28:18.312: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 23 19:28:18.312: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
May 23 19:28:18.312: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 23 19:28:18.326: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 23 19:28:18.326: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
May 23 19:28:18.326: INFO: e2e test version: v1.14.2
May 23 19:28:18.328: INFO: kube-apiserver version: v1.14.2
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:28:18.329: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
May 23 19:28:18.393: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 23 19:28:18.402: INFO: Waiting up to 5m0s for pod "pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-7720" to be "success or failure"
May 23 19:28:18.406: INFO: Pod "pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.587167ms
May 23 19:28:20.414: INFO: Pod "pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012094714s
May 23 19:28:22.431: INFO: Pod "pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028925245s
STEP: Saw pod success
May 23 19:28:22.431: INFO: Pod "pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:28:22.436: INFO: Trying to get logs from node worker-1 pod pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:28:22.495: INFO: Waiting for pod pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:28:22.499: INFO: Pod pod-eb0fdfca-7d90-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:28:22.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7720" for this suite.
May 23 19:28:28.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:28:28.594: INFO: namespace emptydir-7720 deletion completed in 6.09206594s

• [SLOW TEST:10.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:28:28.594: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
May 23 19:28:28.617: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4177" to be "success or failure"
May 23 19:28:28.620: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.450982ms
May 23 19:28:30.626: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00923633s
May 23 19:28:32.629: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011482631s
STEP: Saw pod success
May 23 19:28:32.629: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 23 19:28:32.630: INFO: Trying to get logs from node worker-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 23 19:28:32.649: INFO: Waiting for pod pod-host-path-test to disappear
May 23 19:28:32.651: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:28:32.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4177" for this suite.
May 23 19:28:38.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:28:38.711: INFO: namespace hostpath-4177 deletion completed in 6.058380383s

• [SLOW TEST:10.117 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:28:38.712: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3324
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 23 19:28:38.731: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 23 19:28:58.893: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.0.3:8080/dial?request=hostName&protocol=http&host=10.38.0.2&port=8080&tries=1'] Namespace:pod-network-test-3324 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:28:58.894: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:28:59.045: INFO: Waiting for endpoints: map[]
May 23 19:28:59.047: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.0.3:8080/dial?request=hostName&protocol=http&host=10.40.0.2&port=8080&tries=1'] Namespace:pod-network-test-3324 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:28:59.047: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:28:59.157: INFO: Waiting for endpoints: map[]
May 23 19:28:59.159: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.0.3:8080/dial?request=hostName&protocol=http&host=10.32.0.4&port=8080&tries=1'] Namespace:pod-network-test-3324 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:28:59.159: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:28:59.256: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:28:59.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3324" for this suite.
May 23 19:29:21.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:29:21.346: INFO: namespace pod-network-test-3324 deletion completed in 22.088599814s

• [SLOW TEST:42.635 seconds]
[sig-network] Networking
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:29:21.346: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-109db610-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating secret with name s-test-opt-upd-109db637-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-109db610-7d91-11e9-b22f-2a454b6ec3fe
STEP: Updating secret s-test-opt-upd-109db637-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating secret with name s-test-opt-create-109db653-7d91-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:30:52.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8170" for this suite.
May 23 19:31:14.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:31:14.511: INFO: namespace projected-8170 deletion completed in 22.055363279s

• [SLOW TEST:113.165 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:31:14.511: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 23 19:31:14.558: INFO: Pod name pod-release: Found 0 pods out of 1
May 23 19:31:19.561: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:31:19.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6982" for this suite.
May 23 19:31:25.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:31:25.663: INFO: namespace replication-controller-6982 deletion completed in 6.072920485s

• [SLOW TEST:11.152 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:31:25.663: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
May 23 19:31:25.684: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-041930030 proxy --unix-socket=/tmp/kubectl-proxy-unix126597813/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:31:25.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7800" for this suite.
May 23 19:31:31.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:31:31.824: INFO: namespace kubectl-7800 deletion completed in 6.084303438s

• [SLOW TEST:6.161 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:31:31.824: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0523 19:32:01.893353      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 19:32:01.893: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:32:01.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1123" for this suite.
May 23 19:32:07.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:32:08.037: INFO: namespace gc-1123 deletion completed in 6.136769675s

• [SLOW TEST:36.213 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:32:08.040: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
May 23 19:32:08.066: INFO: Waiting up to 5m0s for pod "client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe" in namespace "containers-5937" to be "success or failure"
May 23 19:32:08.070: INFO: Pod "client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.570896ms
May 23 19:32:10.076: INFO: Pod "client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010688584s
May 23 19:32:12.083: INFO: Pod "client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017562969s
STEP: Saw pod success
May 23 19:32:12.083: INFO: Pod "client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:32:12.085: INFO: Trying to get logs from node worker-1 pod client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:32:12.098: INFO: Waiting for pod client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:32:12.100: INFO: Pod client-containers-73f42a6d-7d91-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:32:12.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5937" for this suite.
May 23 19:32:18.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:32:18.156: INFO: namespace containers-5937 deletion completed in 6.054581698s

• [SLOW TEST:10.117 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:32:18.157: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 23 19:32:18.184: INFO: Waiting up to 5m0s for pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-9071" to be "success or failure"
May 23 19:32:18.192: INFO: Pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.369675ms
May 23 19:32:20.198: INFO: Pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01370387s
May 23 19:32:22.204: INFO: Pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020067648s
May 23 19:32:24.208: INFO: Pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024029707s
STEP: Saw pod success
May 23 19:32:24.209: INFO: Pod "downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:32:24.212: INFO: Trying to get logs from node worker-1 pod downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 19:32:24.230: INFO: Waiting for pod downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:32:24.235: INFO: Pod downward-api-79fbd36c-7d91-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:32:24.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9071" for this suite.
May 23 19:32:30.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:32:30.342: INFO: namespace downward-api-9071 deletion completed in 6.104211828s

• [SLOW TEST:12.186 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:32:30.343: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6082
May 23 19:32:34.382: INFO: Started pod liveness-http in namespace container-probe-6082
STEP: checking the pod's current state and verifying that restartCount is present
May 23 19:32:34.396: INFO: Initial restart count of pod liveness-http is 0
May 23 19:32:56.499: INFO: Restart count of pod container-probe-6082/liveness-http is now 1 (22.103139331s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:32:56.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6082" for this suite.
May 23 19:33:02.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:33:02.616: INFO: namespace container-probe-6082 deletion completed in 6.083805206s

• [SLOW TEST:32.274 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:33:02.618: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-947c722f-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 19:33:02.650: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe" in namespace "projected-6226" to be "success or failure"
May 23 19:33:02.655: INFO: Pod "pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.80268ms
May 23 19:33:04.657: INFO: Pod "pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006875974s
STEP: Saw pod success
May 23 19:33:04.657: INFO: Pod "pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:33:04.659: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 19:33:04.672: INFO: Waiting for pod pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:33:04.673: INFO: Pod pod-projected-configmaps-947cbe92-7d91-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:33:04.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6226" for this suite.
May 23 19:33:10.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:33:10.725: INFO: namespace projected-6226 deletion completed in 6.049766454s

• [SLOW TEST:8.106 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:33:10.727: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-995107ff-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating secret with name secret-projected-all-test-volume-995107f6-7d91-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test Check all projections for projected volume plugin
May 23 19:33:10.754: INFO: Waiting up to 5m0s for pod "projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe" in namespace "projected-1329" to be "success or failure"
May 23 19:33:10.761: INFO: Pod "projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.467711ms
May 23 19:33:12.765: INFO: Pod "projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010326604s
STEP: Saw pod success
May 23 19:33:12.765: INFO: Pod "projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:33:12.767: INFO: Trying to get logs from node worker-1 pod projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe container projected-all-volume-test: <nil>
STEP: delete the pod
May 23 19:33:12.779: INFO: Waiting for pod projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:33:12.780: INFO: Pod projected-volume-995107d8-7d91-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:33:12.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1329" for this suite.
May 23 19:33:18.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:33:18.862: INFO: namespace projected-1329 deletion completed in 6.07979605s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:33:18.862: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 23 19:33:18.886: INFO: Waiting up to 5m0s for pod "pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-2398" to be "success or failure"
May 23 19:33:18.889: INFO: Pod "pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.611154ms
May 23 19:33:20.896: INFO: Pod "pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009488949s
May 23 19:33:22.901: INFO: Pod "pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013952146s
STEP: Saw pod success
May 23 19:33:22.901: INFO: Pod "pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:33:22.902: INFO: Trying to get logs from node worker-1 pod pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:33:22.916: INFO: Waiting for pod pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:33:22.918: INFO: Pod pod-9e2a267e-7d91-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:33:22.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2398" for this suite.
May 23 19:33:28.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:33:28.987: INFO: namespace emptydir-2398 deletion completed in 6.068219241s

• [SLOW TEST:10.126 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:33:28.988: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:33:29.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9132" for this suite.
May 23 19:33:51.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:33:51.099: INFO: namespace pods-9132 deletion completed in 22.072749213s

• [SLOW TEST:22.111 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:33:51.099: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:34:51.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2178" for this suite.
May 23 19:35:07.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:35:07.227: INFO: namespace container-probe-2178 deletion completed in 16.085698973s

• [SLOW TEST:76.128 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:35:07.227: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:35:07.260: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 23 19:35:07.267: INFO: Number of nodes with available pods: 0
May 23 19:35:07.267: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:08.271: INFO: Number of nodes with available pods: 0
May 23 19:35:08.271: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:09.273: INFO: Number of nodes with available pods: 1
May 23 19:35:09.273: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:10.283: INFO: Number of nodes with available pods: 2
May 23 19:35:10.284: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:11.276: INFO: Number of nodes with available pods: 2
May 23 19:35:11.276: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:12.271: INFO: Number of nodes with available pods: 2
May 23 19:35:12.271: INFO: Node controlplane-1 is running more than one daemon pod
May 23 19:35:13.278: INFO: Number of nodes with available pods: 3
May 23 19:35:13.279: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 23 19:35:13.341: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:13.341: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:13.341: INFO: Wrong image for pod: daemon-set-v9r8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:14.350: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:14.351: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:14.351: INFO: Wrong image for pod: daemon-set-v9r8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:15.348: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:15.348: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:15.348: INFO: Wrong image for pod: daemon-set-v9r8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:16.358: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:16.358: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:16.358: INFO: Wrong image for pod: daemon-set-v9r8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:16.358: INFO: Pod daemon-set-v9r8t is not available
May 23 19:35:17.348: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:17.348: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:17.348: INFO: Pod daemon-set-kjz6m is not available
May 23 19:35:18.356: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:18.356: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:18.356: INFO: Pod daemon-set-kjz6m is not available
May 23 19:35:19.347: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:19.347: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:19.347: INFO: Pod daemon-set-kjz6m is not available
May 23 19:35:20.347: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:20.347: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:21.352: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:21.352: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:21.352: INFO: Pod daemon-set-4flqn is not available
May 23 19:35:22.352: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:22.352: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:22.352: INFO: Pod daemon-set-4flqn is not available
May 23 19:35:23.353: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:23.353: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:23.353: INFO: Pod daemon-set-4flqn is not available
May 23 19:35:24.348: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:24.348: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:24.348: INFO: Pod daemon-set-4flqn is not available
May 23 19:35:25.350: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:25.350: INFO: Wrong image for pod: daemon-set-4flqn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:25.350: INFO: Pod daemon-set-4flqn is not available
May 23 19:35:26.347: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:26.347: INFO: Pod daemon-set-296d2 is not available
May 23 19:35:27.350: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:27.350: INFO: Pod daemon-set-296d2 is not available
May 23 19:35:28.346: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:28.346: INFO: Pod daemon-set-296d2 is not available
May 23 19:35:29.347: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:30.356: INFO: Wrong image for pod: daemon-set-25fp4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 23 19:35:30.356: INFO: Pod daemon-set-25fp4 is not available
May 23 19:35:31.356: INFO: Pod daemon-set-qf9cp is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 23 19:35:31.375: INFO: Number of nodes with available pods: 2
May 23 19:35:31.375: INFO: Node worker-1 is running more than one daemon pod
May 23 19:35:32.388: INFO: Number of nodes with available pods: 2
May 23 19:35:32.388: INFO: Node worker-1 is running more than one daemon pod
May 23 19:35:33.379: INFO: Number of nodes with available pods: 2
May 23 19:35:33.379: INFO: Node worker-1 is running more than one daemon pod
May 23 19:35:34.394: INFO: Number of nodes with available pods: 3
May 23 19:35:34.395: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1454, will wait for the garbage collector to delete the pods
May 23 19:35:34.516: INFO: Deleting DaemonSet.extensions daemon-set took: 33.526346ms
May 23 19:35:34.820: INFO: Terminating DaemonSet.extensions daemon-set pods took: 303.890704ms
May 23 19:35:46.723: INFO: Number of nodes with available pods: 0
May 23 19:35:46.723: INFO: Number of running nodes: 0, number of available pods: 0
May 23 19:35:46.724: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1454/daemonsets","resourceVersion":"2238"},"items":null}

May 23 19:35:46.726: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1454/pods","resourceVersion":"2238"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:35:46.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1454" for this suite.
May 23 19:35:52.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:35:52.815: INFO: namespace daemonsets-1454 deletion completed in 6.082209672s

• [SLOW TEST:45.588 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:35:52.815: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6776
I0523 19:35:52.845341      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6776, replica count: 1
I0523 19:35:53.902377      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0523 19:35:54.904916      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0523 19:35:55.905237      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 23 19:35:56.032: INFO: Created: latency-svc-bb6s5
May 23 19:35:56.040: INFO: Got endpoints: latency-svc-bb6s5 [34.393042ms]
May 23 19:35:56.080: INFO: Created: latency-svc-nzb9s
May 23 19:35:56.088: INFO: Got endpoints: latency-svc-nzb9s [48.11829ms]
May 23 19:35:56.126: INFO: Created: latency-svc-rvxns
May 23 19:35:56.132: INFO: Got endpoints: latency-svc-rvxns [90.793029ms]
May 23 19:35:56.144: INFO: Created: latency-svc-c27gg
May 23 19:35:56.145: INFO: Got endpoints: latency-svc-c27gg [103.739758ms]
May 23 19:35:56.146: INFO: Created: latency-svc-8db2k
May 23 19:35:56.150: INFO: Got endpoints: latency-svc-8db2k [107.779226ms]
May 23 19:35:56.159: INFO: Created: latency-svc-clgrl
May 23 19:35:56.163: INFO: Got endpoints: latency-svc-clgrl [120.656227ms]
May 23 19:35:56.171: INFO: Created: latency-svc-n8fcb
May 23 19:35:56.178: INFO: Got endpoints: latency-svc-n8fcb [135.18041ms]
May 23 19:35:56.182: INFO: Created: latency-svc-gj5lx
May 23 19:35:56.189: INFO: Got endpoints: latency-svc-gj5lx [145.61643ms]
May 23 19:35:56.191: INFO: Created: latency-svc-t84z8
May 23 19:35:56.194: INFO: Got endpoints: latency-svc-t84z8 [151.181384ms]
May 23 19:35:56.200: INFO: Created: latency-svc-xxs8s
May 23 19:35:56.203: INFO: Got endpoints: latency-svc-xxs8s [159.13256ms]
May 23 19:35:56.208: INFO: Created: latency-svc-pq26t
May 23 19:35:56.210: INFO: Got endpoints: latency-svc-pq26t [166.248797ms]
May 23 19:35:56.220: INFO: Created: latency-svc-6vghd
May 23 19:35:56.223: INFO: Got endpoints: latency-svc-6vghd [179.013366ms]
May 23 19:35:56.230: INFO: Created: latency-svc-dg525
May 23 19:35:56.233: INFO: Got endpoints: latency-svc-dg525 [188.643299ms]
May 23 19:35:56.252: INFO: Created: latency-svc-vzt97
May 23 19:35:56.253: INFO: Got endpoints: latency-svc-vzt97 [209.230083ms]
May 23 19:35:56.264: INFO: Created: latency-svc-tj4gg
May 23 19:35:56.270: INFO: Got endpoints: latency-svc-tj4gg [225.605306ms]
May 23 19:35:56.286: INFO: Created: latency-svc-px57b
May 23 19:35:56.290: INFO: Got endpoints: latency-svc-px57b [246.534215ms]
May 23 19:35:56.301: INFO: Created: latency-svc-vb2q7
May 23 19:35:56.304: INFO: Got endpoints: latency-svc-vb2q7 [215.402046ms]
May 23 19:35:56.314: INFO: Created: latency-svc-qw86b
May 23 19:35:56.317: INFO: Got endpoints: latency-svc-qw86b [184.466202ms]
May 23 19:35:56.326: INFO: Created: latency-svc-brqqc
May 23 19:35:56.328: INFO: Got endpoints: latency-svc-brqqc [182.903072ms]
May 23 19:35:56.339: INFO: Created: latency-svc-pmt2g
May 23 19:35:56.341: INFO: Got endpoints: latency-svc-pmt2g [190.662062ms]
May 23 19:35:56.348: INFO: Created: latency-svc-fj9mg
May 23 19:35:56.371: INFO: Created: latency-svc-gt6pd
May 23 19:35:56.372: INFO: Got endpoints: latency-svc-fj9mg [208.761098ms]
May 23 19:35:56.375: INFO: Got endpoints: latency-svc-gt6pd [196.312422ms]
May 23 19:35:56.387: INFO: Created: latency-svc-mw4zs
May 23 19:35:56.391: INFO: Got endpoints: latency-svc-mw4zs [201.728657ms]
May 23 19:35:56.401: INFO: Created: latency-svc-89nt2
May 23 19:35:56.401: INFO: Got endpoints: latency-svc-89nt2 [206.868688ms]
May 23 19:35:56.413: INFO: Created: latency-svc-4ttmg
May 23 19:35:56.414: INFO: Got endpoints: latency-svc-4ttmg [211.069175ms]
May 23 19:35:56.425: INFO: Created: latency-svc-j2hdj
May 23 19:35:56.432: INFO: Got endpoints: latency-svc-j2hdj [221.521956ms]
May 23 19:35:56.437: INFO: Created: latency-svc-fmpzb
May 23 19:35:56.441: INFO: Got endpoints: latency-svc-fmpzb [217.60463ms]
May 23 19:35:56.446: INFO: Created: latency-svc-6cdtx
May 23 19:35:56.447: INFO: Got endpoints: latency-svc-6cdtx [213.902035ms]
May 23 19:35:56.454: INFO: Created: latency-svc-q9h56
May 23 19:35:56.460: INFO: Got endpoints: latency-svc-q9h56 [206.758633ms]
May 23 19:35:56.482: INFO: Created: latency-svc-tq4zs
May 23 19:35:56.483: INFO: Got endpoints: latency-svc-tq4zs [212.985302ms]
May 23 19:35:56.492: INFO: Created: latency-svc-xkj94
May 23 19:35:56.494: INFO: Got endpoints: latency-svc-xkj94 [203.973148ms]
May 23 19:35:56.502: INFO: Created: latency-svc-6lqrc
May 23 19:35:56.513: INFO: Got endpoints: latency-svc-6lqrc [208.914494ms]
May 23 19:35:56.526: INFO: Created: latency-svc-ld7s8
May 23 19:35:56.531: INFO: Got endpoints: latency-svc-ld7s8 [213.753005ms]
May 23 19:35:56.535: INFO: Created: latency-svc-v2cp6
May 23 19:35:56.539: INFO: Got endpoints: latency-svc-v2cp6 [211.404403ms]
May 23 19:35:56.542: INFO: Created: latency-svc-6jqw8
May 23 19:35:56.553: INFO: Got endpoints: latency-svc-6jqw8 [211.785128ms]
May 23 19:35:56.559: INFO: Created: latency-svc-k78k2
May 23 19:35:56.564: INFO: Got endpoints: latency-svc-k78k2 [191.623885ms]
May 23 19:35:56.569: INFO: Created: latency-svc-qtr9l
May 23 19:35:56.573: INFO: Got endpoints: latency-svc-qtr9l [198.538983ms]
May 23 19:35:56.578: INFO: Created: latency-svc-b5sm7
May 23 19:35:56.585: INFO: Got endpoints: latency-svc-b5sm7 [193.902747ms]
May 23 19:35:56.600: INFO: Created: latency-svc-hpkm6
May 23 19:35:56.600: INFO: Got endpoints: latency-svc-hpkm6 [185.599857ms]
May 23 19:35:56.606: INFO: Created: latency-svc-pkdv6
May 23 19:35:56.606: INFO: Got endpoints: latency-svc-pkdv6 [204.498112ms]
May 23 19:35:56.611: INFO: Created: latency-svc-jh2zk
May 23 19:35:56.611: INFO: Got endpoints: latency-svc-jh2zk [179.253596ms]
May 23 19:35:56.622: INFO: Created: latency-svc-tsf4p
May 23 19:35:56.633: INFO: Got endpoints: latency-svc-tsf4p [191.690191ms]
May 23 19:35:56.633: INFO: Created: latency-svc-2t552
May 23 19:35:56.641: INFO: Created: latency-svc-wghpb
May 23 19:35:56.650: INFO: Created: latency-svc-bgqzp
May 23 19:35:56.660: INFO: Created: latency-svc-8ltnd
May 23 19:35:56.672: INFO: Created: latency-svc-75zpc
May 23 19:35:56.685: INFO: Got endpoints: latency-svc-2t552 [238.250444ms]
May 23 19:35:56.686: INFO: Created: latency-svc-x4fwf
May 23 19:35:56.705: INFO: Created: latency-svc-sznd4
May 23 19:35:56.724: INFO: Created: latency-svc-crt86
May 23 19:35:56.767: INFO: Got endpoints: latency-svc-wghpb [307.005466ms]
May 23 19:35:56.797: INFO: Got endpoints: latency-svc-bgqzp [313.486484ms]
May 23 19:35:56.797: INFO: Created: latency-svc-9d99h
May 23 19:35:56.906: INFO: Got endpoints: latency-svc-8ltnd [411.373856ms]
May 23 19:35:56.911: INFO: Got endpoints: latency-svc-75zpc [398.143559ms]
May 23 19:35:56.913: INFO: Created: latency-svc-9xzkh
May 23 19:35:56.951: INFO: Got endpoints: latency-svc-x4fwf [420.223478ms]
May 23 19:35:56.959: INFO: Created: latency-svc-lhwwq
May 23 19:35:56.963: INFO: Created: latency-svc-5wt4v
May 23 19:35:56.980: INFO: Created: latency-svc-2txgw
May 23 19:35:57.002: INFO: Got endpoints: latency-svc-sznd4 [462.584557ms]
May 23 19:35:57.006: INFO: Created: latency-svc-pn8sn
May 23 19:35:57.061: INFO: Got endpoints: latency-svc-crt86 [507.943299ms]
May 23 19:35:57.066: INFO: Created: latency-svc-4nw9d
May 23 19:35:57.100: INFO: Got endpoints: latency-svc-9d99h [535.964783ms]
May 23 19:35:57.101: INFO: Created: latency-svc-fhr6t
May 23 19:35:57.116: INFO: Created: latency-svc-zvgxc
May 23 19:35:57.150: INFO: Got endpoints: latency-svc-9xzkh [576.2581ms]
May 23 19:35:57.151: INFO: Created: latency-svc-sv2kb
May 23 19:35:57.233: INFO: Got endpoints: latency-svc-lhwwq [648.00904ms]
May 23 19:35:57.237: INFO: Created: latency-svc-zvt5l
May 23 19:35:57.239: INFO: Got endpoints: latency-svc-5wt4v [638.60562ms]
May 23 19:35:57.266: INFO: Created: latency-svc-8j9qw
May 23 19:35:57.322: INFO: Got endpoints: latency-svc-2txgw [716.432932ms]
May 23 19:35:57.324: INFO: Created: latency-svc-g9kct
May 23 19:35:57.395: INFO: Got endpoints: latency-svc-pn8sn [783.474824ms]
May 23 19:35:57.400: INFO: Created: latency-svc-84k64
May 23 19:35:57.400: INFO: Got endpoints: latency-svc-4nw9d [766.755653ms]
May 23 19:35:57.410: INFO: Created: latency-svc-nvf2g
May 23 19:35:57.430: INFO: Created: latency-svc-hs9pf
May 23 19:35:57.432: INFO: Got endpoints: latency-svc-fhr6t [746.877536ms]
May 23 19:35:57.461: INFO: Created: latency-svc-ff6mc
May 23 19:35:57.476: INFO: Created: latency-svc-8mql7
May 23 19:35:57.563: INFO: Got endpoints: latency-svc-zvgxc [795.167408ms]
May 23 19:35:57.564: INFO: Got endpoints: latency-svc-sv2kb [766.603988ms]
May 23 19:35:57.569: INFO: Created: latency-svc-8dhrw
May 23 19:35:57.576: INFO: Created: latency-svc-wf7rn
May 23 19:35:57.592: INFO: Got endpoints: latency-svc-zvt5l [685.682204ms]
May 23 19:35:57.595: INFO: Created: latency-svc-7q96m
May 23 19:35:57.623: INFO: Created: latency-svc-zgvkh
May 23 19:35:57.639: INFO: Got endpoints: latency-svc-8j9qw [726.625134ms]
May 23 19:35:57.639: INFO: Created: latency-svc-sq44b
May 23 19:35:57.691: INFO: Created: latency-svc-nsjxh
May 23 19:35:57.691: INFO: Got endpoints: latency-svc-g9kct [740.489214ms]
May 23 19:35:57.699: INFO: Created: latency-svc-d8rns
May 23 19:35:57.707: INFO: Created: latency-svc-s66nh
May 23 19:35:57.714: INFO: Created: latency-svc-qrbvb
May 23 19:35:57.719: INFO: Created: latency-svc-dr67s
May 23 19:35:57.733: INFO: Got endpoints: latency-svc-84k64 [730.622662ms]
May 23 19:35:57.740: INFO: Created: latency-svc-6wlgl
May 23 19:35:57.782: INFO: Got endpoints: latency-svc-nvf2g [721.167649ms]
May 23 19:35:57.791: INFO: Created: latency-svc-mpl5s
May 23 19:35:57.832: INFO: Got endpoints: latency-svc-hs9pf [732.542913ms]
May 23 19:35:57.843: INFO: Created: latency-svc-v4rsx
May 23 19:35:57.886: INFO: Got endpoints: latency-svc-ff6mc [734.831726ms]
May 23 19:35:57.900: INFO: Created: latency-svc-9vl79
May 23 19:35:57.931: INFO: Got endpoints: latency-svc-8mql7 [697.759712ms]
May 23 19:35:57.939: INFO: Created: latency-svc-nrst7
May 23 19:35:57.981: INFO: Got endpoints: latency-svc-8dhrw [742.408034ms]
May 23 19:35:57.988: INFO: Created: latency-svc-jf28g
May 23 19:35:58.033: INFO: Got endpoints: latency-svc-wf7rn [710.688905ms]
May 23 19:35:58.053: INFO: Created: latency-svc-gtl8t
May 23 19:35:58.083: INFO: Got endpoints: latency-svc-7q96m [687.936114ms]
May 23 19:35:58.094: INFO: Created: latency-svc-k2sdj
May 23 19:35:58.131: INFO: Got endpoints: latency-svc-zgvkh [730.701487ms]
May 23 19:35:58.140: INFO: Created: latency-svc-nlhx8
May 23 19:35:58.185: INFO: Got endpoints: latency-svc-sq44b [753.25624ms]
May 23 19:35:58.192: INFO: Created: latency-svc-4h7j5
May 23 19:35:58.231: INFO: Got endpoints: latency-svc-nsjxh [668.35186ms]
May 23 19:35:58.239: INFO: Created: latency-svc-jkmbk
May 23 19:35:58.286: INFO: Got endpoints: latency-svc-d8rns [721.876893ms]
May 23 19:35:58.296: INFO: Created: latency-svc-dhspw
May 23 19:35:58.332: INFO: Got endpoints: latency-svc-s66nh [739.872847ms]
May 23 19:35:58.343: INFO: Created: latency-svc-gfx2l
May 23 19:35:58.381: INFO: Got endpoints: latency-svc-qrbvb [742.629908ms]
May 23 19:35:58.388: INFO: Created: latency-svc-j845s
May 23 19:35:58.435: INFO: Got endpoints: latency-svc-dr67s [743.619878ms]
May 23 19:35:58.444: INFO: Created: latency-svc-7wlqh
May 23 19:35:58.481: INFO: Got endpoints: latency-svc-6wlgl [747.980955ms]
May 23 19:35:58.490: INFO: Created: latency-svc-fg6z9
May 23 19:35:58.532: INFO: Got endpoints: latency-svc-mpl5s [749.649767ms]
May 23 19:35:58.540: INFO: Created: latency-svc-jksrz
May 23 19:35:58.581: INFO: Got endpoints: latency-svc-v4rsx [748.175357ms]
May 23 19:35:58.591: INFO: Created: latency-svc-bzc44
May 23 19:35:58.632: INFO: Got endpoints: latency-svc-9vl79 [745.95444ms]
May 23 19:35:58.640: INFO: Created: latency-svc-hpxqp
May 23 19:35:58.681: INFO: Got endpoints: latency-svc-nrst7 [749.787725ms]
May 23 19:35:58.690: INFO: Created: latency-svc-szcjx
May 23 19:35:58.732: INFO: Got endpoints: latency-svc-jf28g [751.056224ms]
May 23 19:35:58.769: INFO: Created: latency-svc-wnchf
May 23 19:35:58.783: INFO: Got endpoints: latency-svc-gtl8t [750.410157ms]
May 23 19:35:58.798: INFO: Created: latency-svc-g25f2
May 23 19:35:58.833: INFO: Got endpoints: latency-svc-k2sdj [749.73412ms]
May 23 19:35:58.885: INFO: Created: latency-svc-6j6nx
May 23 19:35:58.887: INFO: Got endpoints: latency-svc-nlhx8 [756.696709ms]
May 23 19:35:58.901: INFO: Created: latency-svc-98lp8
May 23 19:35:58.932: INFO: Got endpoints: latency-svc-4h7j5 [746.932692ms]
May 23 19:35:58.945: INFO: Created: latency-svc-p2sjt
May 23 19:35:58.981: INFO: Got endpoints: latency-svc-jkmbk [749.799268ms]
May 23 19:35:58.990: INFO: Created: latency-svc-s5hvz
May 23 19:35:59.032: INFO: Got endpoints: latency-svc-dhspw [746.002071ms]
May 23 19:35:59.040: INFO: Created: latency-svc-w5mxq
May 23 19:35:59.080: INFO: Got endpoints: latency-svc-gfx2l [748.241381ms]
May 23 19:35:59.093: INFO: Created: latency-svc-zv8fx
May 23 19:35:59.135: INFO: Got endpoints: latency-svc-j845s [753.293611ms]
May 23 19:35:59.144: INFO: Created: latency-svc-99vh2
May 23 19:35:59.182: INFO: Got endpoints: latency-svc-7wlqh [747.027962ms]
May 23 19:35:59.191: INFO: Created: latency-svc-sckvv
May 23 19:35:59.231: INFO: Got endpoints: latency-svc-fg6z9 [750.134703ms]
May 23 19:35:59.243: INFO: Created: latency-svc-xfls2
May 23 19:35:59.281: INFO: Got endpoints: latency-svc-jksrz [749.107239ms]
May 23 19:35:59.290: INFO: Created: latency-svc-b4kmr
May 23 19:35:59.333: INFO: Got endpoints: latency-svc-bzc44 [752.337813ms]
May 23 19:35:59.346: INFO: Created: latency-svc-bs9z5
May 23 19:35:59.382: INFO: Got endpoints: latency-svc-hpxqp [750.338488ms]
May 23 19:35:59.390: INFO: Created: latency-svc-8k56w
May 23 19:35:59.434: INFO: Got endpoints: latency-svc-szcjx [753.027951ms]
May 23 19:35:59.443: INFO: Created: latency-svc-ngbth
May 23 19:35:59.481: INFO: Got endpoints: latency-svc-wnchf [748.890351ms]
May 23 19:35:59.496: INFO: Created: latency-svc-slsqg
May 23 19:35:59.532: INFO: Got endpoints: latency-svc-g25f2 [748.120523ms]
May 23 19:35:59.541: INFO: Created: latency-svc-l2f2h
May 23 19:35:59.581: INFO: Got endpoints: latency-svc-6j6nx [748.793335ms]
May 23 19:35:59.595: INFO: Created: latency-svc-xnw52
May 23 19:35:59.633: INFO: Got endpoints: latency-svc-98lp8 [745.785513ms]
May 23 19:35:59.643: INFO: Created: latency-svc-9j4lb
May 23 19:35:59.683: INFO: Got endpoints: latency-svc-p2sjt [750.395705ms]
May 23 19:35:59.695: INFO: Created: latency-svc-86lpj
May 23 19:35:59.732: INFO: Got endpoints: latency-svc-s5hvz [750.803434ms]
May 23 19:35:59.740: INFO: Created: latency-svc-7qrxl
May 23 19:35:59.782: INFO: Got endpoints: latency-svc-w5mxq [749.882397ms]
May 23 19:35:59.793: INFO: Created: latency-svc-hjvqk
May 23 19:35:59.832: INFO: Got endpoints: latency-svc-zv8fx [751.828908ms]
May 23 19:35:59.848: INFO: Created: latency-svc-nvrjw
May 23 19:35:59.882: INFO: Got endpoints: latency-svc-99vh2 [747.341763ms]
May 23 19:35:59.897: INFO: Created: latency-svc-d96hn
May 23 19:35:59.931: INFO: Got endpoints: latency-svc-sckvv [748.533027ms]
May 23 19:35:59.938: INFO: Created: latency-svc-cg2sf
May 23 19:35:59.982: INFO: Got endpoints: latency-svc-xfls2 [751.364199ms]
May 23 19:35:59.993: INFO: Created: latency-svc-gwpsw
May 23 19:36:00.034: INFO: Got endpoints: latency-svc-b4kmr [752.472403ms]
May 23 19:36:00.048: INFO: Created: latency-svc-xv58g
May 23 19:36:00.083: INFO: Got endpoints: latency-svc-bs9z5 [749.34864ms]
May 23 19:36:00.094: INFO: Created: latency-svc-s6nm9
May 23 19:36:00.134: INFO: Got endpoints: latency-svc-8k56w [751.895655ms]
May 23 19:36:00.144: INFO: Created: latency-svc-mlvkz
May 23 19:36:00.181: INFO: Got endpoints: latency-svc-ngbth [747.214143ms]
May 23 19:36:00.191: INFO: Created: latency-svc-9m7nw
May 23 19:36:00.233: INFO: Got endpoints: latency-svc-slsqg [751.55013ms]
May 23 19:36:00.247: INFO: Created: latency-svc-ww5jt
May 23 19:36:00.282: INFO: Got endpoints: latency-svc-l2f2h [749.895111ms]
May 23 19:36:00.299: INFO: Created: latency-svc-swrxk
May 23 19:36:00.331: INFO: Got endpoints: latency-svc-xnw52 [749.63735ms]
May 23 19:36:00.338: INFO: Created: latency-svc-5p7rv
May 23 19:36:00.385: INFO: Got endpoints: latency-svc-9j4lb [752.066106ms]
May 23 19:36:00.395: INFO: Created: latency-svc-d5m9x
May 23 19:36:00.432: INFO: Got endpoints: latency-svc-86lpj [749.061864ms]
May 23 19:36:00.443: INFO: Created: latency-svc-smpwx
May 23 19:36:00.481: INFO: Got endpoints: latency-svc-7qrxl [748.843393ms]
May 23 19:36:00.489: INFO: Created: latency-svc-8498r
May 23 19:36:00.534: INFO: Got endpoints: latency-svc-hjvqk [751.831078ms]
May 23 19:36:00.546: INFO: Created: latency-svc-slldl
May 23 19:36:00.581: INFO: Got endpoints: latency-svc-nvrjw [748.42052ms]
May 23 19:36:00.591: INFO: Created: latency-svc-blpnc
May 23 19:36:00.631: INFO: Got endpoints: latency-svc-d96hn [748.546869ms]
May 23 19:36:00.645: INFO: Created: latency-svc-5znw9
May 23 19:36:00.684: INFO: Got endpoints: latency-svc-cg2sf [753.423447ms]
May 23 19:36:00.690: INFO: Created: latency-svc-bvtrh
May 23 19:36:00.733: INFO: Got endpoints: latency-svc-gwpsw [750.092859ms]
May 23 19:36:00.740: INFO: Created: latency-svc-tpfhb
May 23 19:36:00.781: INFO: Got endpoints: latency-svc-xv58g [747.808994ms]
May 23 19:36:00.794: INFO: Created: latency-svc-c8jf4
May 23 19:36:00.834: INFO: Got endpoints: latency-svc-s6nm9 [751.264096ms]
May 23 19:36:00.843: INFO: Created: latency-svc-8944x
May 23 19:36:00.882: INFO: Got endpoints: latency-svc-mlvkz [747.366476ms]
May 23 19:36:00.891: INFO: Created: latency-svc-9l9pc
May 23 19:36:00.931: INFO: Got endpoints: latency-svc-9m7nw [749.164078ms]
May 23 19:36:00.941: INFO: Created: latency-svc-k264p
May 23 19:36:00.981: INFO: Got endpoints: latency-svc-ww5jt [747.837257ms]
May 23 19:36:00.989: INFO: Created: latency-svc-bdvgk
May 23 19:36:01.031: INFO: Got endpoints: latency-svc-swrxk [749.11622ms]
May 23 19:36:01.052: INFO: Created: latency-svc-dk5g6
May 23 19:36:01.084: INFO: Got endpoints: latency-svc-5p7rv [753.240558ms]
May 23 19:36:01.102: INFO: Created: latency-svc-gnxgx
May 23 19:36:01.131: INFO: Got endpoints: latency-svc-d5m9x [745.581661ms]
May 23 19:36:01.148: INFO: Created: latency-svc-jwpb2
May 23 19:36:01.181: INFO: Got endpoints: latency-svc-smpwx [748.902526ms]
May 23 19:36:01.191: INFO: Created: latency-svc-p6xq6
May 23 19:36:01.232: INFO: Got endpoints: latency-svc-8498r [751.493312ms]
May 23 19:36:01.265: INFO: Created: latency-svc-t8stl
May 23 19:36:01.286: INFO: Got endpoints: latency-svc-slldl [752.261224ms]
May 23 19:36:01.295: INFO: Created: latency-svc-n29ls
May 23 19:36:01.331: INFO: Got endpoints: latency-svc-blpnc [749.897944ms]
May 23 19:36:01.341: INFO: Created: latency-svc-2pl8q
May 23 19:36:01.382: INFO: Got endpoints: latency-svc-5znw9 [750.549158ms]
May 23 19:36:01.390: INFO: Created: latency-svc-8mhb8
May 23 19:36:01.431: INFO: Got endpoints: latency-svc-bvtrh [746.660132ms]
May 23 19:36:01.441: INFO: Created: latency-svc-h7r84
May 23 19:36:01.482: INFO: Got endpoints: latency-svc-tpfhb [748.868298ms]
May 23 19:36:01.492: INFO: Created: latency-svc-7wjbc
May 23 19:36:01.534: INFO: Got endpoints: latency-svc-c8jf4 [752.405304ms]
May 23 19:36:01.545: INFO: Created: latency-svc-8t2x7
May 23 19:36:01.581: INFO: Got endpoints: latency-svc-8944x [747.026235ms]
May 23 19:36:01.590: INFO: Created: latency-svc-8fcmg
May 23 19:36:01.633: INFO: Got endpoints: latency-svc-9l9pc [750.739447ms]
May 23 19:36:01.644: INFO: Created: latency-svc-8zt57
May 23 19:36:01.681: INFO: Got endpoints: latency-svc-k264p [750.11555ms]
May 23 19:36:01.690: INFO: Created: latency-svc-k4h5l
May 23 19:36:01.732: INFO: Got endpoints: latency-svc-bdvgk [750.21397ms]
May 23 19:36:01.738: INFO: Created: latency-svc-p7xhq
May 23 19:36:01.782: INFO: Got endpoints: latency-svc-dk5g6 [750.600055ms]
May 23 19:36:01.791: INFO: Created: latency-svc-v96gt
May 23 19:36:01.832: INFO: Got endpoints: latency-svc-gnxgx [747.479613ms]
May 23 19:36:01.842: INFO: Created: latency-svc-84x9m
May 23 19:36:01.884: INFO: Got endpoints: latency-svc-jwpb2 [752.665137ms]
May 23 19:36:01.892: INFO: Created: latency-svc-28gjm
May 23 19:36:01.931: INFO: Got endpoints: latency-svc-p6xq6 [749.389497ms]
May 23 19:36:01.941: INFO: Created: latency-svc-lvt6v
May 23 19:36:01.982: INFO: Got endpoints: latency-svc-t8stl [749.474094ms]
May 23 19:36:01.993: INFO: Created: latency-svc-vplvg
May 23 19:36:02.031: INFO: Got endpoints: latency-svc-n29ls [744.31952ms]
May 23 19:36:02.054: INFO: Created: latency-svc-n2qgn
May 23 19:36:02.086: INFO: Got endpoints: latency-svc-2pl8q [754.553278ms]
May 23 19:36:02.094: INFO: Created: latency-svc-4qv96
May 23 19:36:02.132: INFO: Got endpoints: latency-svc-8mhb8 [750.275587ms]
May 23 19:36:02.144: INFO: Created: latency-svc-lcjvb
May 23 19:36:02.181: INFO: Got endpoints: latency-svc-h7r84 [750.094194ms]
May 23 19:36:02.190: INFO: Created: latency-svc-m57w6
May 23 19:36:02.232: INFO: Got endpoints: latency-svc-7wjbc [750.024843ms]
May 23 19:36:02.240: INFO: Created: latency-svc-kmfbm
May 23 19:36:02.284: INFO: Got endpoints: latency-svc-8t2x7 [749.99551ms]
May 23 19:36:02.293: INFO: Created: latency-svc-89pxz
May 23 19:36:02.332: INFO: Got endpoints: latency-svc-8fcmg [750.765084ms]
May 23 19:36:02.344: INFO: Created: latency-svc-v8pbg
May 23 19:36:02.381: INFO: Got endpoints: latency-svc-8zt57 [748.044419ms]
May 23 19:36:02.391: INFO: Created: latency-svc-kd2mk
May 23 19:36:02.433: INFO: Got endpoints: latency-svc-k4h5l [751.852893ms]
May 23 19:36:02.442: INFO: Created: latency-svc-cdbn7
May 23 19:36:02.482: INFO: Got endpoints: latency-svc-p7xhq [750.629077ms]
May 23 19:36:02.492: INFO: Created: latency-svc-hv85v
May 23 19:36:02.533: INFO: Got endpoints: latency-svc-v96gt [751.016487ms]
May 23 19:36:02.538: INFO: Created: latency-svc-wlk9r
May 23 19:36:02.583: INFO: Got endpoints: latency-svc-84x9m [750.853982ms]
May 23 19:36:02.594: INFO: Created: latency-svc-nkk5j
May 23 19:36:02.638: INFO: Got endpoints: latency-svc-28gjm [753.921389ms]
May 23 19:36:02.650: INFO: Created: latency-svc-g5w9c
May 23 19:36:02.683: INFO: Got endpoints: latency-svc-lvt6v [751.653596ms]
May 23 19:36:02.693: INFO: Created: latency-svc-q4zrh
May 23 19:36:02.731: INFO: Got endpoints: latency-svc-vplvg [747.745239ms]
May 23 19:36:02.739: INFO: Created: latency-svc-f279w
May 23 19:36:02.786: INFO: Got endpoints: latency-svc-n2qgn [754.912374ms]
May 23 19:36:02.794: INFO: Created: latency-svc-d7bp5
May 23 19:36:02.832: INFO: Got endpoints: latency-svc-4qv96 [746.338288ms]
May 23 19:36:02.841: INFO: Created: latency-svc-tnnrq
May 23 19:36:02.882: INFO: Got endpoints: latency-svc-lcjvb [749.591911ms]
May 23 19:36:02.893: INFO: Created: latency-svc-26xjz
May 23 19:36:02.931: INFO: Got endpoints: latency-svc-m57w6 [749.392355ms]
May 23 19:36:02.944: INFO: Created: latency-svc-gkcn8
May 23 19:36:02.982: INFO: Got endpoints: latency-svc-kmfbm [749.580298ms]
May 23 19:36:02.992: INFO: Created: latency-svc-6v5qj
May 23 19:36:03.038: INFO: Got endpoints: latency-svc-89pxz [753.494646ms]
May 23 19:36:03.053: INFO: Created: latency-svc-rsvqb
May 23 19:36:03.081: INFO: Got endpoints: latency-svc-v8pbg [747.505786ms]
May 23 19:36:03.090: INFO: Created: latency-svc-n2qjz
May 23 19:36:03.133: INFO: Got endpoints: latency-svc-kd2mk [751.611213ms]
May 23 19:36:03.144: INFO: Created: latency-svc-cvhx7
May 23 19:36:03.181: INFO: Got endpoints: latency-svc-cdbn7 [747.415713ms]
May 23 19:36:03.189: INFO: Created: latency-svc-ts6hf
May 23 19:36:03.232: INFO: Got endpoints: latency-svc-hv85v [749.743477ms]
May 23 19:36:03.241: INFO: Created: latency-svc-qhjst
May 23 19:36:03.284: INFO: Got endpoints: latency-svc-wlk9r [751.462719ms]
May 23 19:36:03.299: INFO: Created: latency-svc-xnb9z
May 23 19:36:03.333: INFO: Got endpoints: latency-svc-nkk5j [749.857313ms]
May 23 19:36:03.342: INFO: Created: latency-svc-gvwqv
May 23 19:36:03.381: INFO: Got endpoints: latency-svc-g5w9c [743.155575ms]
May 23 19:36:03.392: INFO: Created: latency-svc-5t7vd
May 23 19:36:03.432: INFO: Got endpoints: latency-svc-q4zrh [748.843977ms]
May 23 19:36:03.442: INFO: Created: latency-svc-pqvwx
May 23 19:36:03.482: INFO: Got endpoints: latency-svc-f279w [750.162895ms]
May 23 19:36:03.494: INFO: Created: latency-svc-nxhtb
May 23 19:36:03.532: INFO: Got endpoints: latency-svc-d7bp5 [745.731603ms]
May 23 19:36:03.544: INFO: Created: latency-svc-swv4q
May 23 19:36:03.582: INFO: Got endpoints: latency-svc-tnnrq [749.984168ms]
May 23 19:36:03.595: INFO: Created: latency-svc-4slq2
May 23 19:36:03.634: INFO: Got endpoints: latency-svc-26xjz [751.695676ms]
May 23 19:36:03.642: INFO: Created: latency-svc-xw4d5
May 23 19:36:03.681: INFO: Got endpoints: latency-svc-gkcn8 [749.94342ms]
May 23 19:36:03.729: INFO: Created: latency-svc-989tj
May 23 19:36:03.731: INFO: Got endpoints: latency-svc-6v5qj [748.801627ms]
May 23 19:36:03.738: INFO: Created: latency-svc-p926l
May 23 19:36:03.781: INFO: Got endpoints: latency-svc-rsvqb [743.269146ms]
May 23 19:36:03.789: INFO: Created: latency-svc-xb5q4
May 23 19:36:03.831: INFO: Got endpoints: latency-svc-n2qjz [750.138449ms]
May 23 19:36:03.841: INFO: Created: latency-svc-42tj9
May 23 19:36:03.882: INFO: Got endpoints: latency-svc-cvhx7 [748.650521ms]
May 23 19:36:03.933: INFO: Got endpoints: latency-svc-ts6hf [752.550069ms]
May 23 19:36:03.984: INFO: Got endpoints: latency-svc-qhjst [751.906567ms]
May 23 19:36:04.032: INFO: Got endpoints: latency-svc-xnb9z [744.973822ms]
May 23 19:36:04.081: INFO: Got endpoints: latency-svc-gvwqv [747.672984ms]
May 23 19:36:04.131: INFO: Got endpoints: latency-svc-5t7vd [749.813346ms]
May 23 19:36:04.181: INFO: Got endpoints: latency-svc-pqvwx [749.23091ms]
May 23 19:36:04.232: INFO: Got endpoints: latency-svc-nxhtb [750.348776ms]
May 23 19:36:04.281: INFO: Got endpoints: latency-svc-swv4q [749.543834ms]
May 23 19:36:04.336: INFO: Got endpoints: latency-svc-4slq2 [753.206332ms]
May 23 19:36:04.381: INFO: Got endpoints: latency-svc-xw4d5 [747.587075ms]
May 23 19:36:04.432: INFO: Got endpoints: latency-svc-989tj [750.635596ms]
May 23 19:36:04.482: INFO: Got endpoints: latency-svc-p926l [751.341309ms]
May 23 19:36:04.535: INFO: Got endpoints: latency-svc-xb5q4 [753.364841ms]
May 23 19:36:04.582: INFO: Got endpoints: latency-svc-42tj9 [750.153095ms]
May 23 19:36:04.582: INFO: Latencies: [48.11829ms 90.793029ms 103.739758ms 107.779226ms 120.656227ms 135.18041ms 145.61643ms 151.181384ms 159.13256ms 166.248797ms 179.013366ms 179.253596ms 182.903072ms 184.466202ms 185.599857ms 188.643299ms 190.662062ms 191.623885ms 191.690191ms 193.902747ms 196.312422ms 198.538983ms 201.728657ms 203.973148ms 204.498112ms 206.758633ms 206.868688ms 208.761098ms 208.914494ms 209.230083ms 211.069175ms 211.404403ms 211.785128ms 212.985302ms 213.753005ms 213.902035ms 215.402046ms 217.60463ms 221.521956ms 225.605306ms 238.250444ms 246.534215ms 307.005466ms 313.486484ms 398.143559ms 411.373856ms 420.223478ms 462.584557ms 507.943299ms 535.964783ms 576.2581ms 638.60562ms 648.00904ms 668.35186ms 685.682204ms 687.936114ms 697.759712ms 710.688905ms 716.432932ms 721.167649ms 721.876893ms 726.625134ms 730.622662ms 730.701487ms 732.542913ms 734.831726ms 739.872847ms 740.489214ms 742.408034ms 742.629908ms 743.155575ms 743.269146ms 743.619878ms 744.31952ms 744.973822ms 745.581661ms 745.731603ms 745.785513ms 745.95444ms 746.002071ms 746.338288ms 746.660132ms 746.877536ms 746.932692ms 747.026235ms 747.027962ms 747.214143ms 747.341763ms 747.366476ms 747.415713ms 747.479613ms 747.505786ms 747.587075ms 747.672984ms 747.745239ms 747.808994ms 747.837257ms 747.980955ms 748.044419ms 748.120523ms 748.175357ms 748.241381ms 748.42052ms 748.533027ms 748.546869ms 748.650521ms 748.793335ms 748.801627ms 748.843393ms 748.843977ms 748.868298ms 748.890351ms 748.902526ms 749.061864ms 749.107239ms 749.11622ms 749.164078ms 749.23091ms 749.34864ms 749.389497ms 749.392355ms 749.474094ms 749.543834ms 749.580298ms 749.591911ms 749.63735ms 749.649767ms 749.73412ms 749.743477ms 749.787725ms 749.799268ms 749.813346ms 749.857313ms 749.882397ms 749.895111ms 749.897944ms 749.94342ms 749.984168ms 749.99551ms 750.024843ms 750.092859ms 750.094194ms 750.11555ms 750.134703ms 750.138449ms 750.153095ms 750.162895ms 750.21397ms 750.275587ms 750.338488ms 750.348776ms 750.395705ms 750.410157ms 750.549158ms 750.600055ms 750.629077ms 750.635596ms 750.739447ms 750.765084ms 750.803434ms 750.853982ms 751.016487ms 751.056224ms 751.264096ms 751.341309ms 751.364199ms 751.462719ms 751.493312ms 751.55013ms 751.611213ms 751.653596ms 751.695676ms 751.828908ms 751.831078ms 751.852893ms 751.895655ms 751.906567ms 752.066106ms 752.261224ms 752.337813ms 752.405304ms 752.472403ms 752.550069ms 752.665137ms 753.027951ms 753.206332ms 753.240558ms 753.25624ms 753.293611ms 753.364841ms 753.423447ms 753.494646ms 753.921389ms 754.553278ms 754.912374ms 756.696709ms 766.603988ms 766.755653ms 783.474824ms 795.167408ms]
May 23 19:36:04.582: INFO: 50 %ile: 748.175357ms
May 23 19:36:04.583: INFO: 90 %ile: 752.405304ms
May 23 19:36:04.583: INFO: 99 %ile: 783.474824ms
May 23 19:36:04.583: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:36:04.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6776" for this suite.
May 23 19:36:26.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:36:26.675: INFO: namespace svc-latency-6776 deletion completed in 22.088253682s

• [SLOW TEST:33.859 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:36:26.676: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:36:26.751: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-4659" to be "success or failure"
May 23 19:36:26.754: INFO: Pod "downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.811111ms
May 23 19:36:28.758: INFO: Pod "downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006402636s
May 23 19:36:30.765: INFO: Pod "downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013345061s
STEP: Saw pod success
May 23 19:36:30.765: INFO: Pod "downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:36:30.771: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:36:30.809: INFO: Waiting for pod downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:36:30.813: INFO: Pod downwardapi-volume-0e2478d0-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:36:30.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4659" for this suite.
May 23 19:36:36.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:36:36.879: INFO: namespace downward-api-4659 deletion completed in 6.06336487s

• [SLOW TEST:10.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:36:36.880: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0523 19:37:16.930441      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 19:37:16.930: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:37:16.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-98" for this suite.
May 23 19:37:22.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:37:23.010: INFO: namespace gc-98 deletion completed in 6.078003737s

• [SLOW TEST:46.130 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:37:23.010: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:37:26.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4932" for this suite.
May 23 19:37:48.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:37:48.172: INFO: namespace replication-controller-4932 deletion completed in 22.078780803s

• [SLOW TEST:25.162 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:37:48.173: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-3eb094fa-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 19:37:48.203: INFO: Waiting up to 5m0s for pod "pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe" in namespace "secrets-6787" to be "success or failure"
May 23 19:37:48.205: INFO: Pod "pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.436885ms
May 23 19:37:50.263: INFO: Pod "pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059318616s
STEP: Saw pod success
May 23 19:37:50.263: INFO: Pod "pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:37:50.264: INFO: Trying to get logs from node worker-1 pod pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 19:37:50.279: INFO: Waiting for pod pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:37:50.280: INFO: Pod pod-secrets-3eb0eece-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:37:50.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6787" for this suite.
May 23 19:37:56.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:37:56.359: INFO: namespace secrets-6787 deletion completed in 6.077101605s

• [SLOW TEST:8.186 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:37:56.359: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-4584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4584 to expose endpoints map[]
May 23 19:37:56.392: INFO: successfully validated that service endpoint-test2 in namespace services-4584 exposes endpoints map[] (6.25018ms elapsed)
STEP: Creating pod pod1 in namespace services-4584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4584 to expose endpoints map[pod1:[80]]
May 23 19:37:58.423: INFO: successfully validated that service endpoint-test2 in namespace services-4584 exposes endpoints map[pod1:[80]] (2.021865312s elapsed)
STEP: Creating pod pod2 in namespace services-4584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4584 to expose endpoints map[pod1:[80] pod2:[80]]
May 23 19:38:00.456: INFO: successfully validated that service endpoint-test2 in namespace services-4584 exposes endpoints map[pod1:[80] pod2:[80]] (2.026322075s elapsed)
STEP: Deleting pod pod1 in namespace services-4584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4584 to expose endpoints map[pod2:[80]]
May 23 19:38:01.487: INFO: successfully validated that service endpoint-test2 in namespace services-4584 exposes endpoints map[pod2:[80]] (1.027921979s elapsed)
STEP: Deleting pod pod2 in namespace services-4584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4584 to expose endpoints map[]
May 23 19:38:01.505: INFO: successfully validated that service endpoint-test2 in namespace services-4584 exposes endpoints map[] (5.779894ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:38:01.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4584" for this suite.
May 23 19:38:07.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:07.636: INFO: namespace services-4584 deletion completed in 6.109918234s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:11.277 seconds]
[sig-network] Services
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:38:07.637: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:38:07.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe" in namespace "projected-7587" to be "success or failure"
May 23 19:38:07.670: INFO: Pod "downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.659076ms
May 23 19:38:09.681: INFO: Pod "downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016654736s
May 23 19:38:11.696: INFO: Pod "downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03167957s
STEP: Saw pod success
May 23 19:38:11.696: INFO: Pod "downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:38:11.701: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:38:11.735: INFO: Waiting for pod downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:38:11.737: INFO: Pod downwardapi-volume-4a4ab0df-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:38:11.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7587" for this suite.
May 23 19:38:17.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:17.808: INFO: namespace projected-7587 deletion completed in 6.068296114s

• [SLOW TEST:10.171 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:38:17.809: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:38:23.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-136" for this suite.
May 23 19:38:29.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:29.977: INFO: namespace namespaces-136 deletion completed in 6.05942139s
STEP: Destroying namespace "nsdeletetest-3861" for this suite.
May 23 19:38:29.979: INFO: Namespace nsdeletetest-3861 was already deleted
STEP: Destroying namespace "nsdeletetest-1378" for this suite.
May 23 19:38:35.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:36.057: INFO: namespace nsdeletetest-1378 deletion completed in 6.077801444s

• [SLOW TEST:18.248 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:38:36.057: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-5b3afea2-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 19:38:36.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe" in namespace "configmap-6721" to be "success or failure"
May 23 19:38:36.094: INFO: Pod "pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349926ms
May 23 19:38:38.097: INFO: Pod "pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006547776s
May 23 19:38:40.099: INFO: Pod "pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009343683s
STEP: Saw pod success
May 23 19:38:40.099: INFO: Pod "pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:38:40.102: INFO: Trying to get logs from node worker-1 pod pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 19:38:40.123: INFO: Waiting for pod pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:38:40.128: INFO: Pod pod-configmaps-5b3b644f-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:38:40.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6721" for this suite.
May 23 19:38:46.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:46.215: INFO: namespace configmap-6721 deletion completed in 6.085326332s

• [SLOW TEST:10.158 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:38:46.217: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 23 19:38:46.236: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 23 19:38:46.240: INFO: Waiting for terminating namespaces to be deleted...
May 23 19:38:46.242: INFO: 
Logging pods the kubelet thinks is on node controlplane-1 before test
May 23 19:38:46.261: INFO: kube-scheduler-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 19:38:46.261: INFO: kube-proxy-kcbp9 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.261: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 19:38:46.261: INFO: weave-net-kt8s6 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.261: INFO: 	Container weave ready: true, restart count 0
May 23 19:38:46.261: INFO: 	Container weave-npc ready: true, restart count 0
May 23 19:38:46.261: INFO: coredns-fb8b8dccf-j6x4t from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.261: INFO: 	Container coredns ready: true, restart count 0
May 23 19:38:46.261: INFO: kube-apiserver-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 19:38:46.261: INFO: kube-controller-manager-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 19:38:46.261: INFO: etcd-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 19:38:46.261: INFO: coredns-fb8b8dccf-t24wc from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.261: INFO: 	Container coredns ready: true, restart count 0
May 23 19:38:46.261: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-ghmvv from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 19:38:46.261: INFO: 	Container systemd-logs ready: true, restart count 0
May 23 19:38:46.261: INFO: 
Logging pods the kubelet thinks is on node worker-1 before test
May 23 19:38:46.265: INFO: kube-proxy-lpxwl from kube-system started at 2019-05-23 19:25:04 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.265: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 19:38:46.265: INFO: weave-net-t292l from kube-system started at 2019-05-23 19:25:04 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.265: INFO: 	Container weave ready: true, restart count 0
May 23 19:38:46.265: INFO: 	Container weave-npc ready: true, restart count 0
May 23 19:38:46.265: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-23 19:26:01 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.265: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 23 19:38:46.265: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-wpj4k from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.265: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 19:38:46.265: INFO: 	Container systemd-logs ready: true, restart count 0
May 23 19:38:46.265: INFO: 
Logging pods the kubelet thinks is on node worker-2 before test
May 23 19:38:46.273: INFO: kube-proxy-5fwlj from kube-system started at 2019-05-23 19:25:19 +0000 UTC (1 container statuses recorded)
May 23 19:38:46.273: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 19:38:46.273: INFO: weave-net-lp9js from kube-system started at 2019-05-23 19:25:19 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.273: INFO: 	Container weave ready: true, restart count 1
May 23 19:38:46.273: INFO: 	Container weave-npc ready: true, restart count 0
May 23 19:38:46.273: INFO: sonobuoy-e2e-job-67a3a42f03d24ef6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.273: INFO: 	Container e2e ready: true, restart count 0
May 23 19:38:46.273: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 19:38:46.273: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-b25f6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 19:38:46.273: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 19:38:46.273: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a1671e7c753842], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:38:47.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8755" for this suite.
May 23 19:38:53.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:38:53.369: INFO: namespace sched-pred-8755 deletion completed in 6.076703742s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.152 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:38:53.370: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:38:59.429: INFO: Waiting up to 5m0s for pod "client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe" in namespace "pods-4830" to be "success or failure"
May 23 19:38:59.436: INFO: Pod "client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.421653ms
May 23 19:39:01.442: INFO: Pod "client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01281139s
May 23 19:39:03.448: INFO: Pod "client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018968656s
STEP: Saw pod success
May 23 19:39:03.448: INFO: Pod "client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:39:03.453: INFO: Trying to get logs from node worker-1 pod client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe container env3cont: <nil>
STEP: delete the pod
May 23 19:39:03.500: INFO: Waiting for pod client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:39:03.503: INFO: Pod client-envvars-6924886b-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:39:03.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4830" for this suite.
May 23 19:39:41.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:39:41.600: INFO: namespace pods-4830 deletion completed in 38.09484692s

• [SLOW TEST:48.230 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:39:41.600: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-824badec-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 19:39:41.628: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe" in namespace "projected-5255" to be "success or failure"
May 23 19:39:41.633: INFO: Pod "pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.467131ms
May 23 19:39:43.639: INFO: Pod "pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011026686s
STEP: Saw pod success
May 23 19:39:43.639: INFO: Pod "pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:39:43.645: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe container projected-secret-volume-test: <nil>
STEP: delete the pod
May 23 19:39:43.677: INFO: Waiting for pod pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:39:43.679: INFO: Pod pod-projected-secrets-824c045c-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:39:43.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5255" for this suite.
May 23 19:39:49.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:39:49.736: INFO: namespace projected-5255 deletion completed in 6.054755178s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:39:49.736: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0523 19:39:50.821264      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 19:39:50.821: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:39:50.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6859" for this suite.
May 23 19:39:56.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:39:56.894: INFO: namespace gc-6859 deletion completed in 6.066941937s

• [SLOW TEST:7.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:39:56.894: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:39:56.916: INFO: Creating deployment "nginx-deployment"
May 23 19:39:56.919: INFO: Waiting for observed generation 1
May 23 19:39:58.936: INFO: Waiting for all required pods to come up
May 23 19:39:58.944: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 23 19:40:00.977: INFO: Waiting for deployment "nginx-deployment" to complete
May 23 19:40:00.988: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 23 19:40:00.995: INFO: Updating deployment nginx-deployment
May 23 19:40:00.995: INFO: Waiting for observed generation 2
May 23 19:40:03.011: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 23 19:40:03.014: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 23 19:40:03.016: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 23 19:40:03.024: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 23 19:40:03.024: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 23 19:40:03.026: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 23 19:40:03.034: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 23 19:40:03.034: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 23 19:40:03.040: INFO: Updating deployment nginx-deployment
May 23 19:40:03.041: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 23 19:40:03.057: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 23 19:40:03.078: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 23 19:40:03.128: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7338,SelfLink:/apis/apps/v1/namespaces/deployment-7338/deployments/nginx-deployment,UID:8ba69ae3-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4654,Generation:3,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-05-23 19:40:01 +0000 UTC 2019-05-23 19:39:57 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-05-23 19:40:03 +0000 UTC 2019-05-23 19:40:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

May 23 19:40:03.173: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-7338,SelfLink:/apis/apps/v1/namespaces/deployment-7338/replicasets/nginx-deployment-5f9595f595,UID:8e1562c1-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4639,Generation:3,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8ba69ae3-7d92-11e9-a2d7-080027c2be11 0xc0030a27b7 0xc0030a27b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 19:40:03.174: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 23 19:40:03.174: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-7338,SelfLink:/apis/apps/v1/namespaces/deployment-7338/replicasets/nginx-deployment-6f478d8d8,UID:8ba6e21b-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4635,Generation:3,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8ba69ae3-7d92-11e9-a2d7-080027c2be11 0xc0030a2887 0xc0030a2888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 23 19:40:03.218: INFO: Pod "nginx-deployment-5f9595f595-2hjw4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2hjw4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-2hjw4,UID:8f51ebdc-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4667,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3160 0xc0030a3161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a31e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-4rpm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4rpm8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-4rpm8,UID:8e177282-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4625,Generation:0,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3280 0xc0030a3281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.11,PodIP:10.32.0.5,StartTime:2019-05-23 19:40:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-8zd77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8zd77,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-8zd77,UID:8f5f57e2-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4674,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3410 0xc0030a3411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a34a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-cn477" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-cn477,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-cn477,UID:8e176674-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4578,Generation:0,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3507 0xc0030a3508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a35a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:,StartTime:2019-05-23 19:40:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-gkmjl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-gkmjl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-gkmjl,UID:8e200e20-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4628,Generation:0,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3670 0xc0030a3671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a36f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.6,StartTime:2019-05-23 19:40:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-h7n4x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-h7n4x,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-h7n4x,UID:8f5f5cf7-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4675,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3800 0xc0030a3801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-km6rb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-km6rb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-km6rb,UID:8f581fec-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4672,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a38f7 0xc0030a38f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-mjpbj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mjpbj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-mjpbj,UID:8e23e295-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4601,Generation:0,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3a10 0xc0030a3a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:,StartTime:2019-05-23 19:40:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-mwzhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mwzhc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-mwzhc,UID:8e160edb-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4632,Generation:0,CreationTimestamp:2019-05-23 19:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3b80 0xc0030a3b81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:10.40.0.4,StartTime:2019-05-23 19:40:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-s2bpl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-s2bpl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-s2bpl,UID:8f5f5245-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4673,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3d10 0xc0030a3d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-wwmv4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wwmv4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-wwmv4,UID:8f5f23b9-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4671,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3e07 0xc0030a3e08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-5f9595f595-wz9lx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wz9lx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-5f9595f595-wz9lx,UID:8f582817-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4676,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 8e1562c1-7d92-11e9-a2d7-080027c2be11 0xc0030a3ef7 0xc0030a3ef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030a3f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030a3f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.219: INFO: Pod "nginx-deployment-6f478d8d8-5vtfw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-5vtfw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-5vtfw,UID:8f5848ab-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4677,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2010 0xc0028c2011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c20a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.220: INFO: Pod "nginx-deployment-6f478d8d8-68cp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-68cp8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-68cp8,UID:8f502698-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4649,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2120 0xc0028c2121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c21b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.220: INFO: Pod "nginx-deployment-6f478d8d8-6j6rd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6j6rd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-6j6rd,UID:8f523f0f-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4666,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2230 0xc0028c2231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c22a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c22c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.220: INFO: Pod "nginx-deployment-6f478d8d8-6q74b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6q74b,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-6q74b,UID:8bae3952-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4532,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2340 0xc0028c2341}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c23b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c23d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.4,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ebd664740651acbb6038ae70b8dcc11ed5359f5b53cac3d185de2f27e420f9b2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.220: INFO: Pod "nginx-deployment-6f478d8d8-8hngk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8hngk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-8hngk,UID:8f522d3c-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4656,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c24a0 0xc0028c24a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-8xkql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8xkql,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-8xkql,UID:8f585971-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4681,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c25b0 0xc0028c25b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-bmfrb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bmfrb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-bmfrb,UID:8ba78b86-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4525,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c26c0 0xc0028c26c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:10.40.0.3,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://32c4aca7d116c278d0f6fa7368013e3f5d7393486bf3519797807da95c4b8b3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-bw6cl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bw6cl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-bw6cl,UID:8f58544a-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4680,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2820 0xc0028c2821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c28b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-ctwnf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ctwnf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-ctwnf,UID:8ba86aff-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4529,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2930 0xc0028c2931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c29a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c29c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.2,StartTime:2019-05-23 19:39:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c4a9483efede65292304a4f93d3636b3728e4c59a27e59ff9c5cb48308c1fe4d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-hhdqv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hhdqv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-hhdqv,UID:8bab308b-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4520,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2a90 0xc0028c2a91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.11,PodIP:10.32.0.4,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://263e00dedd4cfa505e042f9355aeeba4c7913328a27a63cbf5d0ff4aaddc4198}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-hr47m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hr47m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-hr47m,UID:8f4e6a62-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4658,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2bf0 0xc0028c2bf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:,StartTime:2019-05-23 19:40:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-klw5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-klw5s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-klw5s,UID:8f524da3-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4657,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2d40 0xc0028c2d41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.222: INFO: Pod "nginx-deployment-6f478d8d8-l8cpl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-l8cpl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-l8cpl,UID:8bae2b00-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4535,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2e50 0xc0028c2e51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c2ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c2ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.5,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a1e197a9a791cb76d58fbbfd594edf7fc71c70d60729bbaf3d72200bcb6d61e3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-mgl5x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mgl5x,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-mgl5x,UID:8bae4087-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4526,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c2fb0 0xc0028c2fb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c3020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.11,PodIP:10.32.0.6,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4cc28ce6d820e988817d5938c91fe6d756e3564e4d13fed1234cc1b80bf7f5ca}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-mgr2p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mgr2p,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-mgr2p,UID:8bab35c0-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4522,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c3110 0xc0028c3111}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c3180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c31a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:10.40.0.5,StartTime:2019-05-23 19:39:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://dd16449ec2c721ab1b753b4445e2415ce8992c7dd1c28fec6465a281c800689e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-pl9bj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pl9bj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-pl9bj,UID:8f585172-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4679,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c3270 0xc0028c3271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c32e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-t8f68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-t8f68,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-t8f68,UID:8f500be4-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4670,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c3380 0xc0028c3381}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:controlplane-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c33f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.11,PodIP:,StartTime:2019-05-23 19:40:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-vckhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vckhg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-vckhg,UID:8f51914d-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4655,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c34d0 0xc0028c34d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c3540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-x69w4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x69w4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-x69w4,UID:8f584d75-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4678,Generation:0,CreationTimestamp:2019-05-23 19:40:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c35e0 0xc0028c35e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c3650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:40:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 23 19:40:03.223: INFO: Pod "nginx-deployment-6f478d8d8-xzbdv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xzbdv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7338,SelfLink:/api/v1/namespaces/deployment-7338/pods/nginx-deployment-6f478d8d8-xzbdv,UID:8bab1605-7d92-11e9-a2d7-080027c2be11,ResourceVersion:4538,Generation:0,CreationTimestamp:2019-05-23 19:39:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8ba6e21b-7d92-11e9-a2d7-080027c2be11 0xc0028c36f0 0xc0028c36f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d4s2l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d4s2l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d4s2l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c3760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c3780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:39:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.3,StartTime:2019-05-23 19:39:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-23 19:39:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://33d2f767bbe6a1fa570183420c8dbafb99d48a4764634d8a3bc19d1158c392b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:40:03.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7338" for this suite.
May 23 19:40:11.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:40:11.378: INFO: namespace deployment-7338 deletion completed in 8.119818571s

• [SLOW TEST:14.484 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:40:11.379: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
May 23 19:40:11.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 cluster-info'
May 23 19:40:12.106: INFO: stderr: ""
May 23 19:40:12.106: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:40:12.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4771" for this suite.
May 23 19:40:18.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:40:18.201: INFO: namespace kubectl-4771 deletion completed in 6.077962611s

• [SLOW TEST:6.822 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:40:18.201: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 23 19:40:18.228: INFO: Waiting up to 5m0s for pod "pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-6279" to be "success or failure"
May 23 19:40:18.233: INFO: Pod "pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.117004ms
May 23 19:40:20.239: INFO: Pod "pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011078508s
STEP: Saw pod success
May 23 19:40:20.240: INFO: Pod "pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:40:20.244: INFO: Trying to get logs from node worker-1 pod pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:40:20.273: INFO: Waiting for pod pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:40:20.277: INFO: Pod pod-981ce2c3-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:40:20.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6279" for this suite.
May 23 19:40:26.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:40:26.369: INFO: namespace emptydir-6279 deletion completed in 6.088757069s

• [SLOW TEST:8.168 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:40:26.369: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 23 19:40:30.457: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 23 19:40:30.462: INFO: Pod pod-with-poststart-http-hook still exists
May 23 19:40:32.462: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 23 19:40:32.465: INFO: Pod pod-with-poststart-http-hook still exists
May 23 19:40:34.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 23 19:40:34.466: INFO: Pod pod-with-poststart-http-hook still exists
May 23 19:40:36.462: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 23 19:40:36.464: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:40:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6841" for this suite.
May 23 19:40:58.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:40:58.569: INFO: namespace container-lifecycle-hook-6841 deletion completed in 22.103444913s

• [SLOW TEST:32.200 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:40:58.571: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:41:00.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1316" for this suite.
May 23 19:41:50.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:41:50.729: INFO: namespace kubelet-test-1316 deletion completed in 50.097508233s

• [SLOW TEST:52.159 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:41:50.730: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-cf42ecec-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 19:41:50.754: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe" in namespace "configmap-9825" to be "success or failure"
May 23 19:41:50.762: INFO: Pod "pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.840664ms
May 23 19:41:52.769: INFO: Pod "pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014613062s
May 23 19:41:54.775: INFO: Pod "pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020608806s
STEP: Saw pod success
May 23 19:41:54.775: INFO: Pod "pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:41:54.780: INFO: Trying to get logs from node worker-1 pod pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 19:41:54.815: INFO: Waiting for pod pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:41:54.821: INFO: Pod pod-configmaps-cf433904-7d92-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:41:54.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9825" for this suite.
May 23 19:42:00.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:42:00.908: INFO: namespace configmap-9825 deletion completed in 6.081512825s

• [SLOW TEST:10.178 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:42:00.908: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-d554b731-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating configMap with name cm-test-opt-upd-d554b756-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d554b731-7d92-11e9-b22f-2a454b6ec3fe
STEP: Updating configmap cm-test-opt-upd-d554b756-7d92-11e9-b22f-2a454b6ec3fe
STEP: Creating configMap with name cm-test-opt-create-d554b761-7d92-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:43:09.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7595" for this suite.
May 23 19:43:31.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:43:31.709: INFO: namespace projected-7595 deletion completed in 22.110088748s

• [SLOW TEST:90.801 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:43:31.709: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:43:51.833: INFO: Container started at 2019-05-23 19:43:33 +0000 UTC, pod became ready at 2019-05-23 19:43:51 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:43:51.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9358" for this suite.
May 23 19:44:13.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:44:13.938: INFO: namespace container-probe-9358 deletion completed in 22.097473902s

• [SLOW TEST:42.229 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:44:13.939: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
May 23 19:44:13.962: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 23 19:44:13.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.115: INFO: stderr: ""
May 23 19:44:14.115: INFO: stdout: "service/redis-slave created\n"
May 23 19:44:14.115: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 23 19:44:14.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.239: INFO: stderr: ""
May 23 19:44:14.239: INFO: stdout: "service/redis-master created\n"
May 23 19:44:14.239: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 23 19:44:14.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.359: INFO: stderr: ""
May 23 19:44:14.359: INFO: stdout: "service/frontend created\n"
May 23 19:44:14.359: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 23 19:44:14.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.471: INFO: stderr: ""
May 23 19:44:14.471: INFO: stdout: "deployment.apps/frontend created\n"
May 23 19:44:14.471: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 23 19:44:14.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.591: INFO: stderr: ""
May 23 19:44:14.591: INFO: stdout: "deployment.apps/redis-master created\n"
May 23 19:44:14.591: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 23 19:44:14.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6957'
May 23 19:44:14.709: INFO: stderr: ""
May 23 19:44:14.709: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May 23 19:44:14.709: INFO: Waiting for all frontend pods to be Running.
May 23 19:45:34.766: INFO: Waiting for frontend to serve content.
May 23 19:45:44.374: INFO: Trying to add a new entry to the guestbook.
May 23 19:45:44.404: INFO: Verifying that added entry can be retrieved.
May 23 19:45:44.424: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
May 23 19:45:49.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.576: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.576: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 23 19:45:49.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.658: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 23 19:45:49.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.737: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.737: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 23 19:45:49.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.804: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.804: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 23 19:45:49.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.858: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.858: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 23 19:45:49.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6957'
May 23 19:45:49.904: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:45:49.904: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:45:49.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6957" for this suite.
May 23 19:46:27.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:46:27.999: INFO: namespace kubectl-6957 deletion completed in 38.093491853s

• [SLOW TEST:134.061 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:46:28.001: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 23 19:46:32.646: INFO: Successfully updated pod "annotationupdate74932b3b-7d93-11e9-b22f-2a454b6ec3fe"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:46:34.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9930" for this suite.
May 23 19:46:56.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:46:56.734: INFO: namespace downward-api-9930 deletion completed in 22.065711112s

• [SLOW TEST:28.733 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:46:56.736: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
May 23 19:46:57.288: INFO: created pod pod-service-account-defaultsa
May 23 19:46:57.288: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 23 19:46:57.300: INFO: created pod pod-service-account-mountsa
May 23 19:46:57.300: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 23 19:46:57.305: INFO: created pod pod-service-account-nomountsa
May 23 19:46:57.306: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 23 19:46:57.316: INFO: created pod pod-service-account-defaultsa-mountspec
May 23 19:46:57.317: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 23 19:46:57.331: INFO: created pod pod-service-account-mountsa-mountspec
May 23 19:46:57.334: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 23 19:46:57.340: INFO: created pod pod-service-account-nomountsa-mountspec
May 23 19:46:57.340: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 23 19:46:57.345: INFO: created pod pod-service-account-defaultsa-nomountspec
May 23 19:46:57.345: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 23 19:46:57.357: INFO: created pod pod-service-account-mountsa-nomountspec
May 23 19:46:57.357: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 23 19:46:57.371: INFO: created pod pod-service-account-nomountsa-nomountspec
May 23 19:46:57.371: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:46:57.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3705" for this suite.
May 23 19:47:03.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:47:03.497: INFO: namespace svcaccounts-3705 deletion completed in 6.123055703s

• [SLOW TEST:6.762 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:47:03.497: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 23 19:47:08.564: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:47:09.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4011" for this suite.
May 23 19:47:31.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:47:31.689: INFO: namespace replicaset-4011 deletion completed in 22.096484733s

• [SLOW TEST:28.192 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:47:31.689: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 23 19:47:31.715: INFO: Waiting up to 5m0s for pod "pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-2319" to be "success or failure"
May 23 19:47:31.722: INFO: Pod "pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.860223ms
May 23 19:47:33.729: INFO: Pod "pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013656867s
May 23 19:47:35.736: INFO: Pod "pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021399031s
STEP: Saw pod success
May 23 19:47:35.736: INFO: Pod "pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:47:35.742: INFO: Trying to get logs from node worker-1 pod pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:47:35.776: INFO: Waiting for pod pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:47:35.778: INFO: Pod pod-9a7dab0f-7d93-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:47:35.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2319" for this suite.
May 23 19:47:41.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:47:41.861: INFO: namespace emptydir-2319 deletion completed in 6.079933171s

• [SLOW TEST:10.172 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:47:41.862: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:47:41.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-2997" to be "success or failure"
May 23 19:47:41.895: INFO: Pod "downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464883ms
May 23 19:47:43.902: INFO: Pod "downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011468533s
May 23 19:47:45.909: INFO: Pod "downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018178598s
STEP: Saw pod success
May 23 19:47:45.909: INFO: Pod "downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:47:45.915: INFO: Trying to get logs from node worker-2 pod downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:47:45.954: INFO: Waiting for pod downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:47:45.957: INFO: Pod downwardapi-volume-a08e07e3-7d93-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:47:45.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2997" for this suite.
May 23 19:47:51.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:47:52.032: INFO: namespace downward-api-2997 deletion completed in 6.071568255s

• [SLOW TEST:10.170 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:47:52.032: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:47:52.057: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 23 19:47:57.063: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 23 19:47:57.064: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 23 19:48:01.087: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2676,SelfLink:/apis/apps/v1/namespaces/deployment-2676/deployments/test-cleanup-deployment,UID:a9d82346-7d93-11e9-a2d7-080027c2be11,ResourceVersion:6296,Generation:1,CreationTimestamp:2019-05-23 19:47:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-23 19:47:57 +0000 UTC 2019-05-23 19:47:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-23 19:47:59 +0000 UTC 2019-05-23 19:47:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 23 19:48:01.089: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-2676,SelfLink:/apis/apps/v1/namespaces/deployment-2676/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:a9d9e560-7d93-11e9-a2d7-080027c2be11,ResourceVersion:6285,Generation:1,CreationTimestamp:2019-05-23 19:47:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment a9d82346-7d93-11e9-a2d7-080027c2be11 0xc0031ce967 0xc0031ce968}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 23 19:48:01.091: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-nw4gg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-nw4gg,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-2676,SelfLink:/api/v1/namespaces/deployment-2676/pods/test-cleanup-deployment-55cbfbc8f5-nw4gg,UID:a9da86fa-7d93-11e9-a2d7-080027c2be11,ResourceVersion:6284,Generation:0,CreationTimestamp:2019-05-23 19:47:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 a9d9e560-7d93-11e9-a2d7-080027c2be11 0xc0031ceef7 0xc0031ceef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6wl4j {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6wl4j,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6wl4j true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031cef70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031cef90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:47:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:47:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:47:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 19:47:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.2,StartTime:2019-05-23 19:47:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-23 19:47:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://2f594f9257dabd90a8672eaf2c7d3348de2cbcef6ed6f22d11d5da1e6588d116}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:48:01.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2676" for this suite.
May 23 19:48:07.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:48:07.208: INFO: namespace deployment-2676 deletion completed in 6.115358687s

• [SLOW TEST:15.176 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:48:07.209: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-afaa3122-7d93-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 19:48:07.242: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe" in namespace "projected-6060" to be "success or failure"
May 23 19:48:07.249: INFO: Pod "pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.766751ms
May 23 19:48:09.256: INFO: Pod "pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014091944s
May 23 19:48:11.274: INFO: Pod "pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032588735s
STEP: Saw pod success
May 23 19:48:11.275: INFO: Pod "pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:48:11.281: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 19:48:11.322: INFO: Waiting for pod pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:48:11.325: INFO: Pod pod-projected-configmaps-afaa85ca-7d93-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:48:11.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6060" for this suite.
May 23 19:48:17.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:48:17.415: INFO: namespace projected-6060 deletion completed in 6.085332539s

• [SLOW TEST:10.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:48:17.415: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:48:17.459: INFO: (0) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 22.121961ms)
May 23 19:48:17.464: INFO: (1) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 5.185932ms)
May 23 19:48:17.471: INFO: (2) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 7.329167ms)
May 23 19:48:17.479: INFO: (3) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.642723ms)
May 23 19:48:17.485: INFO: (4) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.30526ms)
May 23 19:48:17.491: INFO: (5) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 5.523346ms)
May 23 19:48:17.497: INFO: (6) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.117313ms)
May 23 19:48:17.503: INFO: (7) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 5.218947ms)
May 23 19:48:17.509: INFO: (8) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.157065ms)
May 23 19:48:17.516: INFO: (9) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 7.167714ms)
May 23 19:48:17.523: INFO: (10) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.03761ms)
May 23 19:48:17.529: INFO: (11) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 5.919559ms)
May 23 19:48:17.535: INFO: (12) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 5.693986ms)
May 23 19:48:17.541: INFO: (13) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 6.332407ms)
May 23 19:48:17.549: INFO: (14) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 7.228752ms)
May 23 19:48:17.553: INFO: (15) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 4.347371ms)
May 23 19:48:17.556: INFO: (16) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 2.813542ms)
May 23 19:48:17.559: INFO: (17) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 3.133257ms)
May 23 19:48:17.562: INFO: (18) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 2.643678ms)
May 23 19:48:17.565: INFO: (19) /api/v1/nodes/controlplane-1/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 2.434322ms)
[AfterEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:48:17.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6086" for this suite.
May 23 19:48:23.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:48:23.672: INFO: namespace proxy-6086 deletion completed in 6.104402582s

• [SLOW TEST:6.257 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:48:23.673: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:48:23.692: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:48:25.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7961" for this suite.
May 23 19:49:15.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:49:15.863: INFO: namespace pods-7961 deletion completed in 50.118370248s

• [SLOW TEST:52.190 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:49:15.863: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
May 23 19:49:15.888: INFO: Waiting up to 5m0s for pod "var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe" in namespace "var-expansion-7339" to be "success or failure"
May 23 19:49:15.892: INFO: Pod "var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.152734ms
May 23 19:49:17.899: INFO: Pod "var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011304656s
May 23 19:49:19.917: INFO: Pod "var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029265462s
STEP: Saw pod success
May 23 19:49:19.918: INFO: Pod "var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:49:19.923: INFO: Trying to get logs from node worker-1 pod var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 19:49:19.956: INFO: Waiting for pod var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:49:19.959: INFO: Pod var-expansion-d895380b-7d93-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:49:19.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7339" for this suite.
May 23 19:49:25.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:49:26.047: INFO: namespace var-expansion-7339 deletion completed in 6.084477768s

• [SLOW TEST:10.184 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:49:26.047: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2668
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 23 19:49:26.143: INFO: Found 0 stateful pods, waiting for 3
May 23 19:49:36.149: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:49:36.149: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:49:36.149: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:49:36.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-2668 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 19:49:36.320: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 19:49:36.320: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 19:49:36.320: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 23 19:49:46.363: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 23 19:49:56.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-2668 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 19:49:56.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 19:49:56.554: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 19:49:56.554: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 19:50:06.579: INFO: Waiting for StatefulSet statefulset-2668/ss2 to complete update
May 23 19:50:06.579: INFO: Waiting for Pod statefulset-2668/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:50:06.579: INFO: Waiting for Pod statefulset-2668/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:50:06.579: INFO: Waiting for Pod statefulset-2668/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:50:16.583: INFO: Waiting for StatefulSet statefulset-2668/ss2 to complete update
May 23 19:50:16.583: INFO: Waiting for Pod statefulset-2668/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:50:26.596: INFO: Waiting for StatefulSet statefulset-2668/ss2 to complete update
STEP: Rolling back to a previous revision
May 23 19:50:36.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-2668 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 19:50:36.759: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 19:50:36.759: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 19:50:36.759: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 19:50:46.784: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 23 19:50:56.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-2668 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 19:50:56.962: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 19:50:56.962: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 19:50:56.962: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 19:51:06.994: INFO: Waiting for StatefulSet statefulset-2668/ss2 to complete update
May 23 19:51:06.994: INFO: Waiting for Pod statefulset-2668/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 23 19:51:06.994: INFO: Waiting for Pod statefulset-2668/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May 23 19:51:17.007: INFO: Waiting for StatefulSet statefulset-2668/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 23 19:51:27.007: INFO: Deleting all statefulset in ns statefulset-2668
May 23 19:51:27.013: INFO: Scaling statefulset ss2 to 0
May 23 19:51:47.039: INFO: Waiting for statefulset status.replicas updated to 0
May 23 19:51:47.044: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:51:47.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2668" for this suite.
May 23 19:51:53.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:51:53.183: INFO: namespace statefulset-2668 deletion completed in 6.105061221s

• [SLOW TEST:147.135 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:51:53.183: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4083
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 23 19:51:53.260: INFO: Found 0 stateful pods, waiting for 3
May 23 19:52:03.279: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:52:03.279: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:52:03.279: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 23 19:52:03.317: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 23 19:52:13.362: INFO: Updating stateful set ss2
May 23 19:52:13.383: INFO: Waiting for Pod statefulset-4083/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:52:23.393: INFO: Waiting for Pod statefulset-4083/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 23 19:52:33.489: INFO: Found 2 stateful pods, waiting for 3
May 23 19:52:43.496: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:52:43.496: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 23 19:52:43.496: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 23 19:52:43.533: INFO: Updating stateful set ss2
May 23 19:52:43.551: INFO: Waiting for Pod statefulset-4083/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:52:53.562: INFO: Waiting for Pod statefulset-4083/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:53:03.577: INFO: Updating stateful set ss2
May 23 19:53:03.603: INFO: Waiting for StatefulSet statefulset-4083/ss2 to complete update
May 23 19:53:03.603: INFO: Waiting for Pod statefulset-4083/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 23 19:53:13.616: INFO: Waiting for StatefulSet statefulset-4083/ss2 to complete update
May 23 19:53:13.616: INFO: Waiting for Pod statefulset-4083/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 23 19:53:23.611: INFO: Deleting all statefulset in ns statefulset-4083
May 23 19:53:23.613: INFO: Scaling statefulset ss2 to 0
May 23 19:53:43.633: INFO: Waiting for statefulset status.replicas updated to 0
May 23 19:53:43.638: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:53:43.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4083" for this suite.
May 23 19:53:49.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:53:49.764: INFO: namespace statefulset-4083 deletion completed in 6.094588208s

• [SLOW TEST:116.582 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:53:49.764: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:53:49.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-8300" to be "success or failure"
May 23 19:53:49.794: INFO: Pod "downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371335ms
May 23 19:53:51.800: INFO: Pod "downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009632458s
May 23 19:53:53.806: INFO: Pod "downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015333692s
STEP: Saw pod success
May 23 19:53:53.806: INFO: Pod "downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:53:53.811: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:53:53.851: INFO: Waiting for pod downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:53:53.855: INFO: Pod downwardapi-volume-7bd78c66-7d94-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:53:53.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8300" for this suite.
May 23 19:53:59.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:53:59.962: INFO: namespace downward-api-8300 deletion completed in 6.104037811s

• [SLOW TEST:10.198 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:53:59.962: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 23 19:53:59.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-9527'
May 23 19:54:00.648: INFO: stderr: ""
May 23 19:54:00.648: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 19:54:00.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9527'
May 23 19:54:00.723: INFO: stderr: ""
May 23 19:54:00.723: INFO: stdout: "update-demo-nautilus-k2v5q update-demo-nautilus-lpb2j "
May 23 19:54:00.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-k2v5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9527'
May 23 19:54:00.775: INFO: stderr: ""
May 23 19:54:00.775: INFO: stdout: ""
May 23 19:54:00.775: INFO: update-demo-nautilus-k2v5q is created but not running
May 23 19:54:05.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9527'
May 23 19:54:05.854: INFO: stderr: ""
May 23 19:54:05.854: INFO: stdout: "update-demo-nautilus-k2v5q update-demo-nautilus-lpb2j "
May 23 19:54:05.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-k2v5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9527'
May 23 19:54:05.899: INFO: stderr: ""
May 23 19:54:05.899: INFO: stdout: "true"
May 23 19:54:05.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-k2v5q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9527'
May 23 19:54:05.951: INFO: stderr: ""
May 23 19:54:05.951: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 19:54:05.951: INFO: validating pod update-demo-nautilus-k2v5q
May 23 19:54:05.954: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 19:54:05.954: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 19:54:05.954: INFO: update-demo-nautilus-k2v5q is verified up and running
May 23 19:54:05.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-lpb2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9527'
May 23 19:54:06.002: INFO: stderr: ""
May 23 19:54:06.002: INFO: stdout: "true"
May 23 19:54:06.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-lpb2j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9527'
May 23 19:54:06.054: INFO: stderr: ""
May 23 19:54:06.054: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 19:54:06.054: INFO: validating pod update-demo-nautilus-lpb2j
May 23 19:54:06.058: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 19:54:06.058: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 19:54:06.058: INFO: update-demo-nautilus-lpb2j is verified up and running
STEP: using delete to clean up resources
May 23 19:54:06.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-9527'
May 23 19:54:06.115: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 19:54:06.115: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 23 19:54:06.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9527'
May 23 19:54:06.194: INFO: stderr: "No resources found.\n"
May 23 19:54:06.194: INFO: stdout: ""
May 23 19:54:06.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=update-demo --namespace=kubectl-9527 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 19:54:06.240: INFO: stderr: ""
May 23 19:54:06.240: INFO: stdout: "update-demo-nautilus-k2v5q\nupdate-demo-nautilus-lpb2j\n"
May 23 19:54:06.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9527'
May 23 19:54:06.820: INFO: stderr: "No resources found.\n"
May 23 19:54:06.820: INFO: stdout: ""
May 23 19:54:06.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=update-demo --namespace=kubectl-9527 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 19:54:06.866: INFO: stderr: ""
May 23 19:54:06.866: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:54:06.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9527" for this suite.
May 23 19:54:28.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:54:28.918: INFO: namespace kubectl-9527 deletion completed in 22.050144762s

• [SLOW TEST:28.956 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:54:28.919: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 23 19:54:33.467: INFO: Successfully updated pod "labelsupdate932e0ae4-7d94-11e9-b22f-2a454b6ec3fe"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:54:35.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1798" for this suite.
May 23 19:54:57.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:54:57.590: INFO: namespace downward-api-1798 deletion completed in 22.093315353s

• [SLOW TEST:28.671 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:54:57.591: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:54:57.616: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-8665" to be "success or failure"
May 23 19:54:57.621: INFO: Pod "downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.538229ms
May 23 19:54:59.632: INFO: Pod "downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015128874s
May 23 19:55:01.641: INFO: Pod "downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024470757s
STEP: Saw pod success
May 23 19:55:01.641: INFO: Pod "downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:55:01.643: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:55:01.659: INFO: Waiting for pod downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:55:01.661: INFO: Pod downwardapi-volume-a444e39e-7d94-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:55:01.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8665" for this suite.
May 23 19:55:07.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:55:07.720: INFO: namespace downward-api-8665 deletion completed in 6.057334032s

• [SLOW TEST:10.129 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:55:07.721: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 23 19:55:07.743: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:55:12.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-684" for this suite.
May 23 19:55:34.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:55:34.164: INFO: namespace init-container-684 deletion completed in 22.10031376s

• [SLOW TEST:26.444 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:55:34.165: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 19:55:34.189: INFO: (0) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 2.514745ms)
May 23 19:55:34.191: INFO: (1) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.789245ms)
May 23 19:55:34.192: INFO: (2) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.750736ms)
May 23 19:55:34.194: INFO: (3) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.682096ms)
May 23 19:55:34.196: INFO: (4) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.65185ms)
May 23 19:55:34.198: INFO: (5) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.543251ms)
May 23 19:55:34.199: INFO: (6) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.673198ms)
May 23 19:55:34.202: INFO: (7) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 2.318412ms)
May 23 19:55:34.203: INFO: (8) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.579825ms)
May 23 19:55:34.205: INFO: (9) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.884179ms)
May 23 19:55:34.207: INFO: (10) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.415964ms)
May 23 19:55:34.208: INFO: (11) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.647221ms)
May 23 19:55:34.210: INFO: (12) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.836119ms)
May 23 19:55:34.212: INFO: (13) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.672011ms)
May 23 19:55:34.214: INFO: (14) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.688337ms)
May 23 19:55:34.216: INFO: (15) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.787113ms)
May 23 19:55:34.217: INFO: (16) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.866824ms)
May 23 19:55:34.219: INFO: (17) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.774397ms)
May 23 19:55:34.221: INFO: (18) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.792421ms)
May 23 19:55:34.223: INFO: (19) /api/v1/nodes/controlplane-1:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="co... (200; 1.71544ms)
[AfterEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:55:34.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1590" for this suite.
May 23 19:55:40.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:55:40.318: INFO: namespace proxy-1590 deletion completed in 6.092973222s

• [SLOW TEST:6.153 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:55:40.318: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-rrgh
STEP: Creating a pod to test atomic-volume-subpath
May 23 19:55:40.346: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rrgh" in namespace "subpath-3458" to be "success or failure"
May 23 19:55:40.347: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637155ms
May 23 19:55:42.353: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007583445s
May 23 19:55:44.367: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 4.021067777s
May 23 19:55:46.376: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 6.029737352s
May 23 19:55:48.389: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 8.043339055s
May 23 19:55:50.395: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 10.048938345s
May 23 19:55:52.399: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 12.053337103s
May 23 19:55:54.413: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 14.067205121s
May 23 19:55:56.417: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 16.071654831s
May 23 19:55:58.420: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 18.074629978s
May 23 19:56:00.423: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Running", Reason="", readiness=true. Elapsed: 20.077015256s
May 23 19:56:02.429: INFO: Pod "pod-subpath-test-downwardapi-rrgh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.083543s
STEP: Saw pod success
May 23 19:56:02.429: INFO: Pod "pod-subpath-test-downwardapi-rrgh" satisfied condition "success or failure"
May 23 19:56:02.435: INFO: Trying to get logs from node worker-1 pod pod-subpath-test-downwardapi-rrgh container test-container-subpath-downwardapi-rrgh: <nil>
STEP: delete the pod
May 23 19:56:02.477: INFO: Waiting for pod pod-subpath-test-downwardapi-rrgh to disappear
May 23 19:56:02.480: INFO: Pod pod-subpath-test-downwardapi-rrgh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rrgh
May 23 19:56:02.480: INFO: Deleting pod "pod-subpath-test-downwardapi-rrgh" in namespace "subpath-3458"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:56:02.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3458" for this suite.
May 23 19:56:08.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:56:08.573: INFO: namespace subpath-3458 deletion completed in 6.088679592s

• [SLOW TEST:28.255 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:56:08.574: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
May 23 19:56:08.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 api-versions'
May 23 19:56:08.640: INFO: stderr: ""
May 23 19:56:08.640: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:56:08.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8826" for this suite.
May 23 19:56:14.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:56:14.710: INFO: namespace kubectl-8826 deletion completed in 6.068433163s

• [SLOW TEST:6.136 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:56:14.712: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:56:14.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe" in namespace "projected-9613" to be "success or failure"
May 23 19:56:14.739: INFO: Pod "downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637431ms
May 23 19:56:16.756: INFO: Pod "downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019748011s
STEP: Saw pod success
May 23 19:56:16.756: INFO: Pod "downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:56:16.761: INFO: Trying to get logs from node worker-2 pod downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:56:16.802: INFO: Waiting for pod downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:56:16.804: INFO: Pod downwardapi-volume-d23cab6a-7d94-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:56:16.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9613" for this suite.
May 23 19:56:22.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:56:22.895: INFO: namespace projected-9613 deletion completed in 6.088686705s

• [SLOW TEST:8.183 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:56:22.895: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-378
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 23 19:56:22.913: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 23 19:56:49.029: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.38.0.2:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:56:49.029: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:56:49.117: INFO: Found all expected endpoints: [netserver-0]
May 23 19:56:49.119: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.32.0.4:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:56:49.119: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:56:49.212: INFO: Found all expected endpoints: [netserver-1]
May 23 19:56:49.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.40.0.2:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 19:56:49.215: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 19:56:49.390: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:56:49.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-378" for this suite.
May 23 19:57:11.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:57:11.453: INFO: namespace pod-network-test-378 deletion completed in 22.060370378s

• [SLOW TEST:48.559 seconds]
[sig-network] Networking
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:57:11.454: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-jrmj
STEP: Creating a pod to test atomic-volume-subpath
May 23 19:57:11.481: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-jrmj" in namespace "subpath-911" to be "success or failure"
May 23 19:57:11.486: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.893555ms
May 23 19:57:13.492: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 2.010294191s
May 23 19:57:15.494: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 4.01257431s
May 23 19:57:17.500: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 6.018544187s
May 23 19:57:19.508: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 8.02674431s
May 23 19:57:21.515: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 10.033576396s
May 23 19:57:23.523: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 12.041979321s
May 23 19:57:25.530: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 14.048050438s
May 23 19:57:27.536: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 16.054949908s
May 23 19:57:29.541: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 18.05942298s
May 23 19:57:31.547: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 20.065771833s
May 23 19:57:33.557: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Running", Reason="", readiness=true. Elapsed: 22.075442465s
May 23 19:57:35.563: INFO: Pod "pod-subpath-test-projected-jrmj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.08120773s
STEP: Saw pod success
May 23 19:57:35.563: INFO: Pod "pod-subpath-test-projected-jrmj" satisfied condition "success or failure"
May 23 19:57:35.568: INFO: Trying to get logs from node worker-1 pod pod-subpath-test-projected-jrmj container test-container-subpath-projected-jrmj: <nil>
STEP: delete the pod
May 23 19:57:35.609: INFO: Waiting for pod pod-subpath-test-projected-jrmj to disappear
May 23 19:57:35.612: INFO: Pod pod-subpath-test-projected-jrmj no longer exists
STEP: Deleting pod pod-subpath-test-projected-jrmj
May 23 19:57:35.613: INFO: Deleting pod "pod-subpath-test-projected-jrmj" in namespace "subpath-911"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:57:35.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-911" for this suite.
May 23 19:57:41.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:57:41.684: INFO: namespace subpath-911 deletion completed in 6.066393601s

• [SLOW TEST:30.230 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:57:41.685: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 19:57:41.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe" in namespace "projected-6622" to be "success or failure"
May 23 19:57:41.717: INFO: Pod "downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.195838ms
May 23 19:57:43.730: INFO: Pod "downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018775527s
STEP: Saw pod success
May 23 19:57:43.730: INFO: Pod "downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:57:43.733: INFO: Trying to get logs from node worker-2 pod downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 19:57:43.751: INFO: Waiting for pod downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:57:43.752: INFO: Pod downwardapi-volume-0613aa92-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:57:43.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6622" for this suite.
May 23 19:57:49.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:57:49.841: INFO: namespace projected-6622 deletion completed in 6.086946667s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:57:49.844: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0523 19:57:55.949974      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 19:57:55.950: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:57:55.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6163" for this suite.
May 23 19:58:01.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:58:02.059: INFO: namespace gc-6163 deletion completed in 6.103665192s

• [SLOW TEST:12.215 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:58:02.062: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 19:58:02.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8663'
May 23 19:58:02.142: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 23 19:58:02.142: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
May 23 19:58:04.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8663'
May 23 19:58:04.233: INFO: stderr: ""
May 23 19:58:04.233: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:58:04.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8663" for this suite.
May 23 19:58:26.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:58:26.378: INFO: namespace kubectl-8663 deletion completed in 22.142414836s

• [SLOW TEST:24.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:58:26.380: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
May 23 19:58:26.403: INFO: Waiting up to 5m0s for pod "client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe" in namespace "containers-9319" to be "success or failure"
May 23 19:58:26.405: INFO: Pod "client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.609043ms
May 23 19:58:28.414: INFO: Pod "client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01061612s
May 23 19:58:30.418: INFO: Pod "client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014871094s
STEP: Saw pod success
May 23 19:58:30.418: INFO: Pod "client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 19:58:30.421: INFO: Trying to get logs from node worker-1 pod client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 19:58:30.449: INFO: Waiting for pod client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 19:58:30.458: INFO: Pod client-containers-20b75d12-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 19:58:30.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9319" for this suite.
May 23 19:58:36.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 19:58:36.552: INFO: namespace containers-9319 deletion completed in 6.087380554s

• [SLOW TEST:10.173 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 19:58:36.552: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5590
May 23 19:58:38.598: INFO: Started pod liveness-http in namespace container-probe-5590
STEP: checking the pod's current state and verifying that restartCount is present
May 23 19:58:38.604: INFO: Initial restart count of pod liveness-http is 0
May 23 19:58:50.664: INFO: Restart count of pod container-probe-5590/liveness-http is now 1 (12.060284752s elapsed)
May 23 19:59:10.751: INFO: Restart count of pod container-probe-5590/liveness-http is now 2 (32.146523686s elapsed)
May 23 19:59:30.811: INFO: Restart count of pod container-probe-5590/liveness-http is now 3 (52.206813914s elapsed)
May 23 19:59:50.876: INFO: Restart count of pod container-probe-5590/liveness-http is now 4 (1m12.272207002s elapsed)
May 23 20:01:03.132: INFO: Restart count of pod container-probe-5590/liveness-http is now 5 (2m24.528403752s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:01:03.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5590" for this suite.
May 23 20:01:09.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:01:09.244: INFO: namespace container-probe-5590 deletion completed in 6.078691876s

• [SLOW TEST:152.691 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:01:09.244: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9606.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9606.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9606.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 181.191.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.191.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.191.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.191.181_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9606.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9606.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9606.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9606.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 181.191.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.191.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.191.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.191.181_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 23 20:01:33.316: INFO: Unable to read wheezy_udp@dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.321: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.326: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.329: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.332: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.335: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.337: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.339: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.341: INFO: Unable to read 10.105.191.181_udp@PTR from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.343: INFO: Unable to read 10.105.191.181_tcp@PTR from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.346: INFO: Unable to read jessie_udp@dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.348: INFO: Unable to read jessie_tcp@dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.349: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.351: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.353: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.355: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.357: INFO: Unable to read jessie_udp@PodARecord from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.359: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.361: INFO: Unable to read 10.105.191.181_udp@PTR from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.363: INFO: Unable to read 10.105.191.181_tcp@PTR from pod dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe)
May 23 20:01:33.363: INFO: Lookups using dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe failed for: [wheezy_udp@dns-test-service.dns-9606.svc.cluster.local wheezy_tcp@dns-test-service.dns-9606.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local wheezy_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local wheezy_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.105.191.181_udp@PTR 10.105.191.181_tcp@PTR jessie_udp@dns-test-service.dns-9606.svc.cluster.local jessie_tcp@dns-test-service.dns-9606.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9606.svc.cluster.local jessie_udp@_http._tcp.test-service-2.dns-9606.svc.cluster.local jessie_tcp@_http._tcp.test-service-2.dns-9606.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord 10.105.191.181_udp@PTR 10.105.191.181_tcp@PTR]

May 23 20:01:38.499: INFO: DNS probes using dns-9606/dns-test-81cba5da-7d95-11e9-b22f-2a454b6ec3fe succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:01:38.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9606" for this suite.
May 23 20:01:44.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:01:44.656: INFO: namespace dns-9606 deletion completed in 6.091351744s

• [SLOW TEST:35.413 seconds]
[sig-network] DNS
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:01:44.656: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:01:44.686: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 23 20:01:44.692: INFO: Number of nodes with available pods: 0
May 23 20:01:44.692: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 23 20:01:44.703: INFO: Number of nodes with available pods: 0
May 23 20:01:44.703: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:45.713: INFO: Number of nodes with available pods: 0
May 23 20:01:45.713: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:46.719: INFO: Number of nodes with available pods: 1
May 23 20:01:46.720: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 23 20:01:46.754: INFO: Number of nodes with available pods: 1
May 23 20:01:46.755: INFO: Number of running nodes: 0, number of available pods: 1
May 23 20:01:47.761: INFO: Number of nodes with available pods: 0
May 23 20:01:47.761: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 23 20:01:47.779: INFO: Number of nodes with available pods: 0
May 23 20:01:47.779: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:48.781: INFO: Number of nodes with available pods: 0
May 23 20:01:48.781: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:49.782: INFO: Number of nodes with available pods: 0
May 23 20:01:49.782: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:50.784: INFO: Number of nodes with available pods: 0
May 23 20:01:50.784: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:51.784: INFO: Number of nodes with available pods: 0
May 23 20:01:51.784: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:52.794: INFO: Number of nodes with available pods: 0
May 23 20:01:52.794: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:53.785: INFO: Number of nodes with available pods: 0
May 23 20:01:53.785: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:54.785: INFO: Number of nodes with available pods: 0
May 23 20:01:54.785: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:55.785: INFO: Number of nodes with available pods: 0
May 23 20:01:55.785: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:56.801: INFO: Number of nodes with available pods: 0
May 23 20:01:56.801: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:57.781: INFO: Number of nodes with available pods: 0
May 23 20:01:57.781: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:58.785: INFO: Number of nodes with available pods: 0
May 23 20:01:58.785: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:01:59.785: INFO: Number of nodes with available pods: 1
May 23 20:01:59.785: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7410, will wait for the garbage collector to delete the pods
May 23 20:01:59.868: INFO: Deleting DaemonSet.extensions daemon-set took: 14.082315ms
May 23 20:02:00.169: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.59725ms
May 23 20:02:02.974: INFO: Number of nodes with available pods: 0
May 23 20:02:02.974: INFO: Number of running nodes: 0, number of available pods: 0
May 23 20:02:02.977: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7410/daemonsets","resourceVersion":"9053"},"items":null}

May 23 20:02:02.979: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7410/pods","resourceVersion":"9053"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:02:03.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7410" for this suite.
May 23 20:02:09.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:02:09.115: INFO: namespace daemonsets-7410 deletion completed in 6.10796087s

• [SLOW TEST:24.459 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:02:09.117: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:02:35.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6314" for this suite.
May 23 20:02:41.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:02:41.586: INFO: namespace container-runtime-6314 deletion completed in 6.130986839s

• [SLOW TEST:32.469 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:02:41.588: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:02:41.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe" in namespace "projected-3338" to be "success or failure"
May 23 20:02:41.618: INFO: Pod "downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.76102ms
May 23 20:02:43.622: INFO: Pod "downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007335909s
STEP: Saw pod success
May 23 20:02:43.622: INFO: Pod "downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:02:43.625: INFO: Trying to get logs from node worker-2 pod downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:02:43.644: INFO: Waiting for pod downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:02:43.645: INFO: Pod downwardapi-volume-b8d50a2c-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:02:43.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3338" for this suite.
May 23 20:02:49.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:02:49.698: INFO: namespace projected-3338 deletion completed in 6.050205059s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:02:49.699: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe
May 23 20:02:49.732: INFO: Pod name my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe: Found 0 pods out of 1
May 23 20:02:54.739: INFO: Pod name my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe: Found 1 pods out of 1
May 23 20:02:54.740: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe" are running
May 23 20:02:54.746: INFO: Pod "my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe-dsdf8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:02:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:02:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:02:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:02:49 +0000 UTC Reason: Message:}])
May 23 20:02:54.746: INFO: Trying to dial the pod
May 23 20:02:59.783: INFO: Controller my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe: Got expected result from replica 1 [my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe-dsdf8]: "my-hostname-basic-bdaad38a-7d95-11e9-b22f-2a454b6ec3fe-dsdf8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:02:59.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-423" for this suite.
May 23 20:03:05.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:03:05.884: INFO: namespace replication-controller-423 deletion completed in 6.094463683s

• [SLOW TEST:16.186 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:03:05.885: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 23 20:03:05.910: INFO: Waiting up to 5m0s for pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-1304" to be "success or failure"
May 23 20:03:05.913: INFO: Pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217601ms
May 23 20:03:07.917: INFO: Pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007767617s
May 23 20:03:09.925: INFO: Pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01498574s
May 23 20:03:11.931: INFO: Pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020862657s
STEP: Saw pod success
May 23 20:03:11.931: INFO: Pod "downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:03:11.936: INFO: Trying to get logs from node worker-2 pod downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 20:03:11.974: INFO: Waiting for pod downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:03:11.976: INFO: Pod downward-api-c750a0fa-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:03:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1304" for this suite.
May 23 20:03:17.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:03:18.080: INFO: namespace downward-api-1304 deletion completed in 6.099515541s

• [SLOW TEST:12.195 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:03:18.081: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-3477/secret-test-ce95785d-7d95-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:03:18.109: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe" in namespace "secrets-3477" to be "success or failure"
May 23 20:03:18.114: INFO: Pod "pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.720092ms
May 23 20:03:20.122: INFO: Pod "pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012542197s
May 23 20:03:22.133: INFO: Pod "pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023630861s
STEP: Saw pod success
May 23 20:03:22.133: INFO: Pod "pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:03:22.141: INFO: Trying to get logs from node worker-1 pod pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe container env-test: <nil>
STEP: delete the pod
May 23 20:03:22.183: INFO: Waiting for pod pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:03:22.185: INFO: Pod pod-configmaps-ce95d01d-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:03:22.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3477" for this suite.
May 23 20:03:28.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:03:28.273: INFO: namespace secrets-3477 deletion completed in 6.085201698s

• [SLOW TEST:10.193 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:03:28.273: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:03:28.299: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-3578" to be "success or failure"
May 23 20:03:28.304: INFO: Pod "downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.287814ms
May 23 20:03:30.311: INFO: Pod "downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011978589s
May 23 20:03:32.320: INFO: Pod "downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021808336s
STEP: Saw pod success
May 23 20:03:32.321: INFO: Pod "downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:03:32.327: INFO: Trying to get logs from node worker-2 pod downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:03:32.367: INFO: Waiting for pod downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:03:32.370: INFO: Pod downwardapi-volume-d4a8b61b-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:03:32.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3578" for this suite.
May 23 20:03:38.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:03:38.429: INFO: namespace downward-api-3578 deletion completed in 6.055960032s

• [SLOW TEST:10.156 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:03:38.429: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-378
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-378 to expose endpoints map[]
May 23 20:03:38.458: INFO: successfully validated that service multi-endpoint-test in namespace services-378 exposes endpoints map[] (5.497985ms elapsed)
STEP: Creating pod pod1 in namespace services-378
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-378 to expose endpoints map[pod1:[100]]
May 23 20:03:41.509: INFO: successfully validated that service multi-endpoint-test in namespace services-378 exposes endpoints map[pod1:[100]] (3.042421956s elapsed)
STEP: Creating pod pod2 in namespace services-378
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-378 to expose endpoints map[pod1:[100] pod2:[101]]
May 23 20:03:43.581: INFO: successfully validated that service multi-endpoint-test in namespace services-378 exposes endpoints map[pod1:[100] pod2:[101]] (2.057526438s elapsed)
STEP: Deleting pod pod1 in namespace services-378
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-378 to expose endpoints map[pod2:[101]]
May 23 20:03:43.609: INFO: successfully validated that service multi-endpoint-test in namespace services-378 exposes endpoints map[pod2:[101]] (18.410108ms elapsed)
STEP: Deleting pod pod2 in namespace services-378
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-378 to expose endpoints map[]
May 23 20:03:43.627: INFO: successfully validated that service multi-endpoint-test in namespace services-378 exposes endpoints map[] (8.885677ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:03:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-378" for this suite.
May 23 20:04:05.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:04:05.810: INFO: namespace services-378 deletion completed in 22.159444535s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.381 seconds]
[sig-network] Services
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:04:05.810: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 23 20:04:05.836: INFO: Waiting up to 5m0s for pod "pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-6482" to be "success or failure"
May 23 20:04:05.843: INFO: Pod "pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.030272ms
May 23 20:04:07.847: INFO: Pod "pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010629131s
May 23 20:04:09.860: INFO: Pod "pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023947538s
STEP: Saw pod success
May 23 20:04:09.860: INFO: Pod "pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:04:09.867: INFO: Trying to get logs from node worker-1 pod pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:04:09.911: INFO: Waiting for pod pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:04:09.913: INFO: Pod pod-eb088583-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:04:09.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6482" for this suite.
May 23 20:04:15.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:04:15.973: INFO: namespace emptydir-6482 deletion completed in 6.056810827s

• [SLOW TEST:10.162 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:04:15.976: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f1183d3c-7d95-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:04:16.006: INFO: Waiting up to 5m0s for pod "pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe" in namespace "secrets-503" to be "success or failure"
May 23 20:04:16.012: INFO: Pod "pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.756039ms
May 23 20:04:18.018: INFO: Pod "pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011866322s
May 23 20:04:20.029: INFO: Pod "pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022335143s
STEP: Saw pod success
May 23 20:04:20.029: INFO: Pod "pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:04:20.034: INFO: Trying to get logs from node worker-1 pod pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:04:20.056: INFO: Waiting for pod pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:04:20.059: INFO: Pod pod-secrets-f118851b-7d95-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:04:20.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-503" for this suite.
May 23 20:04:26.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:04:26.159: INFO: namespace secrets-503 deletion completed in 6.096587722s

• [SLOW TEST:10.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:04:26.160: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 23 20:04:26.181: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 23 20:04:26.184: INFO: Waiting for terminating namespaces to be deleted...
May 23 20:04:26.185: INFO: 
Logging pods the kubelet thinks is on node controlplane-1 before test
May 23 20:04:26.189: INFO: coredns-fb8b8dccf-j6x4t from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.189: INFO: 	Container coredns ready: true, restart count 0
May 23 20:04:26.189: INFO: kube-scheduler-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:04:26.189: INFO: kube-proxy-kcbp9 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.189: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:04:26.189: INFO: kube-apiserver-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:04:26.189: INFO: weave-net-kt8s6 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.189: INFO: 	Container weave ready: true, restart count 0
May 23 20:04:26.189: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:04:26.189: INFO: coredns-fb8b8dccf-t24wc from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.189: INFO: 	Container coredns ready: true, restart count 0
May 23 20:04:26.189: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-ghmvv from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.189: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 20:04:26.189: INFO: 	Container systemd-logs ready: true, restart count 0
May 23 20:04:26.189: INFO: kube-controller-manager-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:04:26.189: INFO: etcd-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:04:26.189: INFO: 
Logging pods the kubelet thinks is on node worker-1 before test
May 23 20:04:26.194: INFO: weave-net-t292l from kube-system started at 2019-05-23 19:25:04 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.194: INFO: 	Container weave ready: true, restart count 0
May 23 20:04:26.194: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:04:26.194: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-23 19:26:01 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.194: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 23 20:04:26.194: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-wpj4k from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.194: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 20:04:26.194: INFO: 	Container systemd-logs ready: true, restart count 0
May 23 20:04:26.194: INFO: kube-proxy-lpxwl from kube-system started at 2019-05-23 19:25:04 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.194: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:04:26.194: INFO: 
Logging pods the kubelet thinks is on node worker-2 before test
May 23 20:04:26.197: INFO: weave-net-lp9js from kube-system started at 2019-05-23 19:25:19 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.197: INFO: 	Container weave ready: true, restart count 1
May 23 20:04:26.197: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:04:26.197: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-b25f6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.197: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 20:04:26.197: INFO: 	Container systemd-logs ready: true, restart count 0
May 23 20:04:26.197: INFO: kube-proxy-5fwlj from kube-system started at 2019-05-23 19:25:19 +0000 UTC (1 container statuses recorded)
May 23 20:04:26.197: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:04:26.197: INFO: sonobuoy-e2e-job-67a3a42f03d24ef6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 20:04:26.197: INFO: 	Container e2e ready: true, restart count 0
May 23 20:04:26.197: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f861485c-7d95-11e9-b22f-2a454b6ec3fe 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f861485c-7d95-11e9-b22f-2a454b6ec3fe off the node worker-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f861485c-7d95-11e9-b22f-2a454b6ec3fe
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:04:32.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7364" for this suite.
May 23 20:04:40.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:04:40.316: INFO: namespace sched-pred-7364 deletion completed in 8.053700556s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.157 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:04:40.318: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6804
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6804
STEP: Creating statefulset with conflicting port in namespace statefulset-6804
STEP: Waiting until pod test-pod will start running in namespace statefulset-6804
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6804
May 23 20:04:44.392: INFO: Observed stateful pod in namespace: statefulset-6804, name: ss-0, uid: 01be1a8a-7d96-11e9-a2d7-080027c2be11, status phase: Failed. Waiting for statefulset controller to delete.
May 23 20:04:44.393: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6804
STEP: Removing pod with conflicting port in namespace statefulset-6804
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6804 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 23 20:04:48.433: INFO: Deleting all statefulset in ns statefulset-6804
May 23 20:04:48.438: INFO: Scaling statefulset ss to 0
May 23 20:04:58.470: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:04:58.476: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:04:58.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6804" for this suite.
May 23 20:05:04.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:05:04.601: INFO: namespace statefulset-6804 deletion completed in 6.083551141s

• [SLOW TEST:24.282 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:05:04.601: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-0e137507-7d96-11e9-b22f-2a454b6ec3fe
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:05:04.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2789" for this suite.
May 23 20:05:10.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:05:10.723: INFO: namespace configmap-2789 deletion completed in 6.080673878s

• [SLOW TEST:6.123 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:05:10.724: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-11b99803-7d96-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-11b99803-7d96-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:06:37.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9754" for this suite.
May 23 20:06:59.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:06:59.666: INFO: namespace projected-9754 deletion completed in 22.067706541s

• [SLOW TEST:108.942 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:06:59.666: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:06:59.692: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 23 20:07:04.697: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 23 20:07:04.697: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 23 20:07:06.703: INFO: Creating deployment "test-rollover-deployment"
May 23 20:07:06.713: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 23 20:07:08.725: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 23 20:07:08.736: INFO: Ensure that both replica sets have 1 created replica
May 23 20:07:08.748: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 23 20:07:08.770: INFO: Updating deployment test-rollover-deployment
May 23 20:07:08.770: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 23 20:07:10.797: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 23 20:07:10.808: INFO: Make sure deployment "test-rollover-deployment" is complete
May 23 20:07:10.818: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:10.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238828, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:12.827: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:12.828: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238831, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:14.829: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:14.830: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238831, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:16.829: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:16.830: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238831, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:18.830: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:18.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238831, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:20.833: INFO: all replica sets need to contain the pod-template-hash label
May 23 20:07:20.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238831, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694238826, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:07:22.833: INFO: 
May 23 20:07:22.833: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 23 20:07:22.853: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-436,SelfLink:/apis/apps/v1/namespaces/deployment-436/deployments/test-rollover-deployment,UID:56e1f284-7d96-11e9-a2d7-080027c2be11,ResourceVersion:10135,Generation:2,CreationTimestamp:2019-05-23 20:07:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-23 20:07:06 +0000 UTC 2019-05-23 20:07:06 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-23 20:07:21 +0000 UTC 2019-05-23 20:07:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 23 20:07:22.859: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-436,SelfLink:/apis/apps/v1/namespaces/deployment-436/replicasets/test-rollover-deployment-766b4d6c9d,UID:581bafad-7d96-11e9-a2d7-080027c2be11,ResourceVersion:10124,Generation:2,CreationTimestamp:2019-05-23 20:07:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 56e1f284-7d96-11e9-a2d7-080027c2be11 0xc0024308f7 0xc0024308f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 23 20:07:22.859: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 23 20:07:22.859: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-436,SelfLink:/apis/apps/v1/namespaces/deployment-436/replicasets/test-rollover-controller,UID:52b38c95-7d96-11e9-a2d7-080027c2be11,ResourceVersion:10134,Generation:2,CreationTimestamp:2019-05-23 20:06:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 56e1f284-7d96-11e9-a2d7-080027c2be11 0xc002430747 0xc002430748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 20:07:22.860: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-436,SelfLink:/apis/apps/v1/namespaces/deployment-436/replicasets/test-rollover-deployment-6455657675,UID:56e384f8-7d96-11e9-a2d7-080027c2be11,ResourceVersion:10100,Generation:2,CreationTimestamp:2019-05-23 20:07:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 56e1f284-7d96-11e9-a2d7-080027c2be11 0xc002430817 0xc002430818}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 20:07:22.864: INFO: Pod "test-rollover-deployment-766b4d6c9d-v9zqs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-v9zqs,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-436,SelfLink:/api/v1/namespaces/deployment-436/pods/test-rollover-deployment-766b4d6c9d-v9zqs,UID:581fc906-7d96-11e9-a2d7-080027c2be11,ResourceVersion:10107,Generation:0,CreationTimestamp:2019-05-23 20:07:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 581bafad-7d96-11e9-a2d7-080027c2be11 0xc0021e8067 0xc0021e8068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2sn9s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2sn9s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2sn9s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e80e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e8100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:07:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:07:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:07:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:07:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:10.40.0.3,StartTime:2019-05-23 20:07:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-23 20:07:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a27c0fb97efcc096677491deba250ea74c1885d04acb7792f164ce52190d0295}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:07:22.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-436" for this suite.
May 23 20:07:28.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:07:28.965: INFO: namespace deployment-436 deletion completed in 6.097691066s

• [SLOW TEST:29.299 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:07:28.966: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 23 20:07:28.988: INFO: Waiting up to 5m0s for pod "pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-4233" to be "success or failure"
May 23 20:07:28.990: INFO: Pod "pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.978418ms
May 23 20:07:30.997: INFO: Pod "pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008360609s
May 23 20:07:33.004: INFO: Pod "pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015580663s
STEP: Saw pod success
May 23 20:07:33.004: INFO: Pod "pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:07:33.006: INFO: Trying to get logs from node worker-1 pod pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:07:33.020: INFO: Waiting for pod pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:07:33.022: INFO: Pod pod-641f6431-7d96-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:07:33.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4233" for this suite.
May 23 20:07:39.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:07:39.111: INFO: namespace emptydir-4233 deletion completed in 6.087252336s

• [SLOW TEST:10.146 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:07:39.112: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3467
May 23 20:07:43.154: INFO: Started pod liveness-exec in namespace container-probe-3467
STEP: checking the pod's current state and verifying that restartCount is present
May 23 20:07:43.159: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:11:44.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3467" for this suite.
May 23 20:11:50.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:11:50.175: INFO: namespace container-probe-3467 deletion completed in 6.076847186s

• [SLOW TEST:251.064 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:11:50.177: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
May 23 20:11:50.205: INFO: Waiting up to 5m0s for pod "var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe" in namespace "var-expansion-7012" to be "success or failure"
May 23 20:11:50.211: INFO: Pod "var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.837529ms
May 23 20:11:52.214: INFO: Pod "var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008881667s
STEP: Saw pod success
May 23 20:11:52.214: INFO: Pod "var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:11:52.215: INFO: Trying to get logs from node worker-1 pod var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 20:11:52.231: INFO: Waiting for pod var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:11:52.233: INFO: Pod var-expansion-ffd14b32-7d96-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:11:52.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7012" for this suite.
May 23 20:11:58.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:11:58.347: INFO: namespace var-expansion-7012 deletion completed in 6.111639521s

• [SLOW TEST:8.170 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:11:58.347: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-qm94
STEP: Creating a pod to test atomic-volume-subpath
May 23 20:11:58.376: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qm94" in namespace "subpath-3546" to be "success or failure"
May 23 20:11:58.381: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Pending", Reason="", readiness=false. Elapsed: 5.031654ms
May 23 20:12:00.386: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 2.010722839s
May 23 20:12:02.392: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 4.016545915s
May 23 20:12:04.397: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 6.021281906s
May 23 20:12:06.412: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 8.036013165s
May 23 20:12:08.421: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 10.045332443s
May 23 20:12:10.427: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 12.051620524s
May 23 20:12:12.438: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 14.062411597s
May 23 20:12:14.443: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 16.067862404s
May 23 20:12:16.450: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 18.074124331s
May 23 20:12:18.461: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 20.085109957s
May 23 20:12:20.467: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Running", Reason="", readiness=true. Elapsed: 22.091533933s
May 23 20:12:22.473: INFO: Pod "pod-subpath-test-configmap-qm94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.097193386s
STEP: Saw pod success
May 23 20:12:22.473: INFO: Pod "pod-subpath-test-configmap-qm94" satisfied condition "success or failure"
May 23 20:12:22.478: INFO: Trying to get logs from node worker-1 pod pod-subpath-test-configmap-qm94 container test-container-subpath-configmap-qm94: <nil>
STEP: delete the pod
May 23 20:12:22.524: INFO: Waiting for pod pod-subpath-test-configmap-qm94 to disappear
May 23 20:12:22.528: INFO: Pod pod-subpath-test-configmap-qm94 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qm94
May 23 20:12:22.528: INFO: Deleting pod "pod-subpath-test-configmap-qm94" in namespace "subpath-3546"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:12:22.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3546" for this suite.
May 23 20:12:28.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:12:28.613: INFO: namespace subpath-3546 deletion completed in 6.080239696s

• [SLOW TEST:30.266 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:12:28.614: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-16ba3b36-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:12:28.643: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-5882" to be "success or failure"
May 23 20:12:28.646: INFO: Pod "pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.516564ms
May 23 20:12:30.652: INFO: Pod "pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00882489s
May 23 20:12:32.657: INFO: Pod "pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013328207s
STEP: Saw pod success
May 23 20:12:32.657: INFO: Pod "pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:12:32.661: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe container projected-secret-volume-test: <nil>
STEP: delete the pod
May 23 20:12:32.697: INFO: Waiting for pod pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:12:32.703: INFO: Pod pod-projected-secrets-16ba8587-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:12:32.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5882" for this suite.
May 23 20:12:38.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:12:38.770: INFO: namespace projected-5882 deletion completed in 6.064157624s

• [SLOW TEST:10.156 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:12:38.773: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:12:38.863: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-1071" to be "success or failure"
May 23 20:12:38.873: INFO: Pod "downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.312823ms
May 23 20:12:40.880: INFO: Pod "downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015985491s
May 23 20:12:42.886: INFO: Pod "downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021872527s
STEP: Saw pod success
May 23 20:12:42.886: INFO: Pod "downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:12:42.890: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:12:42.935: INFO: Waiting for pod downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:12:42.939: INFO: Pod downwardapi-volume-1cd24e9f-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:12:42.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1071" for this suite.
May 23 20:12:48.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:12:49.055: INFO: namespace projected-1071 deletion completed in 6.10845222s

• [SLOW TEST:10.282 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:12:49.055: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:12:49.077: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-8309" to be "success or failure"
May 23 20:12:49.080: INFO: Pod "downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.887628ms
May 23 20:12:51.084: INFO: Pod "downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007582738s
May 23 20:12:53.091: INFO: Pod "downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014565703s
STEP: Saw pod success
May 23 20:12:53.091: INFO: Pod "downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:12:53.097: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:12:53.119: INFO: Waiting for pod downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:12:53.121: INFO: Pod downwardapi-volume-22e90ad4-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:12:53.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8309" for this suite.
May 23 20:12:59.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:12:59.194: INFO: namespace projected-8309 deletion completed in 6.070596951s

• [SLOW TEST:10.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:12:59.194: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 23 20:12:59.272: INFO: Waiting up to 5m0s for pod "pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-7298" to be "success or failure"
May 23 20:12:59.276: INFO: Pod "pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074651ms
May 23 20:13:01.282: INFO: Pod "pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009841014s
May 23 20:13:03.289: INFO: Pod "pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016817753s
STEP: Saw pod success
May 23 20:13:03.289: INFO: Pod "pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:13:03.294: INFO: Trying to get logs from node worker-1 pod pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:13:03.333: INFO: Waiting for pod pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:13:03.336: INFO: Pod pod-28fbf378-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:13:03.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7298" for this suite.
May 23 20:13:09.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:13:09.438: INFO: namespace emptydir-7298 deletion completed in 6.098443077s

• [SLOW TEST:10.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:13:09.438: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2f10319a-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:13:09.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe" in namespace "configmap-1451" to be "success or failure"
May 23 20:13:09.474: INFO: Pod "pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.955139ms
May 23 20:13:11.483: INFO: Pod "pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013349102s
May 23 20:13:13.493: INFO: Pod "pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023067375s
STEP: Saw pod success
May 23 20:13:13.493: INFO: Pod "pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:13:13.498: INFO: Trying to get logs from node worker-1 pod pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:13:13.537: INFO: Waiting for pod pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:13:13.543: INFO: Pod pod-configmaps-2f1091d8-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:13:13.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1451" for this suite.
May 23 20:13:19.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:13:19.639: INFO: namespace configmap-1451 deletion completed in 6.092484303s

• [SLOW TEST:10.201 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:13:19.639: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 23 20:13:19.667: INFO: Waiting up to 5m0s for pod "pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-917" to be "success or failure"
May 23 20:13:19.673: INFO: Pod "pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.931164ms
May 23 20:13:21.680: INFO: Pod "pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012501489s
May 23 20:13:23.684: INFO: Pod "pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017258904s
STEP: Saw pod success
May 23 20:13:23.684: INFO: Pod "pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:13:23.686: INFO: Trying to get logs from node worker-1 pod pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:13:23.700: INFO: Waiting for pod pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:13:23.701: INFO: Pod pod-352429e3-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:13:23.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-917" for this suite.
May 23 20:13:29.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:13:29.771: INFO: namespace emptydir-917 deletion completed in 6.067938516s

• [SLOW TEST:10.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:13:29.772: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3b359b74-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:13:29.851: INFO: Waiting up to 5m0s for pod "pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe" in namespace "secrets-4321" to be "success or failure"
May 23 20:13:29.853: INFO: Pod "pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.557814ms
May 23 20:13:31.864: INFO: Pod "pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012826046s
May 23 20:13:33.874: INFO: Pod "pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022946829s
STEP: Saw pod success
May 23 20:13:33.874: INFO: Pod "pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:13:33.879: INFO: Trying to get logs from node worker-1 pod pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:13:33.917: INFO: Waiting for pod pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:13:33.921: INFO: Pod pod-secrets-3b3622c0-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:13:33.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4321" for this suite.
May 23 20:13:39.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:13:40.030: INFO: namespace secrets-4321 deletion completed in 6.106255962s

• [SLOW TEST:10.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:13:40.030: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:13:40.060: INFO: Create a RollingUpdate DaemonSet
May 23 20:13:40.063: INFO: Check that daemon pods launch on every node of the cluster
May 23 20:13:40.068: INFO: Number of nodes with available pods: 0
May 23 20:13:40.068: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:13:41.075: INFO: Number of nodes with available pods: 0
May 23 20:13:41.075: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:13:42.081: INFO: Number of nodes with available pods: 1
May 23 20:13:42.081: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:13:43.076: INFO: Number of nodes with available pods: 3
May 23 20:13:43.076: INFO: Number of running nodes: 3, number of available pods: 3
May 23 20:13:43.076: INFO: Update the DaemonSet to trigger a rollout
May 23 20:13:43.083: INFO: Updating DaemonSet daemon-set
May 23 20:13:57.106: INFO: Roll back the DaemonSet before rollout is complete
May 23 20:13:57.122: INFO: Updating DaemonSet daemon-set
May 23 20:13:57.123: INFO: Make sure DaemonSet rollback is complete
May 23 20:13:57.127: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:13:57.127: INFO: Pod daemon-set-vw555 is not available
May 23 20:13:58.146: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:13:58.146: INFO: Pod daemon-set-vw555 is not available
May 23 20:13:59.158: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:13:59.158: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:00.144: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:00.144: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:01.146: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:01.146: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:02.157: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:02.158: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:03.147: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:03.147: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:04.150: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:04.150: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:05.150: INFO: Wrong image for pod: daemon-set-vw555. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 23 20:14:05.150: INFO: Pod daemon-set-vw555 is not available
May 23 20:14:06.146: INFO: Pod daemon-set-vzhvb is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1133, will wait for the garbage collector to delete the pods
May 23 20:14:06.209: INFO: Deleting DaemonSet.extensions daemon-set took: 5.042797ms
May 23 20:14:06.515: INFO: Terminating DaemonSet.extensions daemon-set pods took: 306.035643ms
May 23 20:14:17.117: INFO: Number of nodes with available pods: 0
May 23 20:14:17.117: INFO: Number of running nodes: 0, number of available pods: 0
May 23 20:14:17.132: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1133/daemonsets","resourceVersion":"11138"},"items":null}

May 23 20:14:17.134: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1133/pods","resourceVersion":"11138"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:14:17.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1133" for this suite.
May 23 20:14:23.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:14:23.233: INFO: namespace daemonsets-1133 deletion completed in 6.0892791s

• [SLOW TEST:43.203 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:14:23.235: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-5b0c5b85-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:14:23.263: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-8032" to be "success or failure"
May 23 20:14:23.265: INFO: Pod "pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.759002ms
May 23 20:14:25.271: INFO: Pod "pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007937678s
STEP: Saw pod success
May 23 20:14:25.271: INFO: Pod "pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:14:25.277: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe container projected-secret-volume-test: <nil>
STEP: delete the pod
May 23 20:14:25.299: INFO: Waiting for pod pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:14:25.303: INFO: Pod pod-projected-secrets-5b0ca5ef-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:14:25.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8032" for this suite.
May 23 20:14:31.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:14:31.436: INFO: namespace projected-8032 deletion completed in 6.129159183s

• [SLOW TEST:8.201 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:14:31.436: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 23 20:14:31.459: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:14:35.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4183" for this suite.
May 23 20:14:41.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:14:41.804: INFO: namespace init-container-4183 deletion completed in 6.108720407s

• [SLOW TEST:10.368 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:14:41.805: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 23 20:14:41.825: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:14:45.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8494" for this suite.
May 23 20:14:51.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:14:51.236: INFO: namespace init-container-8494 deletion completed in 6.093550989s

• [SLOW TEST:9.430 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:14:51.236: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-6bbc73e0-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:14:51.261: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-2707" to be "success or failure"
May 23 20:14:51.269: INFO: Pod "pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.317975ms
May 23 20:14:53.276: INFO: Pod "pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014658298s
May 23 20:14:55.282: INFO: Pod "pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02096257s
STEP: Saw pod success
May 23 20:14:55.282: INFO: Pod "pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:14:55.287: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe container projected-secret-volume-test: <nil>
STEP: delete the pod
May 23 20:14:55.326: INFO: Waiting for pod pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:14:55.328: INFO: Pod pod-projected-secrets-6bbcc3e6-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:14:55.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2707" for this suite.
May 23 20:15:01.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:15:01.440: INFO: namespace projected-2707 deletion completed in 6.108698666s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:15:01.440: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
May 23 20:15:01.472: INFO: Waiting up to 5m0s for pod "pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-4268" to be "success or failure"
May 23 20:15:01.478: INFO: Pod "pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.378703ms
May 23 20:15:03.488: INFO: Pod "pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016428549s
May 23 20:15:05.503: INFO: Pod "pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030787416s
STEP: Saw pod success
May 23 20:15:05.503: INFO: Pod "pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:15:05.508: INFO: Trying to get logs from node worker-1 pod pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:15:05.543: INFO: Waiting for pod pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:15:05.545: INFO: Pod pod-71d27f1f-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:15:05.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4268" for this suite.
May 23 20:15:11.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:15:11.639: INFO: namespace emptydir-4268 deletion completed in 6.091496191s

• [SLOW TEST:10.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:15:11.640: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:15:11.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-1302" to be "success or failure"
May 23 20:15:11.664: INFO: Pod "downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.865403ms
May 23 20:15:13.673: INFO: Pod "downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011716649s
May 23 20:15:15.686: INFO: Pod "downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024003961s
STEP: Saw pod success
May 23 20:15:15.686: INFO: Pod "downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:15:15.692: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:15:15.728: INFO: Waiting for pod downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:15:15.731: INFO: Pod downwardapi-volume-77e5c55c-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:15:15.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1302" for this suite.
May 23 20:15:21.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:15:21.813: INFO: namespace downward-api-1302 deletion completed in 6.079645332s

• [SLOW TEST:10.174 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:15:21.814: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-7df644c2-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:15:21.840: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe" in namespace "projected-7453" to be "success or failure"
May 23 20:15:21.845: INFO: Pod "pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.641283ms
May 23 20:15:23.854: INFO: Pod "pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013492708s
May 23 20:15:25.892: INFO: Pod "pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051993894s
STEP: Saw pod success
May 23 20:15:25.893: INFO: Pod "pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:15:25.897: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:15:25.936: INFO: Waiting for pod pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:15:25.938: INFO: Pod pod-projected-configmaps-7df69129-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:15:25.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7453" for this suite.
May 23 20:15:31.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:15:32.038: INFO: namespace projected-7453 deletion completed in 6.096627463s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:15:32.038: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3983
May 23 20:15:36.074: INFO: Started pod liveness-exec in namespace container-probe-3983
STEP: checking the pod's current state and verifying that restartCount is present
May 23 20:15:36.081: INFO: Initial restart count of pod liveness-exec is 0
May 23 20:16:20.239: INFO: Restart count of pod container-probe-3983/liveness-exec is now 1 (44.157535998s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:16:20.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3983" for this suite.
May 23 20:16:26.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:16:26.352: INFO: namespace container-probe-3983 deletion completed in 6.074305253s

• [SLOW TEST:54.313 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:16:26.352: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 23 20:16:26.376: INFO: Waiting up to 5m0s for pod "downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-5224" to be "success or failure"
May 23 20:16:26.380: INFO: Pod "downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.83634ms
May 23 20:16:28.391: INFO: Pod "downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014712137s
STEP: Saw pod success
May 23 20:16:28.391: INFO: Pod "downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:16:28.393: INFO: Trying to get logs from node worker-1 pod downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 20:16:28.407: INFO: Waiting for pod downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:16:28.409: INFO: Pod downward-api-a46df594-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:16:28.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5224" for this suite.
May 23 20:16:34.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:16:34.517: INFO: namespace downward-api-5224 deletion completed in 6.105385538s

• [SLOW TEST:8.165 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:16:34.519: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:16:34.554: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-9470" to be "success or failure"
May 23 20:16:34.559: INFO: Pod "downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.942155ms
May 23 20:16:36.566: INFO: Pod "downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011869293s
May 23 20:16:38.572: INFO: Pod "downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017749038s
STEP: Saw pod success
May 23 20:16:38.572: INFO: Pod "downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:16:38.578: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:16:38.627: INFO: Waiting for pod downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:16:38.630: INFO: Pod downwardapi-volume-a94d928a-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:16:38.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9470" for this suite.
May 23 20:16:44.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:16:44.726: INFO: namespace downward-api-9470 deletion completed in 6.092804555s

• [SLOW TEST:10.207 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:16:44.726: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 20:16:44.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-3558'
May 23 20:16:45.330: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 23 20:16:45.331: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
May 23 20:16:47.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3558'
May 23 20:16:47.441: INFO: stderr: ""
May 23 20:16:47.441: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:16:47.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3558" for this suite.
May 23 20:17:09.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:17:09.575: INFO: namespace kubectl-3558 deletion completed in 22.128523028s

• [SLOW TEST:24.849 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:17:09.576: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-be317215-7d97-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:17:09.603: INFO: Waiting up to 5m0s for pod "pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe" in namespace "secrets-207" to be "success or failure"
May 23 20:17:09.607: INFO: Pod "pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232187ms
May 23 20:17:11.613: INFO: Pod "pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01045355s
May 23 20:17:13.620: INFO: Pod "pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017132878s
STEP: Saw pod success
May 23 20:17:13.620: INFO: Pod "pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:17:13.625: INFO: Trying to get logs from node worker-1 pod pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe container secret-env-test: <nil>
STEP: delete the pod
May 23 20:17:13.661: INFO: Waiting for pod pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:17:13.665: INFO: Pod pod-secrets-be31c9eb-7d97-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:17:13.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-207" for this suite.
May 23 20:17:19.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:17:19.726: INFO: namespace secrets-207 deletion completed in 6.057987471s

• [SLOW TEST:10.150 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:17:19.729: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 23 20:17:24.407: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c4496e0e-7d97-11e9-b22f-2a454b6ec3fe"
May 23 20:17:24.407: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c4496e0e-7d97-11e9-b22f-2a454b6ec3fe" in namespace "pods-6964" to be "terminated due to deadline exceeded"
May 23 20:17:24.412: INFO: Pod "pod-update-activedeadlineseconds-c4496e0e-7d97-11e9-b22f-2a454b6ec3fe": Phase="Running", Reason="", readiness=true. Elapsed: 4.955591ms
May 23 20:17:26.418: INFO: Pod "pod-update-activedeadlineseconds-c4496e0e-7d97-11e9-b22f-2a454b6ec3fe": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.011028127s
May 23 20:17:26.418: INFO: Pod "pod-update-activedeadlineseconds-c4496e0e-7d97-11e9-b22f-2a454b6ec3fe" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:17:26.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6964" for this suite.
May 23 20:17:32.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:17:32.550: INFO: namespace pods-6964 deletion completed in 6.126029872s

• [SLOW TEST:12.821 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:17:32.551: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 23 20:17:32.620: INFO: namespace kubectl-721
May 23 20:17:32.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-721'
May 23 20:17:32.737: INFO: stderr: ""
May 23 20:17:32.737: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 23 20:17:33.740: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:17:33.740: INFO: Found 0 / 1
May 23 20:17:34.742: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:17:34.742: INFO: Found 1 / 1
May 23 20:17:34.742: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 23 20:17:34.745: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:17:34.745: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 23 20:17:34.745: INFO: wait on redis-master startup in kubectl-721 
May 23 20:17:34.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 logs redis-master-6vb55 redis-master --namespace=kubectl-721'
May 23 20:17:34.848: INFO: stderr: ""
May 23 20:17:34.848: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 May 20:17:34.085 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 May 20:17:34.085 # Server started, Redis version 3.2.12\n1:M 23 May 20:17:34.086 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 May 20:17:34.086 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 23 20:17:34.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-721'
May 23 20:17:34.913: INFO: stderr: ""
May 23 20:17:34.913: INFO: stdout: "service/rm2 exposed\n"
May 23 20:17:34.917: INFO: Service rm2 in namespace kubectl-721 found.
STEP: exposing service
May 23 20:17:36.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-721'
May 23 20:17:37.038: INFO: stderr: ""
May 23 20:17:37.038: INFO: stdout: "service/rm3 exposed\n"
May 23 20:17:37.042: INFO: Service rm3 in namespace kubectl-721 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:17:39.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-721" for this suite.
May 23 20:18:01.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:18:01.178: INFO: namespace kubectl-721 deletion completed in 22.098194823s

• [SLOW TEST:28.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:18:01.178: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 23 20:18:09.242: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.243: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.371: INFO: Exec stderr: ""
May 23 20:18:09.371: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.371: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.466: INFO: Exec stderr: ""
May 23 20:18:09.466: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.466: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.545: INFO: Exec stderr: ""
May 23 20:18:09.545: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.545: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.629: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 23 20:18:09.629: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.629: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.707: INFO: Exec stderr: ""
May 23 20:18:09.707: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.707: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.778: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 23 20:18:09.778: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.778: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.859: INFO: Exec stderr: ""
May 23 20:18:09.860: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.860: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:09.935: INFO: Exec stderr: ""
May 23 20:18:09.935: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:09.935: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:10.020: INFO: Exec stderr: ""
May 23 20:18:10.020: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-366 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:18:10.020: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:18:10.104: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:18:10.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-366" for this suite.
May 23 20:19:00.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:19:00.202: INFO: namespace e2e-kubelet-etc-hosts-366 deletion completed in 50.096131071s

• [SLOW TEST:59.024 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:19:00.203: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0021b01b-7d98-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:19:00.250: INFO: Waiting up to 5m0s for pod "pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe" in namespace "secrets-820" to be "success or failure"
May 23 20:19:00.256: INFO: Pod "pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.137593ms
May 23 20:19:02.271: INFO: Pod "pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020944568s
STEP: Saw pod success
May 23 20:19:02.271: INFO: Pod "pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:19:02.276: INFO: Trying to get logs from node worker-1 pod pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:19:02.295: INFO: Waiting for pod pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:19:02.297: INFO: Pod pod-secrets-00251598-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:19:02.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-820" for this suite.
May 23 20:19:08.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:19:08.398: INFO: namespace secrets-820 deletion completed in 6.097669215s
STEP: Destroying namespace "secret-namespace-5778" for this suite.
May 23 20:19:14.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:19:14.539: INFO: namespace secret-namespace-5778 deletion completed in 6.140739963s

• [SLOW TEST:14.336 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:19:14.539: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 20:19:14.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8382'
May 23 20:19:14.612: INFO: stderr: ""
May 23 20:19:14.612: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
May 23 20:19:14.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete pods e2e-test-nginx-pod --namespace=kubectl-8382'
May 23 20:19:24.358: INFO: stderr: ""
May 23 20:19:24.358: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:19:24.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8382" for this suite.
May 23 20:19:30.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:19:30.462: INFO: namespace kubectl-8382 deletion completed in 6.10164682s

• [SLOW TEST:15.923 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:19:30.462: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6908
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 23 20:19:30.481: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 23 20:19:54.613: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.38.0.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6908 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:19:54.613: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:19:55.731: INFO: Found all expected endpoints: [netserver-0]
May 23 20:19:55.733: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.40.0.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6908 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:19:55.733: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:19:56.842: INFO: Found all expected endpoints: [netserver-1]
May 23 20:19:56.844: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.32.0.4 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6908 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:19:56.844: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:19:57.966: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:19:57.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6908" for this suite.
May 23 20:20:19.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:20:20.071: INFO: namespace pod-network-test-6908 deletion completed in 22.102005242s

• [SLOW TEST:49.609 seconds]
[sig-network] Networking
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:20:20.080: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 23 20:20:20.124: INFO: Number of nodes with available pods: 0
May 23 20:20:20.124: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:20:21.139: INFO: Number of nodes with available pods: 0
May 23 20:20:21.139: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:20:22.136: INFO: Number of nodes with available pods: 3
May 23 20:20:22.136: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 23 20:20:22.177: INFO: Number of nodes with available pods: 2
May 23 20:20:22.177: INFO: Node worker-1 is running more than one daemon pod
May 23 20:20:23.182: INFO: Number of nodes with available pods: 2
May 23 20:20:23.182: INFO: Node worker-1 is running more than one daemon pod
May 23 20:20:24.186: INFO: Number of nodes with available pods: 2
May 23 20:20:24.186: INFO: Node worker-1 is running more than one daemon pod
May 23 20:20:25.190: INFO: Number of nodes with available pods: 3
May 23 20:20:25.190: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8345, will wait for the garbage collector to delete the pods
May 23 20:20:25.273: INFO: Deleting DaemonSet.extensions daemon-set took: 12.649722ms
May 23 20:20:25.575: INFO: Terminating DaemonSet.extensions daemon-set pods took: 302.439351ms
May 23 20:20:36.180: INFO: Number of nodes with available pods: 0
May 23 20:20:36.181: INFO: Number of running nodes: 0, number of available pods: 0
May 23 20:20:36.185: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8345/daemonsets","resourceVersion":"12414"},"items":null}

May 23 20:20:36.190: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8345/pods","resourceVersion":"12414"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:20:36.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8345" for this suite.
May 23 20:20:42.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:20:42.297: INFO: namespace daemonsets-8345 deletion completed in 6.08117862s

• [SLOW TEST:22.217 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:20:42.297: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:20:42.318: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:20:43.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4020" for this suite.
May 23 20:20:49.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:20:49.630: INFO: namespace custom-resource-definition-4020 deletion completed in 6.135688443s

• [SLOW TEST:7.332 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:20:49.630: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-4142
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4142
STEP: Deleting pre-stop pod
May 23 20:21:02.714: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:21:02.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4142" for this suite.
May 23 20:21:40.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:21:40.818: INFO: namespace prestop-4142 deletion completed in 38.074654744s

• [SLOW TEST:51.188 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:21:40.818: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 23 20:21:40.926: INFO: Waiting up to 5m0s for pod "pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-8443" to be "success or failure"
May 23 20:21:40.929: INFO: Pod "pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.555961ms
May 23 20:21:42.934: INFO: Pod "pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008606087s
STEP: Saw pod success
May 23 20:21:42.935: INFO: Pod "pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:21:42.937: INFO: Trying to get logs from node worker-1 pod pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:21:42.956: INFO: Waiting for pod pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:21:42.958: INFO: Pod pod-5fe8d4d0-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:21:42.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8443" for this suite.
May 23 20:21:48.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:21:49.047: INFO: namespace emptydir-8443 deletion completed in 6.085315651s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:21:49.047: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 23 20:21:49.073: INFO: Waiting up to 5m0s for pod "pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-9038" to be "success or failure"
May 23 20:21:49.077: INFO: Pod "pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.482034ms
May 23 20:21:51.082: INFO: Pod "pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009067592s
May 23 20:21:53.088: INFO: Pod "pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015238219s
STEP: Saw pod success
May 23 20:21:53.089: INFO: Pod "pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:21:53.094: INFO: Trying to get logs from node worker-1 pod pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:21:53.118: INFO: Waiting for pod pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:21:53.121: INFO: Pod pod-64c5ba22-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:21:53.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9038" for this suite.
May 23 20:21:59.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:21:59.213: INFO: namespace emptydir-9038 deletion completed in 6.089626631s

• [SLOW TEST:10.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:21:59.213: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:21:59.286: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-3667" to be "success or failure"
May 23 20:21:59.291: INFO: Pod "downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.767899ms
May 23 20:22:01.295: INFO: Pod "downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009079977s
STEP: Saw pod success
May 23 20:22:01.295: INFO: Pod "downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:22:01.299: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:22:01.316: INFO: Waiting for pod downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:22:01.318: INFO: Pod downwardapi-volume-6adbe5b8-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:22:01.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3667" for this suite.
May 23 20:22:07.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:22:07.417: INFO: namespace downward-api-3667 deletion completed in 6.096667172s

• [SLOW TEST:8.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:22:07.417: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
May 23 20:22:07.443: INFO: Waiting up to 5m0s for pod "var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe" in namespace "var-expansion-8933" to be "success or failure"
May 23 20:22:07.449: INFO: Pod "var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.146705ms
May 23 20:22:09.460: INFO: Pod "var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0165951s
May 23 20:22:11.463: INFO: Pod "var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020136307s
STEP: Saw pod success
May 23 20:22:11.463: INFO: Pod "var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:22:11.465: INFO: Trying to get logs from node worker-1 pod var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 20:22:11.482: INFO: Waiting for pod var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:22:11.484: INFO: Pod var-expansion-6fb889d0-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:22:11.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8933" for this suite.
May 23 20:22:17.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:22:17.580: INFO: namespace var-expansion-8933 deletion completed in 6.089031254s

• [SLOW TEST:10.163 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:22:17.581: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9898/configmap-test-75c74071-7d98-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:22:17.608: INFO: Waiting up to 5m0s for pod "pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe" in namespace "configmap-9898" to be "success or failure"
May 23 20:22:17.617: INFO: Pod "pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.945319ms
May 23 20:22:19.619: INFO: Pod "pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011339353s
May 23 20:22:21.626: INFO: Pod "pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017745128s
STEP: Saw pod success
May 23 20:22:21.626: INFO: Pod "pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:22:21.631: INFO: Trying to get logs from node worker-1 pod pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe container env-test: <nil>
STEP: delete the pod
May 23 20:22:21.671: INFO: Waiting for pod pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:22:21.673: INFO: Pod pod-configmaps-75c79422-7d98-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:22:21.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9898" for this suite.
May 23 20:22:27.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:22:27.766: INFO: namespace configmap-9898 deletion completed in 6.090292618s

• [SLOW TEST:10.186 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:22:27.766: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 23 20:22:35.822: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:35.825: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:37.835: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:37.840: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:39.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:39.828: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:41.835: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:41.850: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:43.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:43.835: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:45.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:45.830: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:47.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:47.843: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:49.826: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:49.834: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:51.835: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:51.841: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:53.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:53.831: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:55.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:55.827: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:57.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:57.829: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:22:59.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:22:59.831: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:23:01.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:23:01.828: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:23:03.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:23:03.833: INFO: Pod pod-with-prestop-exec-hook still exists
May 23 20:23:05.842: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 23 20:23:05.844: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:23:05.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7023" for this suite.
May 23 20:23:27.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:23:27.924: INFO: namespace container-lifecycle-hook-7023 deletion completed in 22.07390505s

• [SLOW TEST:60.158 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:23:27.926: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 23 20:26:16.057: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:16.061: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:18.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:18.067: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:20.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:20.068: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:22.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:22.066: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:24.062: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:24.068: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:26.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:26.067: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:28.077: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:28.084: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:30.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:30.067: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:32.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:32.068: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:34.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:34.077: INFO: Pod pod-with-poststart-exec-hook still exists
May 23 20:26:36.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 23 20:26:36.067: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:26:36.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5575" for this suite.
May 23 20:26:58.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:26:58.156: INFO: namespace container-lifecycle-hook-5575 deletion completed in 22.082766592s

• [SLOW TEST:210.230 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:26:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-1d039438-7d99-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:26:58.181: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe" in namespace "projected-6730" to be "success or failure"
May 23 20:26:58.183: INFO: Pod "pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.948712ms
May 23 20:27:00.190: INFO: Pod "pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009244798s
May 23 20:27:02.196: INFO: Pod "pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015735055s
STEP: Saw pod success
May 23 20:27:02.197: INFO: Pod "pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:27:02.202: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:27:02.241: INFO: Waiting for pod pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:27:02.245: INFO: Pod pod-projected-secrets-1d03e93c-7d99-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:27:02.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6730" for this suite.
May 23 20:27:08.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:27:08.301: INFO: namespace projected-6730 deletion completed in 6.051604943s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:27:08.301: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 20:27:08.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-245'
May 23 20:27:08.864: INFO: stderr: ""
May 23 20:27:08.864: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 23 20:27:13.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pod e2e-test-nginx-pod --namespace=kubectl-245 -o json'
May 23 20:27:13.995: INFO: stderr: ""
May 23 20:27:13.995: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-23T20:27:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-245\",\n        \"resourceVersion\": \"13346\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-245/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2361d05b-7d99-11e9-a2d7-080027c2be11\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2r89r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2r89r\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2r89r\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-23T20:27:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-23T20:27:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-23T20:27:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-23T20:27:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://933d70d7f7e016cb307b9ab345d3f2dc43ac9a79fe30df45b8b028649a149cce\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-23T20:27:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.5.101\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.40.0.2\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-23T20:27:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 23 20:27:13.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 replace -f - --namespace=kubectl-245'
May 23 20:27:14.103: INFO: stderr: ""
May 23 20:27:14.103: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
May 23 20:27:14.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete pods e2e-test-nginx-pod --namespace=kubectl-245'
May 23 20:27:24.320: INFO: stderr: ""
May 23 20:27:24.320: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:27:24.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-245" for this suite.
May 23 20:27:30.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:27:30.444: INFO: namespace kubectl-245 deletion completed in 6.118318828s

• [SLOW TEST:22.143 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:27:30.444: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 23 20:27:30.469: INFO: Waiting up to 5m0s for pod "pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-3662" to be "success or failure"
May 23 20:27:30.472: INFO: Pod "pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.570066ms
May 23 20:27:32.476: INFO: Pod "pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00760385s
May 23 20:27:34.483: INFO: Pod "pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013746222s
STEP: Saw pod success
May 23 20:27:34.483: INFO: Pod "pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:27:34.490: INFO: Trying to get logs from node worker-1 pod pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:27:34.548: INFO: Waiting for pod pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:27:34.549: INFO: Pod pod-304249a9-7d99-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:27:34.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3662" for this suite.
May 23 20:27:40.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:27:40.645: INFO: namespace emptydir-3662 deletion completed in 6.093601007s

• [SLOW TEST:10.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:27:40.647: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 23 20:27:40.680: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3677,SelfLink:/api/v1/namespaces/watch-3677/configmaps/e2e-watch-test-resource-version,UID:3659f86e-7d99-11e9-a2d7-080027c2be11,ResourceVersion:13476,Generation:0,CreationTimestamp:2019-05-23 20:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 23 20:27:40.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3677,SelfLink:/api/v1/namespaces/watch-3677/configmaps/e2e-watch-test-resource-version,UID:3659f86e-7d99-11e9-a2d7-080027c2be11,ResourceVersion:13477,Generation:0,CreationTimestamp:2019-05-23 20:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:27:40.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3677" for this suite.
May 23 20:27:46.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:27:46.767: INFO: namespace watch-3677 deletion completed in 6.084775974s

• [SLOW TEST:6.120 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:27:46.767: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
May 23 20:27:48.817: INFO: Pod pod-hostip-39fd3d71-7d99-11e9-b22f-2a454b6ec3fe has hostIP: 192.168.5.101
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:27:48.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9910" for this suite.
May 23 20:28:10.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:28:10.946: INFO: namespace pods-9910 deletion completed in 22.121976504s

• [SLOW TEST:24.179 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:28:10.946: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 23 20:28:13.528: INFO: Successfully updated pod "pod-update-48683ddf-7d99-11e9-b22f-2a454b6ec3fe"
STEP: verifying the updated pod is in kubernetes
May 23 20:28:13.539: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:28:13.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4365" for this suite.
May 23 20:28:35.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:28:35.686: INFO: namespace pods-4365 deletion completed in 22.13851672s

• [SLOW TEST:24.740 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:28:35.686: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 23 20:28:35.957: INFO: Pod name wrapped-volume-race-5733c6c4-7d99-11e9-b22f-2a454b6ec3fe: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5733c6c4-7d99-11e9-b22f-2a454b6ec3fe in namespace emptydir-wrapper-7176, will wait for the garbage collector to delete the pods
May 23 20:28:58.073: INFO: Deleting ReplicationController wrapped-volume-race-5733c6c4-7d99-11e9-b22f-2a454b6ec3fe took: 15.062082ms
May 23 20:28:58.373: INFO: Terminating ReplicationController wrapped-volume-race-5733c6c4-7d99-11e9-b22f-2a454b6ec3fe pods took: 300.350909ms
STEP: Creating RC which spawns configmap-volume pods
May 23 20:29:37.494: INFO: Pod name wrapped-volume-race-7bf6acfe-7d99-11e9-b22f-2a454b6ec3fe: Found 0 pods out of 5
May 23 20:29:42.505: INFO: Pod name wrapped-volume-race-7bf6acfe-7d99-11e9-b22f-2a454b6ec3fe: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7bf6acfe-7d99-11e9-b22f-2a454b6ec3fe in namespace emptydir-wrapper-7176, will wait for the garbage collector to delete the pods
May 23 20:29:52.593: INFO: Deleting ReplicationController wrapped-volume-race-7bf6acfe-7d99-11e9-b22f-2a454b6ec3fe took: 12.638527ms
May 23 20:29:52.894: INFO: Terminating ReplicationController wrapped-volume-race-7bf6acfe-7d99-11e9-b22f-2a454b6ec3fe pods took: 300.530745ms
STEP: Creating RC which spawns configmap-volume pods
May 23 20:30:37.506: INFO: Pod name wrapped-volume-race-9fbd12c3-7d99-11e9-b22f-2a454b6ec3fe: Found 0 pods out of 5
May 23 20:30:42.519: INFO: Pod name wrapped-volume-race-9fbd12c3-7d99-11e9-b22f-2a454b6ec3fe: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9fbd12c3-7d99-11e9-b22f-2a454b6ec3fe in namespace emptydir-wrapper-7176, will wait for the garbage collector to delete the pods
May 23 20:30:54.624: INFO: Deleting ReplicationController wrapped-volume-race-9fbd12c3-7d99-11e9-b22f-2a454b6ec3fe took: 7.998621ms
May 23 20:30:54.924: INFO: Terminating ReplicationController wrapped-volume-race-9fbd12c3-7d99-11e9-b22f-2a454b6ec3fe pods took: 300.428326ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:31:37.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7176" for this suite.
May 23 20:31:43.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:31:43.795: INFO: namespace emptydir-wrapper-7176 deletion completed in 6.094808885s

• [SLOW TEST:188.109 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:31:43.796: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
May 23 20:31:44.217: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 23 20:31:46.324: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:31:48.327: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:31:50.329: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:31:52.331: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:31:54.326: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:31:56.328: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694240304, loc:(*time.Location)(0x8a140e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 23 20:32:10.786: INFO: Waited 12.440627412s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:32:11.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5129" for this suite.
May 23 20:32:17.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:32:17.437: INFO: namespace aggregator-5129 deletion completed in 6.191044281s

• [SLOW TEST:33.642 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:32:17.438: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6995
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 23 20:32:17.458: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 23 20:32:39.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.3:8080/dial?request=hostName&protocol=udp&host=10.32.0.4&port=8081&tries=1'] Namespace:pod-network-test-6995 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:32:39.615: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:32:39.779: INFO: Waiting for endpoints: map[]
May 23 20:32:39.781: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.3:8080/dial?request=hostName&protocol=udp&host=10.38.0.2&port=8081&tries=1'] Namespace:pod-network-test-6995 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:32:39.781: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:32:39.854: INFO: Waiting for endpoints: map[]
May 23 20:32:39.857: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.3:8080/dial?request=hostName&protocol=udp&host=10.40.0.2&port=8081&tries=1'] Namespace:pod-network-test-6995 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 23 20:32:39.857: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
May 23 20:32:39.947: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:32:39.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6995" for this suite.
May 23 20:33:01.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:02.059: INFO: namespace pod-network-test-6995 deletion completed in 22.109568367s

• [SLOW TEST:44.621 seconds]
[sig-network] Networking
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:02.059: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f5eb8c4b-7d99-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:33:02.091: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe" in namespace "projected-2371" to be "success or failure"
May 23 20:33:02.096: INFO: Pod "pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.246766ms
May 23 20:33:04.102: INFO: Pod "pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010895232s
May 23 20:33:06.107: INFO: Pod "pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016219379s
STEP: Saw pod success
May 23 20:33:06.107: INFO: Pod "pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:33:06.112: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:33:06.155: INFO: Waiting for pod pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:33:06.161: INFO: Pod pod-projected-configmaps-f5ebe16f-7d99-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:06.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2371" for this suite.
May 23 20:33:12.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:12.275: INFO: namespace projected-2371 deletion completed in 6.110283078s

• [SLOW TEST:10.216 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:12.275: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
May 23 20:33:12.295: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-041930030 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:12.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1896" for this suite.
May 23 20:33:18.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:18.433: INFO: namespace kubectl-1896 deletion completed in 6.082041945s

• [SLOW TEST:6.158 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:18.435: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:33:18.455: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 23 20:33:18.460: INFO: Pod name sample-pod: Found 0 pods out of 1
May 23 20:33:23.469: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 23 20:33:23.469: INFO: Creating deployment "test-rolling-update-deployment"
May 23 20:33:23.477: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 23 20:33:23.491: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 23 20:33:25.498: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 23 20:33:25.499: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 23 20:33:25.503: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9213,SelfLink:/apis/apps/v1/namespaces/deployment-9213/deployments/test-rolling-update-deployment,UID:02ad9bd4-7d9a-11e9-a2d7-080027c2be11,ResourceVersion:15142,Generation:1,CreationTimestamp:2019-05-23 20:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-23 20:33:23 +0000 UTC 2019-05-23 20:33:23 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-23 20:33:25 +0000 UTC 2019-05-23 20:33:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 23 20:33:25.505: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-9213,SelfLink:/apis/apps/v1/namespaces/deployment-9213/replicasets/test-rolling-update-deployment-67599b4d9,UID:02b0edbb-7d9a-11e9-a2d7-080027c2be11,ResourceVersion:15132,Generation:1,CreationTimestamp:2019-05-23 20:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 02ad9bd4-7d9a-11e9-a2d7-080027c2be11 0xc002bbb5a0 0xc002bbb5a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 23 20:33:25.505: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 23 20:33:25.505: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9213,SelfLink:/apis/apps/v1/namespaces/deployment-9213/replicasets/test-rolling-update-controller,UID:ffb047d6-7d99-11e9-a2d7-080027c2be11,ResourceVersion:15141,Generation:2,CreationTimestamp:2019-05-23 20:33:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 02ad9bd4-7d9a-11e9-a2d7-080027c2be11 0xc002bbb457 0xc002bbb458}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 20:33:25.506: INFO: Pod "test-rolling-update-deployment-67599b4d9-ksmvw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-ksmvw,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-9213,SelfLink:/api/v1/namespaces/deployment-9213/pods/test-rolling-update-deployment-67599b4d9-ksmvw,UID:02b15e34-7d9a-11e9-a2d7-080027c2be11,ResourceVersion:15131,Generation:0,CreationTimestamp:2019-05-23 20:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 02b0edbb-7d9a-11e9-a2d7-080027c2be11 0xc002f30300 0xc002f30301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rwl5x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rwl5x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rwl5x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f30370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f30390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:33:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:33:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:33:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:33:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.102,PodIP:10.38.0.2,StartTime:2019-05-23 20:33:23 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-23 20:33:24 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3808e3ae4004e7bf2232313c7c95909f2f052c6b58bde6ce643922fdaba46035}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:25.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9213" for this suite.
May 23 20:33:31.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:31.641: INFO: namespace deployment-9213 deletion completed in 6.132876s

• [SLOW TEST:13.206 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:31.641: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-078f9443-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:33:31.689: INFO: Waiting up to 5m0s for pod "pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "secrets-9255" to be "success or failure"
May 23 20:33:31.693: INFO: Pod "pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943152ms
May 23 20:33:33.710: INFO: Pod "pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021362833s
STEP: Saw pod success
May 23 20:33:33.710: INFO: Pod "pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:33:33.715: INFO: Trying to get logs from node worker-1 pod pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:33:33.740: INFO: Waiting for pod pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:33:33.742: INFO: Pod pod-secrets-07904605-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:33.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9255" for this suite.
May 23 20:33:39.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:39.837: INFO: namespace secrets-9255 deletion completed in 6.092385875s

• [SLOW TEST:8.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:39.838: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-0c6f8e8b-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:33:39.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "configmap-2694" to be "success or failure"
May 23 20:33:39.871: INFO: Pod "pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015012ms
May 23 20:33:41.875: INFO: Pod "pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010346464s
STEP: Saw pod success
May 23 20:33:41.875: INFO: Pod "pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:33:41.877: INFO: Trying to get logs from node worker-1 pod pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:33:41.894: INFO: Waiting for pod pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:33:41.910: INFO: Pod pod-configmaps-0c6fd984-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:41.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2694" for this suite.
May 23 20:33:47.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:48.001: INFO: namespace configmap-2694 deletion completed in 6.087559127s

• [SLOW TEST:8.163 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:48.001: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-114cf79b-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:33:48.025: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "projected-3407" to be "success or failure"
May 23 20:33:48.028: INFO: Pod "pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.132884ms
May 23 20:33:50.033: INFO: Pod "pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008462432s
STEP: Saw pod success
May 23 20:33:50.033: INFO: Pod "pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:33:50.035: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe container projected-secret-volume-test: <nil>
STEP: delete the pod
May 23 20:33:50.046: INFO: Waiting for pod pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:33:50.048: INFO: Pod pod-projected-secrets-114d3857-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:50.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3407" for this suite.
May 23 20:33:56.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:33:56.116: INFO: namespace projected-3407 deletion completed in 6.065278418s

• [SLOW TEST:8.115 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:33:56.117: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9206/configmap-test-162c926f-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:33:56.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "configmap-9206" to be "success or failure"
May 23 20:33:56.223: INFO: Pod "pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.69622ms
May 23 20:33:58.229: INFO: Pod "pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014963631s
STEP: Saw pod success
May 23 20:33:58.229: INFO: Pod "pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:33:58.247: INFO: Trying to get logs from node worker-1 pod pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe container env-test: <nil>
STEP: delete the pod
May 23 20:33:58.265: INFO: Waiting for pod pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:33:58.266: INFO: Pod pod-configmaps-162d37f8-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:33:58.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9206" for this suite.
May 23 20:34:04.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:34:04.360: INFO: namespace configmap-9206 deletion completed in 6.092344976s

• [SLOW TEST:8.244 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:34:04.362: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-72l7
STEP: Creating a pod to test atomic-volume-subpath
May 23 20:34:04.389: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-72l7" in namespace "subpath-7287" to be "success or failure"
May 23 20:34:04.392: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.469698ms
May 23 20:34:06.399: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 2.010352011s
May 23 20:34:08.407: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 4.018587847s
May 23 20:34:10.411: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 6.022151412s
May 23 20:34:12.417: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 8.028546152s
May 23 20:34:14.423: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 10.034755383s
May 23 20:34:16.443: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 12.054002571s
May 23 20:34:18.445: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 14.056045108s
May 23 20:34:20.450: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 16.061819769s
May 23 20:34:22.456: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 18.06756551s
May 23 20:34:24.462: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 20.073504886s
May 23 20:34:26.469: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Running", Reason="", readiness=true. Elapsed: 22.080366778s
May 23 20:34:28.496: INFO: Pod "pod-subpath-test-configmap-72l7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.107676652s
STEP: Saw pod success
May 23 20:34:28.496: INFO: Pod "pod-subpath-test-configmap-72l7" satisfied condition "success or failure"
May 23 20:34:28.507: INFO: Trying to get logs from node worker-1 pod pod-subpath-test-configmap-72l7 container test-container-subpath-configmap-72l7: <nil>
STEP: delete the pod
May 23 20:34:28.565: INFO: Waiting for pod pod-subpath-test-configmap-72l7 to disappear
May 23 20:34:28.567: INFO: Pod pod-subpath-test-configmap-72l7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-72l7
May 23 20:34:28.567: INFO: Deleting pod "pod-subpath-test-configmap-72l7" in namespace "subpath-7287"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:34:28.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7287" for this suite.
May 23 20:34:34.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:34:34.647: INFO: namespace subpath-7287 deletion completed in 6.076978019s

• [SLOW TEST:30.285 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:34:34.647: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 23 20:34:34.672: INFO: Waiting up to 5m0s for pod "downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-7813" to be "success or failure"
May 23 20:34:34.679: INFO: Pod "downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.256657ms
May 23 20:34:36.685: INFO: Pod "downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013148309s
May 23 20:34:38.691: INFO: Pod "downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019149366s
STEP: Saw pod success
May 23 20:34:38.691: INFO: Pod "downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:34:38.697: INFO: Trying to get logs from node worker-2 pod downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 20:34:38.729: INFO: Waiting for pod downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:34:38.731: INFO: Pod downward-api-2d1aab13-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:34:38.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7813" for this suite.
May 23 20:34:44.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:34:44.830: INFO: namespace downward-api-7813 deletion completed in 6.096278638s

• [SLOW TEST:10.183 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:34:44.830: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-332dc356-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:34:44.866: INFO: Waiting up to 5m0s for pod "pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "secrets-2467" to be "success or failure"
May 23 20:34:44.867: INFO: Pod "pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.532342ms
May 23 20:34:46.874: INFO: Pod "pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008273568s
May 23 20:34:48.880: INFO: Pod "pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014458792s
STEP: Saw pod success
May 23 20:34:48.880: INFO: Pod "pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:34:48.886: INFO: Trying to get logs from node worker-1 pod pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:34:48.924: INFO: Waiting for pod pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:34:48.930: INFO: Pod pod-secrets-332e14ab-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:34:48.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2467" for this suite.
May 23 20:34:54.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:34:55.026: INFO: namespace secrets-2467 deletion completed in 6.091403455s

• [SLOW TEST:10.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:34:55.026: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-39416d72-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:34:55.061: INFO: Waiting up to 5m0s for pod "pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "configmap-9702" to be "success or failure"
May 23 20:34:55.064: INFO: Pod "pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.464154ms
May 23 20:34:57.069: INFO: Pod "pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007395073s
May 23 20:34:59.073: INFO: Pod "pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012224039s
STEP: Saw pod success
May 23 20:34:59.073: INFO: Pod "pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:34:59.076: INFO: Trying to get logs from node worker-1 pod pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:34:59.092: INFO: Waiting for pod pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:34:59.094: INFO: Pod pod-configmaps-3941c240-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:34:59.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9702" for this suite.
May 23 20:35:05.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:35:05.204: INFO: namespace configmap-9702 deletion completed in 6.108147147s

• [SLOW TEST:10.179 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:35:05.205: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3f518438-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:35:05.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "configmap-8052" to be "success or failure"
May 23 20:35:05.233: INFO: Pod "pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.452272ms
May 23 20:35:07.246: INFO: Pod "pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015345511s
May 23 20:35:09.252: INFO: Pod "pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020757478s
STEP: Saw pod success
May 23 20:35:09.252: INFO: Pod "pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:35:09.256: INFO: Trying to get logs from node worker-1 pod pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:35:09.291: INFO: Waiting for pod pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:35:09.296: INFO: Pod pod-configmaps-3f51d10b-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:35:09.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8052" for this suite.
May 23 20:35:15.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:35:15.349: INFO: namespace configmap-8052 deletion completed in 6.050124647s

• [SLOW TEST:10.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:35:15.351: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:35:15.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 version'
May 23 20:35:15.412: INFO: stderr: ""
May 23 20:35:15.412: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.2\", GitCommit:\"66049e3b21efe110454d67df4fa62b08ea79a19b\", GitTreeState:\"clean\", BuildDate:\"2019-05-16T16:23:09Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.2\", GitCommit:\"66049e3b21efe110454d67df4fa62b08ea79a19b\", GitTreeState:\"clean\", BuildDate:\"2019-05-16T16:14:56Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:35:15.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8430" for this suite.
May 23 20:35:21.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:35:21.488: INFO: namespace kubectl-8430 deletion completed in 6.074671223s

• [SLOW TEST:6.138 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:35:21.489: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-4906ced6-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4906ced6-7d9a-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:36:46.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-264" for this suite.
May 23 20:37:08.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:37:08.454: INFO: namespace configmap-264 deletion completed in 22.097151141s

• [SLOW TEST:106.966 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:37:08.455: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-88d0787d-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:37:12.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4451" for this suite.
May 23 20:37:34.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:37:34.656: INFO: namespace configmap-4451 deletion completed in 22.068064214s

• [SLOW TEST:26.202 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:37:34.657: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9536
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-9536
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9536
May 23 20:37:34.694: INFO: Found 0 stateful pods, waiting for 1
May 23 20:37:44.704: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 23 20:37:44.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:37:44.912: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:37:44.912: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:37:44.912: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:37:44.914: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 23 20:37:54.920: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:37:54.920: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:37:54.951: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:37:54.951: INFO: ss-0  worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:37:54.951: INFO: ss-1            Pending         []
May 23 20:37:54.951: INFO: 
May 23 20:37:54.951: INFO: StatefulSet ss has not reached scale 3, at 2
May 23 20:37:55.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985218732s
May 23 20:37:56.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981168922s
May 23 20:37:57.970: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975652975s
May 23 20:37:58.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967529774s
May 23 20:37:59.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960740406s
May 23 20:38:00.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.950202821s
May 23 20:38:02.000: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.944246266s
May 23 20:38:03.008: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.937280101s
May 23 20:38:04.016: INFO: Verifying statefulset ss doesn't scale past 3 for another 929.771244ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9536
May 23 20:38:05.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:38:05.178: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 20:38:05.178: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:38:05.178: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:38:05.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:38:05.330: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 23 20:38:05.331: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:38:05.331: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:38:05.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:38:05.471: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 23 20:38:05.471: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:38:05.471: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:38:05.473: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 23 20:38:15.502: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 23 20:38:15.502: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 23 20:38:15.502: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 23 20:38:15.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:38:15.689: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:38:15.689: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:38:15.689: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:38:15.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:38:15.837: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:38:15.837: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:38:15.837: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:38:15.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-9536 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:38:16.004: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:38:16.004: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:38:16.004: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:38:16.004: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:38:16.007: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 23 20:38:26.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:38:26.023: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:38:26.023: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:38:26.046: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 23 20:38:26.046: INFO: ss-0  worker-1        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:26.046: INFO: ss-1  worker-2        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:26.046: INFO: ss-2  controlplane-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:26.046: INFO: 
May 23 20:38:26.046: INFO: StatefulSet ss has not reached scale 0, at 3
May 23 20:38:27.053: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 23 20:38:27.053: INFO: ss-0  worker-1        Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:27.053: INFO: ss-1  worker-2        Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:27.053: INFO: ss-2  controlplane-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:27.053: INFO: 
May 23 20:38:27.053: INFO: StatefulSet ss has not reached scale 0, at 3
May 23 20:38:28.066: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:28.066: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:28.066: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:28.066: INFO: 
May 23 20:38:28.066: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:29.072: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:29.072: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:29.072: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:29.072: INFO: 
May 23 20:38:29.072: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:30.084: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:30.084: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:30.084: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:30.084: INFO: 
May 23 20:38:30.084: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:31.149: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:31.149: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:31.149: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:31.149: INFO: 
May 23 20:38:31.149: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:32.162: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:32.162: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:32.162: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:32.162: INFO: 
May 23 20:38:32.162: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:33.169: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:33.169: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:33.169: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:33.169: INFO: 
May 23 20:38:33.169: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:34.183: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:34.183: INFO: ss-0  worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:34 +0000 UTC  }]
May 23 20:38:34.183: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:34.183: INFO: 
May 23 20:38:34.183: INFO: StatefulSet ss has not reached scale 0, at 2
May 23 20:38:35.189: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
May 23 20:38:35.189: INFO: ss-1  worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:38:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:37:54 +0000 UTC  }]
May 23 20:38:35.189: INFO: 
May 23 20:38:35.189: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9536
May 23 20:38:36.199: INFO: Scaling statefulset ss to 0
May 23 20:38:36.217: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 23 20:38:36.223: INFO: Deleting all statefulset in ns statefulset-9536
May 23 20:38:36.228: INFO: Scaling statefulset ss to 0
May 23 20:38:36.247: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:38:36.252: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:38:36.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9536" for this suite.
May 23 20:38:42.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:38:42.365: INFO: namespace statefulset-9536 deletion completed in 6.086842091s

• [SLOW TEST:67.709 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:38:42.367: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-c0c1c634-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:38:42.392: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "configmap-3865" to be "success or failure"
May 23 20:38:42.394: INFO: Pod "pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065043ms
May 23 20:38:44.396: INFO: Pod "pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003861947s
STEP: Saw pod success
May 23 20:38:44.396: INFO: Pod "pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:38:44.397: INFO: Trying to get logs from node worker-1 pod pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe container configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:38:44.407: INFO: Waiting for pod pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:38:44.409: INFO: Pod pod-configmaps-c0c207fb-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:38:44.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3865" for this suite.
May 23 20:38:50.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:38:50.503: INFO: namespace configmap-3865 deletion completed in 6.092607423s

• [SLOW TEST:8.136 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:38:50.504: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:38:50.593: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:38:52.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8675" for this suite.
May 23 20:39:36.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:39:36.837: INFO: namespace pods-8675 deletion completed in 44.085929423s

• [SLOW TEST:46.333 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:39:36.838: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:39:36.891: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e13e6c1b-7d9a-11e9-a2d7-080027c2be11", Controller:(*bool)(0xc00233b736), BlockOwnerDeletion:(*bool)(0xc00233b737)}}
May 23 20:39:36.903: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e13c02fe-7d9a-11e9-a2d7-080027c2be11", Controller:(*bool)(0xc0031cf6fe), BlockOwnerDeletion:(*bool)(0xc0031cf6ff)}}
May 23 20:39:36.907: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e13ce3bd-7d9a-11e9-a2d7-080027c2be11", Controller:(*bool)(0xc00233b966), BlockOwnerDeletion:(*bool)(0xc00233b967)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:39:41.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3051" for this suite.
May 23 20:39:47.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:39:48.013: INFO: namespace gc-3051 deletion completed in 6.099077013s

• [SLOW TEST:11.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:39:48.014: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e7e2d7d4-7d9a-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 20:39:48.041: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe" in namespace "projected-6522" to be "success or failure"
May 23 20:39:48.043: INFO: Pod "pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9146ms
May 23 20:39:50.049: INFO: Pod "pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007924091s
May 23 20:39:52.062: INFO: Pod "pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021190868s
STEP: Saw pod success
May 23 20:39:52.062: INFO: Pod "pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:39:52.067: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 20:39:52.106: INFO: Waiting for pod pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:39:52.108: INFO: Pod pod-projected-configmaps-e7e32438-7d9a-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:39:52.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6522" for this suite.
May 23 20:39:58.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:39:58.201: INFO: namespace projected-6522 deletion completed in 6.090180183s

• [SLOW TEST:10.187 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:39:58.203: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-84dc8 in namespace proxy-6583
I0523 20:39:58.245454      15 runners.go:184] Created replication controller with name: proxy-service-84dc8, namespace: proxy-6583, replica count: 1
I0523 20:39:59.296467      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0523 20:40:00.296902      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0523 20:40:01.297594      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0523 20:40:02.298094      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:03.298519      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:04.298827      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:05.304361      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:06.307790      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:07.308499      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:08.308713      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0523 20:40:09.309072      15 runners.go:184] proxy-service-84dc8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 23 20:40:09.313: INFO: setup took 11.091420425s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 23 20:40:09.328: INFO: (0) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 14.179496ms)
May 23 20:40:09.328: INFO: (0) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 14.222043ms)
May 23 20:40:09.328: INFO: (0) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 14.575628ms)
May 23 20:40:09.329: INFO: (0) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 14.991473ms)
May 23 20:40:09.329: INFO: (0) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 15.446673ms)
May 23 20:40:09.329: INFO: (0) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 15.528649ms)
May 23 20:40:09.329: INFO: (0) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 16.136021ms)
May 23 20:40:09.335: INFO: (0) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 20.581416ms)
May 23 20:40:09.335: INFO: (0) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 21.4429ms)
May 23 20:40:09.340: INFO: (0) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 25.542661ms)
May 23 20:40:09.341: INFO: (0) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 27.428159ms)
May 23 20:40:09.344: INFO: (0) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 30.855219ms)
May 23 20:40:09.345: INFO: (0) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 31.920086ms)
May 23 20:40:09.346: INFO: (0) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 32.77197ms)
May 23 20:40:09.346: INFO: (0) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 32.370542ms)
May 23 20:40:09.347: INFO: (0) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 32.520809ms)
May 23 20:40:09.352: INFO: (1) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 4.548169ms)
May 23 20:40:09.352: INFO: (1) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 5.155603ms)
May 23 20:40:09.352: INFO: (1) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 5.403294ms)
May 23 20:40:09.353: INFO: (1) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.278745ms)
May 23 20:40:09.354: INFO: (1) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 6.336895ms)
May 23 20:40:09.354: INFO: (1) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 6.465731ms)
May 23 20:40:09.354: INFO: (1) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.39882ms)
May 23 20:40:09.354: INFO: (1) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 6.516889ms)
May 23 20:40:09.355: INFO: (1) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.973897ms)
May 23 20:40:09.355: INFO: (1) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 7.788735ms)
May 23 20:40:09.355: INFO: (1) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 7.707666ms)
May 23 20:40:09.355: INFO: (1) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 7.832207ms)
May 23 20:40:09.356: INFO: (1) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 8.902438ms)
May 23 20:40:09.356: INFO: (1) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.74555ms)
May 23 20:40:09.356: INFO: (1) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 8.957283ms)
May 23 20:40:09.357: INFO: (1) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 10.373432ms)
May 23 20:40:09.361: INFO: (2) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 3.603216ms)
May 23 20:40:09.361: INFO: (2) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 3.664136ms)
May 23 20:40:09.361: INFO: (2) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 3.731235ms)
May 23 20:40:09.361: INFO: (2) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 3.726512ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 6.171421ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 6.406479ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.727451ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 6.749108ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.739974ms)
May 23 20:40:09.364: INFO: (2) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.886485ms)
May 23 20:40:09.365: INFO: (2) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 7.523186ms)
May 23 20:40:09.367: INFO: (2) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 9.274197ms)
May 23 20:40:09.367: INFO: (2) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 9.336704ms)
May 23 20:40:09.367: INFO: (2) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 9.546991ms)
May 23 20:40:09.367: INFO: (2) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 9.79073ms)
May 23 20:40:09.367: INFO: (2) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 9.687778ms)
May 23 20:40:09.371: INFO: (3) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 3.544197ms)
May 23 20:40:09.372: INFO: (3) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.706715ms)
May 23 20:40:09.372: INFO: (3) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.924405ms)
May 23 20:40:09.372: INFO: (3) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 4.866084ms)
May 23 20:40:09.372: INFO: (3) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 5.081342ms)
May 23 20:40:09.373: INFO: (3) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.581184ms)
May 23 20:40:09.373: INFO: (3) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 5.790966ms)
May 23 20:40:09.373: INFO: (3) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.873526ms)
May 23 20:40:09.374: INFO: (3) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 6.744505ms)
May 23 20:40:09.375: INFO: (3) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 7.826687ms)
May 23 20:40:09.375: INFO: (3) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.954109ms)
May 23 20:40:09.376: INFO: (3) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.201895ms)
May 23 20:40:09.376: INFO: (3) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.570275ms)
May 23 20:40:09.376: INFO: (3) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.460804ms)
May 23 20:40:09.376: INFO: (3) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.855299ms)
May 23 20:40:09.377: INFO: (3) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 9.294076ms)
May 23 20:40:09.380: INFO: (4) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 3.191994ms)
May 23 20:40:09.380: INFO: (4) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 3.519562ms)
May 23 20:40:09.383: INFO: (4) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.479508ms)
May 23 20:40:09.383: INFO: (4) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.139358ms)
May 23 20:40:09.383: INFO: (4) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.79884ms)
May 23 20:40:09.384: INFO: (4) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 6.710658ms)
May 23 20:40:09.384: INFO: (4) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 6.408418ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 7.655967ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.111833ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 7.778289ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 7.801098ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 8.074049ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 7.890941ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 8.04119ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.147893ms)
May 23 20:40:09.385: INFO: (4) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 8.023901ms)
May 23 20:40:09.391: INFO: (5) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.463456ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.736183ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.003136ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.886427ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.144051ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 6.052126ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 6.358529ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.10716ms)
May 23 20:40:09.392: INFO: (5) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 6.893501ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 8.169386ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.473838ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 8.669399ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.767894ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 8.173616ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.378922ms)
May 23 20:40:09.394: INFO: (5) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 8.343201ms)
May 23 20:40:09.399: INFO: (6) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 3.561621ms)
May 23 20:40:09.399: INFO: (6) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.274332ms)
May 23 20:40:09.399: INFO: (6) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.449426ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 4.318067ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 4.308081ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 4.435682ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 4.833124ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 5.100205ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 5.400251ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 5.897568ms)
May 23 20:40:09.400: INFO: (6) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 5.261166ms)
May 23 20:40:09.402: INFO: (6) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.190477ms)
May 23 20:40:09.402: INFO: (6) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.086102ms)
May 23 20:40:09.402: INFO: (6) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 7.368117ms)
May 23 20:40:09.402: INFO: (6) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 6.87346ms)
May 23 20:40:09.403: INFO: (6) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 7.774533ms)
May 23 20:40:09.407: INFO: (7) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 3.556415ms)
May 23 20:40:09.410: INFO: (7) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 7.05802ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 7.494833ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.570429ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 7.697955ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 7.86709ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.992323ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 8.131433ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.181305ms)
May 23 20:40:09.411: INFO: (7) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.440652ms)
May 23 20:40:09.412: INFO: (7) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.696501ms)
May 23 20:40:09.412: INFO: (7) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.740582ms)
May 23 20:40:09.413: INFO: (7) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 9.62531ms)
May 23 20:40:09.413: INFO: (7) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 9.58449ms)
May 23 20:40:09.413: INFO: (7) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 10.204395ms)
May 23 20:40:09.413: INFO: (7) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 10.272346ms)
May 23 20:40:09.418: INFO: (8) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.141465ms)
May 23 20:40:09.419: INFO: (8) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.171385ms)
May 23 20:40:09.419: INFO: (8) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.332328ms)
May 23 20:40:09.419: INFO: (8) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 5.21853ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 5.988816ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 5.858488ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.884705ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 6.162761ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.566278ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.098152ms)
May 23 20:40:09.420: INFO: (8) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 6.371809ms)
May 23 20:40:09.421: INFO: (8) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 7.39111ms)
May 23 20:40:09.421: INFO: (8) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 7.250959ms)
May 23 20:40:09.422: INFO: (8) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 8.04314ms)
May 23 20:40:09.422: INFO: (8) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 7.63859ms)
May 23 20:40:09.423: INFO: (8) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.541669ms)
May 23 20:40:09.429: INFO: (9) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 6.503149ms)
May 23 20:40:09.430: INFO: (9) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 7.540856ms)
May 23 20:40:09.431: INFO: (9) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 8.494406ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.716049ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 9.04138ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 9.36045ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 9.231625ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 9.281016ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 9.295008ms)
May 23 20:40:09.432: INFO: (9) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 9.353063ms)
May 23 20:40:09.434: INFO: (9) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 11.323698ms)
May 23 20:40:09.434: INFO: (9) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 11.677049ms)
May 23 20:40:09.435: INFO: (9) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 11.730171ms)
May 23 20:40:09.435: INFO: (9) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 11.83903ms)
May 23 20:40:09.435: INFO: (9) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 12.109808ms)
May 23 20:40:09.435: INFO: (9) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 12.141058ms)
May 23 20:40:09.440: INFO: (10) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 4.43703ms)
May 23 20:40:09.440: INFO: (10) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 4.820368ms)
May 23 20:40:09.441: INFO: (10) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 5.085264ms)
May 23 20:40:09.441: INFO: (10) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 5.200108ms)
May 23 20:40:09.443: INFO: (10) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.208617ms)
May 23 20:40:09.443: INFO: (10) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.041882ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.341713ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.194828ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 8.67536ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.686008ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 8.854659ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.799236ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 8.86215ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.806871ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 8.936719ms)
May 23 20:40:09.444: INFO: (10) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.85503ms)
May 23 20:40:09.449: INFO: (11) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.534628ms)
May 23 20:40:09.450: INFO: (11) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 5.473514ms)
May 23 20:40:09.450: INFO: (11) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 5.234826ms)
May 23 20:40:09.451: INFO: (11) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.265855ms)
May 23 20:40:09.451: INFO: (11) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 5.66519ms)
May 23 20:40:09.451: INFO: (11) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 6.714289ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 6.734965ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 7.160959ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 7.302085ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 7.367116ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 7.172255ms)
May 23 20:40:09.452: INFO: (11) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.4419ms)
May 23 20:40:09.453: INFO: (11) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 7.69615ms)
May 23 20:40:09.453: INFO: (11) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 7.664539ms)
May 23 20:40:09.453: INFO: (11) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 7.708258ms)
May 23 20:40:09.453: INFO: (11) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 7.435558ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.019061ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 5.033117ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.275115ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.283667ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.388767ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 6.362962ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 6.139791ms)
May 23 20:40:09.459: INFO: (12) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.976153ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 6.495162ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 5.971878ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 6.684038ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.563173ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 6.407204ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 6.098949ms)
May 23 20:40:09.460: INFO: (12) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 6.346768ms)
May 23 20:40:09.461: INFO: (12) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 8.058219ms)
May 23 20:40:09.464: INFO: (13) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 3.115916ms)
May 23 20:40:09.467: INFO: (13) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 5.194269ms)
May 23 20:40:09.467: INFO: (13) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.804608ms)
May 23 20:40:09.467: INFO: (13) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 5.806604ms)
May 23 20:40:09.467: INFO: (13) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.691208ms)
May 23 20:40:09.468: INFO: (13) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.575033ms)
May 23 20:40:09.468: INFO: (13) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.890994ms)
May 23 20:40:09.468: INFO: (13) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.889785ms)
May 23 20:40:09.467: INFO: (13) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 5.543608ms)
May 23 20:40:09.468: INFO: (13) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 5.995835ms)
May 23 20:40:09.468: INFO: (13) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 6.545952ms)
May 23 20:40:09.469: INFO: (13) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 7.138236ms)
May 23 20:40:09.469: INFO: (13) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 7.390116ms)
May 23 20:40:09.469: INFO: (13) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.19555ms)
May 23 20:40:09.469: INFO: (13) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 7.285325ms)
May 23 20:40:09.469: INFO: (13) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.604716ms)
May 23 20:40:09.473: INFO: (14) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 3.215533ms)
May 23 20:40:09.473: INFO: (14) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 3.717101ms)
May 23 20:40:09.473: INFO: (14) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 3.625691ms)
May 23 20:40:09.475: INFO: (14) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 5.469147ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 5.786965ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 6.486926ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 6.693697ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 6.298039ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 6.410365ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.601045ms)
May 23 20:40:09.476: INFO: (14) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.690849ms)
May 23 20:40:09.477: INFO: (14) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.736681ms)
May 23 20:40:09.477: INFO: (14) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 6.820316ms)
May 23 20:40:09.477: INFO: (14) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.12191ms)
May 23 20:40:09.477: INFO: (14) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 7.653771ms)
May 23 20:40:09.478: INFO: (14) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 7.916151ms)
May 23 20:40:09.481: INFO: (15) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 3.449476ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.059172ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 5.658212ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.331282ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.871314ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 6.241019ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.79966ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 6.276717ms)
May 23 20:40:09.484: INFO: (15) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.704025ms)
May 23 20:40:09.485: INFO: (15) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 6.748342ms)
May 23 20:40:09.485: INFO: (15) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 6.857975ms)
May 23 20:40:09.486: INFO: (15) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 7.646009ms)
May 23 20:40:09.487: INFO: (15) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.032524ms)
May 23 20:40:09.487: INFO: (15) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.033608ms)
May 23 20:40:09.488: INFO: (15) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 8.685948ms)
May 23 20:40:09.488: INFO: (15) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 8.888236ms)
May 23 20:40:09.492: INFO: (16) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 4.50629ms)
May 23 20:40:09.494: INFO: (16) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.684311ms)
May 23 20:40:09.495: INFO: (16) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 5.415868ms)
May 23 20:40:09.495: INFO: (16) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 6.026482ms)
May 23 20:40:09.495: INFO: (16) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.420858ms)
May 23 20:40:09.497: INFO: (16) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 7.821587ms)
May 23 20:40:09.497: INFO: (16) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.539217ms)
May 23 20:40:09.498: INFO: (16) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.462738ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 10.64813ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 11.401449ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 10.401212ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 10.947898ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 10.135022ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 11.289174ms)
May 23 20:40:09.499: INFO: (16) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 11.433565ms)
May 23 20:40:09.500: INFO: (16) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 12.126992ms)
May 23 20:40:09.506: INFO: (17) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 5.168384ms)
May 23 20:40:09.506: INFO: (17) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 5.185515ms)
May 23 20:40:09.506: INFO: (17) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 5.364336ms)
May 23 20:40:09.506: INFO: (17) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 5.257107ms)
May 23 20:40:09.506: INFO: (17) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 5.564473ms)
May 23 20:40:09.507: INFO: (17) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.617961ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 6.728801ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 7.390716ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 7.070991ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 7.50405ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 7.592645ms)
May 23 20:40:09.508: INFO: (17) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 7.915962ms)
May 23 20:40:09.509: INFO: (17) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 7.876493ms)
May 23 20:40:09.509: INFO: (17) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 8.162208ms)
May 23 20:40:09.509: INFO: (17) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 8.291699ms)
May 23 20:40:09.510: INFO: (17) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 9.16769ms)
May 23 20:40:09.515: INFO: (18) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 5.027901ms)
May 23 20:40:09.516: INFO: (18) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 6.096607ms)
May 23 20:40:09.517: INFO: (18) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 6.241845ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 8.886024ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 9.40819ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 8.803555ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 9.048416ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 9.378927ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 9.305035ms)
May 23 20:40:09.519: INFO: (18) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 8.800393ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 9.770701ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 9.478136ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 8.932457ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 8.86597ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 9.157437ms)
May 23 20:40:09.520: INFO: (18) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 9.401335ms)
May 23 20:40:09.524: INFO: (19) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 3.760538ms)
May 23 20:40:09.525: INFO: (19) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 4.244927ms)
May 23 20:40:09.526: INFO: (19) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:462/proxy/: tls qux (200; 5.327822ms)
May 23 20:40:09.526: INFO: (19) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v/proxy/rewriteme">test</a> (200; 5.182843ms)
May 23 20:40:09.526: INFO: (19) /api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/http:proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">... (200; 5.14696ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:162/proxy/: bar (200; 5.456593ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:443/proxy/tlsrewritem... (200; 5.873308ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:160/proxy/: foo (200; 5.547373ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname2/proxy/: bar (200; 6.352806ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-6583/pods/proxy-service-84dc8-dgv5v:1080/proxy/rewriteme">test<... (200; 6.026468ms)
May 23 20:40:09.527: INFO: (19) /api/v1/namespaces/proxy-6583/pods/https:proxy-service-84dc8-dgv5v:460/proxy/: tls baz (200; 6.247485ms)
May 23 20:40:09.528: INFO: (19) /api/v1/namespaces/proxy-6583/services/http:proxy-service-84dc8:portname1/proxy/: foo (200; 7.43571ms)
May 23 20:40:09.528: INFO: (19) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname1/proxy/: foo (200; 7.147114ms)
May 23 20:40:09.528: INFO: (19) /api/v1/namespaces/proxy-6583/services/proxy-service-84dc8:portname2/proxy/: bar (200; 7.210689ms)
May 23 20:40:09.528: INFO: (19) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname2/proxy/: tls qux (200; 7.489172ms)
May 23 20:40:09.529: INFO: (19) /api/v1/namespaces/proxy-6583/services/https:proxy-service-84dc8:tlsportname1/proxy/: tls baz (200; 8.566135ms)
STEP: deleting ReplicationController proxy-service-84dc8 in namespace proxy-6583, will wait for the garbage collector to delete the pods
May 23 20:40:09.612: INFO: Deleting ReplicationController proxy-service-84dc8 took: 11.58409ms
May 23 20:40:09.916: INFO: Terminating ReplicationController proxy-service-84dc8 pods took: 303.620922ms
[AfterEach] version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:40:14.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6583" for this suite.
May 23 20:40:20.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:40:20.424: INFO: namespace proxy-6583 deletion completed in 6.105421995s

• [SLOW TEST:22.221 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:40:20.425: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0523 20:40:30.622279      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 20:40:30.622: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:40:30.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3972" for this suite.
May 23 20:40:36.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:40:36.721: INFO: namespace gc-3972 deletion completed in 6.090998858s

• [SLOW TEST:16.296 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:40:36.722: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 20:40:36.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8514'
May 23 20:40:37.344: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 23 20:40:37.344: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 23 20:40:37.366: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-bfxc7]
May 23 20:40:37.366: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-bfxc7" in namespace "kubectl-8514" to be "running and ready"
May 23 20:40:37.374: INFO: Pod "e2e-test-nginx-rc-bfxc7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.991423ms
May 23 20:40:39.388: INFO: Pod "e2e-test-nginx-rc-bfxc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022116545s
May 23 20:40:41.395: INFO: Pod "e2e-test-nginx-rc-bfxc7": Phase="Running", Reason="", readiness=true. Elapsed: 4.02837133s
May 23 20:40:41.395: INFO: Pod "e2e-test-nginx-rc-bfxc7" satisfied condition "running and ready"
May 23 20:40:41.395: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-bfxc7]
May 23 20:40:41.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 logs rc/e2e-test-nginx-rc --namespace=kubectl-8514'
May 23 20:40:41.495: INFO: stderr: ""
May 23 20:40:41.495: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
May 23 20:40:41.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete rc e2e-test-nginx-rc --namespace=kubectl-8514'
May 23 20:40:41.550: INFO: stderr: ""
May 23 20:40:41.550: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:40:41.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8514" for this suite.
May 23 20:41:03.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:41:03.666: INFO: namespace kubectl-8514 deletion completed in 22.113563214s

• [SLOW TEST:26.944 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:41:03.667: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:41:03.686: INFO: Creating ReplicaSet my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe
May 23 20:41:03.689: INFO: Pod name my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe: Found 0 pods out of 1
May 23 20:41:08.696: INFO: Pod name my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe: Found 1 pods out of 1
May 23 20:41:08.696: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe" is running
May 23 20:41:08.702: INFO: Pod "my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe-s99j5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:41:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:41:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:41:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-23 20:41:03 +0000 UTC Reason: Message:}])
May 23 20:41:08.702: INFO: Trying to dial the pod
May 23 20:41:13.736: INFO: Controller my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe: Got expected result from replica 1 [my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe-s99j5]: "my-hostname-basic-14fa4ca1-7d9b-11e9-b22f-2a454b6ec3fe-s99j5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:41:13.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4164" for this suite.
May 23 20:41:19.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:41:19.861: INFO: namespace replicaset-4164 deletion completed in 6.117882803s

• [SLOW TEST:16.194 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:41:19.861: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
May 23 20:41:19.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-1851'
May 23 20:41:20.141: INFO: stderr: ""
May 23 20:41:20.141: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 20:41:20.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1851'
May 23 20:41:20.199: INFO: stderr: ""
May 23 20:41:20.199: INFO: stdout: "update-demo-nautilus-4t7zt update-demo-nautilus-bkntd "
May 23 20:41:20.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-4t7zt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:20.249: INFO: stderr: ""
May 23 20:41:20.249: INFO: stdout: ""
May 23 20:41:20.249: INFO: update-demo-nautilus-4t7zt is created but not running
May 23 20:41:25.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1851'
May 23 20:41:25.313: INFO: stderr: ""
May 23 20:41:25.313: INFO: stdout: "update-demo-nautilus-4t7zt update-demo-nautilus-bkntd "
May 23 20:41:25.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-4t7zt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:25.365: INFO: stderr: ""
May 23 20:41:25.365: INFO: stdout: "true"
May 23 20:41:25.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-4t7zt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:25.411: INFO: stderr: ""
May 23 20:41:25.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:41:25.411: INFO: validating pod update-demo-nautilus-4t7zt
May 23 20:41:25.414: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:41:25.414: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:41:25.414: INFO: update-demo-nautilus-4t7zt is verified up and running
May 23 20:41:25.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-bkntd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:25.460: INFO: stderr: ""
May 23 20:41:25.460: INFO: stdout: "true"
May 23 20:41:25.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-bkntd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:25.523: INFO: stderr: ""
May 23 20:41:25.523: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:41:25.523: INFO: validating pod update-demo-nautilus-bkntd
May 23 20:41:25.526: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:41:25.526: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:41:25.526: INFO: update-demo-nautilus-bkntd is verified up and running
STEP: rolling-update to new replication controller
May 23 20:41:25.527: INFO: scanned /root for discovery docs: <nil>
May 23 20:41:25.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1851'
May 23 20:41:47.943: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 23 20:41:47.943: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 20:41:47.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1851'
May 23 20:41:48.008: INFO: stderr: ""
May 23 20:41:48.008: INFO: stdout: "update-demo-kitten-bw5mq update-demo-kitten-zwst7 "
May 23 20:41:48.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-kitten-bw5mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:48.053: INFO: stderr: ""
May 23 20:41:48.053: INFO: stdout: "true"
May 23 20:41:48.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-kitten-bw5mq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:48.115: INFO: stderr: ""
May 23 20:41:48.115: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 23 20:41:48.115: INFO: validating pod update-demo-kitten-bw5mq
May 23 20:41:48.119: INFO: got data: {
  "image": "kitten.jpg"
}

May 23 20:41:48.119: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 23 20:41:48.119: INFO: update-demo-kitten-bw5mq is verified up and running
May 23 20:41:48.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-kitten-zwst7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:48.166: INFO: stderr: ""
May 23 20:41:48.166: INFO: stdout: "true"
May 23 20:41:48.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-kitten-zwst7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1851'
May 23 20:41:48.219: INFO: stderr: ""
May 23 20:41:48.219: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 23 20:41:48.219: INFO: validating pod update-demo-kitten-zwst7
May 23 20:41:48.223: INFO: got data: {
  "image": "kitten.jpg"
}

May 23 20:41:48.223: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 23 20:41:48.223: INFO: update-demo-kitten-zwst7 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:41:48.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1851" for this suite.
May 23 20:42:10.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:42:10.328: INFO: namespace kubectl-1851 deletion completed in 22.102973247s

• [SLOW TEST:50.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:42:10.328: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 23 20:42:10.355: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 23 20:42:19.403: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:42:19.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9949" for this suite.
May 23 20:42:25.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:42:25.478: INFO: namespace pods-9949 deletion completed in 6.062357007s

• [SLOW TEST:15.151 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:42:25.479: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8490
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8490
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8490
May 23 20:42:25.510: INFO: Found 0 stateful pods, waiting for 1
May 23 20:42:35.517: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 23 20:42:35.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:42:35.686: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:42:35.686: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:42:35.686: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:42:35.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 23 20:42:45.701: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:42:45.701: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:42:45.731: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999191s
May 23 20:42:46.738: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992021453s
May 23 20:42:47.752: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.976880802s
May 23 20:42:48.758: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970869465s
May 23 20:42:49.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.964779069s
May 23 20:42:50.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.95737646s
May 23 20:42:51.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.951064849s
May 23 20:42:52.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.946250714s
May 23 20:42:53.846: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.881781172s
May 23 20:42:54.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 866.281425ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8490
May 23 20:42:55.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:42:55.980: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 20:42:55.980: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:42:55.980: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:42:55.982: INFO: Found 1 stateful pods, waiting for 3
May 23 20:43:05.988: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 23 20:43:05.988: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 23 20:43:05.988: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 23 20:43:05.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:43:06.146: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:43:06.146: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:43:06.146: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:43:06.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:43:06.277: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:43:06.277: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:43:06.277: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:43:06.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 23 20:43:06.420: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 23 20:43:06.420: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 23 20:43:06.420: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 23 20:43:06.420: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:43:06.421: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 23 20:43:16.433: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:43:16.434: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:43:16.434: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 23 20:43:16.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999301s
May 23 20:43:17.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988659303s
May 23 20:43:18.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979019499s
May 23 20:43:19.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970773338s
May 23 20:43:20.519: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963144692s
May 23 20:43:21.521: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.927322083s
May 23 20:43:22.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.924747769s
May 23 20:43:23.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.91784791s
May 23 20:43:24.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.911183142s
May 23 20:43:25.549: INFO: Verifying statefulset ss doesn't scale past 3 for another 903.767394ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8490
May 23 20:43:26.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:43:26.714: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 20:43:26.714: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:43:26.714: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:43:26.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:43:26.903: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 20:43:26.903: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:43:26.903: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:43:26.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 exec --namespace=statefulset-8490 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 23 20:43:27.027: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 23 20:43:27.027: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 23 20:43:27.027: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 23 20:43:27.027: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 23 20:43:37.039: INFO: Deleting all statefulset in ns statefulset-8490
May 23 20:43:37.044: INFO: Scaling statefulset ss to 0
May 23 20:43:37.060: INFO: Waiting for statefulset status.replicas updated to 0
May 23 20:43:37.066: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:43:37.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8490" for this suite.
May 23 20:43:43.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:43:43.189: INFO: namespace statefulset-8490 deletion completed in 6.102314302s

• [SLOW TEST:77.711 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:43:43.191: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:43:43.221: INFO: Waiting up to 5m0s for pod "downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe" in namespace "projected-9651" to be "success or failure"
May 23 20:43:43.226: INFO: Pod "downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.245506ms
May 23 20:43:45.228: INFO: Pod "downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007463302s
STEP: Saw pod success
May 23 20:43:45.228: INFO: Pod "downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:43:45.230: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:43:45.248: INFO: Waiting for pod downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:43:45.250: INFO: Pod downwardapi-volume-740ff703-7d9b-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:43:45.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9651" for this suite.
May 23 20:43:51.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:43:51.339: INFO: namespace projected-9651 deletion completed in 6.086126722s

• [SLOW TEST:8.147 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:43:51.339: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 20:43:51.364: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe" in namespace "projected-6699" to be "success or failure"
May 23 20:43:51.369: INFO: Pod "downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.151713ms
May 23 20:43:53.373: INFO: Pod "downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008984179s
STEP: Saw pod success
May 23 20:43:53.373: INFO: Pod "downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:43:53.375: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 20:43:53.388: INFO: Waiting for pod downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:43:53.389: INFO: Pod downwardapi-volume-78eb4032-7d9b-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:43:53.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6699" for this suite.
May 23 20:43:59.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:43:59.472: INFO: namespace projected-6699 deletion completed in 6.080779987s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:43:59.472: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 23 20:43:59.496: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17415,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 23 20:43:59.496: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17415,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 23 20:44:09.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17430,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 23 20:44:09.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17430,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 23 20:44:19.531: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17446,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 23 20:44:19.531: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17446,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 23 20:44:29.561: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17461,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 23 20:44:29.562: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-a,UID:7dc701da-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17461,Generation:0,CreationTimestamp:2019-05-23 20:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 23 20:44:39.577: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-b,UID:95a9d442-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17477,Generation:0,CreationTimestamp:2019-05-23 20:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 23 20:44:39.577: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-b,UID:95a9d442-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17477,Generation:0,CreationTimestamp:2019-05-23 20:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 23 20:44:49.586: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-b,UID:95a9d442-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17494,Generation:0,CreationTimestamp:2019-05-23 20:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 23 20:44:49.586: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5182,SelfLink:/api/v1/namespaces/watch-5182/configmaps/e2e-watch-test-configmap-b,UID:95a9d442-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17494,Generation:0,CreationTimestamp:2019-05-23 20:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:44:59.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5182" for this suite.
May 23 20:45:05.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:45:05.696: INFO: namespace watch-5182 deletion completed in 6.101104273s

• [SLOW TEST:66.224 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:45:05.696: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 23 20:45:05.731: INFO: Number of nodes with available pods: 0
May 23 20:45:05.731: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:45:06.738: INFO: Number of nodes with available pods: 0
May 23 20:45:06.738: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:45:07.743: INFO: Number of nodes with available pods: 2
May 23 20:45:07.743: INFO: Node controlplane-1 is running more than one daemon pod
May 23 20:45:08.747: INFO: Number of nodes with available pods: 3
May 23 20:45:08.747: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 23 20:45:08.777: INFO: Number of nodes with available pods: 2
May 23 20:45:08.777: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:09.785: INFO: Number of nodes with available pods: 2
May 23 20:45:09.785: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:10.787: INFO: Number of nodes with available pods: 2
May 23 20:45:10.787: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:11.788: INFO: Number of nodes with available pods: 2
May 23 20:45:11.788: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:12.788: INFO: Number of nodes with available pods: 2
May 23 20:45:12.788: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:13.793: INFO: Number of nodes with available pods: 2
May 23 20:45:13.793: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:14.791: INFO: Number of nodes with available pods: 2
May 23 20:45:14.791: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:15.791: INFO: Number of nodes with available pods: 2
May 23 20:45:15.791: INFO: Node worker-1 is running more than one daemon pod
May 23 20:45:16.790: INFO: Number of nodes with available pods: 3
May 23 20:45:16.790: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6011, will wait for the garbage collector to delete the pods
May 23 20:45:16.876: INFO: Deleting DaemonSet.extensions daemon-set took: 13.421186ms
May 23 20:45:17.177: INFO: Terminating DaemonSet.extensions daemon-set pods took: 301.45587ms
May 23 20:45:27.081: INFO: Number of nodes with available pods: 0
May 23 20:45:27.081: INFO: Number of running nodes: 0, number of available pods: 0
May 23 20:45:27.083: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6011/daemonsets","resourceVersion":"17627"},"items":null}

May 23 20:45:27.084: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6011/pods","resourceVersion":"17627"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:45:27.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6011" for this suite.
May 23 20:45:33.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:45:33.158: INFO: namespace daemonsets-6011 deletion completed in 6.065408936s

• [SLOW TEST:27.462 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:45:33.159: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 23 20:45:35.247: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b5a3121f-7d9b-11e9-b22f-2a454b6ec3fe,GenerateName:,Namespace:events-4323,SelfLink:/api/v1/namespaces/events-4323/pods/send-events-b5a3121f-7d9b-11e9-b22f-2a454b6ec3fe,UID:b5a5d050-7d9b-11e9-a2d7-080027c2be11,ResourceVersion:17678,Generation:0,CreationTimestamp:2019-05-23 20:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 227679696,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mst65 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mst65,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-mst65 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000492770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000492820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:45:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 20:45:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:10.40.0.2,StartTime:2019-05-23 20:45:33 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-23 20:45:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://16b9f18b0bbe80b7deed9740c60d63dd3f15b4365e25c1b261b35e100d4b1696}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 23 20:45:37.254: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 23 20:45:39.261: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:45:39.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4323" for this suite.
May 23 20:46:17.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:46:17.366: INFO: namespace events-4323 deletion completed in 38.081355816s

• [SLOW TEST:44.207 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:46:17.366: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 23 20:46:19.929: INFO: Successfully updated pod "labelsupdatecff5c517-7d9b-11e9-b22f-2a454b6ec3fe"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:46:21.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4026" for this suite.
May 23 20:46:43.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:46:44.078: INFO: namespace projected-4026 deletion completed in 22.118564242s

• [SLOW TEST:26.712 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:46:44.078: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 23 20:46:46.120: INFO: Unable to read wheezy_udp@kubernetes.default.svc.cluster.local from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.123: INFO: Unable to read wheezy_tcp@kubernetes.default.svc.cluster.local from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.124: INFO: Unable to read wheezy_udp@PodARecord from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.126: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.128: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.130: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.132: INFO: Unable to read jessie_udp@PodARecord from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.134: INFO: Unable to read jessie_tcp@PodARecord from pod dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe)
May 23 20:46:46.134: INFO: Lookups using dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe failed for: [wheezy_udp@kubernetes.default.svc.cluster.local wheezy_tcp@kubernetes.default.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

May 23 20:46:51.187: INFO: DNS probes using dns-6835/dns-test-dfe1243f-7d9b-11e9-b22f-2a454b6ec3fe succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:46:51.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6835" for this suite.
May 23 20:46:57.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:46:57.305: INFO: namespace dns-6835 deletion completed in 6.097480642s

• [SLOW TEST:13.227 seconds]
[sig-network] DNS
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:46:57.305: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 23 20:47:03.383: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:03.393: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:05.393: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:05.395: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:07.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:07.399: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:09.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:09.395: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:11.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:11.399: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:13.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:13.399: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:15.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:15.401: INFO: Pod pod-with-prestop-http-hook still exists
May 23 20:47:17.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 23 20:47:17.399: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:47:17.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6900" for this suite.
May 23 20:47:39.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:47:39.501: INFO: namespace container-lifecycle-hook-6900 deletion completed in 22.078489996s

• [SLOW TEST:42.197 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:47:39.502: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:47:43.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1641" for this suite.
May 23 20:47:49.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:47:49.644: INFO: namespace kubelet-test-1641 deletion completed in 6.094328054s

• [SLOW TEST:10.143 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:47:49.645: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 23 20:47:49.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6576'
May 23 20:47:49.764: INFO: stderr: ""
May 23 20:47:49.764: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 20:47:49.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:47:49.827: INFO: stderr: ""
May 23 20:47:49.827: INFO: stdout: "update-demo-nautilus-8j7rf update-demo-nautilus-vhzhh "
May 23 20:47:49.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-8j7rf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:47:49.871: INFO: stderr: ""
May 23 20:47:49.871: INFO: stdout: ""
May 23 20:47:49.871: INFO: update-demo-nautilus-8j7rf is created but not running
May 23 20:47:54.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:47:54.953: INFO: stderr: ""
May 23 20:47:54.953: INFO: stdout: "update-demo-nautilus-8j7rf update-demo-nautilus-vhzhh "
May 23 20:47:54.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-8j7rf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:47:55.001: INFO: stderr: ""
May 23 20:47:55.001: INFO: stdout: "true"
May 23 20:47:55.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-8j7rf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:47:55.050: INFO: stderr: ""
May 23 20:47:55.050: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:47:55.050: INFO: validating pod update-demo-nautilus-8j7rf
May 23 20:47:55.053: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:47:55.053: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:47:55.053: INFO: update-demo-nautilus-8j7rf is verified up and running
May 23 20:47:55.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:47:55.097: INFO: stderr: ""
May 23 20:47:55.097: INFO: stdout: "true"
May 23 20:47:55.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:47:55.143: INFO: stderr: ""
May 23 20:47:55.143: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:47:55.143: INFO: validating pod update-demo-nautilus-vhzhh
May 23 20:47:55.147: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:47:55.147: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:47:55.147: INFO: update-demo-nautilus-vhzhh is verified up and running
STEP: scaling down the replication controller
May 23 20:47:55.148: INFO: scanned /root for discovery docs: <nil>
May 23 20:47:55.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6576'
May 23 20:47:56.234: INFO: stderr: ""
May 23 20:47:56.234: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 20:47:56.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:47:56.327: INFO: stderr: ""
May 23 20:47:56.327: INFO: stdout: "update-demo-nautilus-8j7rf update-demo-nautilus-vhzhh "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 23 20:48:01.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:48:01.404: INFO: stderr: ""
May 23 20:48:01.404: INFO: stdout: "update-demo-nautilus-8j7rf update-demo-nautilus-vhzhh "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 23 20:48:06.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:48:06.485: INFO: stderr: ""
May 23 20:48:06.485: INFO: stdout: "update-demo-nautilus-vhzhh "
May 23 20:48:06.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:06.530: INFO: stderr: ""
May 23 20:48:06.530: INFO: stdout: "true"
May 23 20:48:06.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:06.578: INFO: stderr: ""
May 23 20:48:06.578: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:48:06.578: INFO: validating pod update-demo-nautilus-vhzhh
May 23 20:48:06.580: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:48:06.580: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:48:06.580: INFO: update-demo-nautilus-vhzhh is verified up and running
STEP: scaling up the replication controller
May 23 20:48:06.581: INFO: scanned /root for discovery docs: <nil>
May 23 20:48:06.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6576'
May 23 20:48:07.651: INFO: stderr: ""
May 23 20:48:07.651: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 23 20:48:07.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:48:07.747: INFO: stderr: ""
May 23 20:48:07.747: INFO: stdout: "update-demo-nautilus-jwp7z update-demo-nautilus-vhzhh "
May 23 20:48:07.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-jwp7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:07.817: INFO: stderr: ""
May 23 20:48:07.817: INFO: stdout: ""
May 23 20:48:07.817: INFO: update-demo-nautilus-jwp7z is created but not running
May 23 20:48:12.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6576'
May 23 20:48:12.894: INFO: stderr: ""
May 23 20:48:12.895: INFO: stdout: "update-demo-nautilus-jwp7z update-demo-nautilus-vhzhh "
May 23 20:48:12.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-jwp7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:12.949: INFO: stderr: ""
May 23 20:48:12.949: INFO: stdout: "true"
May 23 20:48:12.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-jwp7z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:12.994: INFO: stderr: ""
May 23 20:48:12.994: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:48:12.994: INFO: validating pod update-demo-nautilus-jwp7z
May 23 20:48:12.998: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:48:12.998: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:48:12.998: INFO: update-demo-nautilus-jwp7z is verified up and running
May 23 20:48:12.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:13.049: INFO: stderr: ""
May 23 20:48:13.049: INFO: stdout: "true"
May 23 20:48:13.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods update-demo-nautilus-vhzhh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6576'
May 23 20:48:13.096: INFO: stderr: ""
May 23 20:48:13.096: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 23 20:48:13.096: INFO: validating pod update-demo-nautilus-vhzhh
May 23 20:48:13.098: INFO: got data: {
  "image": "nautilus.jpg"
}

May 23 20:48:13.098: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 23 20:48:13.098: INFO: update-demo-nautilus-vhzhh is verified up and running
STEP: using delete to clean up resources
May 23 20:48:13.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-6576'
May 23 20:48:13.148: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 20:48:13.148: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 23 20:48:13.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6576'
May 23 20:48:13.216: INFO: stderr: "No resources found.\n"
May 23 20:48:13.216: INFO: stdout: ""
May 23 20:48:13.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=update-demo --namespace=kubectl-6576 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 20:48:13.264: INFO: stderr: ""
May 23 20:48:13.264: INFO: stdout: "update-demo-nautilus-jwp7z\nupdate-demo-nautilus-vhzhh\n"
May 23 20:48:13.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6576'
May 23 20:48:13.847: INFO: stderr: "No resources found.\n"
May 23 20:48:13.847: INFO: stdout: ""
May 23 20:48:13.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=update-demo --namespace=kubectl-6576 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 20:48:13.898: INFO: stderr: ""
May 23 20:48:13.898: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:48:13.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6576" for this suite.
May 23 20:48:19.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:48:19.992: INFO: namespace kubectl-6576 deletion completed in 6.091292287s

• [SLOW TEST:30.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:48:19.992: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
May 23 20:48:20.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 --namespace=kubectl-5470 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 23 20:48:22.475: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 23 20:48:22.475: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:48:24.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5470" for this suite.
May 23 20:48:30.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:48:30.562: INFO: namespace kubectl-5470 deletion completed in 6.067626478s

• [SLOW TEST:10.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:48:30.562: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 20:48:30.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 version --client'
May 23 20:48:30.615: INFO: stderr: ""
May 23 20:48:30.615: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.2\", GitCommit:\"66049e3b21efe110454d67df4fa62b08ea79a19b\", GitTreeState:\"clean\", BuildDate:\"2019-05-16T16:23:09Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 23 20:48:30.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6879'
May 23 20:48:30.714: INFO: stderr: ""
May 23 20:48:30.714: INFO: stdout: "replicationcontroller/redis-master created\n"
May 23 20:48:30.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-6879'
May 23 20:48:30.814: INFO: stderr: ""
May 23 20:48:30.814: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 23 20:48:31.816: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:48:31.816: INFO: Found 0 / 1
May 23 20:48:32.821: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:48:32.821: INFO: Found 1 / 1
May 23 20:48:32.821: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 23 20:48:32.839: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:48:32.839: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 23 20:48:32.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 describe pod redis-master-7pgjm --namespace=kubectl-6879'
May 23 20:48:32.926: INFO: stderr: ""
May 23 20:48:32.926: INFO: stdout: "Name:               redis-master-7pgjm\nNamespace:          kubectl-6879\nPriority:           0\nPriorityClassName:  <none>\nNode:               worker-1/192.168.5.101\nStart Time:         Thu, 23 May 2019 20:48:30 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.40.0.2\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d4e13fe5d0b773bf2e3d4b41a423e60408203aed1e49c73e0d578621657796bd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 23 May 2019 20:48:31 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-z2qc5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-z2qc5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-z2qc5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-6879/redis-master-7pgjm to worker-1\n  Normal  Pulled     1s    kubelet, worker-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, worker-1  Created container redis-master\n  Normal  Started    1s    kubelet, worker-1  Started container redis-master\n"
May 23 20:48:32.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 describe rc redis-master --namespace=kubectl-6879'
May 23 20:48:32.989: INFO: stderr: ""
May 23 20:48:32.989: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6879\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-7pgjm\n"
May 23 20:48:32.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 describe service redis-master --namespace=kubectl-6879'
May 23 20:48:33.053: INFO: stderr: ""
May 23 20:48:33.053: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6879\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.80.52\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.40.0.2:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 23 20:48:33.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 describe node controlplane-1'
May 23 20:48:33.116: INFO: stderr: ""
May 23 20:48:33.116: INFO: stdout: "Name:               controlplane-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=controlplane-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 23 May 2019 19:24:41 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 23 May 2019 19:25:38 +0000   Thu, 23 May 2019 19:25:38 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Thu, 23 May 2019 20:48:16 +0000   Thu, 23 May 2019 19:24:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 23 May 2019 20:48:16 +0000   Thu, 23 May 2019 19:24:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 23 May 2019 20:48:16 +0000   Thu, 23 May 2019 19:24:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 23 May 2019 20:48:16 +0000   Thu, 23 May 2019 19:25:31 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.5.11\n  Hostname:    controlplane-1\nCapacity:\n cpu:                2\n ephemeral-storage:  64800356Ki\n hugepages-2Mi:      0\n memory:             2041132Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  59720007991\n hugepages-2Mi:      0\n memory:             1938732Ki\n pods:               110\nSystem Info:\n Machine ID:                 bc741eafe93f40ac9d7e63d65a7d6bbe\n System UUID:                B97707A7-D209-43A2-AEB5-1A8CD70D6687\n Boot ID:                    7bf1d5aa-f326-4878-839b-4d3c878a6bb6\n Kernel Version:             4.15.0-29-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.5\n Kubelet Version:            v1.14.2\n Kube-Proxy Version:         v1.14.2\nPodCIDR:                     10.96.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-ghmvv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                coredns-fb8b8dccf-j6x4t                                    100m (5%)     0 (0%)      70Mi (3%)        170Mi (8%)     83m\n  kube-system                coredns-fb8b8dccf-t24wc                                    100m (5%)     0 (0%)      70Mi (3%)        170Mi (8%)     83m\n  kube-system                etcd-controlplane-1                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                kube-apiserver-controlplane-1                              250m (12%)    0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                kube-controller-manager-controlplane-1                     200m (10%)    0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                kube-proxy-kcbp9                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         83m\n  kube-system                kube-scheduler-controlplane-1                              100m (5%)     0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                weave-net-kt8s6                                            20m (1%)      0 (0%)      0 (0%)           0 (0%)         83m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                770m (38%)  0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
May 23 20:48:33.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 describe namespace kubectl-6879'
May 23 20:48:33.167: INFO: stderr: ""
May 23 20:48:33.167: INFO: stdout: "Name:         kubectl-6879\nLabels:       e2e-framework=kubectl\n              e2e-run=e6484d5c-7d90-11e9-b22f-2a454b6ec3fe\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:48:33.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6879" for this suite.
May 23 20:48:55.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:48:55.221: INFO: namespace kubectl-6879 deletion completed in 22.051540835s

• [SLOW TEST:24.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:48:55.222: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 20:48:55.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5026'
May 23 20:48:55.381: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 23 20:48:55.381: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
May 23 20:48:55.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete jobs e2e-test-nginx-job --namespace=kubectl-5026'
May 23 20:48:55.437: INFO: stderr: ""
May 23 20:48:55.437: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:48:55.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5026" for this suite.
May 23 20:49:17.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:49:17.550: INFO: namespace kubectl-5026 deletion completed in 22.110928231s

• [SLOW TEST:22.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:49:17.550: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:49:19.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4056" for this suite.
May 23 20:50:09.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:50:09.794: INFO: namespace kubelet-test-4056 deletion completed in 50.107783284s

• [SLOW TEST:52.244 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:50:09.794: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
May 23 20:50:09.817: INFO: Waiting up to 5m0s for pod "client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe" in namespace "containers-483" to be "success or failure"
May 23 20:50:09.822: INFO: Pod "client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.431386ms
May 23 20:50:11.824: INFO: Pod "client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007240752s
STEP: Saw pod success
May 23 20:50:11.824: INFO: Pod "client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:50:11.827: INFO: Trying to get logs from node worker-1 pod client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:50:11.839: INFO: Waiting for pod client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:50:11.841: INFO: Pod client-containers-5a7ea75b-7d9c-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:50:11.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-483" for this suite.
May 23 20:50:17.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:50:17.939: INFO: namespace containers-483 deletion completed in 6.096171743s

• [SLOW TEST:8.145 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:50:17.940: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 23 20:50:17.968: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18476,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 23 20:50:17.968: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18477,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 23 20:50:17.968: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18478,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 23 20:50:27.992: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18494,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 23 20:50:27.993: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18495,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 23 20:50:27.993: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3167,SelfLink:/api/v1/namespaces/watch-3167/configmaps/e2e-watch-test-label-changed,UID:5f5c6354-7d9c-11e9-a2d7-080027c2be11,ResourceVersion:18496,Generation:0,CreationTimestamp:2019-05-23 20:50:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:50:27.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3167" for this suite.
May 23 20:50:34.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:50:34.090: INFO: namespace watch-3167 deletion completed in 6.094466007s

• [SLOW TEST:16.151 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:50:34.091: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
May 23 20:50:34.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-366'
May 23 20:50:34.216: INFO: stderr: ""
May 23 20:50:34.216: INFO: stdout: "pod/pause created\n"
May 23 20:50:34.216: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 23 20:50:34.216: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-366" to be "running and ready"
May 23 20:50:34.221: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.359626ms
May 23 20:50:36.227: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011065438s
May 23 20:50:36.227: INFO: Pod "pause" satisfied condition "running and ready"
May 23 20:50:36.228: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
May 23 20:50:36.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 label pods pause testing-label=testing-label-value --namespace=kubectl-366'
May 23 20:50:36.310: INFO: stderr: ""
May 23 20:50:36.310: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 23 20:50:36.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pod pause -L testing-label --namespace=kubectl-366'
May 23 20:50:36.362: INFO: stderr: ""
May 23 20:50:36.362: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 23 20:50:36.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 label pods pause testing-label- --namespace=kubectl-366'
May 23 20:50:36.419: INFO: stderr: ""
May 23 20:50:36.419: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 23 20:50:36.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pod pause -L testing-label --namespace=kubectl-366'
May 23 20:50:36.463: INFO: stderr: ""
May 23 20:50:36.463: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
May 23 20:50:36.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-366'
May 23 20:50:36.525: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 20:50:36.525: INFO: stdout: "pod \"pause\" force deleted\n"
May 23 20:50:36.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=pause --no-headers --namespace=kubectl-366'
May 23 20:50:36.585: INFO: stderr: "No resources found.\n"
May 23 20:50:36.585: INFO: stdout: ""
May 23 20:50:36.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=pause --namespace=kubectl-366 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 20:50:36.632: INFO: stderr: ""
May 23 20:50:36.632: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:50:36.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-366" for this suite.
May 23 20:50:42.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:50:42.719: INFO: namespace kubectl-366 deletion completed in 6.084007236s

• [SLOW TEST:8.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:50:42.719: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-6e265967-7d9c-11e9-b22f-2a454b6ec3fe
STEP: Creating secret with name s-test-opt-upd-6e265996-7d9c-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6e265967-7d9c-11e9-b22f-2a454b6ec3fe
STEP: Updating secret s-test-opt-upd-6e265996-7d9c-11e9-b22f-2a454b6ec3fe
STEP: Creating secret with name s-test-opt-create-6e2659a5-7d9c-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:50:46.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6855" for this suite.
May 23 20:51:08.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:51:09.108: INFO: namespace secrets-6855 deletion completed in 22.163315057s

• [SLOW TEST:26.388 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:51:09.109: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:51:11.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7062" for this suite.
May 23 20:51:17.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:51:17.256: INFO: namespace emptydir-wrapper-7062 deletion completed in 6.05690161s

• [SLOW TEST:8.147 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:51:17.256: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:51:41.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2245" for this suite.
May 23 20:51:47.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:51:47.456: INFO: namespace namespaces-2245 deletion completed in 6.089162493s
STEP: Destroying namespace "nsdeletetest-3140" for this suite.
May 23 20:51:47.457: INFO: Namespace nsdeletetest-3140 was already deleted
STEP: Destroying namespace "nsdeletetest-1448" for this suite.
May 23 20:51:53.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:51:53.528: INFO: namespace nsdeletetest-1448 deletion completed in 6.071205488s

• [SLOW TEST:36.272 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:51:53.529: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3591.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3591.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3591.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3591.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 23 20:51:57.604: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.611: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.617: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.623: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.627: INFO: Unable to read jessie_udp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.631: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:51:57.631: INFO: Lookups using dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

May 23 20:52:02.667: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:02.674: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:02.680: INFO: Unable to read jessie_udp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:02.686: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:02.686: INFO: Lookups using dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe failed for: [jessie_hosts@dns-querier-1.dns-test-service.dns-3591.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

May 23 20:52:07.666: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:07.669: INFO: Unable to read jessie_udp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:07.673: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:07.673: INFO: Lookups using dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

May 23 20:52:12.676: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:12.681: INFO: Unable to read jessie_udp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:12.685: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe: the server could not find the requested resource (get pods dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe)
May 23 20:52:12.686: INFO: Lookups using dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

May 23 20:52:17.698: INFO: DNS probes using dns-3591/dns-test-98540868-7d9c-11e9-b22f-2a454b6ec3fe succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:52:17.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3591" for this suite.
May 23 20:52:23.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:52:23.823: INFO: namespace dns-3591 deletion completed in 6.108004203s

• [SLOW TEST:30.295 seconds]
[sig-network] DNS
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:52:23.823: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 23 20:52:23.847: INFO: Waiting up to 5m0s for pod "pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-8055" to be "success or failure"
May 23 20:52:23.849: INFO: Pod "pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126604ms
May 23 20:52:25.858: INFO: Pod "pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010950796s
May 23 20:52:27.863: INFO: Pod "pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016601829s
STEP: Saw pod success
May 23 20:52:27.863: INFO: Pod "pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:52:27.869: INFO: Trying to get logs from node worker-1 pod pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:52:27.901: INFO: Waiting for pod pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:52:27.905: INFO: Pod pod-aa622101-7d9c-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:52:27.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8055" for this suite.
May 23 20:52:33.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:52:33.997: INFO: namespace emptydir-8055 deletion completed in 6.089509201s

• [SLOW TEST:10.174 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:52:33.998: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:52:36.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7744" for this suite.
May 23 20:53:14.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:53:14.149: INFO: namespace kubelet-test-7744 deletion completed in 38.09588038s

• [SLOW TEST:40.151 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:53:14.149: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-949
May 23 20:53:18.186: INFO: Started pod liveness-http in namespace container-probe-949
STEP: checking the pod's current state and verifying that restartCount is present
May 23 20:53:18.192: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:57:19.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-949" for this suite.
May 23 20:57:25.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:57:25.232: INFO: namespace container-probe-949 deletion completed in 6.060097182s

• [SLOW TEST:251.084 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:57:25.233: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-64x7
STEP: Creating a pod to test atomic-volume-subpath
May 23 20:57:25.306: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-64x7" in namespace "subpath-8907" to be "success or failure"
May 23 20:57:25.312: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009416ms
May 23 20:57:27.327: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020285963s
May 23 20:57:29.333: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 4.026291116s
May 23 20:57:31.335: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 6.028553708s
May 23 20:57:33.340: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 8.033923987s
May 23 20:57:35.346: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 10.039613903s
May 23 20:57:37.352: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 12.046013605s
May 23 20:57:39.358: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 14.051418577s
May 23 20:57:41.364: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 16.057403825s
May 23 20:57:43.371: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 18.065053001s
May 23 20:57:45.381: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Running", Reason="", readiness=true. Elapsed: 20.074341071s
May 23 20:57:47.387: INFO: Pod "pod-subpath-test-secret-64x7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.080819763s
STEP: Saw pod success
May 23 20:57:47.388: INFO: Pod "pod-subpath-test-secret-64x7" satisfied condition "success or failure"
May 23 20:57:47.392: INFO: Trying to get logs from node worker-1 pod pod-subpath-test-secret-64x7 container test-container-subpath-secret-64x7: <nil>
STEP: delete the pod
May 23 20:57:47.437: INFO: Waiting for pod pod-subpath-test-secret-64x7 to disappear
May 23 20:57:47.440: INFO: Pod pod-subpath-test-secret-64x7 no longer exists
STEP: Deleting pod pod-subpath-test-secret-64x7
May 23 20:57:47.440: INFO: Deleting pod "pod-subpath-test-secret-64x7" in namespace "subpath-8907"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:57:47.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8907" for this suite.
May 23 20:57:53.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:57:53.530: INFO: namespace subpath-8907 deletion completed in 6.085250039s

• [SLOW TEST:28.297 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:57:53.533: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 23 20:57:53.553: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 23 20:57:53.556: INFO: Waiting for terminating namespaces to be deleted...
May 23 20:57:53.558: INFO: 
Logging pods the kubelet thinks is on node controlplane-1 before test
May 23 20:57:53.562: INFO: weave-net-kt8s6 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.562: INFO: 	Container weave ready: true, restart count 0
May 23 20:57:53.562: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:57:53.562: INFO: kube-controller-manager-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:57:53.562: INFO: etcd-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:57:53.562: INFO: coredns-fb8b8dccf-t24wc from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.562: INFO: 	Container coredns ready: true, restart count 0
May 23 20:57:53.562: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-ghmvv from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.562: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 23 20:57:53.562: INFO: 	Container systemd-logs ready: true, restart count 1
May 23 20:57:53.562: INFO: kube-scheduler-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:57:53.562: INFO: kube-proxy-kcbp9 from kube-system started at 2019-05-23 19:25:01 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.562: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:57:53.562: INFO: coredns-fb8b8dccf-j6x4t from kube-system started at 2019-05-23 19:25:32 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.562: INFO: 	Container coredns ready: true, restart count 0
May 23 20:57:53.562: INFO: kube-apiserver-controlplane-1 from kube-system started at <nil> (0 container statuses recorded)
May 23 20:57:53.562: INFO: 
Logging pods the kubelet thinks is on node worker-1 before test
May 23 20:57:53.566: INFO: kube-proxy-lpxwl from kube-system started at 2019-05-23 19:25:04 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.566: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:57:53.566: INFO: weave-net-t292l from kube-system started at 2019-05-23 19:25:04 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.566: INFO: 	Container weave ready: true, restart count 0
May 23 20:57:53.566: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:57:53.566: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-23 19:26:01 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 23 20:57:53.566: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-wpj4k from heptio-sonobuoy started at 2019-05-23 19:26:14 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.566: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 23 20:57:53.566: INFO: 	Container systemd-logs ready: true, restart count 1
May 23 20:57:53.566: INFO: 
Logging pods the kubelet thinks is on node worker-2 before test
May 23 20:57:53.569: INFO: kube-proxy-5fwlj from kube-system started at 2019-05-23 19:25:19 +0000 UTC (1 container statuses recorded)
May 23 20:57:53.569: INFO: 	Container kube-proxy ready: true, restart count 0
May 23 20:57:53.569: INFO: sonobuoy-e2e-job-67a3a42f03d24ef6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.569: INFO: 	Container e2e ready: true, restart count 0
May 23 20:57:53.569: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 23 20:57:53.569: INFO: weave-net-lp9js from kube-system started at 2019-05-23 19:25:19 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.569: INFO: 	Container weave ready: true, restart count 1
May 23 20:57:53.569: INFO: 	Container weave-npc ready: true, restart count 0
May 23 20:57:53.569: INFO: sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-b25f6 from heptio-sonobuoy started at 2019-05-23 19:26:13 +0000 UTC (2 container statuses recorded)
May 23 20:57:53.569: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 23 20:57:53.569: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node controlplane-1
STEP: verifying the node has the label node worker-1
STEP: verifying the node has the label node worker-2
May 23 20:57:53.592: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-1
May 23 20:57:53.592: INFO: Pod sonobuoy-e2e-job-67a3a42f03d24ef6 requesting resource cpu=0m on Node worker-2
May 23 20:57:53.592: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-b25f6 requesting resource cpu=0m on Node worker-2
May 23 20:57:53.592: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-ghmvv requesting resource cpu=0m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9749dcb1c8d419c-wpj4k requesting resource cpu=0m on Node worker-1
May 23 20:57:53.592: INFO: Pod coredns-fb8b8dccf-j6x4t requesting resource cpu=100m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod coredns-fb8b8dccf-t24wc requesting resource cpu=100m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod etcd-controlplane-1 requesting resource cpu=0m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod kube-apiserver-controlplane-1 requesting resource cpu=250m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod kube-controller-manager-controlplane-1 requesting resource cpu=200m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod kube-proxy-5fwlj requesting resource cpu=0m on Node worker-2
May 23 20:57:53.592: INFO: Pod kube-proxy-kcbp9 requesting resource cpu=0m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod kube-proxy-lpxwl requesting resource cpu=0m on Node worker-1
May 23 20:57:53.592: INFO: Pod kube-scheduler-controlplane-1 requesting resource cpu=100m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod weave-net-kt8s6 requesting resource cpu=20m on Node controlplane-1
May 23 20:57:53.592: INFO: Pod weave-net-lp9js requesting resource cpu=20m on Node worker-2
May 23 20:57:53.592: INFO: Pod weave-net-t292l requesting resource cpu=20m on Node worker-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6fb7c481ea], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1419/filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe to worker-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ff9d0ea04], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ffd46c4ed], Reason = [Created], Message = [Created container filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe.15a16b700b019ca6], Reason = [Started], Message = [Started container filler-pod-6eedcffd-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6fb8ace1eb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1419/filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe to controlplane-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ff33ef68f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ff7608f33], Reason = [Created], Message = [Created container filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe.15a16b7003d6d6d4], Reason = [Started], Message = [Started container filler-pod-6eee92b5-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6fb94ed2b3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1419/filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe to worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ff08eca51], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ff4c824e7], Reason = [Created], Message = [Created container filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe.15a16b6ffcd68424], Reason = [Started], Message = [Started container filler-pod-6ef0a804-7d9d-11e9-b22f-2a454b6ec3fe]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a16b70a9b216cd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node worker-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node controlplane-1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:57:58.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1419" for this suite.
May 23 20:58:04.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:58:04.820: INFO: namespace sched-pred-1419 deletion completed in 6.085675804s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.287 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:58:04.820: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
May 23 20:58:04.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-2904'
May 23 20:58:05.449: INFO: stderr: ""
May 23 20:58:05.449: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
May 23 20:58:06.469: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:58:06.469: INFO: Found 0 / 1
May 23 20:58:07.462: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:58:07.462: INFO: Found 0 / 1
May 23 20:58:08.456: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:58:08.456: INFO: Found 1 / 1
May 23 20:58:08.456: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 23 20:58:08.461: INFO: Selector matched 1 pods for map[app:redis]
May 23 20:58:08.461: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 23 20:58:08.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 logs redis-master-zbwvz redis-master --namespace=kubectl-2904'
May 23 20:58:08.538: INFO: stderr: ""
May 23 20:58:08.538: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 May 20:58:06.796 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 May 20:58:06.796 # Server started, Redis version 3.2.12\n1:M 23 May 20:58:06.796 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 May 20:58:06.796 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 23 20:58:08.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 log redis-master-zbwvz redis-master --namespace=kubectl-2904 --tail=1'
May 23 20:58:08.599: INFO: stderr: ""
May 23 20:58:08.599: INFO: stdout: "1:M 23 May 20:58:06.796 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 23 20:58:08.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 log redis-master-zbwvz redis-master --namespace=kubectl-2904 --limit-bytes=1'
May 23 20:58:08.667: INFO: stderr: ""
May 23 20:58:08.667: INFO: stdout: " "
STEP: exposing timestamps
May 23 20:58:08.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 log redis-master-zbwvz redis-master --namespace=kubectl-2904 --tail=1 --timestamps'
May 23 20:58:08.720: INFO: stderr: ""
May 23 20:58:08.720: INFO: stdout: "2019-05-23T20:58:06.796456563Z 1:M 23 May 20:58:06.796 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 23 20:58:11.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 log redis-master-zbwvz redis-master --namespace=kubectl-2904 --since=1s'
May 23 20:58:11.329: INFO: stderr: ""
May 23 20:58:11.329: INFO: stdout: ""
May 23 20:58:11.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 log redis-master-zbwvz redis-master --namespace=kubectl-2904 --since=24h'
May 23 20:58:11.380: INFO: stderr: ""
May 23 20:58:11.380: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 May 20:58:06.796 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 May 20:58:06.796 # Server started, Redis version 3.2.12\n1:M 23 May 20:58:06.796 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 May 20:58:06.796 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
May 23 20:58:11.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete --grace-period=0 --force -f - --namespace=kubectl-2904'
May 23 20:58:11.436: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 23 20:58:11.436: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 23 20:58:11.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get rc,svc -l name=nginx --no-headers --namespace=kubectl-2904'
May 23 20:58:11.485: INFO: stderr: "No resources found.\n"
May 23 20:58:11.485: INFO: stdout: ""
May 23 20:58:11.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -l name=nginx --namespace=kubectl-2904 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 23 20:58:11.533: INFO: stderr: ""
May 23 20:58:11.533: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:58:11.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2904" for this suite.
May 23 20:58:33.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:58:33.651: INFO: namespace kubectl-2904 deletion completed in 22.11629506s

• [SLOW TEST:28.831 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:58:33.652: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
May 23 20:58:33.678: INFO: Waiting up to 5m0s for pod "pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe" in namespace "emptydir-5494" to be "success or failure"
May 23 20:58:33.685: INFO: Pod "pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.48926ms
May 23 20:58:35.687: INFO: Pod "pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009078656s
STEP: Saw pod success
May 23 20:58:35.687: INFO: Pod "pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:58:35.689: INFO: Trying to get logs from node worker-1 pod pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 20:58:35.704: INFO: Waiting for pod pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:58:35.705: INFO: Pod pod-86d1a2d3-7d9d-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:58:35.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5494" for this suite.
May 23 20:58:41.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:58:41.799: INFO: namespace emptydir-5494 deletion completed in 6.091093892s

• [SLOW TEST:8.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:58:41.799: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-8bace9ff-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Creating configMap with name cm-test-opt-upd-8bacea22-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8bace9ff-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Updating configmap cm-test-opt-upd-8bacea22-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Creating configMap with name cm-test-opt-create-8bacea2d-7d9d-11e9-b22f-2a454b6ec3fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:58:48.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5305" for this suite.
May 23 20:59:10.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:59:10.206: INFO: namespace configmap-5305 deletion completed in 22.096052212s

• [SLOW TEST:28.407 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:59:10.209: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0523 20:59:20.272130      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 23 20:59:20.272: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:59:20.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-420" for this suite.
May 23 20:59:26.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:59:26.375: INFO: namespace gc-420 deletion completed in 6.096850884s

• [SLOW TEST:16.167 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:59:26.376: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a640177c-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume secrets
May 23 20:59:26.413: INFO: Waiting up to 5m0s for pod "pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe" in namespace "secrets-5508" to be "success or failure"
May 23 20:59:26.420: INFO: Pod "pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.262889ms
May 23 20:59:28.422: INFO: Pod "pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009493648s
STEP: Saw pod success
May 23 20:59:28.422: INFO: Pod "pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 20:59:28.425: INFO: Trying to get logs from node worker-1 pod pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe container secret-volume-test: <nil>
STEP: delete the pod
May 23 20:59:28.444: INFO: Waiting for pod pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe to disappear
May 23 20:59:28.447: INFO: Pod pod-secrets-a640679b-7d9d-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:59:28.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5508" for this suite.
May 23 20:59:34.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:59:34.538: INFO: namespace secrets-5508 deletion completed in 6.088174703s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:59:34.539: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 20:59:34.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4839" for this suite.
May 23 20:59:40.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 20:59:40.661: INFO: namespace services-4839 deletion completed in 6.089815897s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.122 seconds]
[sig-network] Services
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 20:59:40.661: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 23 20:59:40.680: INFO: PodSpec: initContainers in spec.initContainers
May 23 21:00:26.529: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-aec22754-7d9d-11e9-b22f-2a454b6ec3fe", GenerateName:"", Namespace:"init-container-1944", SelfLink:"/api/v1/namespaces/init-container-1944/pods/pod-init-aec22754-7d9d-11e9-b22f-2a454b6ec3fe", UID:"aec4d637-7d9d-11e9-a2d7-080027c2be11", ResourceVersion:"19948", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694241980, loc:(*time.Location)(0x8a140e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"680791793"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-lnvlp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001fbc0c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lnvlp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lnvlp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lnvlp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f96148), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001c76000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f962d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f962f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001f962f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f962fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694241980, loc:(*time.Location)(0x8a140e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694241980, loc:(*time.Location)(0x8a140e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694241980, loc:(*time.Location)(0x8a140e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694241980, loc:(*time.Location)(0x8a140e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.101", PodIP:"10.40.0.2", StartTime:(*v1.Time)(0xc0010ee0c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0010ee1c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002260070)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://289035527c5b3c84aeff7ab8deb49f2c626c0455be6f4aa3df13dc97fd9036a7"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010ee240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010ee100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:00:26.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1944" for this suite.
May 23 21:00:48.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:00:48.619: INFO: namespace init-container-1944 deletion completed in 22.086208949s

• [SLOW TEST:67.958 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:00:48.620: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 23 21:00:48.639: INFO: Creating deployment "test-recreate-deployment"
May 23 21:00:48.641: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 23 21:00:48.644: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
May 23 21:00:50.714: INFO: Waiting deployment "test-recreate-deployment" to complete
May 23 21:00:50.720: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 23 21:00:50.734: INFO: Updating deployment test-recreate-deployment
May 23 21:00:50.734: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 23 21:00:50.803: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6666,SelfLink:/apis/apps/v1/namespaces/deployment-6666/deployments/test-recreate-deployment,UID:d7465026-7d9d-11e9-a2d7-080027c2be11,ResourceVersion:20041,Generation:2,CreationTimestamp:2019-05-23 21:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-23 21:00:50 +0000 UTC 2019-05-23 21:00:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-23 21:00:50 +0000 UTC 2019-05-23 21:00:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 23 21:00:50.807: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-6666,SelfLink:/apis/apps/v1/namespaces/deployment-6666/replicasets/test-recreate-deployment-c9cbd8684,UID:d88bc283-7d9d-11e9-a2d7-080027c2be11,ResourceVersion:20040,Generation:1,CreationTimestamp:2019-05-23 21:00:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d7465026-7d9d-11e9-a2d7-080027c2be11 0xc002bf4bc0 0xc002bf4bc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 21:00:50.807: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 23 21:00:50.807: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-6666,SelfLink:/apis/apps/v1/namespaces/deployment-6666/replicasets/test-recreate-deployment-7d57d5ff7c,UID:d74823e3-7d9d-11e9-a2d7-080027c2be11,ResourceVersion:20032,Generation:2,CreationTimestamp:2019-05-23 21:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d7465026-7d9d-11e9-a2d7-080027c2be11 0xc002bf4aa7 0xc002bf4aa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 23 21:00:50.809: INFO: Pod "test-recreate-deployment-c9cbd8684-cxzlc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-cxzlc,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-6666,SelfLink:/api/v1/namespaces/deployment-6666/pods/test-recreate-deployment-c9cbd8684-cxzlc,UID:d88c04e2-7d9d-11e9-a2d7-080027c2be11,ResourceVersion:20043,Generation:0,CreationTimestamp:2019-05-23 21:00:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 d88bc283-7d9d-11e9-a2d7-080027c2be11 0xc002bf5470 0xc002bf5471}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bhs6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bhs6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bhs6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bf5510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bf5530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 21:00:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 21:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-23 21:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-23 21:00:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.101,PodIP:,StartTime:2019-05-23 21:00:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:00:50.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6666" for this suite.
May 23 21:00:56.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:00:56.903: INFO: namespace deployment-6666 deletion completed in 6.091932194s

• [SLOW TEST:8.283 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:00:56.903: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 23 21:00:56.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3276'
May 23 21:00:56.981: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 23 21:00:56.981: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 23 21:00:56.990: INFO: scanned /root for discovery docs: <nil>
May 23 21:00:56.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3276'
May 23 21:01:12.874: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 23 21:01:12.874: INFO: stdout: "Created e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d\nScaling up e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 23 21:01:12.874: INFO: stdout: "Created e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d\nScaling up e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 23 21:01:12.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3276'
May 23 21:01:12.940: INFO: stderr: ""
May 23 21:01:12.940: INFO: stdout: "e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d-48r5f e2e-test-nginx-rc-sj99s "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
May 23 21:01:17.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3276'
May 23 21:01:18.036: INFO: stderr: ""
May 23 21:01:18.036: INFO: stdout: "e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d-48r5f "
May 23 21:01:18.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d-48r5f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3276'
May 23 21:01:18.099: INFO: stderr: ""
May 23 21:01:18.099: INFO: stdout: "true"
May 23 21:01:18.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 get pods e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d-48r5f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3276'
May 23 21:01:18.150: INFO: stderr: ""
May 23 21:01:18.150: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 23 21:01:18.150: INFO: e2e-test-nginx-rc-0806439417bf805a12e59f05b299899d-48r5f is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
May 23 21:01:18.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 delete rc e2e-test-nginx-rc --namespace=kubectl-3276'
May 23 21:01:18.212: INFO: stderr: ""
May 23 21:01:18.212: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:01:18.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3276" for this suite.
May 23 21:01:24.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:01:24.432: INFO: namespace kubectl-3276 deletion completed in 6.217902552s

• [SLOW TEST:27.529 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:01:24.433: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
May 23 21:01:27.006: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1510 pod-service-account-ecec0733-7d9d-11e9-b22f-2a454b6ec3fe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 23 21:01:27.206: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1510 pod-service-account-ecec0733-7d9d-11e9-b22f-2a454b6ec3fe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 23 21:01:27.348: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1510 pod-service-account-ecec0733-7d9d-11e9-b22f-2a454b6ec3fe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:01:27.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1510" for this suite.
May 23 21:01:33.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:01:33.544: INFO: namespace svcaccounts-1510 deletion completed in 6.072710053s

• [SLOW TEST:9.111 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:01:33.544: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:01:33.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3950" for this suite.
May 23 21:01:39.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:01:39.666: INFO: namespace kubelet-test-3950 deletion completed in 6.08249909s

• [SLOW TEST:6.122 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:01:39.667: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-f5b10524-7d9d-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 21:01:39.694: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe" in namespace "projected-8917" to be "success or failure"
May 23 21:01:39.700: INFO: Pod "pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070074ms
May 23 21:01:41.707: INFO: Pod "pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012306049s
May 23 21:01:43.713: INFO: Pod "pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018499756s
STEP: Saw pod success
May 23 21:01:43.713: INFO: Pod "pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:01:43.718: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 21:01:43.764: INFO: Waiting for pod pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:01:43.767: INFO: Pod pod-projected-configmaps-f5b15177-7d9d-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:01:43.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8917" for this suite.
May 23 21:01:49.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:01:49.837: INFO: namespace projected-8917 deletion completed in 6.067096549s

• [SLOW TEST:10.171 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:01:49.838: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 23 21:01:54.405: INFO: Successfully updated pod "annotationupdatefbc0f6b5-7d9d-11e9-b22f-2a454b6ec3fe"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:01:56.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4590" for this suite.
May 23 21:02:18.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:02:18.563: INFO: namespace projected-4590 deletion completed in 22.115242837s

• [SLOW TEST:28.725 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:02:18.564: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 21:02:18.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe" in namespace "projected-7999" to be "success or failure"
May 23 21:02:18.592: INFO: Pod "downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.407064ms
May 23 21:02:20.598: INFO: Pod "downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011061741s
May 23 21:02:22.605: INFO: Pod "downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017720642s
STEP: Saw pod success
May 23 21:02:22.605: INFO: Pod "downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:02:22.610: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 21:02:22.660: INFO: Waiting for pod downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:02:22.665: INFO: Pod downwardapi-volume-0ce037e8-7d9e-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:02:22.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7999" for this suite.
May 23 21:02:28.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:02:28.748: INFO: namespace projected-7999 deletion completed in 6.078958546s

• [SLOW TEST:10.184 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:02:28.749: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 23 21:02:28.775: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-6265" to be "success or failure"
May 23 21:02:28.782: INFO: Pod "downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.881317ms
May 23 21:02:30.790: INFO: Pod "downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014946138s
May 23 21:02:32.798: INFO: Pod "downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023349851s
STEP: Saw pod success
May 23 21:02:32.798: INFO: Pod "downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:02:32.804: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe container client-container: <nil>
STEP: delete the pod
May 23 21:02:32.840: INFO: Waiting for pod downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:02:32.843: INFO: Pod downwardapi-volume-12f29ebc-7d9e-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:02:32.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6265" for this suite.
May 23 21:02:38.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:02:38.945: INFO: namespace downward-api-6265 deletion completed in 6.098076977s

• [SLOW TEST:10.197 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:02:38.947: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
May 23 21:02:38.978: INFO: Waiting up to 5m0s for pod "client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe" in namespace "containers-802" to be "success or failure"
May 23 21:02:38.981: INFO: Pod "client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.639631ms
May 23 21:02:40.990: INFO: Pod "client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011224281s
May 23 21:02:42.998: INFO: Pod "client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019887448s
STEP: Saw pod success
May 23 21:02:42.999: INFO: Pod "client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:02:43.004: INFO: Trying to get logs from node worker-1 pod client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe container test-container: <nil>
STEP: delete the pod
May 23 21:02:43.037: INFO: Waiting for pod client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:02:43.044: INFO: Pod client-containers-19076103-7d9e-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:02:43.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-802" for this suite.
May 23 21:02:49.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:02:49.106: INFO: namespace containers-802 deletion completed in 6.053696272s

• [SLOW TEST:10.159 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:02:49.107: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 23 21:02:49.133: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1176,SelfLink:/api/v1/namespaces/watch-1176/configmaps/e2e-watch-test-watch-closed,UID:1f1778c7-7d9e-11e9-a2d7-080027c2be11,ResourceVersion:20500,Generation:0,CreationTimestamp:2019-05-23 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 23 21:02:49.134: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1176,SelfLink:/api/v1/namespaces/watch-1176/configmaps/e2e-watch-test-watch-closed,UID:1f1778c7-7d9e-11e9-a2d7-080027c2be11,ResourceVersion:20501,Generation:0,CreationTimestamp:2019-05-23 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 23 21:02:49.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1176,SelfLink:/api/v1/namespaces/watch-1176/configmaps/e2e-watch-test-watch-closed,UID:1f1778c7-7d9e-11e9-a2d7-080027c2be11,ResourceVersion:20502,Generation:0,CreationTimestamp:2019-05-23 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 23 21:02:49.140: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1176,SelfLink:/api/v1/namespaces/watch-1176/configmaps/e2e-watch-test-watch-closed,UID:1f1778c7-7d9e-11e9-a2d7-080027c2be11,ResourceVersion:20503,Generation:0,CreationTimestamp:2019-05-23 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:02:49.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1176" for this suite.
May 23 21:02:55.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:02:55.256: INFO: namespace watch-1176 deletion completed in 6.113591964s

• [SLOW TEST:6.150 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:02:55.257: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 23 21:02:55.367: INFO: Waiting up to 5m0s for pod "downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe" in namespace "downward-api-6217" to be "success or failure"
May 23 21:02:55.382: INFO: Pod "downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 15.395188ms
May 23 21:02:57.385: INFO: Pod "downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017434605s
STEP: Saw pod success
May 23 21:02:57.385: INFO: Pod "downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:02:57.386: INFO: Trying to get logs from node worker-1 pod downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe container dapi-container: <nil>
STEP: delete the pod
May 23 21:02:57.399: INFO: Waiting for pod downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:02:57.401: INFO: Pod downward-api-22caec85-7d9e-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:02:57.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6217" for this suite.
May 23 21:03:03.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:03:03.509: INFO: namespace downward-api-6217 deletion completed in 6.105690355s

• [SLOW TEST:8.251 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:03:03.509: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-27b204bc-7d9e-11e9-b22f-2a454b6ec3fe
STEP: Creating a pod to test consume configMaps
May 23 21:03:03.588: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe" in namespace "projected-724" to be "success or failure"
May 23 21:03:03.597: INFO: Pod "pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.113061ms
May 23 21:03:05.603: INFO: Pod "pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014894908s
May 23 21:03:07.609: INFO: Pod "pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021188059s
STEP: Saw pod success
May 23 21:03:07.610: INFO: Pod "pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe" satisfied condition "success or failure"
May 23 21:03:07.615: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 23 21:03:07.656: INFO: Waiting for pod pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe to disappear
May 23 21:03:07.661: INFO: Pod pod-projected-configmaps-27b27138-7d9e-11e9-b22f-2a454b6ec3fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:03:07.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-724" for this suite.
May 23 21:03:13.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:03:13.748: INFO: namespace projected-724 deletion completed in 6.082523728s

• [SLOW TEST:10.239 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 23 21:03:13.748: INFO: >>> kubeConfig: /tmp/kubeconfig-041930030
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 23 21:03:13.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 create -f - --namespace=kubectl-2193'
May 23 21:03:13.867: INFO: stderr: ""
May 23 21:03:13.867: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 23 21:03:14.873: INFO: Selector matched 1 pods for map[app:redis]
May 23 21:03:14.873: INFO: Found 0 / 1
May 23 21:03:15.873: INFO: Selector matched 1 pods for map[app:redis]
May 23 21:03:15.873: INFO: Found 0 / 1
May 23 21:03:16.872: INFO: Selector matched 1 pods for map[app:redis]
May 23 21:03:16.872: INFO: Found 1 / 1
May 23 21:03:16.872: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 23 21:03:16.877: INFO: Selector matched 1 pods for map[app:redis]
May 23 21:03:16.877: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 23 21:03:16.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041930030 patch pod redis-master-gpcq6 --namespace=kubectl-2193 -p {"metadata":{"annotations":{"x":"y"}}}'
May 23 21:03:16.948: INFO: stderr: ""
May 23 21:03:16.948: INFO: stdout: "pod/redis-master-gpcq6 patched\n"
STEP: checking annotations
May 23 21:03:16.952: INFO: Selector matched 1 pods for map[app:redis]
May 23 21:03:16.952: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 23 21:03:16.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2193" for this suite.
May 23 21:03:38.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 23 21:03:39.070: INFO: namespace kubectl-2193 deletion completed in 22.116703851s

• [SLOW TEST:25.322 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.2-beta.0.85+66049e3b21efe1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMay 23 21:03:39.070: INFO: Running AfterSuite actions on all nodes
May 23 21:03:39.076: INFO: Running AfterSuite actions on node 1
May 23 21:03:39.076: INFO: Skipping dumping logs from cluster

Ran 204 of 3585 Specs in 5727.949 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3381 Skipped PASS

Ginkgo ran 1 suite in 1h35m28.77212869s
Test Suite Passed
