I0410 15:28:25.394408      19 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-646907027
I0410 15:28:25.394527      19 e2e.go:240] Starting e2e run "47f1ac0b-5ba5-11e9-8040-3209cfee711a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554910104 - Will randomize all specs
Will run 204 of 3584 specs

Apr 10 15:28:25.532: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:28:25.534: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 10 15:28:25.548: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 10 15:28:25.570: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 10 15:28:25.570: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Apr 10 15:28:25.570: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 10 15:28:25.579: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 10 15:28:25.579: INFO: e2e test version: v1.14.1
Apr 10 15:28:25.580: INFO: kube-apiserver version: v1.14.1
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:28:25.580: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename aggregator
Apr 10 15:28:26.538: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 10 15:28:27.901: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 10 15:28:30.405: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:32.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:34.768: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:36.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:38.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:40.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:42.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:44.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:46.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:48.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:50.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:52.408: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:54.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:56.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:28:58.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:29:00.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:29:02.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:29:04.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:29:06.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690506907, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 15:29:09.220: INFO: Waited 711.455883ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:29:11.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4209" for this suite.
Apr 10 15:29:19.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:29:19.387: INFO: namespace aggregator-4209 deletion completed in 8.238823949s

• [SLOW TEST:53.806 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:29:19.388: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:29:30.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9704" for this suite.
Apr 10 15:30:10.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:30:10.276: INFO: namespace kubelet-test-9704 deletion completed in 40.191420681s

• [SLOW TEST:50.889 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:30:10.277: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-873b195f-5ba5-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 15:30:11.067: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a" in namespace "projected-437" to be "success or failure"
Apr 10 15:30:11.132: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 65.003391ms
Apr 10 15:30:13.139: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072195072s
Apr 10 15:30:15.142: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0755827s
Apr 10 15:30:17.350: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.283035221s
Apr 10 15:30:19.353: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.28589855s
STEP: Saw pod success
Apr 10 15:30:19.353: INFO: Pod "pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:30:19.355: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 15:30:19.439: INFO: Waiting for pod pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a to disappear
Apr 10 15:30:19.573: INFO: Pod pod-projected-configmaps-874501ea-5ba5-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:30:19.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-437" for this suite.
Apr 10 15:30:27.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:30:27.686: INFO: namespace projected-437 deletion completed in 8.108605999s

• [SLOW TEST:17.409 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:30:27.686: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-f6n7
STEP: Creating a pod to test atomic-volume-subpath
Apr 10 15:30:28.267: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f6n7" in namespace "subpath-2294" to be "success or failure"
Apr 10 15:30:28.328: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Pending", Reason="", readiness=false. Elapsed: 60.814197ms
Apr 10 15:30:30.340: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073010437s
Apr 10 15:30:32.345: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 4.077748913s
Apr 10 15:30:34.425: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 6.157646545s
Apr 10 15:30:36.429: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 8.162007617s
Apr 10 15:30:38.433: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 10.165485426s
Apr 10 15:30:40.436: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 12.168180739s
Apr 10 15:30:42.441: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 14.173909682s
Apr 10 15:30:44.446: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 16.178249747s
Apr 10 15:30:46.450: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 18.182796468s
Apr 10 15:30:48.454: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 20.186853029s
Apr 10 15:30:50.458: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Running", Reason="", readiness=true. Elapsed: 22.191025645s
Apr 10 15:30:52.462: INFO: Pod "pod-subpath-test-configmap-f6n7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.194974571s
STEP: Saw pod success
Apr 10 15:30:52.463: INFO: Pod "pod-subpath-test-configmap-f6n7" satisfied condition "success or failure"
Apr 10 15:30:52.465: INFO: Trying to get logs from node g168 pod pod-subpath-test-configmap-f6n7 container test-container-subpath-configmap-f6n7: <nil>
STEP: delete the pod
Apr 10 15:30:52.662: INFO: Waiting for pod pod-subpath-test-configmap-f6n7 to disappear
Apr 10 15:30:52.665: INFO: Pod pod-subpath-test-configmap-f6n7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f6n7
Apr 10 15:30:52.665: INFO: Deleting pod "pod-subpath-test-configmap-f6n7" in namespace "subpath-2294"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:30:52.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2294" for this suite.
Apr 10 15:31:00.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:31:00.762: INFO: namespace subpath-2294 deletion completed in 8.0923304s

• [SLOW TEST:33.076 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:31:00.763: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 15:31:01.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4155'
Apr 10 15:31:07.080: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 10 15:31:07.080: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 10 15:31:07.216: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr 10 15:31:07.280: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 10 15:31:07.492: INFO: scanned /root for discovery docs: <nil>
Apr 10 15:31:07.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4155'
Apr 10 15:31:31.909: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 10 15:31:31.909: INFO: stdout: "Created e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3\nScaling up e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 10 15:31:31.909: INFO: stdout: "Created e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3\nScaling up e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 10 15:31:31.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4155'
Apr 10 15:31:32.096: INFO: stderr: ""
Apr 10 15:31:32.096: INFO: stdout: "e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3-wh5xp "
Apr 10 15:31:32.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3-wh5xp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4155'
Apr 10 15:31:32.158: INFO: stderr: ""
Apr 10 15:31:32.158: INFO: stdout: "true"
Apr 10 15:31:32.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3-wh5xp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4155'
Apr 10 15:31:32.264: INFO: stderr: ""
Apr 10 15:31:32.264: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 10 15:31:32.264: INFO: e2e-test-nginx-rc-a96e7234d3201ce93d7dbdd47d023de3-wh5xp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 10 15:31:32.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete rc e2e-test-nginx-rc --namespace=kubectl-4155'
Apr 10 15:31:32.466: INFO: stderr: ""
Apr 10 15:31:32.466: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:31:32.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4155" for this suite.
Apr 10 15:31:57.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:31:57.131: INFO: namespace kubectl-4155 deletion completed in 24.600575666s

• [SLOW TEST:56.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:31:57.134: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 10 15:31:57.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 --namespace=kubectl-5341 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 10 15:32:00.166: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 10 15:32:00.166: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:32:02.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5341" for this suite.
Apr 10 15:32:08.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:32:08.523: INFO: namespace kubectl-5341 deletion completed in 6.347383694s

• [SLOW TEST:11.389 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:32:08.524: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 10 15:32:13.573: INFO: Successfully updated pod "annotationupdatecd92db99-5ba5-11e9-8040-3209cfee711a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:32:15.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4242" for this suite.
Apr 10 15:32:39.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:32:39.968: INFO: namespace projected-4242 deletion completed in 24.204454398s

• [SLOW TEST:31.444 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:32:39.968: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 15:32:40.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a" in namespace "projected-6195" to be "success or failure"
Apr 10 15:32:40.629: INFO: Pod "downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 197.260474ms
Apr 10 15:32:42.693: INFO: Pod "downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.261387531s
Apr 10 15:32:44.698: INFO: Pod "downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.26685007s
STEP: Saw pod success
Apr 10 15:32:44.698: INFO: Pod "downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:32:44.701: INFO: Trying to get logs from node g168 pod downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 15:32:44.843: INFO: Waiting for pod downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a to disappear
Apr 10 15:32:44.888: INFO: Pod downwardapi-volume-e0616616-5ba5-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:32:44.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6195" for this suite.
Apr 10 15:32:51.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:32:51.233: INFO: namespace projected-6195 deletion completed in 6.341243715s

• [SLOW TEST:11.264 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:32:51.234: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 15:32:51.715: INFO: (0) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 63.969651ms)
Apr 10 15:32:51.718: INFO: (1) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 3.057515ms)
Apr 10 15:32:51.721: INFO: (2) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.555315ms)
Apr 10 15:32:51.724: INFO: (3) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.545233ms)
Apr 10 15:32:51.726: INFO: (4) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.534467ms)
Apr 10 15:32:51.729: INFO: (5) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.513187ms)
Apr 10 15:32:51.731: INFO: (6) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.991594ms)
Apr 10 15:32:51.733: INFO: (7) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.56742ms)
Apr 10 15:32:51.736: INFO: (8) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.371127ms)
Apr 10 15:32:51.738: INFO: (9) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.948367ms)
Apr 10 15:32:51.740: INFO: (10) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.120254ms)
Apr 10 15:32:51.742: INFO: (11) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.000913ms)
Apr 10 15:32:51.819: INFO: (12) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 77.196476ms)
Apr 10 15:32:51.823: INFO: (13) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 4.289069ms)
Apr 10 15:32:51.828: INFO: (14) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 4.717706ms)
Apr 10 15:32:51.833: INFO: (15) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 4.536646ms)
Apr 10 15:32:51.835: INFO: (16) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.620456ms)
Apr 10 15:32:51.838: INFO: (17) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.25642ms)
Apr 10 15:32:51.840: INFO: (18) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.52568ms)
Apr 10 15:32:51.843: INFO: (19) /api/v1/nodes/e173/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.265651ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:32:51.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4128" for this suite.
Apr 10 15:32:57.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:32:58.027: INFO: namespace proxy-4128 deletion completed in 6.182417198s

• [SLOW TEST:6.794 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:32:58.028: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 10 15:32:58.388: INFO: Waiting up to 5m0s for pod "downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a" in namespace "downward-api-7356" to be "success or failure"
Apr 10 15:32:58.439: INFO: Pod "downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 50.931953ms
Apr 10 15:33:00.444: INFO: Pod "downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055424624s
Apr 10 15:33:02.448: INFO: Pod "downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059789409s
STEP: Saw pod success
Apr 10 15:33:02.448: INFO: Pod "downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:33:02.451: INFO: Trying to get logs from node g168 pod downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 15:33:02.613: INFO: Waiting for pod downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a to disappear
Apr 10 15:33:02.685: INFO: Pod downward-api-eb0a0bd0-5ba5-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:33:02.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7356" for this suite.
Apr 10 15:33:08.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:33:09.069: INFO: namespace downward-api-7356 deletion completed in 6.379843278s

• [SLOW TEST:11.041 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:33:09.070: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-mz8f
STEP: Creating a pod to test atomic-volume-subpath
Apr 10 15:33:09.814: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mz8f" in namespace "subpath-4565" to be "success or failure"
Apr 10 15:33:09.869: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Pending", Reason="", readiness=false. Elapsed: 54.911965ms
Apr 10 15:33:11.905: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090447504s
Apr 10 15:33:13.909: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.094657019s
Apr 10 15:33:15.914: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 6.099827821s
Apr 10 15:33:18.001: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 8.187318729s
Apr 10 15:33:20.006: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 10.192329429s
Apr 10 15:33:22.011: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 12.19675876s
Apr 10 15:33:24.016: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 14.201788069s
Apr 10 15:33:26.021: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 16.206413527s
Apr 10 15:33:28.024: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 18.21033568s
Apr 10 15:33:30.029: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 20.215211569s
Apr 10 15:33:32.071: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Running", Reason="", readiness=true. Elapsed: 22.256427819s
Apr 10 15:33:34.255: INFO: Pod "pod-subpath-test-configmap-mz8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.440943581s
STEP: Saw pod success
Apr 10 15:33:34.255: INFO: Pod "pod-subpath-test-configmap-mz8f" satisfied condition "success or failure"
Apr 10 15:33:34.258: INFO: Trying to get logs from node g168 pod pod-subpath-test-configmap-mz8f container test-container-subpath-configmap-mz8f: <nil>
STEP: delete the pod
Apr 10 15:33:34.327: INFO: Waiting for pod pod-subpath-test-configmap-mz8f to disappear
Apr 10 15:33:34.446: INFO: Pod pod-subpath-test-configmap-mz8f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mz8f
Apr 10 15:33:34.446: INFO: Deleting pod "pod-subpath-test-configmap-mz8f" in namespace "subpath-4565"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:33:34.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4565" for this suite.
Apr 10 15:33:40.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:33:40.853: INFO: namespace subpath-4565 deletion completed in 6.342740991s

• [SLOW TEST:31.783 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:33:40.853: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7494
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 10 15:33:41.125: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 10 15:34:18.008: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.14:8080/dial?request=hostName&protocol=udp&host=10.244.1.13&port=8081&tries=1'] Namespace:pod-network-test-7494 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:34:18.008: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:34:18.068: INFO: Waiting for endpoints: map[]
Apr 10 15:34:18.071: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.14:8080/dial?request=hostName&protocol=udp&host=10.244.2.4&port=8081&tries=1'] Namespace:pod-network-test-7494 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:34:18.071: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:34:18.132: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:34:18.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7494" for this suite.
Apr 10 15:34:44.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:34:44.396: INFO: namespace pod-network-test-7494 deletion completed in 26.26100448s

• [SLOW TEST:63.542 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:34:44.396: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 10 15:34:49.524: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3572 pod-service-account-2adac6b5-5ba6-11e9-8040-3209cfee711a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 10 15:34:49.648: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3572 pod-service-account-2adac6b5-5ba6-11e9-8040-3209cfee711a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 10 15:34:49.761: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3572 pod-service-account-2adac6b5-5ba6-11e9-8040-3209cfee711a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:34:49.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3572" for this suite.
Apr 10 15:34:57.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:34:57.973: INFO: namespace svcaccounts-3572 deletion completed in 8.103723803s

• [SLOW TEST:13.577 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:34:57.973: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 10 15:34:58.416: INFO: Waiting up to 5m0s for pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a" in namespace "emptydir-4080" to be "success or failure"
Apr 10 15:34:58.472: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 56.244911ms
Apr 10 15:35:00.477: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060687752s
Apr 10 15:35:02.515: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09851797s
Apr 10 15:35:04.519: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.103197147s
Apr 10 15:35:06.590: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.174209609s
STEP: Saw pod success
Apr 10 15:35:06.590: INFO: Pod "pod-328f1d62-5ba6-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:35:06.646: INFO: Trying to get logs from node g168 pod pod-328f1d62-5ba6-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:35:06.794: INFO: Waiting for pod pod-328f1d62-5ba6-11e9-8040-3209cfee711a to disappear
Apr 10 15:35:06.846: INFO: Pod pod-328f1d62-5ba6-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:35:06.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4080" for this suite.
Apr 10 15:35:15.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:35:15.081: INFO: namespace emptydir-4080 deletion completed in 8.229778985s

• [SLOW TEST:17.108 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:35:15.083: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:35:15.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7750" for this suite.
Apr 10 15:35:38.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:35:38.217: INFO: namespace kubelet-test-7750 deletion completed in 22.322592418s

• [SLOW TEST:23.134 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:35:38.217: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4959
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4959
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4959
Apr 10 15:35:38.882: INFO: Found 0 stateful pods, waiting for 1
Apr 10 15:35:48.886: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 10 15:35:48.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:35:49.142: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:35:49.142: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:35:49.142: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:35:49.144: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 10 15:35:59.148: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:35:59.148: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:35:59.414: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999557s
Apr 10 15:36:00.508: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.749068957s
Apr 10 15:36:01.513: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.65436952s
Apr 10 15:36:02.600: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.650143868s
Apr 10 15:36:03.605: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.563089127s
Apr 10 15:36:04.634: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.558166778s
Apr 10 15:36:05.639: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.528490569s
Apr 10 15:36:06.644: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.52349512s
Apr 10 15:36:07.650: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.518728949s
Apr 10 15:36:08.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 513.294618ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4959
Apr 10 15:36:09.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:36:09.826: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 15:36:09.826: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:36:09.826: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:36:09.829: INFO: Found 1 stateful pods, waiting for 3
Apr 10 15:36:19.833: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 15:36:19.833: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 15:36:19.833: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 10 15:36:19.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:36:19.967: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:36:19.967: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:36:19.967: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:36:19.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:36:20.083: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:36:20.083: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:36:20.083: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:36:20.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:36:20.204: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:36:20.204: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:36:20.204: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:36:20.204: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:36:20.387: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 10 15:36:30.532: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:36:30.532: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:36:30.532: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:36:30.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999537s
Apr 10 15:36:31.748: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.820159547s
Apr 10 15:36:32.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.792255758s
Apr 10 15:36:33.898: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.716460236s
Apr 10 15:36:34.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.642119564s
Apr 10 15:36:35.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.63657105s
Apr 10 15:36:36.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.631743374s
Apr 10 15:36:37.927: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.627134256s
Apr 10 15:36:38.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.612967075s
Apr 10 15:36:39.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 608.358841ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4959
Apr 10 15:36:40.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:36:41.080: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 15:36:41.080: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:36:41.080: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:36:41.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:36:41.211: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 15:36:41.211: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:36:41.211: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:36:41.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-4959 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:36:41.442: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 15:36:41.442: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:36:41.442: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:36:41.442: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 10 15:36:51.977: INFO: Deleting all statefulset in ns statefulset-4959
Apr 10 15:36:51.980: INFO: Scaling statefulset ss to 0
Apr 10 15:36:51.988: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:36:51.990: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:36:52.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4959" for this suite.
Apr 10 15:37:04.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:37:04.481: INFO: namespace statefulset-4959 deletion completed in 12.258780354s

• [SLOW TEST:86.264 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:37:04.481: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 10 15:37:04.895: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:37:10.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9725" for this suite.
Apr 10 15:37:18.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:37:18.833: INFO: namespace init-container-9725 deletion completed in 8.247653804s

• [SLOW TEST:14.351 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:37:18.833: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 10 15:37:19.270: INFO: Waiting up to 5m0s for pod "pod-869c4143-5ba6-11e9-8040-3209cfee711a" in namespace "emptydir-7184" to be "success or failure"
Apr 10 15:37:19.314: INFO: Pod "pod-869c4143-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 43.458105ms
Apr 10 15:37:21.363: INFO: Pod "pod-869c4143-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092326808s
Apr 10 15:37:23.367: INFO: Pod "pod-869c4143-5ba6-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.096234851s
STEP: Saw pod success
Apr 10 15:37:23.367: INFO: Pod "pod-869c4143-5ba6-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:37:23.371: INFO: Trying to get logs from node g168 pod pod-869c4143-5ba6-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:37:23.444: INFO: Waiting for pod pod-869c4143-5ba6-11e9-8040-3209cfee711a to disappear
Apr 10 15:37:23.583: INFO: Pod pod-869c4143-5ba6-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:37:23.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7184" for this suite.
Apr 10 15:37:31.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:37:31.701: INFO: namespace emptydir-7184 deletion completed in 8.113368956s

• [SLOW TEST:12.868 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:37:31.701: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 10 15:37:32.098: INFO: PodSpec: initContainers in spec.initContainers
Apr 10 15:38:22.364: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8e434a3d-5ba6-11e9-8040-3209cfee711a", GenerateName:"", Namespace:"init-container-267", SelfLink:"/api/v1/namespaces/init-container-267/pods/pod-init-8e434a3d-5ba6-11e9-8040-3209cfee711a", UID:"8e443cab-5ba6-11e9-b4c9-5254005baff5", ResourceVersion:"3265", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63690507452, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"98420557"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-49cn2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001450f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-49cn2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-49cn2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-49cn2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0029c4418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"g168", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026c2b40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029c44a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029c44c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0029c44c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0029c44cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690507452, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690507452, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690507452, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690507452, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.160.67.168", PodIP:"10.244.1.21", StartTime:(*v1.Time)(0xc0028a2a20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00288f960)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00288f9d0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"cri-o://1c920d6968900d05c858d070c87a152dd53b33922851523a1b5975c103817868"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028a2aa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028a2a60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:38:22.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-267" for this suite.
Apr 10 15:38:40.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:38:40.614: INFO: namespace init-container-267 deletion completed in 18.116285875s

• [SLOW TEST:68.913 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:38:40.615: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 15:38:41.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a" in namespace "projected-8893" to be "success or failure"
Apr 10 15:38:41.250: INFO: Pod "downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 181.476305ms
Apr 10 15:38:43.305: INFO: Pod "downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.23609586s
Apr 10 15:38:45.309: INFO: Pod "downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.240598745s
STEP: Saw pod success
Apr 10 15:38:45.309: INFO: Pod "downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:38:45.312: INFO: Trying to get logs from node g168 pod downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 15:38:45.383: INFO: Waiting for pod downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a to disappear
Apr 10 15:38:45.504: INFO: Pod downwardapi-volume-b75655a6-5ba6-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:38:45.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8893" for this suite.
Apr 10 15:38:53.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:38:53.605: INFO: namespace projected-8893 deletion completed in 8.096634157s

• [SLOW TEST:12.990 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:38:53.605: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-befe645a-5ba6-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 15:38:54.029: INFO: Waiting up to 5m0s for pod "pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a" in namespace "secrets-8951" to be "success or failure"
Apr 10 15:38:54.077: INFO: Pod "pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 47.936073ms
Apr 10 15:38:56.082: INFO: Pod "pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05272962s
Apr 10 15:38:58.086: INFO: Pod "pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056722194s
STEP: Saw pod success
Apr 10 15:38:58.086: INFO: Pod "pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:38:58.089: INFO: Trying to get logs from node g168 pod pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 15:38:58.228: INFO: Waiting for pod pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a to disappear
Apr 10 15:38:58.274: INFO: Pod pod-secrets-bf183fd5-5ba6-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:38:58.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8951" for this suite.
Apr 10 15:39:06.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:39:06.377: INFO: namespace secrets-8951 deletion completed in 8.100045411s

• [SLOW TEST:12.772 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:39:06.377: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 15:39:07.034: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 10 15:39:12.039: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 10 15:39:12.039: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 10 15:39:12.236: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7008,SelfLink:/apis/apps/v1/namespaces/deployment-7008/deployments/test-cleanup-deployment,UID:c9d5eb9d-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3436,Generation:1,CreationTimestamp:2019-04-10 15:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 10 15:39:12.423: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-7008,SelfLink:/apis/apps/v1/namespaces/deployment-7008/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:c9ec6cdc-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3438,Generation:1,CreationTimestamp:2019-04-10 15:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c9d5eb9d-5ba6-11e9-b4c9-5254005baff5 0xc002c44637 0xc002c44638}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 15:39:12.423: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 10 15:39:12.423: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-7008,SelfLink:/apis/apps/v1/namespaces/deployment-7008/replicasets/test-cleanup-controller,UID:c6b30776-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3437,Generation:1,CreationTimestamp:2019-04-10 15:39:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c9d5eb9d-5ba6-11e9-b4c9-5254005baff5 0xc002c4455f 0xc002c44570}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 10 15:39:12.691: INFO: Pod "test-cleanup-controller-m2dcl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-m2dcl,GenerateName:test-cleanup-controller-,Namespace:deployment-7008,SelfLink:/api/v1/namespaces/deployment-7008/pods/test-cleanup-controller-m2dcl,UID:c6bc332f-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3430,Generation:0,CreationTimestamp:2019-04-10 15:39:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c6b30776-5ba6-11e9-b4c9-5254005baff5 0xc002c44e9f 0xc002c44eb0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dw588 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dw588,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dw588 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:39:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:39:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:39:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:39:07 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.24,StartTime:2019-04-10 15:39:07 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 15:39:08 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://16e1195f186cd39eddea97c5ad792d794144433dfaca7696dd29c2260491ad55}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 15:39:12.691: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-5j4kf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-5j4kf,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-7008,SelfLink:/api/v1/namespaces/deployment-7008/pods/test-cleanup-deployment-55cbfbc8f5-5j4kf,UID:c9f3c063-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3442,Generation:0,CreationTimestamp:2019-04-10 15:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 c9ec6cdc-5ba6-11e9-b4c9-5254005baff5 0xc002c45017 0xc002c45018}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dw588 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dw588,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dw588 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c450b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:39:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:39:12.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7008" for this suite.
Apr 10 15:39:23.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:39:23.211: INFO: namespace deployment-7008 deletion completed in 10.460835855s

• [SLOW TEST:16.834 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:39:23.211: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 10 15:39:26.044: INFO: Pod pod-hostip-d0b8bfd3-5ba6-11e9-8040-3209cfee711a has hostIP: 10.160.67.168
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:39:26.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1386" for this suite.
Apr 10 15:39:48.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:39:48.220: INFO: namespace pods-1386 deletion completed in 22.171960279s

• [SLOW TEST:25.009 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:39:48.221: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4351.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4351.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 10 15:40:16.735: INFO: DNS probes using dns-4351/dns-test-dfa4cc6e-5ba6-11e9-8040-3209cfee711a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:40:16.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4351" for this suite.
Apr 10 15:40:25.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:40:25.229: INFO: namespace dns-4351 deletion completed in 8.320977254s

• [SLOW TEST:37.008 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:40:25.231: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-f59e522f-5ba6-11e9-8040-3209cfee711a
STEP: Creating secret with name secret-projected-all-test-volume-f59e5222-5ba6-11e9-8040-3209cfee711a
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 10 15:40:25.808: INFO: Waiting up to 5m0s for pod "projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a" in namespace "projected-7470" to be "success or failure"
Apr 10 15:40:25.989: INFO: Pod "projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 180.80067ms
Apr 10 15:40:27.994: INFO: Pod "projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.185431129s
Apr 10 15:40:29.999: INFO: Pod "projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.190203318s
STEP: Saw pod success
Apr 10 15:40:29.999: INFO: Pod "projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:40:30.003: INFO: Trying to get logs from node g168 pod projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 10 15:40:30.199: INFO: Waiting for pod projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a to disappear
Apr 10 15:40:30.318: INFO: Pod projected-volume-f59e51ff-5ba6-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:40:30.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7470" for this suite.
Apr 10 15:40:36.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:40:36.457: INFO: namespace projected-7470 deletion completed in 6.132950402s

• [SLOW TEST:11.226 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:40:36.457: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 10 15:40:37.231: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7780,SelfLink:/api/v1/namespaces/watch-7780/configmaps/e2e-watch-test-resource-version,UID:fc5a29de-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3730,Generation:0,CreationTimestamp:2019-04-10 15:40:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 10 15:40:37.232: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7780,SelfLink:/api/v1/namespaces/watch-7780/configmaps/e2e-watch-test-resource-version,UID:fc5a29de-5ba6-11e9-b4c9-5254005baff5,ResourceVersion:3731,Generation:0,CreationTimestamp:2019-04-10 15:40:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:40:37.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7780" for this suite.
Apr 10 15:40:43.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:40:43.471: INFO: namespace watch-7780 deletion completed in 6.196962193s

• [SLOW TEST:7.014 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:40:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 10 15:40:49.020: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:40:50.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9482" for this suite.
Apr 10 15:41:14.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:41:14.322: INFO: namespace replicaset-9482 deletion completed in 24.236134942s

• [SLOW TEST:30.847 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:41:14.326: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 10 15:41:14.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3611'
Apr 10 15:41:18.451: INFO: stderr: ""
Apr 10 15:41:18.451: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 15:41:18.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3611'
Apr 10 15:41:18.687: INFO: stderr: ""
Apr 10 15:41:18.687: INFO: stdout: "update-demo-nautilus-rnqpc update-demo-nautilus-srcsm "
Apr 10 15:41:18.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-rnqpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:18.943: INFO: stderr: ""
Apr 10 15:41:18.943: INFO: stdout: ""
Apr 10 15:41:18.943: INFO: update-demo-nautilus-rnqpc is created but not running
Apr 10 15:41:23.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3611'
Apr 10 15:41:24.020: INFO: stderr: ""
Apr 10 15:41:24.020: INFO: stdout: "update-demo-nautilus-rnqpc update-demo-nautilus-srcsm "
Apr 10 15:41:24.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-rnqpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:24.201: INFO: stderr: ""
Apr 10 15:41:24.201: INFO: stdout: ""
Apr 10 15:41:24.201: INFO: update-demo-nautilus-rnqpc is created but not running
Apr 10 15:41:29.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3611'
Apr 10 15:41:29.274: INFO: stderr: ""
Apr 10 15:41:29.274: INFO: stdout: "update-demo-nautilus-rnqpc update-demo-nautilus-srcsm "
Apr 10 15:41:29.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-rnqpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:29.331: INFO: stderr: ""
Apr 10 15:41:29.331: INFO: stdout: "true"
Apr 10 15:41:29.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-rnqpc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:29.396: INFO: stderr: ""
Apr 10 15:41:29.396: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 15:41:29.396: INFO: validating pod update-demo-nautilus-rnqpc
Apr 10 15:41:29.399: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 15:41:29.399: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 15:41:29.399: INFO: update-demo-nautilus-rnqpc is verified up and running
Apr 10 15:41:29.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-srcsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:29.454: INFO: stderr: ""
Apr 10 15:41:29.454: INFO: stdout: "true"
Apr 10 15:41:29.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-srcsm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3611'
Apr 10 15:41:29.555: INFO: stderr: ""
Apr 10 15:41:29.555: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 15:41:29.555: INFO: validating pod update-demo-nautilus-srcsm
Apr 10 15:41:29.560: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 15:41:29.560: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 15:41:29.560: INFO: update-demo-nautilus-srcsm is verified up and running
STEP: using delete to clean up resources
Apr 10 15:41:29.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3611'
Apr 10 15:41:29.685: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 15:41:29.685: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 10 15:41:29.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3611'
Apr 10 15:41:29.852: INFO: stderr: "No resources found.\n"
Apr 10 15:41:29.852: INFO: stdout: ""
Apr 10 15:41:29.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -l name=update-demo --namespace=kubectl-3611 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 10 15:41:30.068: INFO: stderr: ""
Apr 10 15:41:30.068: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:41:30.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3611" for this suite.
Apr 10 15:41:54.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:41:54.428: INFO: namespace kubectl-3611 deletion completed in 24.131959282s

• [SLOW TEST:40.102 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:41:54.429: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 10 15:41:54.866: INFO: Waiting up to 5m0s for pod "pod-2ad900fa-5ba7-11e9-8040-3209cfee711a" in namespace "emptydir-9706" to be "success or failure"
Apr 10 15:41:55.057: INFO: Pod "pod-2ad900fa-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 191.093215ms
Apr 10 15:41:57.061: INFO: Pod "pod-2ad900fa-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.195201413s
Apr 10 15:41:59.065: INFO: Pod "pod-2ad900fa-5ba7-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.198954407s
STEP: Saw pod success
Apr 10 15:41:59.065: INFO: Pod "pod-2ad900fa-5ba7-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:41:59.069: INFO: Trying to get logs from node g168 pod pod-2ad900fa-5ba7-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:41:59.210: INFO: Waiting for pod pod-2ad900fa-5ba7-11e9-8040-3209cfee711a to disappear
Apr 10 15:41:59.259: INFO: Pod pod-2ad900fa-5ba7-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:41:59.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9706" for this suite.
Apr 10 15:42:07.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:42:07.456: INFO: namespace emptydir-9706 deletion completed in 8.192346201s

• [SLOW TEST:13.027 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:42:07.461: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 10 15:42:07.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-1334'
Apr 10 15:42:08.385: INFO: stderr: ""
Apr 10 15:42:08.385: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 10 15:42:09.388: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:09.388: INFO: Found 0 / 1
Apr 10 15:42:10.389: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:10.389: INFO: Found 0 / 1
Apr 10 15:42:11.389: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:11.389: INFO: Found 0 / 1
Apr 10 15:42:12.387: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:12.387: INFO: Found 0 / 1
Apr 10 15:42:13.389: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:13.389: INFO: Found 0 / 1
Apr 10 15:42:14.597: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:14.597: INFO: Found 0 / 1
Apr 10 15:42:15.388: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:15.388: INFO: Found 0 / 1
Apr 10 15:42:16.457: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:16.457: INFO: Found 1 / 1
Apr 10 15:42:16.457: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 10 15:42:16.460: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:42:16.460: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 10 15:42:16.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 logs redis-master-5dw84 redis-master --namespace=kubectl-1334'
Apr 10 15:42:16.548: INFO: stderr: ""
Apr 10 15:42:16.549: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Apr 15:42:15.157 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Apr 15:42:15.157 # Server started, Redis version 3.2.12\n1:M 10 Apr 15:42:15.157 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Apr 15:42:15.157 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 10 15:42:16.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 log redis-master-5dw84 redis-master --namespace=kubectl-1334 --tail=1'
Apr 10 15:42:16.632: INFO: stderr: ""
Apr 10 15:42:16.632: INFO: stdout: "1:M 10 Apr 15:42:15.157 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 10 15:42:16.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 log redis-master-5dw84 redis-master --namespace=kubectl-1334 --limit-bytes=1'
Apr 10 15:42:16.763: INFO: stderr: ""
Apr 10 15:42:16.763: INFO: stdout: " "
STEP: exposing timestamps
Apr 10 15:42:16.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 log redis-master-5dw84 redis-master --namespace=kubectl-1334 --tail=1 --timestamps'
Apr 10 15:42:16.868: INFO: stderr: ""
Apr 10 15:42:16.868: INFO: stdout: "2019-04-10T15:42:15.157210599Z 1:M 10 Apr 15:42:15.157 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 10 15:42:19.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 log redis-master-5dw84 redis-master --namespace=kubectl-1334 --since=1s'
Apr 10 15:42:19.454: INFO: stderr: ""
Apr 10 15:42:19.454: INFO: stdout: ""
Apr 10 15:42:19.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 log redis-master-5dw84 redis-master --namespace=kubectl-1334 --since=24h'
Apr 10 15:42:19.532: INFO: stderr: ""
Apr 10 15:42:19.532: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Apr 15:42:15.157 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Apr 15:42:15.157 # Server started, Redis version 3.2.12\n1:M 10 Apr 15:42:15.157 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Apr 15:42:15.157 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 10 15:42:19.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-1334'
Apr 10 15:42:19.731: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 15:42:19.731: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 10 15:42:19.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1334'
Apr 10 15:42:19.877: INFO: stderr: "No resources found.\n"
Apr 10 15:42:19.877: INFO: stdout: ""
Apr 10 15:42:19.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -l name=nginx --namespace=kubectl-1334 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 10 15:42:20.154: INFO: stderr: ""
Apr 10 15:42:20.154: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:42:20.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1334" for this suite.
Apr 10 15:42:44.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:42:44.792: INFO: namespace kubectl-1334 deletion completed in 24.581048562s

• [SLOW TEST:37.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:42:44.793: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-48eac19a-5ba7-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 15:42:45.481: INFO: Waiting up to 5m0s for pod "pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a" in namespace "secrets-7420" to be "success or failure"
Apr 10 15:42:45.531: INFO: Pod "pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 50.081332ms
Apr 10 15:42:47.535: INFO: Pod "pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054106451s
Apr 10 15:42:49.540: INFO: Pod "pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05849883s
STEP: Saw pod success
Apr 10 15:42:49.540: INFO: Pod "pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:42:49.544: INFO: Trying to get logs from node g168 pod pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a container secret-env-test: <nil>
STEP: delete the pod
Apr 10 15:42:49.792: INFO: Waiting for pod pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a to disappear
Apr 10 15:42:49.934: INFO: Pod pod-secrets-490c1dc1-5ba7-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:42:49.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7420" for this suite.
Apr 10 15:42:58.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:42:58.272: INFO: namespace secrets-7420 deletion completed in 8.332773844s

• [SLOW TEST:13.479 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:42:58.272: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6543.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6543.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6543.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6543.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.175.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.175.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.175.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.175.241_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6543.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6543.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6543.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6543.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6543.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6543.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.175.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.175.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.175.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.175.241_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 10 15:43:27.390: INFO: Unable to read wheezy_udp@dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.392: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.395: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.397: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.413: INFO: Unable to read jessie_udp@dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.415: INFO: Unable to read jessie_tcp@dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.416: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.418: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local from pod dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a: the server could not find the requested resource (get pods dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a)
Apr 10 15:43:27.431: INFO: Lookups using dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a failed for: [wheezy_udp@dns-test-service.dns-6543.svc.cluster.local wheezy_tcp@dns-test-service.dns-6543.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local jessie_udp@dns-test-service.dns-6543.svc.cluster.local jessie_tcp@dns-test-service.dns-6543.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6543.svc.cluster.local]

Apr 10 15:43:32.479: INFO: DNS probes using dns-6543/dns-test-512c3fe7-5ba7-11e9-8040-3209cfee711a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:43:33.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6543" for this suite.
Apr 10 15:43:41.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:43:42.223: INFO: namespace dns-6543 deletion completed in 8.324223269s

• [SLOW TEST:43.952 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:43:42.225: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 10 15:43:42.757: INFO: Waiting up to 5m0s for pod "pod-6b30864b-5ba7-11e9-8040-3209cfee711a" in namespace "emptydir-9379" to be "success or failure"
Apr 10 15:43:42.831: INFO: Pod "pod-6b30864b-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 73.349989ms
Apr 10 15:43:44.875: INFO: Pod "pod-6b30864b-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117346357s
Apr 10 15:43:46.887: INFO: Pod "pod-6b30864b-5ba7-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.130118314s
STEP: Saw pod success
Apr 10 15:43:46.887: INFO: Pod "pod-6b30864b-5ba7-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:43:46.891: INFO: Trying to get logs from node g168 pod pod-6b30864b-5ba7-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:43:46.972: INFO: Waiting for pod pod-6b30864b-5ba7-11e9-8040-3209cfee711a to disappear
Apr 10 15:43:47.140: INFO: Pod pod-6b30864b-5ba7-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:43:47.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9379" for this suite.
Apr 10 15:43:55.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:43:55.385: INFO: namespace emptydir-9379 deletion completed in 8.240152189s

• [SLOW TEST:13.159 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:43:55.385: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 10 15:43:56.121: INFO: Waiting up to 5m0s for pod "downward-api-730715c4-5ba7-11e9-8040-3209cfee711a" in namespace "downward-api-8879" to be "success or failure"
Apr 10 15:43:56.322: INFO: Pod "downward-api-730715c4-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 201.593655ms
Apr 10 15:43:58.358: INFO: Pod "downward-api-730715c4-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237093037s
Apr 10 15:44:00.362: INFO: Pod "downward-api-730715c4-5ba7-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.240829102s
STEP: Saw pod success
Apr 10 15:44:00.362: INFO: Pod "downward-api-730715c4-5ba7-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:44:00.365: INFO: Trying to get logs from node g168 pod downward-api-730715c4-5ba7-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 15:44:00.449: INFO: Waiting for pod downward-api-730715c4-5ba7-11e9-8040-3209cfee711a to disappear
Apr 10 15:44:00.591: INFO: Pod downward-api-730715c4-5ba7-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:44:00.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8879" for this suite.
Apr 10 15:44:08.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:44:09.055: INFO: namespace downward-api-8879 deletion completed in 8.460341151s

• [SLOW TEST:13.670 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:44:09.057: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 10 15:44:19.835: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:19.835: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:19.892: INFO: Exec stderr: ""
Apr 10 15:44:19.892: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:19.892: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:19.938: INFO: Exec stderr: ""
Apr 10 15:44:19.938: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:19.938: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:19.989: INFO: Exec stderr: ""
Apr 10 15:44:19.989: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:19.989: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.041: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 10 15:44:20.041: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.041: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.091: INFO: Exec stderr: ""
Apr 10 15:44:20.091: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.091: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.142: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 10 15:44:20.142: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.142: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.201: INFO: Exec stderr: ""
Apr 10 15:44:20.201: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.201: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.254: INFO: Exec stderr: ""
Apr 10 15:44:20.254: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.254: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.310: INFO: Exec stderr: ""
Apr 10 15:44:20.310: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4092 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 15:44:20.310: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 15:44:20.363: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:44:20.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4092" for this suite.
Apr 10 15:45:12.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:45:12.624: INFO: namespace e2e-kubelet-etc-hosts-4092 deletion completed in 52.257939535s

• [SLOW TEST:63.568 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:45:12.625: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a103f7fc-5ba7-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 15:45:13.281: INFO: Waiting up to 5m0s for pod "pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a" in namespace "configmap-3707" to be "success or failure"
Apr 10 15:45:13.330: INFO: Pod "pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 49.341582ms
Apr 10 15:45:15.378: INFO: Pod "pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096512746s
Apr 10 15:45:17.381: INFO: Pod "pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100410451s
STEP: Saw pod success
Apr 10 15:45:17.382: INFO: Pod "pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:45:17.385: INFO: Trying to get logs from node g168 pod pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 15:45:17.568: INFO: Waiting for pod pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a to disappear
Apr 10 15:45:17.624: INFO: Pod pod-configmaps-a10d7e6e-5ba7-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:45:17.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3707" for this suite.
Apr 10 15:45:25.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:45:25.868: INFO: namespace configmap-3707 deletion completed in 8.2409435s

• [SLOW TEST:13.244 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:45:25.872: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9094
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-9094
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9094
Apr 10 15:45:26.645: INFO: Found 0 stateful pods, waiting for 1
Apr 10 15:45:36.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 10 15:45:36.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:45:36.776: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:45:36.776: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:45:36.776: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:45:36.779: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 10 15:45:46.783: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:45:46.783: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:45:47.005: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:45:47.005: INFO: ss-0  g168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:45:47.005: INFO: ss-1        Pending         []
Apr 10 15:45:47.005: INFO: 
Apr 10 15:45:47.005: INFO: StatefulSet ss has not reached scale 3, at 2
Apr 10 15:45:48.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.787849634s
Apr 10 15:45:49.095: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.729213411s
Apr 10 15:45:50.163: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.697960779s
Apr 10 15:45:51.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.630201617s
Apr 10 15:45:52.172: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.626595596s
Apr 10 15:45:53.177: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.621372698s
Apr 10 15:45:54.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.616538159s
Apr 10 15:45:55.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.503943228s
Apr 10 15:45:56.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 500.344099ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9094
Apr 10 15:45:57.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:45:57.417: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 15:45:57.417: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:45:57.417: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:45:57.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:45:57.536: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 10 15:45:57.536: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:45:57.536: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:45:57.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:45:57.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 10 15:45:57.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 15:45:57.653: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 15:45:57.656: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 10 15:46:07.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 15:46:07.661: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 15:46:07.661: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 10 15:46:07.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:46:07.777: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:46:07.778: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:46:07.778: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:46:07.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:46:08.039: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:46:08.039: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:46:08.040: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:46:08.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 15:46:08.263: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 15:46:08.263: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 15:46:08.263: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 15:46:08.263: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:46:08.266: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 10 15:46:18.273: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:46:18.273: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:46:18.273: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 10 15:46:18.340: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:18.340: INFO: ss-0  g168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:18.340: INFO: ss-1  e173  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:18.340: INFO: ss-2  g168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:18.341: INFO: 
Apr 10 15:46:18.341: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:19.655: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:19.655: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:19.656: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:19.656: INFO: ss-2  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:19.656: INFO: 
Apr 10 15:46:19.656: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:20.760: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:20.760: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:20.760: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:20.760: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:20.760: INFO: 
Apr 10 15:46:20.760: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:21.765: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:21.766: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:21.766: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:21.766: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:21.766: INFO: 
Apr 10 15:46:21.766: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:22.794: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:22.794: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:22.794: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:22.794: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:22.794: INFO: 
Apr 10 15:46:22.794: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:23.799: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:23.799: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:23.800: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:23.800: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:23.800: INFO: 
Apr 10 15:46:23.800: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:24.805: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:24.805: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:24.805: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:24.805: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:24.805: INFO: 
Apr 10 15:46:24.806: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:25.810: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:25.810: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:25.811: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:25.811: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:25.811: INFO: 
Apr 10 15:46:25.811: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:26.815: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:26.815: INFO: ss-0  g168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:26 +0000 UTC  }]
Apr 10 15:46:26.815: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:26.816: INFO: ss-2  g168  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:26.816: INFO: 
Apr 10 15:46:26.816: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 10 15:46:27.837: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Apr 10 15:46:27.837: INFO: ss-1  e173  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:46:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 15:45:47 +0000 UTC  }]
Apr 10 15:46:27.837: INFO: 
Apr 10 15:46:27.837: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9094
Apr 10 15:46:28.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:46:28.926: INFO: rc: 1
Apr 10 15:46:28.926: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc00182cb70 exit status 1 <nil> <nil> true [0xc0029020c0 0xc0029020d8 0xc0029020f0] [0xc0029020c0 0xc0029020d8 0xc0029020f0] [0xc0029020d0 0xc0029020e8] [0x9bf9f0 0x9bf9f0] 0xc001b85440 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Apr 10 15:46:38.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:46:39.040: INFO: rc: 1
Apr 10 15:46:39.041: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b25d0 exit status 1 <nil> <nil> true [0xc0028b20d0 0xc0028b20e8 0xc0028b2100] [0xc0028b20d0 0xc0028b20e8 0xc0028b2100] [0xc0028b20e0 0xc0028b20f8] [0x9bf9f0 0x9bf9f0] 0xc002224720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:46:49.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:46:49.105: INFO: rc: 1
Apr 10 15:46:49.105: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b2930 exit status 1 <nil> <nil> true [0xc0028b2108 0xc0028b2120 0xc0028b2138] [0xc0028b2108 0xc0028b2120 0xc0028b2138] [0xc0028b2118 0xc0028b2130] [0x9bf9f0 0x9bf9f0] 0xc002224cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:46:59.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:46:59.158: INFO: rc: 1
Apr 10 15:46:59.159: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b2c90 exit status 1 <nil> <nil> true [0xc0028b2140 0xc0028b2158 0xc0028b2170] [0xc0028b2140 0xc0028b2158 0xc0028b2170] [0xc0028b2150 0xc0028b2168] [0x9bf9f0 0x9bf9f0] 0xc002225200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:09.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:09.227: INFO: rc: 1
Apr 10 15:47:09.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b2ff0 exit status 1 <nil> <nil> true [0xc0028b2178 0xc0028b2190 0xc0028b21a8] [0xc0028b2178 0xc0028b2190 0xc0028b21a8] [0xc0028b2188 0xc0028b21a0] [0x9bf9f0 0x9bf9f0] 0xc002225800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:19.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:19.344: INFO: rc: 1
Apr 10 15:47:19.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00182cf00 exit status 1 <nil> <nil> true [0xc0029020f8 0xc002902110 0xc002902128] [0xc0029020f8 0xc002902110 0xc002902128] [0xc002902108 0xc002902120] [0x9bf9f0 0x9bf9f0] 0xc0022e8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:29.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:29.402: INFO: rc: 1
Apr 10 15:47:29.402: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00182d260 exit status 1 <nil> <nil> true [0xc002902130 0xc002902148 0xc002902160] [0xc002902130 0xc002902148 0xc002902160] [0xc002902140 0xc002902158] [0x9bf9f0 0x9bf9f0] 0xc0022e8c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:39.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:39.477: INFO: rc: 1
Apr 10 15:47:39.477: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b3350 exit status 1 <nil> <nil> true [0xc0028b21b0 0xc0028b21c8 0xc0028b21e0] [0xc0028b21b0 0xc0028b21c8 0xc0028b21e0] [0xc0028b21c0 0xc0028b21d8] [0x9bf9f0 0x9bf9f0] 0xc002225d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:49.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:49.539: INFO: rc: 1
Apr 10 15:47:49.539: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b3830 exit status 1 <nil> <nil> true [0xc0028b21e8 0xc0028b2220 0xc0028b2250] [0xc0028b21e8 0xc0028b2220 0xc0028b2250] [0xc0028b2218 0xc0028b2248] [0x9bf9f0 0x9bf9f0] 0xc001826480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:47:59.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:47:59.593: INFO: rc: 1
Apr 10 15:47:59.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b3c50 exit status 1 <nil> <nil> true [0xc0028b2258 0xc0028b2290 0xc0028b22c8] [0xc0028b2258 0xc0028b2290 0xc0028b22c8] [0xc0028b2270 0xc0028b22b0] [0x9bf9f0 0x9bf9f0] 0xc001826c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:09.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:09.657: INFO: rc: 1
Apr 10 15:48:09.658: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00182d5c0 exit status 1 <nil> <nil> true [0xc002902168 0xc002902180 0xc002902198] [0xc002902168 0xc002902180 0xc002902198] [0xc002902178 0xc002902190] [0x9bf9f0 0x9bf9f0] 0xc0022e9320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:19.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:19.720: INFO: rc: 1
Apr 10 15:48:19.720: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029b3f80 exit status 1 <nil> <nil> true [0xc0028b22e0 0xc0028b2310 0xc0028b2358] [0xc0028b22e0 0xc0028b2310 0xc0028b2358] [0xc0028b22f8 0xc0028b2340] [0x9bf9f0 0x9bf9f0] 0xc0018273e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:29.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:29.781: INFO: rc: 1
Apr 10 15:48:29.781: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001bd4300 exit status 1 <nil> <nil> true [0xc002902020 0xc002902038 0xc002902050] [0xc002902020 0xc002902038 0xc002902050] [0xc002902030 0xc002902048] [0x9bf9f0 0x9bf9f0] 0xc001b849c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:39.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:39.833: INFO: rc: 1
Apr 10 15:48:39.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696300 exit status 1 <nil> <nil> true [0xc0028b2000 0xc0028b2018 0xc0028b2030] [0xc0028b2000 0xc0028b2018 0xc0028b2030] [0xc0028b2010 0xc0028b2028] [0x9bf9f0 0x9bf9f0] 0xc0022244e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:49.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:49.892: INFO: rc: 1
Apr 10 15:48:49.892: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696660 exit status 1 <nil> <nil> true [0xc0028b2038 0xc0028b2050 0xc0028b2068] [0xc0028b2038 0xc0028b2050 0xc0028b2068] [0xc0028b2048 0xc0028b2060] [0x9bf9f0 0x9bf9f0] 0xc002224a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:48:59.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:48:59.948: INFO: rc: 1
Apr 10 15:48:59.948: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001bd4690 exit status 1 <nil> <nil> true [0xc002902058 0xc002902070 0xc002902088] [0xc002902058 0xc002902070 0xc002902088] [0xc002902068 0xc002902080] [0x9bf9f0 0x9bf9f0] 0xc001b85980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:49:09.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:49:10.018: INFO: rc: 1
Apr 10 15:49:10.018: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696990 exit status 1 <nil> <nil> true [0xc0028b2070 0xc0028b2088 0xc0028b20a8] [0xc0028b2070 0xc0028b2088 0xc0028b20a8] [0xc0028b2080 0xc0028b20a0] [0x9bf9f0 0x9bf9f0] 0xc002224fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:49:20.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:49:20.105: INFO: rc: 1
Apr 10 15:49:20.105: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696cf0 exit status 1 <nil> <nil> true [0xc0028b20b0 0xc0028b20c8 0xc0028b20e0] [0xc0028b20b0 0xc0028b20c8 0xc0028b20e0] [0xc0028b20c0 0xc0028b20d8] [0x9bf9f0 0x9bf9f0] 0xc002225560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:49:30.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:49:30.155: INFO: rc: 1
Apr 10 15:49:30.155: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001697050 exit status 1 <nil> <nil> true [0xc0028b20e8 0xc0028b2100 0xc0028b2118] [0xc0028b20e8 0xc0028b2100 0xc0028b2118] [0xc0028b20f8 0xc0028b2110] [0x9bf9f0 0x9bf9f0] 0xc002225b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:49:40.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:49:40.219: INFO: rc: 1
Apr 10 15:49:40.220: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0016973b0 exit status 1 <nil> <nil> true [0xc0028b2120 0xc0028b2138 0xc0028b2150] [0xc0028b2120 0xc0028b2138 0xc0028b2150] [0xc0028b2130 0xc0028b2148] [0x9bf9f0 0x9bf9f0] 0xc001f8e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:49:50.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:49:50.281: INFO: rc: 1
Apr 10 15:49:50.281: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001bd49f0 exit status 1 <nil> <nil> true [0xc002902090 0xc0029020a8 0xc0029020c0] [0xc002902090 0xc0029020a8 0xc0029020c0] [0xc0029020a0 0xc0029020b8] [0x9bf9f0 0x9bf9f0] 0xc001de0c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:00.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:00.333: INFO: rc: 1
Apr 10 15:50:00.333: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001697710 exit status 1 <nil> <nil> true [0xc0028b2158 0xc0028b2170 0xc0028b2188] [0xc0028b2158 0xc0028b2170 0xc0028b2188] [0xc0028b2168 0xc0028b2180] [0x9bf9f0 0x9bf9f0] 0xc001f8f260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:10.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:10.392: INFO: rc: 1
Apr 10 15:50:10.392: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001697a70 exit status 1 <nil> <nil> true [0xc0028b2190 0xc0028b21a8 0xc0028b21c0] [0xc0028b2190 0xc0028b21a8 0xc0028b21c0] [0xc0028b21a0 0xc0028b21b8] [0x9bf9f0 0x9bf9f0] 0xc0022e8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:20.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:20.446: INFO: rc: 1
Apr 10 15:50:20.446: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001697ef0 exit status 1 <nil> <nil> true [0xc0028b21c8 0xc0028b21e0 0xc0028b2218] [0xc0028b21c8 0xc0028b21e0 0xc0028b2218] [0xc0028b21d8 0xc0028b2210] [0x9bf9f0 0x9bf9f0] 0xc0022e8cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:30.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:30.504: INFO: rc: 1
Apr 10 15:50:30.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696330 exit status 1 <nil> <nil> true [0xc0028b2008 0xc0028b2020 0xc0028b2038] [0xc0028b2008 0xc0028b2020 0xc0028b2038] [0xc0028b2018 0xc0028b2030] [0x9bf9f0 0x9bf9f0] 0xc001f8e600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:40.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:40.558: INFO: rc: 1
Apr 10 15:50:40.558: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001bd4360 exit status 1 <nil> <nil> true [0xc002902018 0xc002902030 0xc002902048] [0xc002902018 0xc002902030 0xc002902048] [0xc002902028 0xc002902040] [0x9bf9f0 0x9bf9f0] 0xc0022244e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:50:50.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:50:50.627: INFO: rc: 1
Apr 10 15:50:50.627: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696690 exit status 1 <nil> <nil> true [0xc0028b2040 0xc0028b2058 0xc0028b2070] [0xc0028b2040 0xc0028b2058 0xc0028b2070] [0xc0028b2050 0xc0028b2068] [0x9bf9f0 0x9bf9f0] 0xc001f8fda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:51:00.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:51:00.693: INFO: rc: 1
Apr 10 15:51:00.693: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696a20 exit status 1 <nil> <nil> true [0xc0028b2078 0xc0028b2090 0xc0028b20b0] [0xc0028b2078 0xc0028b2090 0xc0028b20b0] [0xc0028b2088 0xc0028b20a8] [0x9bf9f0 0x9bf9f0] 0xc001b84ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:51:10.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:51:10.750: INFO: rc: 1
Apr 10 15:51:10.750: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001696db0 exit status 1 <nil> <nil> true [0xc0028b20b8 0xc0028b20d0 0xc0028b20e8] [0xc0028b20b8 0xc0028b20d0 0xc0028b20e8] [0xc0028b20c8 0xc0028b20e0] [0x9bf9f0 0x9bf9f0] 0xc001b85b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:51:20.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:51:20.821: INFO: rc: 1
Apr 10 15:51:20.821: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001bd4720 exit status 1 <nil> <nil> true [0xc002902050 0xc002902068 0xc002902080] [0xc002902050 0xc002902068 0xc002902080] [0xc002902060 0xc002902078] [0x9bf9f0 0x9bf9f0] 0xc002224a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Apr 10 15:51:30.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-9094 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 15:51:30.882: INFO: rc: 1
Apr 10 15:51:30.882: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Apr 10 15:51:30.882: INFO: Scaling statefulset ss to 0
Apr 10 15:51:30.888: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 10 15:51:30.889: INFO: Deleting all statefulset in ns statefulset-9094
Apr 10 15:51:30.892: INFO: Scaling statefulset ss to 0
Apr 10 15:51:31.037: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 15:51:31.040: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:51:31.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9094" for this suite.
Apr 10 15:51:41.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:51:41.474: INFO: namespace statefulset-9094 deletion completed in 10.368749157s

• [SLOW TEST:375.602 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:51:41.475: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:51:45.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3634" for this suite.
Apr 10 15:52:24.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:52:24.410: INFO: namespace kubelet-test-3634 deletion completed in 38.468518051s

• [SLOW TEST:42.935 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:52:24.410: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 10 15:52:24.803: INFO: Waiting up to 5m0s for pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a" in namespace "containers-9401" to be "success or failure"
Apr 10 15:52:24.857: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 54.087897ms
Apr 10 15:52:26.862: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058884842s
Apr 10 15:52:28.874: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07073966s
Apr 10 15:52:30.879: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.076133777s
Apr 10 15:52:32.884: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.080572337s
Apr 10 15:52:34.887: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.084141024s
Apr 10 15:52:36.891: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.088207178s
Apr 10 15:52:38.895: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.092098531s
STEP: Saw pod success
Apr 10 15:52:38.895: INFO: Pod "client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:52:38.898: INFO: Trying to get logs from node g168 pod client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:52:38.967: INFO: Waiting for pod client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a to disappear
Apr 10 15:52:39.115: INFO: Pod client-containers-a25a991a-5ba8-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:52:39.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9401" for this suite.
Apr 10 15:52:45.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:52:45.521: INFO: namespace containers-9401 deletion completed in 6.402022752s

• [SLOW TEST:21.111 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:52:45.521: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-aef4c680-5ba8-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 15:52:46.136: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a" in namespace "projected-1998" to be "success or failure"
Apr 10 15:52:46.189: INFO: Pod "pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 53.534072ms
Apr 10 15:52:48.194: INFO: Pod "pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058451356s
Apr 10 15:52:50.199: INFO: Pod "pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063248884s
STEP: Saw pod success
Apr 10 15:52:50.199: INFO: Pod "pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:52:50.202: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 15:52:50.364: INFO: Waiting for pod pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a to disappear
Apr 10 15:52:50.419: INFO: Pod pod-projected-configmaps-aefe4435-5ba8-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:52:50.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1998" for this suite.
Apr 10 15:52:58.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:52:58.670: INFO: namespace projected-1998 deletion completed in 8.246813673s

• [SLOW TEST:13.148 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:52:58.671: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-wxx6
STEP: Creating a pod to test atomic-volume-subpath
Apr 10 15:52:59.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wxx6" in namespace "subpath-2116" to be "success or failure"
Apr 10 15:52:59.288: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Pending", Reason="", readiness=false. Elapsed: 46.724946ms
Apr 10 15:53:01.334: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092289369s
Apr 10 15:53:03.360: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 4.118472394s
Apr 10 15:53:05.365: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 6.123237561s
Apr 10 15:53:07.369: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 8.127505509s
Apr 10 15:53:09.393: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 10.151649658s
Apr 10 15:53:11.397: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 12.155828128s
Apr 10 15:53:13.402: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 14.160706138s
Apr 10 15:53:15.406: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 16.16455204s
Apr 10 15:53:17.410: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 18.167961086s
Apr 10 15:53:19.413: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 20.171213076s
Apr 10 15:53:21.417: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Running", Reason="", readiness=true. Elapsed: 22.17575458s
Apr 10 15:53:23.422: INFO: Pod "pod-subpath-test-downwardapi-wxx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.180166058s
STEP: Saw pod success
Apr 10 15:53:23.422: INFO: Pod "pod-subpath-test-downwardapi-wxx6" satisfied condition "success or failure"
Apr 10 15:53:23.426: INFO: Trying to get logs from node g168 pod pod-subpath-test-downwardapi-wxx6 container test-container-subpath-downwardapi-wxx6: <nil>
STEP: delete the pod
Apr 10 15:53:23.502: INFO: Waiting for pod pod-subpath-test-downwardapi-wxx6 to disappear
Apr 10 15:53:23.633: INFO: Pod pod-subpath-test-downwardapi-wxx6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wxx6
Apr 10 15:53:23.633: INFO: Deleting pod "pod-subpath-test-downwardapi-wxx6" in namespace "subpath-2116"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:53:23.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2116" for this suite.
Apr 10 15:53:31.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:53:31.748: INFO: namespace subpath-2116 deletion completed in 8.107404246s

• [SLOW TEST:33.077 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:53:31.750: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 15:53:32.329: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 10 15:53:32.523: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:32.587: INFO: Number of nodes with available pods: 0
Apr 10 15:53:32.587: INFO: Node e173 is running more than one daemon pod
Apr 10 15:53:33.605: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:33.609: INFO: Number of nodes with available pods: 0
Apr 10 15:53:33.609: INFO: Node e173 is running more than one daemon pod
Apr 10 15:53:34.767: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:34.825: INFO: Number of nodes with available pods: 0
Apr 10 15:53:34.825: INFO: Node e173 is running more than one daemon pod
Apr 10 15:53:35.803: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:35.807: INFO: Number of nodes with available pods: 2
Apr 10 15:53:35.807: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 10 15:53:36.013: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:36.013: INFO: Wrong image for pod: daemon-set-jvl5f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:36.070: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:37.132: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:37.132: INFO: Wrong image for pod: daemon-set-jvl5f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:37.136: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:38.149: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:38.149: INFO: Wrong image for pod: daemon-set-jvl5f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:38.149: INFO: Pod daemon-set-jvl5f is not available
Apr 10 15:53:38.154: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:39.224: INFO: Pod daemon-set-82rd6 is not available
Apr 10 15:53:39.224: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:39.283: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:40.074: INFO: Pod daemon-set-82rd6 is not available
Apr 10 15:53:40.074: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:40.077: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:41.100: INFO: Pod daemon-set-82rd6 is not available
Apr 10 15:53:41.101: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:41.145: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:42.168: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:42.217: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:43.075: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:43.079: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:44.079: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:44.079: INFO: Pod daemon-set-9c7mk is not available
Apr 10 15:53:44.083: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:45.074: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:45.074: INFO: Pod daemon-set-9c7mk is not available
Apr 10 15:53:45.078: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:46.075: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:46.075: INFO: Pod daemon-set-9c7mk is not available
Apr 10 15:53:46.079: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:47.073: INFO: Wrong image for pod: daemon-set-9c7mk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 10 15:53:47.073: INFO: Pod daemon-set-9c7mk is not available
Apr 10 15:53:47.076: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:48.123: INFO: Pod daemon-set-gf4jh is not available
Apr 10 15:53:48.129: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 10 15:53:48.195: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:48.199: INFO: Number of nodes with available pods: 1
Apr 10 15:53:48.199: INFO: Node g168 is running more than one daemon pod
Apr 10 15:53:49.203: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:49.205: INFO: Number of nodes with available pods: 1
Apr 10 15:53:49.206: INFO: Node g168 is running more than one daemon pod
Apr 10 15:53:50.205: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 15:53:50.209: INFO: Number of nodes with available pods: 2
Apr 10 15:53:50.209: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8706, will wait for the garbage collector to delete the pods
Apr 10 15:53:50.282: INFO: Deleting DaemonSet.extensions daemon-set took: 10.729096ms
Apr 10 15:53:50.583: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.458387ms
Apr 10 15:54:01.187: INFO: Number of nodes with available pods: 0
Apr 10 15:54:01.187: INFO: Number of running nodes: 0, number of available pods: 0
Apr 10 15:54:01.189: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8706/daemonsets","resourceVersion":"5794"},"items":null}

Apr 10 15:54:01.191: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8706/pods","resourceVersion":"5794"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:54:01.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8706" for this suite.
Apr 10 15:54:11.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:54:11.317: INFO: namespace daemonsets-8706 deletion completed in 10.117100696s

• [SLOW TEST:39.568 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:54:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 10 15:54:11.808: INFO: Waiting up to 5m0s for pod "client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a" in namespace "containers-523" to be "success or failure"
Apr 10 15:54:11.990: INFO: Pod "client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 182.402179ms
Apr 10 15:54:13.994: INFO: Pod "client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186118037s
Apr 10 15:54:15.999: INFO: Pod "client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.191396914s
STEP: Saw pod success
Apr 10 15:54:15.999: INFO: Pod "client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:54:16.003: INFO: Trying to get logs from node g168 pod client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:54:16.106: INFO: Waiting for pod client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a to disappear
Apr 10 15:54:16.288: INFO: Pod client-containers-e21832b1-5ba8-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:54:16.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-523" for this suite.
Apr 10 15:54:24.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:54:24.522: INFO: namespace containers-523 deletion completed in 8.22921763s

• [SLOW TEST:13.203 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:54:24.525: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 15:54:24.913: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a" in namespace "downward-api-5747" to be "success or failure"
Apr 10 15:54:24.967: INFO: Pod "downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 53.77854ms
Apr 10 15:54:26.977: INFO: Pod "downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063507401s
Apr 10 15:54:28.988: INFO: Pod "downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074113896s
STEP: Saw pod success
Apr 10 15:54:28.988: INFO: Pod "downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:54:28.991: INFO: Trying to get logs from node g168 pod downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 15:54:29.064: INFO: Waiting for pod downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a to disappear
Apr 10 15:54:29.187: INFO: Pod downwardapi-volume-e9f18695-5ba8-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:54:29.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5747" for this suite.
Apr 10 15:54:37.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:54:37.299: INFO: namespace downward-api-5747 deletion completed in 8.107733356s

• [SLOW TEST:12.774 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:54:37.301: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 10 15:54:37.770: INFO: Waiting up to 5m0s for pod "client-containers-f192809a-5ba8-11e9-8040-3209cfee711a" in namespace "containers-2158" to be "success or failure"
Apr 10 15:54:37.959: INFO: Pod "client-containers-f192809a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 188.626327ms
Apr 10 15:54:39.963: INFO: Pod "client-containers-f192809a-5ba8-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.19232493s
Apr 10 15:54:41.968: INFO: Pod "client-containers-f192809a-5ba8-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.197706706s
STEP: Saw pod success
Apr 10 15:54:41.969: INFO: Pod "client-containers-f192809a-5ba8-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:54:41.974: INFO: Trying to get logs from node g168 pod client-containers-f192809a-5ba8-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:54:42.057: INFO: Waiting for pod client-containers-f192809a-5ba8-11e9-8040-3209cfee711a to disappear
Apr 10 15:54:42.222: INFO: Pod client-containers-f192809a-5ba8-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:54:42.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2158" for this suite.
Apr 10 15:54:48.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:54:48.498: INFO: namespace containers-2158 deletion completed in 6.27049914s

• [SLOW TEST:11.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:54:48.498: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 10 15:54:48.866: INFO: namespace kubectl-5090
Apr 10 15:54:48.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-5090'
Apr 10 15:54:54.386: INFO: stderr: ""
Apr 10 15:54:54.386: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 10 15:54:55.391: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:54:55.391: INFO: Found 0 / 1
Apr 10 15:54:56.425: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:54:56.425: INFO: Found 0 / 1
Apr 10 15:54:57.515: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:54:57.515: INFO: Found 1 / 1
Apr 10 15:54:57.515: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 10 15:54:57.517: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 15:54:57.517: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 10 15:54:57.517: INFO: wait on redis-master startup in kubectl-5090 
Apr 10 15:54:57.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 logs redis-master-r2w79 redis-master --namespace=kubectl-5090'
Apr 10 15:54:57.609: INFO: stderr: ""
Apr 10 15:54:57.609: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Apr 15:54:56.278 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Apr 15:54:56.278 # Server started, Redis version 3.2.12\n1:M 10 Apr 15:54:56.278 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Apr 15:54:56.278 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 10 15:54:57.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5090'
Apr 10 15:54:57.767: INFO: stderr: ""
Apr 10 15:54:57.767: INFO: stdout: "service/rm2 exposed\n"
Apr 10 15:54:57.947: INFO: Service rm2 in namespace kubectl-5090 found.
STEP: exposing service
Apr 10 15:54:59.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5090'
Apr 10 15:55:00.073: INFO: stderr: ""
Apr 10 15:55:00.073: INFO: stdout: "service/rm3 exposed\n"
Apr 10 15:55:00.247: INFO: Service rm3 in namespace kubectl-5090 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:55:02.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5090" for this suite.
Apr 10 15:55:26.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:55:26.375: INFO: namespace kubectl-5090 deletion completed in 24.120261141s

• [SLOW TEST:37.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:55:26.376: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0eb91ecd-5ba9-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 15:55:26.802: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a" in namespace "projected-1961" to be "success or failure"
Apr 10 15:55:26.980: INFO: Pod "pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 177.657145ms
Apr 10 15:55:28.985: INFO: Pod "pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.182833901s
Apr 10 15:55:30.989: INFO: Pod "pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.187309479s
STEP: Saw pod success
Apr 10 15:55:30.989: INFO: Pod "pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:55:30.992: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 15:55:31.137: INFO: Waiting for pod pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a to disappear
Apr 10 15:55:31.309: INFO: Pod pod-projected-configmaps-0ece74f6-5ba9-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:55:31.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1961" for this suite.
Apr 10 15:55:37.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:55:37.627: INFO: namespace projected-1961 deletion completed in 6.257181206s

• [SLOW TEST:11.252 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:55:37.631: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-1580fcee-5ba9-11e9-8040-3209cfee711a
STEP: Creating secret with name s-test-opt-upd-1580fdce-5ba9-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1580fcee-5ba9-11e9-8040-3209cfee711a
STEP: Updating secret s-test-opt-upd-1580fdce-5ba9-11e9-8040-3209cfee711a
STEP: Creating secret with name s-test-opt-create-1580fddf-5ba9-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:57:05.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6029" for this suite.
Apr 10 15:57:29.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:57:29.628: INFO: namespace secrets-6029 deletion completed in 24.311217439s

• [SLOW TEST:111.997 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:57:29.628: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 10 15:57:29.878: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 10 15:57:29.988: INFO: Waiting for terminating namespaces to be deleted...
Apr 10 15:57:29.990: INFO: 
Logging pods the kubelet thinks is on node e173 before test
Apr 10 15:57:29.998: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-h42wp from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 15:57:29.999: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 10 15:57:29.999: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 15:57:29.999: INFO: kube-proxy-vhwbc from kube-system started at 2019-04-10 15:22:23 +0000 UTC (1 container statuses recorded)
Apr 10 15:57:29.999: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 15:57:29.999: INFO: kube-flannel-ds-amd64-rhkjs from kube-system started at 2019-04-10 15:22:24 +0000 UTC (1 container statuses recorded)
Apr 10 15:57:29.999: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 15:57:29.999: INFO: sonobuoy-e2e-job-ec1ea39d8a6e4864 from heptio-sonobuoy started at 2019-04-10 15:27:42 +0000 UTC (2 container statuses recorded)
Apr 10 15:57:29.999: INFO: 	Container e2e ready: true, restart count 0
Apr 10 15:57:29.999: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 15:57:30.000: INFO: 
Logging pods the kubelet thinks is on node g168 before test
Apr 10 15:57:30.009: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-tmmrt from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 15:57:30.009: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 10 15:57:30.009: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 15:57:30.010: INFO: kube-flannel-ds-amd64-jnsnk from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 15:57:30.010: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 15:57:30.010: INFO: kube-proxy-w92n9 from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 15:57:30.010: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 15:57:30.010: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-10 15:27:28 +0000 UTC (1 container statuses recorded)
Apr 10 15:57:30.010: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15942816e08fa827], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:57:31.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6584" for this suite.
Apr 10 15:57:37.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:57:37.267: INFO: namespace sched-pred-6584 deletion completed in 6.183325551s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.639 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:57:37.267: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 15:57:37.967: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5cd8d99c-5ba9-11e9-b4c9-5254005baff5", Controller:(*bool)(0xc002c88016), BlockOwnerDeletion:(*bool)(0xc002c88017)}}
Apr 10 15:57:38.174: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5ccefbd0-5ba9-11e9-b4c9-5254005baff5", Controller:(*bool)(0xc001a74286), BlockOwnerDeletion:(*bool)(0xc001a74287)}}
Apr 10 15:57:38.229: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"5cd00284-5ba9-11e9-b4c9-5254005baff5", Controller:(*bool)(0xc002c88236), BlockOwnerDeletion:(*bool)(0xc002c88237)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:57:43.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1326" for this suite.
Apr 10 15:57:52.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:57:52.063: INFO: namespace gc-1326 deletion completed in 8.217509779s

• [SLOW TEST:14.796 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:57:52.064: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 10 15:57:52.448: INFO: Waiting up to 5m0s for pod "pod-65a4b24a-5ba9-11e9-8040-3209cfee711a" in namespace "emptydir-8932" to be "success or failure"
Apr 10 15:57:52.492: INFO: Pod "pod-65a4b24a-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 43.295752ms
Apr 10 15:57:54.500: INFO: Pod "pod-65a4b24a-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052225597s
Apr 10 15:57:56.505: INFO: Pod "pod-65a4b24a-5ba9-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056565331s
STEP: Saw pod success
Apr 10 15:57:56.505: INFO: Pod "pod-65a4b24a-5ba9-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:57:56.508: INFO: Trying to get logs from node g168 pod pod-65a4b24a-5ba9-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 15:57:56.577: INFO: Waiting for pod pod-65a4b24a-5ba9-11e9-8040-3209cfee711a to disappear
Apr 10 15:57:56.717: INFO: Pod pod-65a4b24a-5ba9-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:57:56.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8932" for this suite.
Apr 10 15:58:02.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:58:02.848: INFO: namespace emptydir-8932 deletion completed in 6.126292594s

• [SLOW TEST:10.784 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:58:02.849: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 15:58:03.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a" in namespace "projected-6691" to be "success or failure"
Apr 10 15:58:03.662: INFO: Pod "downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 85.202285ms
Apr 10 15:58:05.713: INFO: Pod "downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.135942937s
Apr 10 15:58:07.718: INFO: Pod "downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.141660064s
STEP: Saw pod success
Apr 10 15:58:07.719: INFO: Pod "downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:58:07.721: INFO: Trying to get logs from node g168 pod downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 15:58:07.792: INFO: Waiting for pod downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a to disappear
Apr 10 15:58:07.916: INFO: Pod downwardapi-volume-6c186e29-5ba9-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:58:07.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6691" for this suite.
Apr 10 15:58:13.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:58:14.043: INFO: namespace projected-6691 deletion completed in 6.123530064s

• [SLOW TEST:11.194 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:58:14.043: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-72bef4bb-5ba9-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 15:58:14.471: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a" in namespace "projected-9591" to be "success or failure"
Apr 10 15:58:14.509: INFO: Pod "pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 38.475722ms
Apr 10 15:58:16.512: INFO: Pod "pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041287183s
Apr 10 15:58:18.515: INFO: Pod "pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044402125s
STEP: Saw pod success
Apr 10 15:58:18.515: INFO: Pod "pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:58:18.517: INFO: Trying to get logs from node g168 pod pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 10 15:58:18.589: INFO: Waiting for pod pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a to disappear
Apr 10 15:58:18.753: INFO: Pod pod-projected-secrets-72bf897c-5ba9-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:58:18.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9591" for this suite.
Apr 10 15:58:26.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:58:26.879: INFO: namespace projected-9591 deletion completed in 8.123109438s

• [SLOW TEST:12.836 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:58:26.880: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 15:58:27.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a" in namespace "projected-7018" to be "success or failure"
Apr 10 15:58:27.565: INFO: Pod "downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 201.544083ms
Apr 10 15:58:29.645: INFO: Pod "downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281526805s
Apr 10 15:58:31.649: INFO: Pod "downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.286313817s
STEP: Saw pod success
Apr 10 15:58:31.649: INFO: Pod "downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 15:58:31.653: INFO: Trying to get logs from node g168 pod downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 15:58:31.874: INFO: Waiting for pod downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a to disappear
Apr 10 15:58:31.929: INFO: Pod downwardapi-volume-7a6b7a82-5ba9-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 15:58:31.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7018" for this suite.
Apr 10 15:58:40.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 15:58:40.207: INFO: namespace projected-7018 deletion completed in 8.275021044s

• [SLOW TEST:13.328 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 15:58:40.209: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9200
Apr 10 15:58:44.731: INFO: Started pod liveness-http in namespace container-probe-9200
STEP: checking the pod's current state and verifying that restartCount is present
Apr 10 15:58:44.735: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:02:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9200" for this suite.
Apr 10 16:02:54.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:02:54.574: INFO: namespace container-probe-9200 deletion completed in 8.165745193s

• [SLOW TEST:254.365 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:02:54.576: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 10 16:02:55.060: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 10 16:02:55.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:55.583: INFO: stderr: ""
Apr 10 16:02:55.583: INFO: stdout: "service/redis-slave created\n"
Apr 10 16:02:55.583: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 10 16:02:55.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:56.177: INFO: stderr: ""
Apr 10 16:02:56.177: INFO: stdout: "service/redis-master created\n"
Apr 10 16:02:56.177: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 10 16:02:56.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:56.693: INFO: stderr: ""
Apr 10 16:02:56.693: INFO: stdout: "service/frontend created\n"
Apr 10 16:02:56.694: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 10 16:02:56.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:57.236: INFO: stderr: ""
Apr 10 16:02:57.236: INFO: stdout: "deployment.apps/frontend created\n"
Apr 10 16:02:57.236: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 10 16:02:57.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:57.640: INFO: stderr: ""
Apr 10 16:02:57.640: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 10 16:02:57.640: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 10 16:02:57.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3396'
Apr 10 16:02:58.252: INFO: stderr: ""
Apr 10 16:02:58.252: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 10 16:02:58.252: INFO: Waiting for all frontend pods to be Running.
Apr 10 16:03:48.304: INFO: Waiting for frontend to serve content.
Apr 10 16:03:49.326: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr 10 16:03:55.549: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr 10 16:04:00.846: INFO: Trying to add a new entry to the guestbook.
Apr 10 16:04:00.912: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 10 16:04:00.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:01.791: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:01.792: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 10 16:04:01.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:02.321: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:02.321: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 10 16:04:02.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:02.827: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:02.827: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 10 16:04:02.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:03.080: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:03.080: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 10 16:04:03.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:03.345: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:03.345: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 10 16:04:03.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3396'
Apr 10 16:04:04.031: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:04:04.032: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:04:04.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3396" for this suite.
Apr 10 16:04:48.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:04:48.640: INFO: namespace kubectl-3396 deletion completed in 44.601185541s

• [SLOW TEST:114.064 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:04:48.641: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 10 16:04:49.068: INFO: Waiting up to 5m0s for pod "pod-5df767ea-5baa-11e9-8040-3209cfee711a" in namespace "emptydir-4954" to be "success or failure"
Apr 10 16:04:49.112: INFO: Pod "pod-5df767ea-5baa-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 44.289505ms
Apr 10 16:04:51.158: INFO: Pod "pod-5df767ea-5baa-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090022497s
Apr 10 16:04:53.163: INFO: Pod "pod-5df767ea-5baa-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095496522s
STEP: Saw pod success
Apr 10 16:04:53.163: INFO: Pod "pod-5df767ea-5baa-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:04:53.167: INFO: Trying to get logs from node g168 pod pod-5df767ea-5baa-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:04:53.346: INFO: Waiting for pod pod-5df767ea-5baa-11e9-8040-3209cfee711a to disappear
Apr 10 16:04:53.393: INFO: Pod pod-5df767ea-5baa-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:04:53.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4954" for this suite.
Apr 10 16:05:01.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:05:01.695: INFO: namespace emptydir-4954 deletion completed in 8.297174116s

• [SLOW TEST:13.054 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:05:01.696: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 10 16:05:16.778: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:16.834: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:18.835: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:18.839: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:20.835: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:20.839: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:22.835: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:22.840: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:24.835: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:24.839: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:26.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:26.848: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:28.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:28.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:30.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:30.839: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:32.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:32.865: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 10 16:05:34.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 10 16:05:34.871: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:05:34.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5053" for this suite.
Apr 10 16:05:58.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:05:59.171: INFO: namespace container-lifecycle-hook-5053 deletion completed in 24.297782785s

• [SLOW TEST:57.475 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:05:59.172: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:05:59.506: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 10 16:05:59.735: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 10 16:06:04.769: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 10 16:06:04.769: INFO: Creating deployment "test-rolling-update-deployment"
Apr 10 16:06:04.776: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 10 16:06:04.940: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 10 16:06:06.986: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 10 16:06:06.989: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509165, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509165, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509165, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509164, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 16:06:09.104: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509165, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509165, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509168, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690509164, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 16:06:11.050: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 10 16:06:11.060: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1253,SelfLink:/apis/apps/v1/namespaces/deployment-1253/deployments/test-rolling-update-deployment,UID:8b187d2e-5baa-11e9-b4c9-5254005baff5,ResourceVersion:7703,Generation:1,CreationTimestamp:2019-04-10 16:06:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-10 16:06:05 +0000 UTC 2019-04-10 16:06:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-10 16:06:09 +0000 UTC 2019-04-10 16:06:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 10 16:06:11.063: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-1253,SelfLink:/apis/apps/v1/namespaces/deployment-1253/replicasets/test-rolling-update-deployment-67599b4d9,UID:8b327be3-5baa-11e9-b4c9-5254005baff5,ResourceVersion:7690,Generation:1,CreationTimestamp:2019-04-10 16:06:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8b187d2e-5baa-11e9-b4c9-5254005baff5 0xc002be19e0 0xc002be19e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 10 16:06:11.063: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 10 16:06:11.063: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1253,SelfLink:/apis/apps/v1/namespaces/deployment-1253/replicasets/test-rolling-update-controller,UID:87f52ea4-5baa-11e9-b4c9-5254005baff5,ResourceVersion:7702,Generation:2,CreationTimestamp:2019-04-10 16:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8b187d2e-5baa-11e9-b4c9-5254005baff5 0xc002be190f 0xc002be1920}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 16:06:11.066: INFO: Pod "test-rolling-update-deployment-67599b4d9-zhtlj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-zhtlj,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-1253,SelfLink:/api/v1/namespaces/deployment-1253/pods/test-rolling-update-deployment-67599b4d9-zhtlj,UID:8b3ac17b-5baa-11e9-b4c9-5254005baff5,ResourceVersion:7689,Generation:0,CreationTimestamp:2019-04-10 16:06:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 8b327be3-5baa-11e9-b4c9-5254005baff5 0xc001ec0280 0xc001ec0281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tkm6v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tkm6v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tkm6v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ec02f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ec0310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:06:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:06:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:06:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:06:05 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.18,StartTime:2019-04-10 16:06:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-10 16:06:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://1fbf46e26283f08d3475b874071cebf9d2e8c168ea1366e3d24d66490b5f485c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:06:11.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1253" for this suite.
Apr 10 16:06:21.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:06:21.248: INFO: namespace deployment-1253 deletion completed in 10.179553418s

• [SLOW TEST:22.076 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:06:21.251: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 10 16:06:26.706: INFO: Pod name wrapped-volume-race-980ad3f2-5baa-11e9-8040-3209cfee711a: Found 0 pods out of 5
Apr 10 16:06:31.748: INFO: Pod name wrapped-volume-race-980ad3f2-5baa-11e9-8040-3209cfee711a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-980ad3f2-5baa-11e9-8040-3209cfee711a in namespace emptydir-wrapper-1126, will wait for the garbage collector to delete the pods
Apr 10 16:06:57.842: INFO: Deleting ReplicationController wrapped-volume-race-980ad3f2-5baa-11e9-8040-3209cfee711a took: 10.965235ms
Apr 10 16:06:58.143: INFO: Terminating ReplicationController wrapped-volume-race-980ad3f2-5baa-11e9-8040-3209cfee711a pods took: 300.29601ms
STEP: Creating RC which spawns configmap-volume pods
Apr 10 16:07:41.555: INFO: Pod name wrapped-volume-race-c4a827d4-5baa-11e9-8040-3209cfee711a: Found 0 pods out of 5
Apr 10 16:07:46.688: INFO: Pod name wrapped-volume-race-c4a827d4-5baa-11e9-8040-3209cfee711a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c4a827d4-5baa-11e9-8040-3209cfee711a in namespace emptydir-wrapper-1126, will wait for the garbage collector to delete the pods
Apr 10 16:08:03.169: INFO: Deleting ReplicationController wrapped-volume-race-c4a827d4-5baa-11e9-8040-3209cfee711a took: 111.227471ms
Apr 10 16:08:03.870: INFO: Terminating ReplicationController wrapped-volume-race-c4a827d4-5baa-11e9-8040-3209cfee711a pods took: 700.385553ms
STEP: Creating RC which spawns configmap-volume pods
Apr 10 16:08:41.892: INFO: Pod name wrapped-volume-race-e8ac9eaa-5baa-11e9-8040-3209cfee711a: Found 0 pods out of 5
Apr 10 16:08:46.939: INFO: Pod name wrapped-volume-race-e8ac9eaa-5baa-11e9-8040-3209cfee711a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e8ac9eaa-5baa-11e9-8040-3209cfee711a in namespace emptydir-wrapper-1126, will wait for the garbage collector to delete the pods
Apr 10 16:09:03.437: INFO: Deleting ReplicationController wrapped-volume-race-e8ac9eaa-5baa-11e9-8040-3209cfee711a took: 371.436438ms
Apr 10 16:09:03.837: INFO: Terminating ReplicationController wrapped-volume-race-e8ac9eaa-5baa-11e9-8040-3209cfee711a pods took: 400.284933ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:09:46.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1126" for this suite.
Apr 10 16:10:15.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:10:15.302: INFO: namespace emptydir-wrapper-1126 deletion completed in 28.25916026s

• [SLOW TEST:234.051 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:10:15.302: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 10 16:10:15.748: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 10 16:10:15.755: INFO: Waiting for terminating namespaces to be deleted...
Apr 10 16:10:15.757: INFO: 
Logging pods the kubelet thinks is on node e173 before test
Apr 10 16:10:15.762: INFO: sonobuoy-e2e-job-ec1ea39d8a6e4864 from heptio-sonobuoy started at 2019-04-10 15:27:42 +0000 UTC (2 container statuses recorded)
Apr 10 16:10:15.762: INFO: 	Container e2e ready: true, restart count 0
Apr 10 16:10:15.762: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 16:10:15.762: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-h42wp from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 16:10:15.762: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 10 16:10:15.762: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 16:10:15.763: INFO: kube-proxy-vhwbc from kube-system started at 2019-04-10 15:22:23 +0000 UTC (1 container statuses recorded)
Apr 10 16:10:15.763: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 16:10:15.763: INFO: kube-flannel-ds-amd64-rhkjs from kube-system started at 2019-04-10 15:22:24 +0000 UTC (1 container statuses recorded)
Apr 10 16:10:15.763: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 16:10:15.763: INFO: 
Logging pods the kubelet thinks is on node g168 before test
Apr 10 16:10:15.768: INFO: kube-flannel-ds-amd64-jnsnk from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 16:10:15.768: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 16:10:15.768: INFO: kube-proxy-w92n9 from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 16:10:15.768: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 16:10:15.768: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-10 15:27:28 +0000 UTC (1 container statuses recorded)
Apr 10 16:10:15.768: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 10 16:10:15.768: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-tmmrt from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 16:10:15.768: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 10 16:10:15.768: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node e173
STEP: verifying the node has the label node g168
Apr 10 16:10:15.995: INFO: Pod sonobuoy requesting resource cpu=0m on Node g168
Apr 10 16:10:15.995: INFO: Pod sonobuoy-e2e-job-ec1ea39d8a6e4864 requesting resource cpu=0m on Node e173
Apr 10 16:10:15.995: INFO: Pod sonobuoy-systemd-logs-daemon-set-87a756505d084484-h42wp requesting resource cpu=0m on Node e173
Apr 10 16:10:15.995: INFO: Pod sonobuoy-systemd-logs-daemon-set-87a756505d084484-tmmrt requesting resource cpu=0m on Node g168
Apr 10 16:10:15.995: INFO: Pod kube-flannel-ds-amd64-jnsnk requesting resource cpu=100m on Node g168
Apr 10 16:10:15.995: INFO: Pod kube-flannel-ds-amd64-rhkjs requesting resource cpu=100m on Node e173
Apr 10 16:10:15.995: INFO: Pod kube-proxy-vhwbc requesting resource cpu=0m on Node e173
Apr 10 16:10:15.995: INFO: Pod kube-proxy-w92n9 requesting resource cpu=0m on Node g168
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a.159428c9386a067b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9179/filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a to e173]
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a.159428c950e3d24e], Reason = [DNSConfigForming], Message = [Search Line limits were exceeded, some search paths have been omitted, the applied search line is: sched-pred-9179.svc.cluster.local svc.cluster.local cluster.local suse.de arch.suse.de nue.suse.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a.159428c985b74441], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a.159428c9aad0c3a1], Reason = [Created], Message = [Created container filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a.159428c9b2737636], Reason = [Started], Message = [Started container filler-pod-20d6362b-5bab-11e9-8040-3209cfee711a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a.159428c944735a08], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9179/filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a to g168]
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a.159428c95c99c960], Reason = [DNSConfigForming], Message = [Search Line limits were exceeded, some search paths have been omitted, the applied search line is: sched-pred-9179.svc.cluster.local svc.cluster.local cluster.local suse.de arch.suse.de nue.suse.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a.159428c9946e34a8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a.159428c9b988b01e], Reason = [Created], Message = [Created container filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a.159428c9c0fdda04], Reason = [Started], Message = [Started container filler-pod-20d76e6d-5bab-11e9-8040-3209cfee711a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159428ca4550a8ea], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node e173
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node g168
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:10:21.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9179" for this suite.
Apr 10 16:10:30.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:10:30.070: INFO: namespace sched-pred-9179 deletion completed in 8.210447616s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.769 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:10:30.072: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-5826
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5826 to expose endpoints map[]
Apr 10 16:10:30.776: INFO: successfully validated that service multi-endpoint-test in namespace services-5826 exposes endpoints map[] (196.134137ms elapsed)
STEP: Creating pod pod1 in namespace services-5826
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5826 to expose endpoints map[pod1:[100]]
Apr 10 16:10:34.400: INFO: successfully validated that service multi-endpoint-test in namespace services-5826 exposes endpoints map[pod1:[100]] (3.596986344s elapsed)
STEP: Creating pod pod2 in namespace services-5826
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5826 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 10 16:10:37.754: INFO: successfully validated that service multi-endpoint-test in namespace services-5826 exposes endpoints map[pod1:[100] pod2:[101]] (3.346949906s elapsed)
STEP: Deleting pod pod1 in namespace services-5826
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5826 to expose endpoints map[pod2:[101]]
Apr 10 16:10:37.978: INFO: successfully validated that service multi-endpoint-test in namespace services-5826 exposes endpoints map[pod2:[101]] (213.899752ms elapsed)
STEP: Deleting pod pod2 in namespace services-5826
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5826 to expose endpoints map[]
Apr 10 16:10:38.040: INFO: successfully validated that service multi-endpoint-test in namespace services-5826 exposes endpoints map[] (54.782096ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:10:38.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5826" for this suite.
Apr 10 16:11:02.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:11:02.822: INFO: namespace services-5826 deletion completed in 24.132029822s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:32.750 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:11:02.822: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0410 16:11:05.757346      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 16:11:05.757: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:11:05.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4479" for this suite.
Apr 10 16:11:14.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:11:14.498: INFO: namespace gc-4479 deletion completed in 8.660884225s

• [SLOW TEST:11.676 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:11:14.501: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:11:14.778: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:11:18.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2591" for this suite.
Apr 10 16:12:09.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:12:09.311: INFO: namespace pods-2591 deletion completed in 50.311023005s

• [SLOW TEST:54.810 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:12:09.311: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6489c81c-5bab-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:12:09.818: INFO: Waiting up to 5m0s for pod "pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a" in namespace "secrets-2841" to be "success or failure"
Apr 10 16:12:10.016: INFO: Pod "pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 197.931873ms
Apr 10 16:12:12.055: INFO: Pod "pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.236376337s
Apr 10 16:12:14.060: INFO: Pod "pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.241523233s
STEP: Saw pod success
Apr 10 16:12:14.060: INFO: Pod "pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:12:14.064: INFO: Trying to get logs from node g168 pod pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:12:14.384: INFO: Waiting for pod pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a to disappear
Apr 10 16:12:14.531: INFO: Pod pod-secrets-64a64752-5bab-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:12:14.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2841" for this suite.
Apr 10 16:12:20.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:12:21.111: INFO: namespace secrets-2841 deletion completed in 6.565801114s

• [SLOW TEST:11.800 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:12:21.113: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 10 16:12:21.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 api-versions'
Apr 10 16:12:21.720: INFO: stderr: ""
Apr 10 16:12:21.720: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:12:21.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7160" for this suite.
Apr 10 16:12:27.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:12:27.931: INFO: namespace kubectl-7160 deletion completed in 6.204546229s

• [SLOW TEST:6.818 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:12:27.931: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 10 16:12:28.579: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:28.712: INFO: Number of nodes with available pods: 0
Apr 10 16:12:28.712: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:29.879: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:29.881: INFO: Number of nodes with available pods: 0
Apr 10 16:12:29.881: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:30.735: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:30.738: INFO: Number of nodes with available pods: 0
Apr 10 16:12:30.738: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:31.715: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:31.717: INFO: Number of nodes with available pods: 0
Apr 10 16:12:31.717: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:32.811: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:32.870: INFO: Number of nodes with available pods: 2
Apr 10 16:12:32.870: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 10 16:12:33.088: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:33.090: INFO: Number of nodes with available pods: 1
Apr 10 16:12:33.090: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:34.095: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:34.098: INFO: Number of nodes with available pods: 1
Apr 10 16:12:34.098: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:35.122: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:35.125: INFO: Number of nodes with available pods: 1
Apr 10 16:12:35.125: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:36.097: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:36.100: INFO: Number of nodes with available pods: 1
Apr 10 16:12:36.100: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:37.095: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:37.099: INFO: Number of nodes with available pods: 1
Apr 10 16:12:37.099: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:38.096: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:38.100: INFO: Number of nodes with available pods: 1
Apr 10 16:12:38.100: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:39.095: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:39.100: INFO: Number of nodes with available pods: 1
Apr 10 16:12:39.100: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:40.095: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:40.099: INFO: Number of nodes with available pods: 1
Apr 10 16:12:40.099: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:41.171: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:41.255: INFO: Number of nodes with available pods: 1
Apr 10 16:12:41.255: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:42.095: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:42.099: INFO: Number of nodes with available pods: 1
Apr 10 16:12:42.099: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:43.141: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:43.146: INFO: Number of nodes with available pods: 1
Apr 10 16:12:43.146: INFO: Node e173 is running more than one daemon pod
Apr 10 16:12:44.112: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:12:44.161: INFO: Number of nodes with available pods: 2
Apr 10 16:12:44.161: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3161, will wait for the garbage collector to delete the pods
Apr 10 16:12:44.575: INFO: Deleting DaemonSet.extensions daemon-set took: 187.373104ms
Apr 10 16:12:45.075: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.286306ms
Apr 10 16:12:57.548: INFO: Number of nodes with available pods: 0
Apr 10 16:12:57.548: INFO: Number of running nodes: 0, number of available pods: 0
Apr 10 16:12:57.550: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3161/daemonsets","resourceVersion":"9476"},"items":null}

Apr 10 16:12:57.552: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3161/pods","resourceVersion":"9476"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:12:57.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3161" for this suite.
Apr 10 16:13:07.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:13:07.972: INFO: namespace daemonsets-3161 deletion completed in 10.353493876s

• [SLOW TEST:40.041 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:13:07.973: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0410 16:13:38.759840      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 16:13:38.759: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:13:38.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3719" for this suite.
Apr 10 16:13:48.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:13:49.011: INFO: namespace gc-3719 deletion completed in 10.248801243s

• [SLOW TEST:41.038 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:13:49.014: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:13:49.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a" in namespace "projected-3997" to be "success or failure"
Apr 10 16:13:49.785: INFO: Pod "downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.560852ms
Apr 10 16:13:51.899: INFO: Pod "downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116575688s
Apr 10 16:13:53.902: INFO: Pod "downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.120287166s
STEP: Saw pod success
Apr 10 16:13:53.903: INFO: Pod "downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:13:54.066: INFO: Trying to get logs from node g168 pod downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:13:54.330: INFO: Waiting for pod downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a to disappear
Apr 10 16:13:54.604: INFO: Pod downwardapi-volume-a0165264-5bab-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:13:54.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3997" for this suite.
Apr 10 16:14:02.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:14:02.728: INFO: namespace projected-3997 deletion completed in 8.11911793s

• [SLOW TEST:13.715 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:14:02.729: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0410 16:14:43.675424      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 16:14:43.675: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:14:43.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-158" for this suite.
Apr 10 16:15:01.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:15:02.174: INFO: namespace gc-158 deletion completed in 18.496018845s

• [SLOW TEST:59.445 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:15:02.176: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:15:02.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3810" for this suite.
Apr 10 16:15:08.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:15:08.888: INFO: namespace services-3810 deletion completed in 6.181258184s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.712 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:15:08.891: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 10 16:15:13.996: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cfb779f4-5bab-11e9-8040-3209cfee711a"
Apr 10 16:15:13.996: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cfb779f4-5bab-11e9-8040-3209cfee711a" in namespace "pods-1083" to be "terminated due to deadline exceeded"
Apr 10 16:15:14.073: INFO: Pod "pod-update-activedeadlineseconds-cfb779f4-5bab-11e9-8040-3209cfee711a": Phase="Running", Reason="", readiness=true. Elapsed: 76.61234ms
Apr 10 16:15:16.109: INFO: Pod "pod-update-activedeadlineseconds-cfb779f4-5bab-11e9-8040-3209cfee711a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.113275608s
Apr 10 16:15:16.109: INFO: Pod "pod-update-activedeadlineseconds-cfb779f4-5bab-11e9-8040-3209cfee711a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:15:16.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1083" for this suite.
Apr 10 16:15:24.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:15:24.686: INFO: namespace pods-1083 deletion completed in 8.488156647s

• [SLOW TEST:15.795 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:15:24.687: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 16:15:25.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3335'
Apr 10 16:15:31.071: INFO: stderr: ""
Apr 10 16:15:31.071: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 10 16:15:31.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete pods e2e-test-nginx-pod --namespace=kubectl-3335'
Apr 10 16:15:37.401: INFO: stderr: ""
Apr 10 16:15:37.401: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:15:37.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3335" for this suite.
Apr 10 16:15:43.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:15:43.878: INFO: namespace kubectl-3335 deletion completed in 6.319681734s

• [SLOW TEST:19.191 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:15:43.879: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-e492980a-5bab-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 16:15:44.673: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a" in namespace "projected-7948" to be "success or failure"
Apr 10 16:15:44.757: INFO: Pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 83.27856ms
Apr 10 16:15:46.760: INFO: Pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086987614s
Apr 10 16:15:48.957: INFO: Pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.284183979s
Apr 10 16:15:50.961: INFO: Pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.287229141s
STEP: Saw pod success
Apr 10 16:15:50.961: INFO: Pod "pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:15:50.963: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 16:15:51.148: INFO: Waiting for pod pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a to disappear
Apr 10 16:15:51.217: INFO: Pod pod-projected-configmaps-e4bccf34-5bab-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:15:51.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7948" for this suite.
Apr 10 16:15:59.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:15:59.716: INFO: namespace projected-7948 deletion completed in 8.494369332s

• [SLOW TEST:15.837 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:15:59.717: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:16:00.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a" in namespace "projected-2415" to be "success or failure"
Apr 10 16:16:00.273: INFO: Pod "downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 63.830311ms
Apr 10 16:16:02.375: INFO: Pod "downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.165974236s
Apr 10 16:16:04.450: INFO: Pod "downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.240700352s
STEP: Saw pod success
Apr 10 16:16:04.450: INFO: Pod "downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:16:04.453: INFO: Trying to get logs from node g168 pod downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:16:04.525: INFO: Waiting for pod downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a to disappear
Apr 10 16:16:04.705: INFO: Pod downwardapi-volume-ede50b3f-5bab-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:16:04.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2415" for this suite.
Apr 10 16:16:12.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:16:12.832: INFO: namespace projected-2415 deletion completed in 8.122289057s

• [SLOW TEST:13.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:16:12.833: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 10 16:16:17.895: INFO: Successfully updated pod "labelsupdatef5b51f71-5bab-11e9-8040-3209cfee711a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:16:20.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2677" for this suite.
Apr 10 16:16:44.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:16:44.539: INFO: namespace downward-api-2677 deletion completed in 24.219507264s

• [SLOW TEST:31.706 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:16:44.539: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 10 16:16:44.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-1624'
Apr 10 16:16:45.302: INFO: stderr: ""
Apr 10 16:16:45.302: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 16:16:45.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:16:45.459: INFO: stderr: ""
Apr 10 16:16:45.460: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Apr 10 16:16:50.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:16:50.531: INFO: stderr: ""
Apr 10 16:16:50.531: INFO: stdout: "update-demo-nautilus-45l7p update-demo-nautilus-649q7 "
Apr 10 16:16:50.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:50.590: INFO: stderr: ""
Apr 10 16:16:50.590: INFO: stdout: "true"
Apr 10 16:16:50.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:50.650: INFO: stderr: ""
Apr 10 16:16:50.650: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:16:50.650: INFO: validating pod update-demo-nautilus-45l7p
Apr 10 16:16:50.653: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:16:50.653: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:16:50.653: INFO: update-demo-nautilus-45l7p is verified up and running
Apr 10 16:16:50.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-649q7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:50.715: INFO: stderr: ""
Apr 10 16:16:50.715: INFO: stdout: "true"
Apr 10 16:16:50.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-649q7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:50.788: INFO: stderr: ""
Apr 10 16:16:50.788: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:16:50.788: INFO: validating pod update-demo-nautilus-649q7
Apr 10 16:16:50.792: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:16:50.792: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:16:50.792: INFO: update-demo-nautilus-649q7 is verified up and running
STEP: scaling down the replication controller
Apr 10 16:16:50.793: INFO: scanned /root for discovery docs: <nil>
Apr 10 16:16:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1624'
Apr 10 16:16:52.051: INFO: stderr: ""
Apr 10 16:16:52.051: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 16:16:52.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:16:52.107: INFO: stderr: ""
Apr 10 16:16:52.107: INFO: stdout: "update-demo-nautilus-45l7p update-demo-nautilus-649q7 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 10 16:16:57.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:16:57.169: INFO: stderr: ""
Apr 10 16:16:57.169: INFO: stdout: "update-demo-nautilus-45l7p "
Apr 10 16:16:57.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:57.235: INFO: stderr: ""
Apr 10 16:16:57.235: INFO: stdout: "true"
Apr 10 16:16:57.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:57.292: INFO: stderr: ""
Apr 10 16:16:57.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:16:57.292: INFO: validating pod update-demo-nautilus-45l7p
Apr 10 16:16:57.296: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:16:57.296: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:16:57.296: INFO: update-demo-nautilus-45l7p is verified up and running
STEP: scaling up the replication controller
Apr 10 16:16:57.297: INFO: scanned /root for discovery docs: <nil>
Apr 10 16:16:57.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1624'
Apr 10 16:16:58.454: INFO: stderr: ""
Apr 10 16:16:58.454: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 16:16:58.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:16:58.518: INFO: stderr: ""
Apr 10 16:16:58.518: INFO: stdout: "update-demo-nautilus-2jmqx update-demo-nautilus-45l7p "
Apr 10 16:16:58.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-2jmqx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:16:58.577: INFO: stderr: ""
Apr 10 16:16:58.577: INFO: stdout: ""
Apr 10 16:16:58.577: INFO: update-demo-nautilus-2jmqx is created but not running
Apr 10 16:17:03.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1624'
Apr 10 16:17:03.636: INFO: stderr: ""
Apr 10 16:17:03.636: INFO: stdout: "update-demo-nautilus-2jmqx update-demo-nautilus-45l7p "
Apr 10 16:17:03.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-2jmqx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:17:03.691: INFO: stderr: ""
Apr 10 16:17:03.691: INFO: stdout: "true"
Apr 10 16:17:03.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-2jmqx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:17:03.752: INFO: stderr: ""
Apr 10 16:17:03.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:17:03.752: INFO: validating pod update-demo-nautilus-2jmqx
Apr 10 16:17:03.755: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:17:03.755: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:17:03.755: INFO: update-demo-nautilus-2jmqx is verified up and running
Apr 10 16:17:03.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:17:03.863: INFO: stderr: ""
Apr 10 16:17:03.863: INFO: stdout: "true"
Apr 10 16:17:03.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-45l7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1624'
Apr 10 16:17:03.989: INFO: stderr: ""
Apr 10 16:17:03.989: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:17:03.989: INFO: validating pod update-demo-nautilus-45l7p
Apr 10 16:17:03.993: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:17:03.993: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:17:03.993: INFO: update-demo-nautilus-45l7p is verified up and running
STEP: using delete to clean up resources
Apr 10 16:17:03.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-1624'
Apr 10 16:17:04.259: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:17:04.259: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 10 16:17:04.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1624'
Apr 10 16:17:04.486: INFO: stderr: "No resources found.\n"
Apr 10 16:17:04.486: INFO: stdout: ""
Apr 10 16:17:04.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -l name=update-demo --namespace=kubectl-1624 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 10 16:17:04.792: INFO: stderr: ""
Apr 10 16:17:04.792: INFO: stdout: "update-demo-nautilus-2jmqx\n"
Apr 10 16:17:05.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1624'
Apr 10 16:17:05.612: INFO: stderr: "No resources found.\n"
Apr 10 16:17:05.612: INFO: stdout: ""
Apr 10 16:17:05.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -l name=update-demo --namespace=kubectl-1624 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 10 16:17:05.690: INFO: stderr: ""
Apr 10 16:17:05.690: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:17:05.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1624" for this suite.
Apr 10 16:17:31.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:17:31.956: INFO: namespace kubectl-1624 deletion completed in 26.263483246s

• [SLOW TEST:47.417 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:17:31.958: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Apr 10 16:17:38.995: INFO: 10 pods remaining
Apr 10 16:17:38.995: INFO: 0 pods has nil DeletionTimestamp
Apr 10 16:17:38.995: INFO: 
Apr 10 16:17:40.178: INFO: 0 pods remaining
Apr 10 16:17:40.178: INFO: 0 pods has nil DeletionTimestamp
Apr 10 16:17:40.178: INFO: 
STEP: Gathering metrics
W0410 16:17:41.155116      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 16:17:41.155: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:17:41.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5881" for this suite.
Apr 10 16:17:55.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:17:55.567: INFO: namespace gc-5881 deletion completed in 14.135484195s

• [SLOW TEST:23.609 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:17:55.568: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:17:56.329: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:17:58.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2393" for this suite.
Apr 10 16:18:04.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:18:04.943: INFO: namespace custom-resource-definition-2393 deletion completed in 6.340064592s

• [SLOW TEST:9.375 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:18:04.944: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 10 16:18:05.471: INFO: Waiting up to 5m0s for pod "pod-38a270ea-5bac-11e9-8040-3209cfee711a" in namespace "emptydir-9034" to be "success or failure"
Apr 10 16:18:05.734: INFO: Pod "pod-38a270ea-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 263.391933ms
Apr 10 16:18:07.738: INFO: Pod "pod-38a270ea-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26683466s
Apr 10 16:18:09.789: INFO: Pod "pod-38a270ea-5bac-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.318562853s
STEP: Saw pod success
Apr 10 16:18:09.790: INFO: Pod "pod-38a270ea-5bac-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:18:09.793: INFO: Trying to get logs from node g168 pod pod-38a270ea-5bac-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:18:09.879: INFO: Waiting for pod pod-38a270ea-5bac-11e9-8040-3209cfee711a to disappear
Apr 10 16:18:10.048: INFO: Pod pod-38a270ea-5bac-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:18:10.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9034" for this suite.
Apr 10 16:18:18.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:18:18.330: INFO: namespace emptydir-9034 deletion completed in 8.224268158s

• [SLOW TEST:13.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:18:18.331: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 10 16:18:18.795: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:18:27.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3804" for this suite.
Apr 10 16:18:41.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:18:42.204: INFO: namespace init-container-3804 deletion completed in 14.449774757s

• [SLOW TEST:23.873 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:18:42.205: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-4ebf6d58-5bac-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:18:42.720: INFO: Waiting up to 5m0s for pod "pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a" in namespace "secrets-9675" to be "success or failure"
Apr 10 16:18:42.779: INFO: Pod "pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 59.798619ms
Apr 10 16:18:44.784: INFO: Pod "pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064636418s
Apr 10 16:18:46.789: INFO: Pod "pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068929585s
STEP: Saw pod success
Apr 10 16:18:46.789: INFO: Pod "pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:18:46.792: INFO: Trying to get logs from node g168 pod pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:18:46.876: INFO: Waiting for pod pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a to disappear
Apr 10 16:18:47.042: INFO: Pod pod-secrets-4edd871c-5bac-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:18:47.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9675" for this suite.
Apr 10 16:18:55.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:18:55.178: INFO: namespace secrets-9675 deletion completed in 8.13069458s

• [SLOW TEST:12.973 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:18:55.182: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 10 16:18:55.715: INFO: Waiting up to 5m0s for pod "pod-567efce3-5bac-11e9-8040-3209cfee711a" in namespace "emptydir-2681" to be "success or failure"
Apr 10 16:18:55.790: INFO: Pod "pod-567efce3-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 74.853772ms
Apr 10 16:18:57.945: INFO: Pod "pod-567efce3-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.229996326s
Apr 10 16:18:59.981: INFO: Pod "pod-567efce3-5bac-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.265484609s
STEP: Saw pod success
Apr 10 16:18:59.981: INFO: Pod "pod-567efce3-5bac-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:18:59.983: INFO: Trying to get logs from node g168 pod pod-567efce3-5bac-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:19:00.487: INFO: Waiting for pod pod-567efce3-5bac-11e9-8040-3209cfee711a to disappear
Apr 10 16:19:00.728: INFO: Pod pod-567efce3-5bac-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:19:00.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2681" for this suite.
Apr 10 16:19:08.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:19:08.979: INFO: namespace emptydir-2681 deletion completed in 8.246381343s

• [SLOW TEST:13.798 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:19:08.982: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-5ed6c577-5bac-11e9-8040-3209cfee711a
STEP: Creating configMap with name cm-test-opt-upd-5ed6c5ac-5bac-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5ed6c577-5bac-11e9-8040-3209cfee711a
STEP: Updating configmap cm-test-opt-upd-5ed6c5ac-5bac-11e9-8040-3209cfee711a
STEP: Creating configMap with name cm-test-opt-create-5ed6c5b9-5bac-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:19:30.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7778" for this suite.
Apr 10 16:19:54.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:19:54.878: INFO: namespace projected-7778 deletion completed in 24.292295436s

• [SLOW TEST:45.897 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:19:54.878: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-7a2cb81c-5bac-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:19:55.447: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a" in namespace "projected-8427" to be "success or failure"
Apr 10 16:19:55.737: INFO: Pod "pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 289.789714ms
Apr 10 16:19:57.786: INFO: Pod "pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.339195552s
Apr 10 16:19:59.841: INFO: Pod "pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.39427776s
STEP: Saw pod success
Apr 10 16:19:59.841: INFO: Pod "pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:19:59.847: INFO: Trying to get logs from node g168 pod pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:19:59.938: INFO: Waiting for pod pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a to disappear
Apr 10 16:20:00.108: INFO: Pod pod-projected-secrets-7a2d5f90-5bac-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:20:00.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8427" for this suite.
Apr 10 16:20:08.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:20:08.767: INFO: namespace projected-8427 deletion completed in 8.585705111s

• [SLOW TEST:13.889 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:20:08.767: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 10 16:20:09.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-3332'
Apr 10 16:20:09.435: INFO: stderr: ""
Apr 10 16:20:09.435: INFO: stdout: "pod/pause created\n"
Apr 10 16:20:09.435: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 10 16:20:09.435: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3332" to be "running and ready"
Apr 10 16:20:09.667: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 232.178817ms
Apr 10 16:20:11.670: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234565305s
Apr 10 16:20:13.673: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.238297324s
Apr 10 16:20:13.674: INFO: Pod "pause" satisfied condition "running and ready"
Apr 10 16:20:13.674: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 10 16:20:13.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 label pods pause testing-label=testing-label-value --namespace=kubectl-3332'
Apr 10 16:20:13.738: INFO: stderr: ""
Apr 10 16:20:13.738: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 10 16:20:13.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pod pause -L testing-label --namespace=kubectl-3332'
Apr 10 16:20:13.922: INFO: stderr: ""
Apr 10 16:20:13.922: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 10 16:20:13.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 label pods pause testing-label- --namespace=kubectl-3332'
Apr 10 16:20:13.992: INFO: stderr: ""
Apr 10 16:20:13.992: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 10 16:20:13.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pod pause -L testing-label --namespace=kubectl-3332'
Apr 10 16:20:14.160: INFO: stderr: ""
Apr 10 16:20:14.160: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 10 16:20:14.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete --grace-period=0 --force -f - --namespace=kubectl-3332'
Apr 10 16:20:14.689: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 10 16:20:14.689: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 10 16:20:14.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get rc,svc -l name=pause --no-headers --namespace=kubectl-3332'
Apr 10 16:20:14.913: INFO: stderr: "No resources found.\n"
Apr 10 16:20:14.914: INFO: stdout: ""
Apr 10 16:20:14.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -l name=pause --namespace=kubectl-3332 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 10 16:20:14.990: INFO: stderr: ""
Apr 10 16:20:14.990: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:20:14.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3332" for this suite.
Apr 10 16:20:23.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:20:23.267: INFO: namespace kubectl-3332 deletion completed in 8.273991198s

• [SLOW TEST:14.500 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:20:23.268: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7594
Apr 10 16:20:39.842: INFO: Started pod liveness-http in namespace container-probe-7594
STEP: checking the pod's current state and verifying that restartCount is present
Apr 10 16:20:39.845: INFO: Initial restart count of pod liveness-http is 0
Apr 10 16:20:54.090: INFO: Restart count of pod container-probe-7594/liveness-http is now 1 (14.244501003s elapsed)
Apr 10 16:21:14.505: INFO: Restart count of pod container-probe-7594/liveness-http is now 2 (34.659616325s elapsed)
Apr 10 16:21:34.554: INFO: Restart count of pod container-probe-7594/liveness-http is now 3 (54.708443968s elapsed)
Apr 10 16:21:54.592: INFO: Restart count of pod container-probe-7594/liveness-http is now 4 (1m14.746722589s elapsed)
Apr 10 16:23:05.138: INFO: Restart count of pod container-probe-7594/liveness-http is now 5 (2m25.292681606s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:23:05.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7594" for this suite.
Apr 10 16:23:13.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:23:13.817: INFO: namespace container-probe-7594 deletion completed in 8.13694603s

• [SLOW TEST:170.550 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:23:13.818: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:23:19.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-807" for this suite.
Apr 10 16:23:27.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:23:27.709: INFO: namespace emptydir-wrapper-807 deletion completed in 8.446233862s

• [SLOW TEST:13.892 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:23:27.710: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f90d2133-5bac-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:23:28.527: INFO: Waiting up to 5m0s for pod "pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a" in namespace "secrets-8456" to be "success or failure"
Apr 10 16:23:28.762: INFO: Pod "pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 235.586793ms
Apr 10 16:23:30.867: INFO: Pod "pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.340322851s
Apr 10 16:23:32.871: INFO: Pod "pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.34462793s
STEP: Saw pod success
Apr 10 16:23:32.872: INFO: Pod "pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:23:32.874: INFO: Trying to get logs from node g168 pod pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:23:33.059: INFO: Waiting for pod pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a to disappear
Apr 10 16:23:33.278: INFO: Pod pod-secrets-f92eba0f-5bac-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:23:33.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8456" for this suite.
Apr 10 16:23:41.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:23:41.411: INFO: namespace secrets-8456 deletion completed in 8.126337245s

• [SLOW TEST:13.701 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:23:41.411: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-013a76ed-5bad-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:23:46.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5168" for this suite.
Apr 10 16:24:10.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:24:10.498: INFO: namespace configmap-5168 deletion completed in 24.254350658s

• [SLOW TEST:29.087 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:24:10.498: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-12930e67-5bad-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 16:24:11.292: INFO: Waiting up to 5m0s for pod "pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a" in namespace "configmap-2388" to be "success or failure"
Apr 10 16:24:11.370: INFO: Pod "pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 77.915571ms
Apr 10 16:24:13.539: INFO: Pod "pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.246300816s
Apr 10 16:24:15.602: INFO: Pod "pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.309540981s
STEP: Saw pod success
Apr 10 16:24:15.602: INFO: Pod "pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:24:15.604: INFO: Trying to get logs from node g168 pod pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 16:24:15.692: INFO: Waiting for pod pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a to disappear
Apr 10 16:24:15.858: INFO: Pod pod-configmaps-12b52e68-5bad-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:24:15.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2388" for this suite.
Apr 10 16:24:23.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:24:23.991: INFO: namespace configmap-2388 deletion completed in 8.129889918s

• [SLOW TEST:13.493 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:24:23.991: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:24:24.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a" in namespace "downward-api-1174" to be "success or failure"
Apr 10 16:24:24.588: INFO: Pod "downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 68.521102ms
Apr 10 16:24:26.726: INFO: Pod "downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206500629s
Apr 10 16:24:28.731: INFO: Pod "downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210937175s
STEP: Saw pod success
Apr 10 16:24:28.731: INFO: Pod "downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:24:28.734: INFO: Trying to get logs from node g168 pod downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:24:28.924: INFO: Waiting for pod downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a to disappear
Apr 10 16:24:28.990: INFO: Pod downwardapi-volume-1a9752ac-5bad-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:24:28.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1174" for this suite.
Apr 10 16:24:37.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:24:37.264: INFO: namespace downward-api-1174 deletion completed in 8.129179329s

• [SLOW TEST:13.273 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:24:37.264: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:24:56.041: INFO: Container started at 2019-04-10 16:24:39 +0000 UTC, pod became ready at 2019-04-10 16:24:55 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:24:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6291" for this suite.
Apr 10 16:25:20.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:25:20.305: INFO: namespace container-probe-6291 deletion completed in 24.259047074s

• [SLOW TEST:43.041 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:25:20.307: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 10 16:25:20.860: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr 10 16:25:30.320: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:25:30.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5403" for this suite.
Apr 10 16:25:38.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:25:38.678: INFO: namespace pods-5403 deletion completed in 8.350800517s

• [SLOW TEST:18.372 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:25:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 10 16:25:39.507: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5865" to be "success or failure"
Apr 10 16:25:39.572: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 64.43439ms
Apr 10 16:25:41.577: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069375431s
Apr 10 16:25:43.723: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215230178s
Apr 10 16:25:45.727: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.219408069s
STEP: Saw pod success
Apr 10 16:25:45.727: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 10 16:25:45.730: INFO: Trying to get logs from node g168 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 10 16:25:45.925: INFO: Waiting for pod pod-host-path-test to disappear
Apr 10 16:25:45.992: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:25:45.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5865" for this suite.
Apr 10 16:25:54.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:25:54.406: INFO: namespace hostpath-5865 deletion completed in 8.409933646s

• [SLOW TEST:15.728 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:25:54.406: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 10 16:26:00.066: INFO: Successfully updated pod "pod-update-5079428e-5bad-11e9-8040-3209cfee711a"
STEP: verifying the updated pod is in kubernetes
Apr 10 16:26:00.301: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:26:00.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9368" for this suite.
Apr 10 16:26:24.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:26:24.519: INFO: namespace pods-9368 deletion completed in 24.214565798s

• [SLOW TEST:30.113 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:26:24.519: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-626664b5-5bad-11e9-8040-3209cfee711a
STEP: Creating configMap with name cm-test-opt-upd-62666511-5bad-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-626664b5-5bad-11e9-8040-3209cfee711a
STEP: Updating configmap cm-test-opt-upd-62666511-5bad-11e9-8040-3209cfee711a
STEP: Creating configMap with name cm-test-opt-create-62666533-5bad-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:27:55.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1615" for this suite.
Apr 10 16:28:21.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:28:21.482: INFO: namespace configmap-1615 deletion completed in 26.412007728s

• [SLOW TEST:116.963 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:28:21.484: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 10 16:28:22.071: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 10 16:28:27.076: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:28:27.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3829" for this suite.
Apr 10 16:28:36.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:28:36.293: INFO: namespace replication-controller-3829 deletion completed in 8.887512629s

• [SLOW TEST:14.810 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:28:36.298: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 10 16:28:41.652: INFO: Successfully updated pod "annotationupdateb0f6b94b-5bad-11e9-8040-3209cfee711a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:28:43.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2276" for this suite.
Apr 10 16:29:08.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:29:08.110: INFO: namespace downward-api-2276 deletion completed in 24.264242388s

• [SLOW TEST:31.812 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:29:08.110: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-c3f640c5-5bad-11e9-8040-3209cfee711a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:29:08.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9142" for this suite.
Apr 10 16:29:14.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:29:15.002: INFO: namespace configmap-9142 deletion completed in 6.252833904s

• [SLOW TEST:6.892 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:29:15.002: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c809b12a-5bad-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c809b12a-5bad-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:30:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6307" for this suite.
Apr 10 16:31:05.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:31:05.388: INFO: namespace projected-6307 deletion completed in 24.248551252s

• [SLOW TEST:110.385 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:31:05.388: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 10 16:31:06.193: INFO: Waiting up to 5m0s for pod "pod-0a020f36-5bae-11e9-8040-3209cfee711a" in namespace "emptydir-4237" to be "success or failure"
Apr 10 16:31:06.260: INFO: Pod "pod-0a020f36-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 67.04374ms
Apr 10 16:31:08.263: INFO: Pod "pod-0a020f36-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069852161s
Apr 10 16:31:10.266: INFO: Pod "pod-0a020f36-5bae-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073451885s
STEP: Saw pod success
Apr 10 16:31:10.266: INFO: Pod "pod-0a020f36-5bae-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:31:10.269: INFO: Trying to get logs from node g168 pod pod-0a020f36-5bae-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:31:10.454: INFO: Waiting for pod pod-0a020f36-5bae-11e9-8040-3209cfee711a to disappear
Apr 10 16:31:10.700: INFO: Pod pod-0a020f36-5bae-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:31:10.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4237" for this suite.
Apr 10 16:31:18.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:31:18.829: INFO: namespace emptydir-4237 deletion completed in 8.12339333s

• [SLOW TEST:13.441 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:31:18.830: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 10 16:31:19.408: INFO: Waiting up to 5m0s for pod "pod-11bde8c5-5bae-11e9-8040-3209cfee711a" in namespace "emptydir-7126" to be "success or failure"
Apr 10 16:31:19.481: INFO: Pod "pod-11bde8c5-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 72.441557ms
Apr 10 16:31:21.593: INFO: Pod "pod-11bde8c5-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184461097s
Apr 10 16:31:23.667: INFO: Pod "pod-11bde8c5-5bae-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.258114101s
STEP: Saw pod success
Apr 10 16:31:23.667: INFO: Pod "pod-11bde8c5-5bae-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:31:23.670: INFO: Trying to get logs from node g168 pod pod-11bde8c5-5bae-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:31:23.767: INFO: Waiting for pod pod-11bde8c5-5bae-11e9-8040-3209cfee711a to disappear
Apr 10 16:31:23.959: INFO: Pod pod-11bde8c5-5bae-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:31:23.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7126" for this suite.
Apr 10 16:31:32.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:31:32.225: INFO: namespace emptydir-7126 deletion completed in 8.260787082s

• [SLOW TEST:13.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:31:32.225: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8962
Apr 10 16:31:37.124: INFO: Started pod liveness-exec in namespace container-probe-8962
STEP: checking the pod's current state and verifying that restartCount is present
Apr 10 16:31:37.128: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:35:39.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8962" for this suite.
Apr 10 16:35:47.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:35:47.790: INFO: namespace container-probe-8962 deletion completed in 8.374095601s

• [SLOW TEST:255.565 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:35:47.795: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:35:48.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a" in namespace "projected-228" to be "success or failure"
Apr 10 16:35:48.387: INFO: Pod "downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 68.280002ms
Apr 10 16:35:50.391: INFO: Pod "downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071629174s
Apr 10 16:35:52.395: INFO: Pod "downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.076405816s
STEP: Saw pod success
Apr 10 16:35:52.395: INFO: Pod "downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:35:52.398: INFO: Trying to get logs from node g168 pod downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:35:52.481: INFO: Waiting for pod downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a to disappear
Apr 10 16:35:52.690: INFO: Pod downwardapi-volume-b2102aa4-5bae-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:35:52.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-228" for this suite.
Apr 10 16:36:00.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:36:00.830: INFO: namespace projected-228 deletion completed in 8.135425461s

• [SLOW TEST:13.036 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:36:00.831: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 10 16:36:02.300: INFO: created pod pod-service-account-defaultsa
Apr 10 16:36:02.300: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 10 16:36:02.373: INFO: created pod pod-service-account-mountsa
Apr 10 16:36:02.373: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 10 16:36:02.650: INFO: created pod pod-service-account-nomountsa
Apr 10 16:36:02.650: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 10 16:36:03.099: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 10 16:36:03.099: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 10 16:36:03.617: INFO: created pod pod-service-account-mountsa-mountspec
Apr 10 16:36:03.617: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 10 16:36:04.083: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 10 16:36:04.083: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 10 16:36:04.517: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 10 16:36:04.518: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 10 16:36:04.962: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 10 16:36:04.962: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 10 16:36:05.444: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 10 16:36:05.444: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:36:05.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5806" for this suite.
Apr 10 16:36:38.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:36:38.652: INFO: namespace svcaccounts-5806 deletion completed in 32.732217544s

• [SLOW TEST:37.821 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:36:38.653: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7353
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 10 16:36:39.520: INFO: Found 0 stateful pods, waiting for 3
Apr 10 16:36:49.626: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 16:36:49.626: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 16:36:49.626: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 10 16:36:59.526: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 16:36:59.526: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 16:36:59.526: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 16:36:59.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-7353 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 16:36:59.659: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 16:36:59.660: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 16:36:59.660: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 10 16:37:09.690: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 10 16:37:19.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-7353 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 16:37:20.066: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 16:37:20.066: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 16:37:20.066: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 10 16:37:30.084: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
Apr 10 16:37:30.084: INFO: Waiting for Pod statefulset-7353/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:37:30.084: INFO: Waiting for Pod statefulset-7353/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:37:40.094: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
Apr 10 16:37:40.094: INFO: Waiting for Pod statefulset-7353/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:37:40.094: INFO: Waiting for Pod statefulset-7353/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:37:50.092: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
Apr 10 16:37:50.092: INFO: Waiting for Pod statefulset-7353/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:37:50.092: INFO: Waiting for Pod statefulset-7353/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:38:00.110: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
Apr 10 16:38:00.110: INFO: Waiting for Pod statefulset-7353/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:38:10.137: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
Apr 10 16:38:10.137: INFO: Waiting for Pod statefulset-7353/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 16:38:20.252: INFO: Waiting for StatefulSet statefulset-7353/ss2 to complete update
STEP: Rolling back to a previous revision
Apr 10 16:38:30.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-7353 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 10 16:38:30.389: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 10 16:38:30.389: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 10 16:38:30.389: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 10 16:38:40.473: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 10 16:38:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 exec --namespace=statefulset-7353 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 10 16:38:51.072: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 10 16:38:51.072: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 10 16:38:51.072: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 10 16:39:21.123: INFO: Deleting all statefulset in ns statefulset-7353
Apr 10 16:39:21.126: INFO: Scaling statefulset ss2 to 0
Apr 10 16:39:31.302: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 16:39:31.305: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:39:31.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7353" for this suite.
Apr 10 16:39:47.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:39:47.633: INFO: namespace statefulset-7353 deletion completed in 16.136868111s

• [SLOW TEST:188.980 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:39:47.635: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-40fe90c4-5baf-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:39:48.183: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a" in namespace "projected-2924" to be "success or failure"
Apr 10 16:39:48.249: INFO: Pod "pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 65.702235ms
Apr 10 16:39:50.253: INFO: Pod "pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069304865s
Apr 10 16:39:52.297: INFO: Pod "pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113272252s
STEP: Saw pod success
Apr 10 16:39:52.297: INFO: Pod "pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:39:52.302: INFO: Trying to get logs from node g168 pod pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:39:52.393: INFO: Waiting for pod pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a to disappear
Apr 10 16:39:52.568: INFO: Pod pod-projected-secrets-41237346-5baf-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:39:52.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2924" for this suite.
Apr 10 16:40:00.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:40:00.691: INFO: namespace projected-2924 deletion completed in 8.118996392s

• [SLOW TEST:13.057 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:40:00.694: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-48e4c6d3-5baf-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:40:02.067: INFO: Waiting up to 5m0s for pod "pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a" in namespace "secrets-1723" to be "success or failure"
Apr 10 16:40:02.146: INFO: Pod "pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 78.925961ms
Apr 10 16:40:04.166: INFO: Pod "pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098856158s
Apr 10 16:40:06.337: INFO: Pod "pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.270428675s
STEP: Saw pod success
Apr 10 16:40:06.338: INFO: Pod "pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:40:06.342: INFO: Trying to get logs from node g168 pod pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:40:06.432: INFO: Waiting for pod pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a to disappear
Apr 10 16:40:06.604: INFO: Pod pod-secrets-494f3a15-5baf-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:40:06.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1723" for this suite.
Apr 10 16:40:14.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:40:14.730: INFO: namespace secrets-1723 deletion completed in 8.122601174s
STEP: Destroying namespace "secret-namespace-8678" for this suite.
Apr 10 16:40:20.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:40:20.941: INFO: namespace secret-namespace-8678 deletion completed in 6.210375532s

• [SLOW TEST:20.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:40:20.941: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:40:21.347: INFO: Creating deployment "nginx-deployment"
Apr 10 16:40:21.598: INFO: Waiting for observed generation 1
Apr 10 16:40:24.009: INFO: Waiting for all required pods to come up
Apr 10 16:40:24.452: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 10 16:40:37.038: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 10 16:40:37.310: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 10 16:40:37.585: INFO: Updating deployment nginx-deployment
Apr 10 16:40:37.585: INFO: Waiting for observed generation 2
Apr 10 16:40:39.986: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 10 16:40:40.258: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 10 16:40:40.633: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 10 16:40:41.652: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 10 16:40:41.653: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 10 16:40:41.700: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 10 16:40:41.992: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 10 16:40:41.992: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 10 16:40:42.078: INFO: Updating deployment nginx-deployment
Apr 10 16:40:42.078: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 10 16:40:42.396: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 10 16:40:44.983: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 10 16:40:45.447: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6715,SelfLink:/apis/apps/v1/namespaces/deployment-6715/deployments/nginx-deployment,UID:54e950c4-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14506,Generation:3,CreationTimestamp:2019-04-10 16:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-10 16:40:42 +0000 UTC 2019-04-10 16:40:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-10 16:40:44 +0000 UTC 2019-04-10 16:40:21 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 10 16:40:45.869: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-6715,SelfLink:/apis/apps/v1/namespaces/deployment-6715/replicasets/nginx-deployment-5f9595f595,UID:5e968da9-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14498,Generation:3,CreationTimestamp:2019-04-10 16:40:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 54e950c4-5baf-11e9-b4c9-5254005baff5 0xc000a8e447 0xc000a8e448}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 16:40:45.869: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 10 16:40:45.869: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-6715,SelfLink:/apis/apps/v1/namespaces/deployment-6715/replicasets/nginx-deployment-6f478d8d8,UID:550f4b15-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14500,Generation:3,CreationTimestamp:2019-04-10 16:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 54e950c4-5baf-11e9-b4c9-5254005baff5 0xc000a8e517 0xc000a8e518}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 10 16:40:46.279: INFO: Pod "nginx-deployment-5f9595f595-56dhq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-56dhq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-56dhq,UID:5e971eba-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14426,Generation:0,CreationTimestamp:2019-04-10 16:40:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0e747 0xc002a0e748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0e7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0e7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.130,StartTime:2019-04-10 16:40:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.279: INFO: Pod "nginx-deployment-5f9595f595-88t6z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-88t6z,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-88t6z,UID:619aa177-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14525,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0e8d0 0xc002a0e8d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0e950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0e970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.279: INFO: Pod "nginx-deployment-5f9595f595-9jzrp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9jzrp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-9jzrp,UID:5ea0ce9d-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14431,Generation:0,CreationTimestamp:2019-04-10 16:40:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0ea40 0xc002a0ea41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0eac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0eae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.65,StartTime:2019-04-10 16:40:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.279: INFO: Pod "nginx-deployment-5f9595f595-9rrbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9rrbg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-9rrbg,UID:61cb02fc-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14492,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0ebe0 0xc002a0ebe1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0ec60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0ec80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.279: INFO: Pod "nginx-deployment-5f9595f595-b7wbl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b7wbl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-b7wbl,UID:5f60c958-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14412,Generation:0,CreationTimestamp:2019-04-10 16:40:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0ed00 0xc002a0ed01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0ed80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0eda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:39 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 16:40:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.280: INFO: Pod "nginx-deployment-5f9595f595-fqwft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fqwft,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-fqwft,UID:61aa277f-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14486,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0ee70 0xc002a0ee71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0eef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0ef10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.280: INFO: Pod "nginx-deployment-5f9595f595-lcfsk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lcfsk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-lcfsk,UID:61a9e3fa-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14481,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0ef90 0xc002a0ef91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.280: INFO: Pod "nginx-deployment-5f9595f595-lmrp5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lmrp5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-lmrp5,UID:61aa1511-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14487,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f0b0 0xc002a0f0b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.280: INFO: Pod "nginx-deployment-5f9595f595-lqtht" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lqtht,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-lqtht,UID:619a5a3e-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14526,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f1d0 0xc002a0f1d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.280: INFO: Pod "nginx-deployment-5f9595f595-qh22h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qh22h,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-qh22h,UID:5f54584a-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14503,Generation:0,CreationTimestamp:2019-04-10 16:40:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f340 0xc002a0f341}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.131,StartTime:2019-04-10 16:40:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-5f9595f595-slr69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-slr69,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-slr69,UID:5ea0aceb-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14513,Generation:0,CreationTimestamp:2019-04-10 16:40:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f4d0 0xc002a0f4d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:37 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.66,StartTime:2019-04-10 16:40:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-5f9595f595-v7wmw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-v7wmw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-v7wmw,UID:61751382-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14488,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f660 0xc002a0f661}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:,StartTime:2019-04-10 16:40:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-5f9595f595-xdcr7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xdcr7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-5f9595f595-xdcr7,UID:61aa1e59-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14483,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5e968da9-5baf-11e9-b4c9-5254005baff5 0xc002a0f7d0 0xc002a0f7d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-6f478d8d8-222pf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-222pf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-222pf,UID:556cec89-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14282,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0f8f0 0xc002a0f8f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0f960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0f980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.61,StartTime:2019-04-10 16:40:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:29 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://7d4b3e3fb1147a8f2ffb56cdec65724d7a74be61cf3a4eb0226205f79c40e07e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-6f478d8d8-2rc6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2rc6x,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-2rc6x,UID:61a9a742-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14478,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0fa60 0xc002a0fa61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0fad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0faf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.281: INFO: Pod "nginx-deployment-6f478d8d8-7kxhb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7kxhb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-7kxhb,UID:55796217-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14296,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0fb70 0xc002a0fb71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0fbe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0fc00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.127,StartTime:2019-04-10 16:40:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:32 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://cb295f4ff05eeb0541970e5b1040ef7ba1dba7b8a834df73914dc2f3ad378783}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-7pspr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7pspr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-7pspr,UID:553f9334-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14334,Generation:0,CreationTimestamp:2019-04-10 16:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0fce7 0xc002a0fce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0fd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0fd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.128,StartTime:2019-04-10 16:40:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:34 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://45c3bcad2b4bc1df7b286b8a29f6605d4ce89da95712c256fe848c3b802bdeb0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-8g6vp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8g6vp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-8g6vp,UID:619a6912-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14537,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0fe67 0xc002a0fe68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a0fee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a0ff00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-bpfnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bpfnf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-bpfnf,UID:61aa0beb-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14484,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc002a0ffc7 0xc002a0ffc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ec090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ec170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-g8fpf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g8fpf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-g8fpf,UID:619a854e-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14472,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ec1f0 0xc0024ec1f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ec440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ec480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-gw9ml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gw9ml,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-gw9ml,UID:61aa013f-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14485,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ec5f0 0xc0024ec5f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ec6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ec6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-h4q5j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-h4q5j,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-h4q5j,UID:553f69b8-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14317,Generation:0,CreationTimestamp:2019-04-10 16:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ec7f0 0xc0024ec7f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ec9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024eca40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.60,StartTime:2019-04-10 16:40:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://d64122d9fe27ba845e29cdd2ded69e6334c89b1613c1c6e123a193fac39fee70}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.282: INFO: Pod "nginx-deployment-6f478d8d8-hw659" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hw659,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-hw659,UID:6175f2ac-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14501,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ecbd0 0xc0024ecbd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ecc40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ecc70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.283: INFO: Pod "nginx-deployment-6f478d8d8-jjx8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jjx8g,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-jjx8g,UID:616991ae-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14489,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ecd37 0xc0024ecd38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ecdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ecde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 16:40:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.283: INFO: Pod "nginx-deployment-6f478d8d8-k6xmx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-k6xmx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-k6xmx,UID:61a9edab-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14479,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ecea7 0xc0024ecea8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ecf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ecf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.283: INFO: Pod "nginx-deployment-6f478d8d8-kfcbl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kfcbl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-kfcbl,UID:55792749-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14311,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ecfc0 0xc0024ecfc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ed030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ed150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.64,StartTime:2019-04-10 16:40:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://ffe0668fa397b8ad1c950d792bbd051612495fccb0791bbed97300292af84c5a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.283: INFO: Pod "nginx-deployment-6f478d8d8-pghwd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pghwd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-pghwd,UID:619a97ab-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14476,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ed2d0 0xc0024ed2d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ed350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ed390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.283: INFO: Pod "nginx-deployment-6f478d8d8-pgr2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pgr2m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-pgr2m,UID:619a9090-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14536,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ed500 0xc0024ed501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ed5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ed5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.284: INFO: Pod "nginx-deployment-6f478d8d8-rnk7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rnk7m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-rnk7m,UID:6175dc64-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14512,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024ed787 0xc0024ed788}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ed840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ed8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 16:40:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.284: INFO: Pod "nginx-deployment-6f478d8d8-vjrp8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vjrp8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-vjrp8,UID:556d1a44-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14304,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024edaa7 0xc0024edaa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024edb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024edb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.126,StartTime:2019-04-10 16:40:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:32 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://a14d1aac042ad31911ed76a05b75e496ba4ec2d71162a9bc75466535f01f63c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.284: INFO: Pod "nginx-deployment-6f478d8d8-wcqdq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wcqdq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-wcqdq,UID:556ce9fc-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14298,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0024edce7 0xc0024edce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ede40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024eded0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.63,StartTime:2019-04-10 16:40:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://ad086373178420888d4d6f6e0941e786f8c43972bf9bb99ded31069724f98c73}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.284: INFO: Pod "nginx-deployment-6f478d8d8-wjv28" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wjv28,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-wjv28,UID:61a9f72b-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14482,Generation:0,CreationTimestamp:2019-04-10 16:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0027a8020 0xc0027a8021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027a8090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027a80b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 10 16:40:46.284: INFO: Pod "nginx-deployment-6f478d8d8-x57b6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x57b6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6715,SelfLink:/api/v1/namespaces/deployment-6715/pods/nginx-deployment-6f478d8d8-x57b6,UID:557959e5-5baf-11e9-b4c9-5254005baff5,ResourceVersion:14302,Generation:0,CreationTimestamp:2019-04-10 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 550f4b15-5baf-11e9-b4c9-5254005baff5 0xc0027a8130 0xc0027a8131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7hn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7hn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7hn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e173,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027a81a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027a81d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 16:40:22 +0000 UTC  }],Message:,Reason:,HostIP:10.160.65.173,PodIP:10.244.2.62,StartTime:2019-04-10 16:40:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-10 16:40:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://671154ea75f36421d6dc83d8d4e724af1ee8161317708097d91199dcb00f34f9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:40:46.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6715" for this suite.
Apr 10 16:41:27.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:41:27.892: INFO: namespace deployment-6715 deletion completed in 41.15556965s

• [SLOW TEST:66.952 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:41:27.893: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a
Apr 10 16:41:28.762: INFO: Pod name my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a: Found 0 pods out of 1
Apr 10 16:41:33.806: INFO: Pod name my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a: Found 1 pods out of 1
Apr 10 16:41:33.806: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a" are running
Apr 10 16:41:43.816: INFO: Pod "my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a-k6d7t" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 16:41:28 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 16:41:28 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 16:41:28 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 16:41:28 +0000 UTC Reason: Message:}])
Apr 10 16:41:43.816: INFO: Trying to dial the pod
Apr 10 16:41:48.827: INFO: Controller my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a: Got expected result from replica 1 [my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a-k6d7t]: "my-hostname-basic-7cf37310-5baf-11e9-8040-3209cfee711a-k6d7t", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:41:48.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-581" for this suite.
Apr 10 16:41:56.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:41:56.952: INFO: namespace replication-controller-581 deletion completed in 8.120847326s

• [SLOW TEST:29.060 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:41:56.953: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:41:57.445: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a" in namespace "downward-api-5809" to be "success or failure"
Apr 10 16:41:57.508: INFO: Pod "downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 63.194619ms
Apr 10 16:41:59.565: INFO: Pod "downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119809253s
Apr 10 16:42:01.686: INFO: Pod "downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.241233504s
STEP: Saw pod success
Apr 10 16:42:01.687: INFO: Pod "downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:42:01.690: INFO: Trying to get logs from node g168 pod downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:42:01.787: INFO: Waiting for pod downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a to disappear
Apr 10 16:42:01.957: INFO: Pod downwardapi-volume-8e17368c-5baf-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:42:01.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5809" for this suite.
Apr 10 16:42:10.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:42:10.080: INFO: namespace downward-api-5809 deletion completed in 8.117717075s

• [SLOW TEST:13.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:42:10.080: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 16:42:10.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4236'
Apr 10 16:42:17.298: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 10 16:42:17.298: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 10 16:42:19.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4236'
Apr 10 16:42:19.785: INFO: stderr: ""
Apr 10 16:42:19.785: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:42:19.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4236" for this suite.
Apr 10 16:44:21.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:44:21.930: INFO: namespace kubectl-4236 deletion completed in 2m2.138117233s

• [SLOW TEST:131.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:44:21.931: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 10 16:44:30.767: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:30.824: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:32.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:32.828: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:34.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:34.829: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:36.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:36.830: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:38.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:38.828: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:40.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:40.829: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:42.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:42.830: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:44.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:44.829: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:46.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:46.827: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:48.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:48.877: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 10 16:44:50.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 10 16:44:50.829: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:44:50.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7422" for this suite.
Apr 10 16:45:15.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:45:15.099: INFO: namespace container-lifecycle-hook-7422 deletion completed in 24.242215687s

• [SLOW TEST:53.168 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:45:15.101: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 16:45:15.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3162'
Apr 10 16:45:15.716: INFO: stderr: ""
Apr 10 16:45:15.716: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 10 16:45:20.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pod e2e-test-nginx-pod --namespace=kubectl-3162 -o json'
Apr 10 16:45:20.857: INFO: stderr: ""
Apr 10 16:45:20.857: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-10T16:45:15Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3162\",\n        \"resourceVersion\": \"15454\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3162/pods/e2e-test-nginx-pod\",\n        \"uid\": \"045cc8fd-5bb0-11e9-b4c9-5254005baff5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-p6mcj\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"g168\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-p6mcj\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-p6mcj\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-10T16:45:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-10T16:45:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-10T16:45:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-10T16:45:15Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://906770ac4ed540bdd4da8ec396689e03ad18550190cfeddac13620b9970c486e\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-10T16:45:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.160.67.168\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.148\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-10T16:45:16Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 10 16:45:20.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 replace -f - --namespace=kubectl-3162'
Apr 10 16:45:21.216: INFO: stderr: ""
Apr 10 16:45:21.216: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 10 16:45:21.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete pods e2e-test-nginx-pod --namespace=kubectl-3162'
Apr 10 16:45:24.335: INFO: stderr: ""
Apr 10 16:45:24.335: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:45:24.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3162" for this suite.
Apr 10 16:45:32.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:45:33.183: INFO: namespace kubectl-3162 deletion completed in 8.679436676s

• [SLOW TEST:18.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:45:33.183: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0ef7c373-5bb0-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:45:33.737: INFO: Waiting up to 5m0s for pod "pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a" in namespace "secrets-2640" to be "success or failure"
Apr 10 16:45:33.806: INFO: Pod "pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 68.932022ms
Apr 10 16:45:35.810: INFO: Pod "pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072578361s
Apr 10 16:45:37.814: INFO: Pod "pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077542092s
STEP: Saw pod success
Apr 10 16:45:37.815: INFO: Pod "pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:45:37.819: INFO: Trying to get logs from node g168 pod pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:45:37.993: INFO: Waiting for pod pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:45:38.055: INFO: Pod pod-secrets-0f1af021-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:45:38.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2640" for this suite.
Apr 10 16:45:46.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:45:46.282: INFO: namespace secrets-2640 deletion completed in 8.220934659s

• [SLOW TEST:13.099 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:45:46.283: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:45:47.374: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 10 16:45:47.440: INFO: Number of nodes with available pods: 0
Apr 10 16:45:47.440: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 10 16:45:47.758: INFO: Number of nodes with available pods: 0
Apr 10 16:45:47.758: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:48.799: INFO: Number of nodes with available pods: 0
Apr 10 16:45:48.799: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:49.762: INFO: Number of nodes with available pods: 0
Apr 10 16:45:49.762: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:50.761: INFO: Number of nodes with available pods: 1
Apr 10 16:45:50.761: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 10 16:45:50.942: INFO: Number of nodes with available pods: 1
Apr 10 16:45:50.942: INFO: Number of running nodes: 0, number of available pods: 1
Apr 10 16:45:51.950: INFO: Number of nodes with available pods: 0
Apr 10 16:45:51.950: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 10 16:45:52.203: INFO: Number of nodes with available pods: 0
Apr 10 16:45:52.203: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:53.236: INFO: Number of nodes with available pods: 0
Apr 10 16:45:53.236: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:54.361: INFO: Number of nodes with available pods: 0
Apr 10 16:45:54.362: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:55.216: INFO: Number of nodes with available pods: 0
Apr 10 16:45:55.216: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:56.208: INFO: Number of nodes with available pods: 0
Apr 10 16:45:56.208: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:57.224: INFO: Number of nodes with available pods: 0
Apr 10 16:45:57.224: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:58.208: INFO: Number of nodes with available pods: 0
Apr 10 16:45:58.209: INFO: Node e173 is running more than one daemon pod
Apr 10 16:45:59.253: INFO: Number of nodes with available pods: 0
Apr 10 16:45:59.253: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:00.207: INFO: Number of nodes with available pods: 0
Apr 10 16:46:00.207: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:01.276: INFO: Number of nodes with available pods: 0
Apr 10 16:46:01.276: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:02.208: INFO: Number of nodes with available pods: 0
Apr 10 16:46:02.208: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:03.206: INFO: Number of nodes with available pods: 0
Apr 10 16:46:03.206: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:04.360: INFO: Number of nodes with available pods: 0
Apr 10 16:46:04.361: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:05.208: INFO: Number of nodes with available pods: 1
Apr 10 16:46:05.208: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9321, will wait for the garbage collector to delete the pods
Apr 10 16:46:05.280: INFO: Deleting DaemonSet.extensions daemon-set took: 12.457194ms
Apr 10 16:46:05.880: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.369925ms
Apr 10 16:46:07.903: INFO: Number of nodes with available pods: 0
Apr 10 16:46:07.903: INFO: Number of running nodes: 0, number of available pods: 0
Apr 10 16:46:07.907: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9321/daemonsets","resourceVersion":"15635"},"items":null}

Apr 10 16:46:07.910: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9321/pods","resourceVersion":"15635"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:46:07.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9321" for this suite.
Apr 10 16:46:16.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:46:16.420: INFO: namespace daemonsets-9321 deletion completed in 8.426370458s

• [SLOW TEST:30.138 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:46:16.421: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-28ba08b4-5bb0-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 16:46:17.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a" in namespace "configmap-8354" to be "success or failure"
Apr 10 16:46:17.270: INFO: Pod "pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 234.184114ms
Apr 10 16:46:19.394: INFO: Pod "pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.357911637s
Apr 10 16:46:21.398: INFO: Pod "pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.362065926s
STEP: Saw pod success
Apr 10 16:46:21.398: INFO: Pod "pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:46:21.401: INFO: Trying to get logs from node g168 pod pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 16:46:21.617: INFO: Waiting for pod pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:46:21.670: INFO: Pod pod-configmaps-28e009cd-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:46:21.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8354" for this suite.
Apr 10 16:46:29.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:46:29.892: INFO: namespace configmap-8354 deletion completed in 8.218858452s

• [SLOW TEST:13.472 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:46:29.893: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:46:38.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6844" for this suite.
Apr 10 16:46:47.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:46:47.146: INFO: namespace namespaces-6844 deletion completed in 8.118535267s
STEP: Destroying namespace "nsdeletetest-6480" for this suite.
Apr 10 16:46:47.147: INFO: Namespace nsdeletetest-6480 was already deleted
STEP: Destroying namespace "nsdeletetest-6152" for this suite.
Apr 10 16:46:53.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:46:53.410: INFO: namespace nsdeletetest-6152 deletion completed in 6.262885305s

• [SLOW TEST:23.517 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:46:53.410: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 16:46:53.911: INFO: Create a RollingUpdate DaemonSet
Apr 10 16:46:53.916: INFO: Check that daemon pods launch on every node of the cluster
Apr 10 16:46:54.155: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:46:54.158: INFO: Number of nodes with available pods: 0
Apr 10 16:46:54.158: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:55.218: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:46:55.220: INFO: Number of nodes with available pods: 0
Apr 10 16:46:55.220: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:56.291: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:46:56.389: INFO: Number of nodes with available pods: 0
Apr 10 16:46:56.389: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:57.254: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:46:57.425: INFO: Number of nodes with available pods: 0
Apr 10 16:46:57.425: INFO: Node e173 is running more than one daemon pod
Apr 10 16:46:58.238: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:46:58.241: INFO: Number of nodes with available pods: 2
Apr 10 16:46:58.241: INFO: Number of running nodes: 2, number of available pods: 2
Apr 10 16:46:58.241: INFO: Update the DaemonSet to trigger a rollout
Apr 10 16:46:58.253: INFO: Updating DaemonSet daemon-set
Apr 10 16:47:02.422: INFO: Roll back the DaemonSet before rollout is complete
Apr 10 16:47:02.499: INFO: Updating DaemonSet daemon-set
Apr 10 16:47:02.499: INFO: Make sure DaemonSet rollback is complete
Apr 10 16:47:02.760: INFO: Wrong image for pod: daemon-set-wh9wr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 10 16:47:02.760: INFO: Pod daemon-set-wh9wr is not available
Apr 10 16:47:02.837: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:47:03.846: INFO: Wrong image for pod: daemon-set-wh9wr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 10 16:47:03.846: INFO: Pod daemon-set-wh9wr is not available
Apr 10 16:47:03.850: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:47:04.910: INFO: Wrong image for pod: daemon-set-wh9wr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 10 16:47:04.910: INFO: Pod daemon-set-wh9wr is not available
Apr 10 16:47:04.915: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:47:05.841: INFO: Wrong image for pod: daemon-set-wh9wr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 10 16:47:05.842: INFO: Pod daemon-set-wh9wr is not available
Apr 10 16:47:05.847: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:47:06.841: INFO: Wrong image for pod: daemon-set-wh9wr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 10 16:47:06.841: INFO: Pod daemon-set-wh9wr is not available
Apr 10 16:47:06.845: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 16:47:07.877: INFO: Pod daemon-set-scsvz is not available
Apr 10 16:47:08.046: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9925, will wait for the garbage collector to delete the pods
Apr 10 16:47:08.345: INFO: Deleting DaemonSet.extensions daemon-set took: 175.20322ms
Apr 10 16:47:08.845: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.250403ms
Apr 10 16:47:13.401: INFO: Number of nodes with available pods: 0
Apr 10 16:47:13.401: INFO: Number of running nodes: 0, number of available pods: 0
Apr 10 16:47:13.403: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9925/daemonsets","resourceVersion":"15901"},"items":null}

Apr 10 16:47:13.405: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9925/pods","resourceVersion":"15901"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:47:13.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9925" for this suite.
Apr 10 16:47:23.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:47:23.652: INFO: namespace daemonsets-9925 deletion completed in 10.236864456s

• [SLOW TEST:30.242 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:47:23.656: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-50e67a3b-5bb0-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:47:24.183: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a" in namespace "projected-5356" to be "success or failure"
Apr 10 16:47:24.405: INFO: Pod "pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 222.146289ms
Apr 10 16:47:26.529: INFO: Pod "pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.346177902s
Apr 10 16:47:28.534: INFO: Pod "pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.35100882s
STEP: Saw pod success
Apr 10 16:47:28.534: INFO: Pod "pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:47:28.537: INFO: Trying to get logs from node g168 pod pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:47:28.717: INFO: Waiting for pod pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:47:28.936: INFO: Pod pod-projected-secrets-50e771ba-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:47:28.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5356" for this suite.
Apr 10 16:47:37.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:47:37.336: INFO: namespace projected-5356 deletion completed in 8.393181436s

• [SLOW TEST:13.680 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:47:37.336: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-5910d575-5bb0-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 16:47:38.057: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a" in namespace "projected-5871" to be "success or failure"
Apr 10 16:47:38.125: INFO: Pod "pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 67.370714ms
Apr 10 16:47:40.178: INFO: Pod "pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.120261261s
Apr 10 16:47:42.182: INFO: Pod "pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.124814878s
STEP: Saw pod success
Apr 10 16:47:42.182: INFO: Pod "pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:47:42.186: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 16:47:42.284: INFO: Waiting for pod pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:47:42.454: INFO: Pod pod-projected-configmaps-591b7e37-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:47:42.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5871" for this suite.
Apr 10 16:47:50.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:47:50.606: INFO: namespace projected-5871 deletion completed in 8.148896546s

• [SLOW TEST:13.270 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:47:50.608: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 10 16:47:59.452: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:47:59.507: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:01.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:01.511: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:03.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:03.511: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:05.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:05.510: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:07.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:07.511: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:09.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:09.511: INFO: Pod pod-with-poststart-http-hook still exists
Apr 10 16:48:11.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 10 16:48:11.511: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:48:11.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1386" for this suite.
Apr 10 16:48:35.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:48:35.729: INFO: namespace container-lifecycle-hook-1386 deletion completed in 24.211926753s

• [SLOW TEST:45.121 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:48:35.735: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-320
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 10 16:48:36.224: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 10 16:49:00.828: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.158:8080/dial?request=hostName&protocol=http&host=10.244.1.157&port=8080&tries=1'] Namespace:pod-network-test-320 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 16:49:00.828: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 16:49:00.887: INFO: Waiting for endpoints: map[]
Apr 10 16:49:00.890: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.158:8080/dial?request=hostName&protocol=http&host=10.244.2.81&port=8080&tries=1'] Namespace:pod-network-test-320 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 16:49:00.890: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 16:49:00.947: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:49:00.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-320" for this suite.
Apr 10 16:49:27.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:49:27.361: INFO: namespace pod-network-test-320 deletion completed in 26.411719381s

• [SLOW TEST:51.627 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:49:27.362: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:49:27.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a" in namespace "downward-api-9694" to be "success or failure"
Apr 10 16:49:27.933: INFO: Pod "downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 56.27312ms
Apr 10 16:49:29.937: INFO: Pod "downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059847504s
Apr 10 16:49:32.004: INFO: Pod "downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127071717s
STEP: Saw pod success
Apr 10 16:49:32.004: INFO: Pod "downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:49:32.008: INFO: Trying to get logs from node g168 pod downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:49:32.277: INFO: Waiting for pod downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:49:32.335: INFO: Pod downwardapi-volume-9aa99a50-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:49:32.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9694" for this suite.
Apr 10 16:49:40.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:49:40.588: INFO: namespace downward-api-9694 deletion completed in 8.249840499s

• [SLOW TEST:13.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:49:40.589: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 10 16:49:41.223: INFO: Waiting up to 5m0s for pod "var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a" in namespace "var-expansion-6559" to be "success or failure"
Apr 10 16:49:41.462: INFO: Pod "var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 238.332974ms
Apr 10 16:49:43.528: INFO: Pod "var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.305039223s
Apr 10 16:49:45.541: INFO: Pod "var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.31822518s
STEP: Saw pod success
Apr 10 16:49:45.541: INFO: Pod "var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:49:45.544: INFO: Trying to get logs from node g168 pod var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 16:49:45.624: INFO: Waiting for pod var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:49:45.802: INFO: Pod var-expansion-a293e686-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:49:45.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6559" for this suite.
Apr 10 16:49:53.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:49:53.925: INFO: namespace var-expansion-6559 deletion completed in 8.120586747s

• [SLOW TEST:13.336 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:49:53.926: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-aa792075-5bb0-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:49:54.602: INFO: Waiting up to 5m0s for pod "pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a" in namespace "secrets-5467" to be "success or failure"
Apr 10 16:49:54.667: INFO: Pod "pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 64.959257ms
Apr 10 16:49:56.671: INFO: Pod "pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068708864s
Apr 10 16:49:58.693: INFO: Pod "pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.090665401s
STEP: Saw pod success
Apr 10 16:49:58.693: INFO: Pod "pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:49:58.695: INFO: Trying to get logs from node g168 pod pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a container secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:49:58.959: INFO: Waiting for pod pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:49:58.961: INFO: Pod pod-secrets-aa82ac4d-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:49:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5467" for this suite.
Apr 10 16:50:07.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:50:07.094: INFO: namespace secrets-5467 deletion completed in 8.129426991s

• [SLOW TEST:13.168 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:50:07.094: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 16:50:07.646: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a" in namespace "projected-5824" to be "success or failure"
Apr 10 16:50:07.711: INFO: Pod "downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 64.926192ms
Apr 10 16:50:09.854: INFO: Pod "downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207967317s
Apr 10 16:50:11.859: INFO: Pod "downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212483035s
STEP: Saw pod success
Apr 10 16:50:11.859: INFO: Pod "downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:50:11.864: INFO: Trying to get logs from node g168 pod downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 16:50:12.125: INFO: Waiting for pod downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a to disappear
Apr 10 16:50:12.361: INFO: Pod downwardapi-volume-b2440247-5bb0-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:50:12.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5824" for this suite.
Apr 10 16:50:20.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:50:20.856: INFO: namespace projected-5824 deletion completed in 8.488925273s

• [SLOW TEST:13.761 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:50:20.859: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7226
I0410 16:50:21.362991      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7226, replica count: 1
I0410 16:50:22.413678      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 16:50:23.414127      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 16:50:24.414449      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 16:50:25.414909      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 10 16:50:25.830: INFO: Created: latency-svc-7jzqr
Apr 10 16:50:25.835: INFO: Got endpoints: latency-svc-7jzqr [320.464284ms]
Apr 10 16:50:26.204: INFO: Created: latency-svc-dcmtx
Apr 10 16:50:26.204: INFO: Got endpoints: latency-svc-dcmtx [368.493313ms]
Apr 10 16:50:26.536: INFO: Created: latency-svc-kxs5p
Apr 10 16:50:26.540: INFO: Got endpoints: latency-svc-kxs5p [704.256249ms]
Apr 10 16:50:26.880: INFO: Created: latency-svc-2xg87
Apr 10 16:50:26.881: INFO: Got endpoints: latency-svc-2xg87 [1.045937131s]
Apr 10 16:50:27.173: INFO: Created: latency-svc-ddgzk
Apr 10 16:50:27.226: INFO: Got endpoints: latency-svc-ddgzk [1.390791245s]
Apr 10 16:50:27.508: INFO: Created: latency-svc-rr8qk
Apr 10 16:50:27.513: INFO: Got endpoints: latency-svc-rr8qk [1.677207373s]
Apr 10 16:50:27.849: INFO: Created: latency-svc-dlf8k
Apr 10 16:50:27.862: INFO: Got endpoints: latency-svc-dlf8k [2.026837962s]
Apr 10 16:50:28.233: INFO: Created: latency-svc-pndhf
Apr 10 16:50:28.233: INFO: Got endpoints: latency-svc-pndhf [2.397603175s]
Apr 10 16:50:28.540: INFO: Created: latency-svc-fbcdd
Apr 10 16:50:28.544: INFO: Got endpoints: latency-svc-fbcdd [2.708174847s]
Apr 10 16:50:28.893: INFO: Created: latency-svc-6mk4h
Apr 10 16:50:28.896: INFO: Got endpoints: latency-svc-6mk4h [3.060084105s]
Apr 10 16:50:29.209: INFO: Created: latency-svc-7ngpm
Apr 10 16:50:29.217: INFO: Got endpoints: latency-svc-7ngpm [3.381199662s]
Apr 10 16:50:29.598: INFO: Created: latency-svc-7kl8c
Apr 10 16:50:29.666: INFO: Got endpoints: latency-svc-7kl8c [3.830633894s]
Apr 10 16:50:29.924: INFO: Created: latency-svc-rkdls
Apr 10 16:50:29.932: INFO: Got endpoints: latency-svc-rkdls [4.096518307s]
Apr 10 16:50:30.263: INFO: Created: latency-svc-szcxh
Apr 10 16:50:30.268: INFO: Got endpoints: latency-svc-szcxh [4.432307776s]
Apr 10 16:50:30.616: INFO: Created: latency-svc-ctw2g
Apr 10 16:50:30.620: INFO: Got endpoints: latency-svc-ctw2g [4.784531375s]
Apr 10 16:50:30.971: INFO: Created: latency-svc-mgx66
Apr 10 16:50:31.049: INFO: Got endpoints: latency-svc-mgx66 [5.212919804s]
Apr 10 16:50:31.286: INFO: Created: latency-svc-qr6ct
Apr 10 16:50:31.304: INFO: Got endpoints: latency-svc-qr6ct [5.099867709s]
Apr 10 16:50:31.588: INFO: Created: latency-svc-lcppc
Apr 10 16:50:31.672: INFO: Got endpoints: latency-svc-lcppc [5.131787314s]
Apr 10 16:50:31.680: INFO: Created: latency-svc-92wqp
Apr 10 16:50:31.927: INFO: Got endpoints: latency-svc-92wqp [5.045804207s]
Apr 10 16:50:31.937: INFO: Created: latency-svc-2v8lh
Apr 10 16:50:32.227: INFO: Got endpoints: latency-svc-2v8lh [5.000129932s]
Apr 10 16:50:32.514: INFO: Created: latency-svc-hfk9m
Apr 10 16:50:32.520: INFO: Got endpoints: latency-svc-hfk9m [5.007529036s]
Apr 10 16:50:32.821: INFO: Created: latency-svc-fcs4n
Apr 10 16:50:32.837: INFO: Got endpoints: latency-svc-fcs4n [4.974468941s]
Apr 10 16:50:33.169: INFO: Created: latency-svc-2hvtv
Apr 10 16:50:33.170: INFO: Got endpoints: latency-svc-2hvtv [4.936395781s]
Apr 10 16:50:33.558: INFO: Created: latency-svc-phjzz
Apr 10 16:50:33.560: INFO: Got endpoints: latency-svc-phjzz [5.016232545s]
Apr 10 16:50:33.889: INFO: Created: latency-svc-cflj5
Apr 10 16:50:33.892: INFO: Got endpoints: latency-svc-cflj5 [4.996834195s]
Apr 10 16:50:34.216: INFO: Created: latency-svc-6fklr
Apr 10 16:50:34.221: INFO: Got endpoints: latency-svc-6fklr [5.00439822s]
Apr 10 16:50:34.549: INFO: Created: latency-svc-4mw57
Apr 10 16:50:34.641: INFO: Got endpoints: latency-svc-4mw57 [4.974766765s]
Apr 10 16:50:34.935: INFO: Created: latency-svc-6x8cz
Apr 10 16:50:35.000: INFO: Got endpoints: latency-svc-6x8cz [5.068267347s]
Apr 10 16:50:35.008: INFO: Created: latency-svc-gz8f8
Apr 10 16:50:35.261: INFO: Got endpoints: latency-svc-gz8f8 [4.992526639s]
Apr 10 16:50:35.352: INFO: Created: latency-svc-p62m6
Apr 10 16:50:35.352: INFO: Created: latency-svc-2rlk7
Apr 10 16:50:35.583: INFO: Got endpoints: latency-svc-p62m6 [4.96289379s]
Apr 10 16:50:35.596: INFO: Got endpoints: latency-svc-2rlk7 [4.546962031s]
Apr 10 16:50:35.598: INFO: Created: latency-svc-mrngj
Apr 10 16:50:35.659: INFO: Got endpoints: latency-svc-mrngj [4.355003409s]
Apr 10 16:50:36.035: INFO: Created: latency-svc-cks58
Apr 10 16:50:36.290: INFO: Got endpoints: latency-svc-cks58 [4.617931515s]
Apr 10 16:50:36.295: INFO: Created: latency-svc-h6wj7
Apr 10 16:50:36.373: INFO: Got endpoints: latency-svc-h6wj7 [4.445281139s]
Apr 10 16:50:36.382: INFO: Created: latency-svc-cjztx
Apr 10 16:50:36.637: INFO: Got endpoints: latency-svc-cjztx [4.410490304s]
Apr 10 16:50:36.650: INFO: Created: latency-svc-lqlqn
Apr 10 16:50:36.712: INFO: Got endpoints: latency-svc-lqlqn [4.191428902s]
Apr 10 16:50:37.008: INFO: Created: latency-svc-lx6gb
Apr 10 16:50:37.085: INFO: Got endpoints: latency-svc-lx6gb [4.248518866s]
Apr 10 16:50:37.354: INFO: Created: latency-svc-7mjsl
Apr 10 16:50:37.364: INFO: Got endpoints: latency-svc-7mjsl [4.193868788s]
Apr 10 16:50:37.703: INFO: Created: latency-svc-w9nt8
Apr 10 16:50:37.711: INFO: Got endpoints: latency-svc-w9nt8 [4.150447175s]
Apr 10 16:50:38.037: INFO: Created: latency-svc-dhhqj
Apr 10 16:50:38.037: INFO: Got endpoints: latency-svc-dhhqj [4.144676373s]
Apr 10 16:50:38.342: INFO: Created: latency-svc-x2bwk
Apr 10 16:50:38.350: INFO: Got endpoints: latency-svc-x2bwk [4.128313817s]
Apr 10 16:50:38.661: INFO: Created: latency-svc-2vcj4
Apr 10 16:50:38.661: INFO: Got endpoints: latency-svc-2vcj4 [4.019196355s]
Apr 10 16:50:38.999: INFO: Created: latency-svc-4xj85
Apr 10 16:50:39.001: INFO: Got endpoints: latency-svc-4xj85 [4.000135071s]
Apr 10 16:50:39.291: INFO: Created: latency-svc-2ngr4
Apr 10 16:50:39.297: INFO: Got endpoints: latency-svc-2ngr4 [4.035602613s]
Apr 10 16:50:39.577: INFO: Created: latency-svc-mc576
Apr 10 16:50:39.582: INFO: Got endpoints: latency-svc-mc576 [3.998131397s]
Apr 10 16:50:39.894: INFO: Created: latency-svc-6jjkk
Apr 10 16:50:40.179: INFO: Got endpoints: latency-svc-6jjkk [4.583465201s]
Apr 10 16:50:40.187: INFO: Created: latency-svc-bgmv2
Apr 10 16:50:40.194: INFO: Got endpoints: latency-svc-bgmv2 [4.535298835s]
Apr 10 16:50:40.538: INFO: Created: latency-svc-xjxdk
Apr 10 16:50:40.561: INFO: Got endpoints: latency-svc-xjxdk [4.271607269s]
Apr 10 16:50:40.817: INFO: Created: latency-svc-vh4vv
Apr 10 16:50:41.103: INFO: Got endpoints: latency-svc-vh4vv [4.730424386s]
Apr 10 16:50:41.197: INFO: Created: latency-svc-jkkmd
Apr 10 16:50:41.418: INFO: Got endpoints: latency-svc-jkkmd [4.780647527s]
Apr 10 16:50:41.502: INFO: Created: latency-svc-t7b6h
Apr 10 16:50:41.509: INFO: Created: latency-svc-s4r64
Apr 10 16:50:41.729: INFO: Got endpoints: latency-svc-t7b6h [5.017291959s]
Apr 10 16:50:41.732: INFO: Got endpoints: latency-svc-s4r64 [4.646302518s]
Apr 10 16:50:41.745: INFO: Created: latency-svc-tjdw8
Apr 10 16:50:41.809: INFO: Got endpoints: latency-svc-tjdw8 [4.445679521s]
Apr 10 16:50:42.094: INFO: Created: latency-svc-wzvks
Apr 10 16:50:42.099: INFO: Got endpoints: latency-svc-wzvks [4.388503261s]
Apr 10 16:50:42.181: INFO: Created: latency-svc-gfrcn
Apr 10 16:50:42.426: INFO: Got endpoints: latency-svc-gfrcn [4.388554952s]
Apr 10 16:50:42.753: INFO: Created: latency-svc-hfqll
Apr 10 16:50:42.758: INFO: Got endpoints: latency-svc-hfqll [4.408322276s]
Apr 10 16:50:43.062: INFO: Created: latency-svc-n9z5m
Apr 10 16:50:43.064: INFO: Got endpoints: latency-svc-n9z5m [4.403050351s]
Apr 10 16:50:43.425: INFO: Created: latency-svc-rhvk6
Apr 10 16:50:43.435: INFO: Got endpoints: latency-svc-rhvk6 [4.434372457s]
Apr 10 16:50:43.792: INFO: Created: latency-svc-sc7xb
Apr 10 16:50:43.794: INFO: Got endpoints: latency-svc-sc7xb [4.497475656s]
Apr 10 16:50:44.120: INFO: Created: latency-svc-hzf4m
Apr 10 16:50:44.120: INFO: Got endpoints: latency-svc-hzf4m [4.537983644s]
Apr 10 16:50:44.423: INFO: Created: latency-svc-nwbwg
Apr 10 16:50:44.431: INFO: Got endpoints: latency-svc-nwbwg [4.250991117s]
Apr 10 16:50:44.875: INFO: Created: latency-svc-qvcxb
Apr 10 16:50:44.950: INFO: Got endpoints: latency-svc-qvcxb [4.755604439s]
Apr 10 16:50:45.185: INFO: Created: latency-svc-p4x4s
Apr 10 16:50:45.209: INFO: Got endpoints: latency-svc-p4x4s [4.64791386s]
Apr 10 16:50:45.527: INFO: Created: latency-svc-d25h4
Apr 10 16:50:45.537: INFO: Got endpoints: latency-svc-d25h4 [4.432919532s]
Apr 10 16:50:45.921: INFO: Created: latency-svc-sd4k5
Apr 10 16:50:46.243: INFO: Got endpoints: latency-svc-sd4k5 [4.824057728s]
Apr 10 16:50:46.253: INFO: Created: latency-svc-7ghcx
Apr 10 16:50:46.255: INFO: Got endpoints: latency-svc-7ghcx [4.525461451s]
Apr 10 16:50:46.569: INFO: Created: latency-svc-ks7b8
Apr 10 16:50:46.577: INFO: Got endpoints: latency-svc-ks7b8 [4.844912005s]
Apr 10 16:50:46.902: INFO: Created: latency-svc-c8bfw
Apr 10 16:50:46.908: INFO: Got endpoints: latency-svc-c8bfw [5.097981035s]
Apr 10 16:50:47.239: INFO: Created: latency-svc-jqg7k
Apr 10 16:50:47.246: INFO: Got endpoints: latency-svc-jqg7k [5.146620825s]
Apr 10 16:50:47.549: INFO: Created: latency-svc-qk6t7
Apr 10 16:50:47.604: INFO: Got endpoints: latency-svc-qk6t7 [5.177676301s]
Apr 10 16:50:47.880: INFO: Created: latency-svc-hscwm
Apr 10 16:50:47.885: INFO: Got endpoints: latency-svc-hscwm [5.126718365s]
Apr 10 16:50:48.170: INFO: Created: latency-svc-qgc86
Apr 10 16:50:48.170: INFO: Got endpoints: latency-svc-qgc86 [5.106190856s]
Apr 10 16:50:48.503: INFO: Created: latency-svc-4ttch
Apr 10 16:50:48.506: INFO: Got endpoints: latency-svc-4ttch [5.070734747s]
Apr 10 16:50:48.838: INFO: Created: latency-svc-wlfj9
Apr 10 16:50:48.842: INFO: Got endpoints: latency-svc-wlfj9 [5.047407066s]
Apr 10 16:50:49.228: INFO: Created: latency-svc-x6gcd
Apr 10 16:50:49.234: INFO: Got endpoints: latency-svc-x6gcd [5.113835896s]
Apr 10 16:50:49.577: INFO: Created: latency-svc-sbbfj
Apr 10 16:50:49.578: INFO: Got endpoints: latency-svc-sbbfj [5.147797044s]
Apr 10 16:50:49.933: INFO: Created: latency-svc-vr87d
Apr 10 16:50:50.007: INFO: Got endpoints: latency-svc-vr87d [5.057072345s]
Apr 10 16:50:50.329: INFO: Created: latency-svc-n7mxd
Apr 10 16:50:50.340: INFO: Got endpoints: latency-svc-n7mxd [5.130521463s]
Apr 10 16:50:50.691: INFO: Created: latency-svc-48sn7
Apr 10 16:50:50.964: INFO: Got endpoints: latency-svc-48sn7 [5.427321258s]
Apr 10 16:50:50.979: INFO: Created: latency-svc-zlxlq
Apr 10 16:50:50.981: INFO: Got endpoints: latency-svc-zlxlq [4.738409256s]
Apr 10 16:50:51.312: INFO: Created: latency-svc-5x7z6
Apr 10 16:50:51.313: INFO: Got endpoints: latency-svc-5x7z6 [5.058403802s]
Apr 10 16:50:51.687: INFO: Created: latency-svc-kvnql
Apr 10 16:50:51.687: INFO: Got endpoints: latency-svc-kvnql [5.110070187s]
Apr 10 16:50:51.993: INFO: Created: latency-svc-cjskr
Apr 10 16:50:51.994: INFO: Got endpoints: latency-svc-cjskr [5.085957138s]
Apr 10 16:50:52.335: INFO: Created: latency-svc-rr672
Apr 10 16:50:52.343: INFO: Got endpoints: latency-svc-rr672 [5.097350143s]
Apr 10 16:50:52.692: INFO: Created: latency-svc-q7hlk
Apr 10 16:50:52.692: INFO: Got endpoints: latency-svc-q7hlk [5.088630437s]
Apr 10 16:50:53.013: INFO: Created: latency-svc-x8vlw
Apr 10 16:50:53.085: INFO: Got endpoints: latency-svc-x8vlw [5.20025248s]
Apr 10 16:50:53.457: INFO: Created: latency-svc-bsnd6
Apr 10 16:50:53.829: INFO: Got endpoints: latency-svc-bsnd6 [5.659286709s]
Apr 10 16:50:53.843: INFO: Created: latency-svc-8fsp8
Apr 10 16:50:53.843: INFO: Got endpoints: latency-svc-8fsp8 [5.336642951s]
Apr 10 16:50:54.153: INFO: Created: latency-svc-9sssp
Apr 10 16:50:54.219: INFO: Got endpoints: latency-svc-9sssp [5.37700265s]
Apr 10 16:50:54.810: INFO: Created: latency-svc-4mclc
Apr 10 16:50:54.813: INFO: Got endpoints: latency-svc-4mclc [5.578729157s]
Apr 10 16:50:55.129: INFO: Created: latency-svc-gz8mb
Apr 10 16:50:55.130: INFO: Got endpoints: latency-svc-gz8mb [5.551143665s]
Apr 10 16:50:55.437: INFO: Created: latency-svc-8z499
Apr 10 16:50:55.441: INFO: Got endpoints: latency-svc-8z499 [5.433820771s]
Apr 10 16:50:55.808: INFO: Created: latency-svc-8l9h2
Apr 10 16:50:55.808: INFO: Got endpoints: latency-svc-8l9h2 [5.468067836s]
Apr 10 16:50:56.129: INFO: Created: latency-svc-6rtdb
Apr 10 16:50:56.146: INFO: Got endpoints: latency-svc-6rtdb [5.182023196s]
Apr 10 16:50:56.480: INFO: Created: latency-svc-tvl57
Apr 10 16:50:56.488: INFO: Got endpoints: latency-svc-tvl57 [5.506574883s]
Apr 10 16:50:56.845: INFO: Created: latency-svc-trcfp
Apr 10 16:50:56.914: INFO: Got endpoints: latency-svc-trcfp [5.600588792s]
Apr 10 16:50:57.166: INFO: Created: latency-svc-7fr8d
Apr 10 16:50:57.236: INFO: Got endpoints: latency-svc-7fr8d [5.548103238s]
Apr 10 16:50:57.490: INFO: Created: latency-svc-6cf5x
Apr 10 16:50:57.564: INFO: Got endpoints: latency-svc-6cf5x [5.570046253s]
Apr 10 16:50:57.871: INFO: Created: latency-svc-4bhmp
Apr 10 16:50:57.932: INFO: Got endpoints: latency-svc-4bhmp [5.587950125s]
Apr 10 16:50:58.233: INFO: Created: latency-svc-sqcww
Apr 10 16:50:58.244: INFO: Got endpoints: latency-svc-sqcww [5.551434835s]
Apr 10 16:50:58.605: INFO: Created: latency-svc-5z6nz
Apr 10 16:50:58.612: INFO: Got endpoints: latency-svc-5z6nz [679.954637ms]
Apr 10 16:50:58.948: INFO: Created: latency-svc-ct6xf
Apr 10 16:50:58.950: INFO: Got endpoints: latency-svc-ct6xf [5.864517983s]
Apr 10 16:50:59.308: INFO: Created: latency-svc-klxdq
Apr 10 16:50:59.312: INFO: Got endpoints: latency-svc-klxdq [5.482428448s]
Apr 10 16:50:59.643: INFO: Created: latency-svc-5cn2w
Apr 10 16:50:59.644: INFO: Got endpoints: latency-svc-5cn2w [5.801200755s]
Apr 10 16:50:59.964: INFO: Created: latency-svc-hnf84
Apr 10 16:51:00.281: INFO: Got endpoints: latency-svc-hnf84 [6.062251938s]
Apr 10 16:51:00.346: INFO: Created: latency-svc-42rqm
Apr 10 16:51:00.649: INFO: Got endpoints: latency-svc-42rqm [5.836306765s]
Apr 10 16:51:01.020: INFO: Created: latency-svc-gvzwp
Apr 10 16:51:01.021: INFO: Got endpoints: latency-svc-gvzwp [5.891686334s]
Apr 10 16:51:01.374: INFO: Created: latency-svc-ffbms
Apr 10 16:51:01.374: INFO: Got endpoints: latency-svc-ffbms [5.932336303s]
Apr 10 16:51:01.655: INFO: Created: latency-svc-slpvw
Apr 10 16:51:01.721: INFO: Got endpoints: latency-svc-slpvw [5.913056859s]
Apr 10 16:51:02.006: INFO: Created: latency-svc-w5tgg
Apr 10 16:51:02.078: INFO: Got endpoints: latency-svc-w5tgg [5.932463979s]
Apr 10 16:51:02.343: INFO: Created: latency-svc-cqtcc
Apr 10 16:51:02.344: INFO: Got endpoints: latency-svc-cqtcc [5.856629248s]
Apr 10 16:51:02.766: INFO: Created: latency-svc-wrd4z
Apr 10 16:51:02.777: INFO: Got endpoints: latency-svc-wrd4z [5.862381689s]
Apr 10 16:51:03.130: INFO: Created: latency-svc-cnzjr
Apr 10 16:51:03.130: INFO: Got endpoints: latency-svc-cnzjr [5.894806921s]
Apr 10 16:51:03.431: INFO: Created: latency-svc-zfgxb
Apr 10 16:51:03.727: INFO: Got endpoints: latency-svc-zfgxb [6.163554156s]
Apr 10 16:51:04.004: INFO: Created: latency-svc-nmj87
Apr 10 16:51:04.058: INFO: Got endpoints: latency-svc-nmj87 [5.814055025s]
Apr 10 16:51:04.314: INFO: Created: latency-svc-fsq48
Apr 10 16:51:04.319: INFO: Got endpoints: latency-svc-fsq48 [5.707505698s]
Apr 10 16:51:04.665: INFO: Created: latency-svc-rm8hr
Apr 10 16:51:04.743: INFO: Got endpoints: latency-svc-rm8hr [5.793538599s]
Apr 10 16:51:04.966: INFO: Created: latency-svc-vq762
Apr 10 16:51:05.034: INFO: Got endpoints: latency-svc-vq762 [5.721934592s]
Apr 10 16:51:05.324: INFO: Created: latency-svc-vwpkc
Apr 10 16:51:05.389: INFO: Got endpoints: latency-svc-vwpkc [5.744737745s]
Apr 10 16:51:05.768: INFO: Created: latency-svc-9wtqw
Apr 10 16:51:05.768: INFO: Got endpoints: latency-svc-9wtqw [5.485934137s]
Apr 10 16:51:06.125: INFO: Created: latency-svc-2dxlq
Apr 10 16:51:06.201: INFO: Got endpoints: latency-svc-2dxlq [5.552268379s]
Apr 10 16:51:06.493: INFO: Created: latency-svc-zfmhr
Apr 10 16:51:06.498: INFO: Got endpoints: latency-svc-zfmhr [5.476175384s]
Apr 10 16:51:06.861: INFO: Created: latency-svc-dfrmd
Apr 10 16:51:06.869: INFO: Got endpoints: latency-svc-dfrmd [5.495034845s]
Apr 10 16:51:07.285: INFO: Created: latency-svc-sbbn9
Apr 10 16:51:07.285: INFO: Got endpoints: latency-svc-sbbn9 [5.563457662s]
Apr 10 16:51:07.629: INFO: Created: latency-svc-pllgc
Apr 10 16:51:07.643: INFO: Got endpoints: latency-svc-pllgc [5.563792254s]
Apr 10 16:51:07.943: INFO: Created: latency-svc-9rrw5
Apr 10 16:51:08.005: INFO: Got endpoints: latency-svc-9rrw5 [5.660679439s]
Apr 10 16:51:08.348: INFO: Created: latency-svc-292kj
Apr 10 16:51:08.619: INFO: Got endpoints: latency-svc-292kj [5.8423266s]
Apr 10 16:51:08.641: INFO: Created: latency-svc-hqcr8
Apr 10 16:51:08.717: INFO: Got endpoints: latency-svc-hqcr8 [5.587004048s]
Apr 10 16:51:08.936: INFO: Created: latency-svc-fs8vh
Apr 10 16:51:09.002: INFO: Got endpoints: latency-svc-fs8vh [5.274391239s]
Apr 10 16:51:09.320: INFO: Created: latency-svc-mz8hm
Apr 10 16:51:09.622: INFO: Got endpoints: latency-svc-mz8hm [5.56336327s]
Apr 10 16:51:09.637: INFO: Created: latency-svc-28rkn
Apr 10 16:51:09.640: INFO: Got endpoints: latency-svc-28rkn [5.320362715s]
Apr 10 16:51:09.980: INFO: Created: latency-svc-mgb7s
Apr 10 16:51:09.988: INFO: Got endpoints: latency-svc-mgb7s [5.244941076s]
Apr 10 16:51:10.288: INFO: Created: latency-svc-rmjqk
Apr 10 16:51:10.381: INFO: Created: latency-svc-24jj9
Apr 10 16:51:10.381: INFO: Got endpoints: latency-svc-rmjqk [5.346766726s]
Apr 10 16:51:10.687: INFO: Got endpoints: latency-svc-24jj9 [5.297462751s]
Apr 10 16:51:10.768: INFO: Created: latency-svc-vdjgh
Apr 10 16:51:11.058: INFO: Got endpoints: latency-svc-vdjgh [5.290210956s]
Apr 10 16:51:11.067: INFO: Created: latency-svc-2lgcg
Apr 10 16:51:11.392: INFO: Got endpoints: latency-svc-2lgcg [5.190647404s]
Apr 10 16:51:11.491: INFO: Created: latency-svc-bft72
Apr 10 16:51:11.792: INFO: Got endpoints: latency-svc-bft72 [5.294238232s]
Apr 10 16:51:11.879: INFO: Created: latency-svc-4sj2k
Apr 10 16:51:12.112: INFO: Got endpoints: latency-svc-4sj2k [5.243530699s]
Apr 10 16:51:12.125: INFO: Created: latency-svc-8lmwz
Apr 10 16:51:12.196: INFO: Got endpoints: latency-svc-8lmwz [4.911467126s]
Apr 10 16:51:12.474: INFO: Created: latency-svc-567ch
Apr 10 16:51:12.546: INFO: Got endpoints: latency-svc-567ch [4.903318219s]
Apr 10 16:51:12.799: INFO: Created: latency-svc-xwp5t
Apr 10 16:51:12.885: INFO: Got endpoints: latency-svc-xwp5t [4.879623571s]
Apr 10 16:51:13.172: INFO: Created: latency-svc-d4qkn
Apr 10 16:51:13.238: INFO: Got endpoints: latency-svc-d4qkn [4.618459677s]
Apr 10 16:51:13.560: INFO: Created: latency-svc-6swll
Apr 10 16:51:13.633: INFO: Got endpoints: latency-svc-6swll [4.915963085s]
Apr 10 16:51:13.926: INFO: Created: latency-svc-fv85w
Apr 10 16:51:14.168: INFO: Got endpoints: latency-svc-fv85w [5.165797287s]
Apr 10 16:51:14.513: INFO: Created: latency-svc-r9kdl
Apr 10 16:51:14.515: INFO: Got endpoints: latency-svc-r9kdl [4.893181105s]
Apr 10 16:51:14.872: INFO: Created: latency-svc-6n927
Apr 10 16:51:14.944: INFO: Got endpoints: latency-svc-6n927 [5.303766023s]
Apr 10 16:51:15.213: INFO: Created: latency-svc-2tbjj
Apr 10 16:51:15.282: INFO: Got endpoints: latency-svc-2tbjj [5.293120413s]
Apr 10 16:51:15.286: INFO: Created: latency-svc-824lb
Apr 10 16:51:15.683: INFO: Got endpoints: latency-svc-824lb [5.301432985s]
Apr 10 16:51:15.697: INFO: Created: latency-svc-6m2wz
Apr 10 16:51:15.957: INFO: Got endpoints: latency-svc-6m2wz [5.269817546s]
Apr 10 16:51:15.972: INFO: Created: latency-svc-6pbjd
Apr 10 16:51:16.059: INFO: Got endpoints: latency-svc-6pbjd [5.001084551s]
Apr 10 16:51:16.286: INFO: Created: latency-svc-blth6
Apr 10 16:51:16.347: INFO: Got endpoints: latency-svc-blth6 [4.954880183s]
Apr 10 16:51:16.618: INFO: Created: latency-svc-s78b5
Apr 10 16:51:16.685: INFO: Got endpoints: latency-svc-s78b5 [4.89318743s]
Apr 10 16:51:16.933: INFO: Created: latency-svc-qgf2p
Apr 10 16:51:16.934: INFO: Got endpoints: latency-svc-qgf2p [4.821837249s]
Apr 10 16:51:17.250: INFO: Created: latency-svc-59b2h
Apr 10 16:51:17.253: INFO: Got endpoints: latency-svc-59b2h [5.056633444s]
Apr 10 16:51:17.566: INFO: Created: latency-svc-qfgnk
Apr 10 16:51:17.569: INFO: Got endpoints: latency-svc-qfgnk [5.022951826s]
Apr 10 16:51:17.889: INFO: Created: latency-svc-2bq6s
Apr 10 16:51:17.894: INFO: Got endpoints: latency-svc-2bq6s [5.008880145s]
Apr 10 16:51:18.193: INFO: Created: latency-svc-kpzrz
Apr 10 16:51:18.197: INFO: Got endpoints: latency-svc-kpzrz [4.959309935s]
Apr 10 16:51:18.499: INFO: Created: latency-svc-92q7v
Apr 10 16:51:18.507: INFO: Got endpoints: latency-svc-92q7v [4.873208746s]
Apr 10 16:51:18.827: INFO: Created: latency-svc-pdkqk
Apr 10 16:51:18.833: INFO: Got endpoints: latency-svc-pdkqk [4.664940671s]
Apr 10 16:51:19.206: INFO: Created: latency-svc-2fjkg
Apr 10 16:51:19.211: INFO: Got endpoints: latency-svc-2fjkg [4.695613005s]
Apr 10 16:51:19.509: INFO: Created: latency-svc-l55rj
Apr 10 16:51:19.514: INFO: Got endpoints: latency-svc-l55rj [4.569983593s]
Apr 10 16:51:19.825: INFO: Created: latency-svc-6f2hr
Apr 10 16:51:19.889: INFO: Got endpoints: latency-svc-6f2hr [4.607860812s]
Apr 10 16:51:20.214: INFO: Created: latency-svc-m8lxb
Apr 10 16:51:20.214: INFO: Got endpoints: latency-svc-m8lxb [4.531068616s]
Apr 10 16:51:20.552: INFO: Created: latency-svc-75gx9
Apr 10 16:51:20.553: INFO: Got endpoints: latency-svc-75gx9 [4.595689807s]
Apr 10 16:51:20.848: INFO: Created: latency-svc-7tq9q
Apr 10 16:51:20.922: INFO: Got endpoints: latency-svc-7tq9q [4.862883087s]
Apr 10 16:51:21.195: INFO: Created: latency-svc-98hmn
Apr 10 16:51:21.195: INFO: Got endpoints: latency-svc-98hmn [4.847602052s]
Apr 10 16:51:21.519: INFO: Created: latency-svc-m4ckj
Apr 10 16:51:21.836: INFO: Got endpoints: latency-svc-m4ckj [5.150231103s]
Apr 10 16:51:21.837: INFO: Created: latency-svc-4kkwg
Apr 10 16:51:21.915: INFO: Got endpoints: latency-svc-4kkwg [4.980328246s]
Apr 10 16:51:22.213: INFO: Created: latency-svc-x7krj
Apr 10 16:51:22.219: INFO: Got endpoints: latency-svc-x7krj [4.966139846s]
Apr 10 16:51:22.577: INFO: Created: latency-svc-4wgdf
Apr 10 16:51:22.580: INFO: Got endpoints: latency-svc-4wgdf [5.010683853s]
Apr 10 16:51:22.920: INFO: Created: latency-svc-2plk6
Apr 10 16:51:22.994: INFO: Got endpoints: latency-svc-2plk6 [5.099578865s]
Apr 10 16:51:23.288: INFO: Created: latency-svc-4v64k
Apr 10 16:51:23.289: INFO: Got endpoints: latency-svc-4v64k [5.091362528s]
Apr 10 16:51:23.616: INFO: Created: latency-svc-lgknr
Apr 10 16:51:23.679: INFO: Got endpoints: latency-svc-lgknr [5.171690566s]
Apr 10 16:51:23.939: INFO: Created: latency-svc-npcn6
Apr 10 16:51:23.950: INFO: Got endpoints: latency-svc-npcn6 [5.116507107s]
Apr 10 16:51:24.368: INFO: Created: latency-svc-9wgxb
Apr 10 16:51:24.428: INFO: Got endpoints: latency-svc-9wgxb [5.216453377s]
Apr 10 16:51:24.939: INFO: Created: latency-svc-j9z8z
Apr 10 16:51:24.947: INFO: Got endpoints: latency-svc-j9z8z [5.433011681s]
Apr 10 16:51:25.234: INFO: Created: latency-svc-84zqp
Apr 10 16:51:25.238: INFO: Got endpoints: latency-svc-84zqp [5.348508171s]
Apr 10 16:51:25.549: INFO: Created: latency-svc-vctks
Apr 10 16:51:25.553: INFO: Got endpoints: latency-svc-vctks [5.339216537s]
Apr 10 16:51:25.854: INFO: Created: latency-svc-k24xd
Apr 10 16:51:25.943: INFO: Got endpoints: latency-svc-k24xd [5.390878632s]
Apr 10 16:51:26.198: INFO: Created: latency-svc-4hzcf
Apr 10 16:51:26.422: INFO: Got endpoints: latency-svc-4hzcf [5.499839837s]
Apr 10 16:51:26.436: INFO: Created: latency-svc-7w2h4
Apr 10 16:51:26.506: INFO: Got endpoints: latency-svc-7w2h4 [5.31087315s]
Apr 10 16:51:26.742: INFO: Created: latency-svc-p27p2
Apr 10 16:51:26.807: INFO: Got endpoints: latency-svc-p27p2 [4.970915767s]
Apr 10 16:51:27.053: INFO: Created: latency-svc-zdsw2
Apr 10 16:51:27.057: INFO: Got endpoints: latency-svc-zdsw2 [5.142631334s]
Apr 10 16:51:27.438: INFO: Created: latency-svc-lqzlc
Apr 10 16:51:27.441: INFO: Got endpoints: latency-svc-lqzlc [5.221618376s]
Apr 10 16:51:27.754: INFO: Created: latency-svc-k9778
Apr 10 16:51:27.759: INFO: Got endpoints: latency-svc-k9778 [5.178812346s]
Apr 10 16:51:28.059: INFO: Created: latency-svc-8n6tl
Apr 10 16:51:28.068: INFO: Got endpoints: latency-svc-8n6tl [5.073901043s]
Apr 10 16:51:28.406: INFO: Created: latency-svc-f87fc
Apr 10 16:51:28.478: INFO: Got endpoints: latency-svc-f87fc [5.189069423s]
Apr 10 16:51:28.722: INFO: Created: latency-svc-69gzm
Apr 10 16:51:28.730: INFO: Got endpoints: latency-svc-69gzm [5.050787703s]
Apr 10 16:51:29.000: INFO: Created: latency-svc-s9xs5
Apr 10 16:51:29.069: INFO: Got endpoints: latency-svc-s9xs5 [5.119108116s]
Apr 10 16:51:29.076: INFO: Created: latency-svc-zlzvl
Apr 10 16:51:29.300: INFO: Got endpoints: latency-svc-zlzvl [4.872869025s]
Apr 10 16:51:29.371: INFO: Created: latency-svc-4qpqj
Apr 10 16:51:29.604: INFO: Got endpoints: latency-svc-4qpqj [4.65720827s]
Apr 10 16:51:29.616: INFO: Created: latency-svc-zfltg
Apr 10 16:51:29.700: INFO: Got endpoints: latency-svc-zfltg [4.461270555s]
Apr 10 16:51:29.905: INFO: Created: latency-svc-6swnh
Apr 10 16:51:29.911: INFO: Got endpoints: latency-svc-6swnh [4.358297356s]
Apr 10 16:51:30.186: INFO: Created: latency-svc-f8g67
Apr 10 16:51:30.194: INFO: Got endpoints: latency-svc-f8g67 [4.250817282s]
Apr 10 16:51:30.439: INFO: Created: latency-svc-cdvp9
Apr 10 16:51:30.442: INFO: Got endpoints: latency-svc-cdvp9 [4.019722505s]
Apr 10 16:51:30.704: INFO: Created: latency-svc-f7qbn
Apr 10 16:51:30.707: INFO: Got endpoints: latency-svc-f7qbn [4.201277712s]
Apr 10 16:51:30.983: INFO: Created: latency-svc-w84t4
Apr 10 16:51:30.999: INFO: Got endpoints: latency-svc-w84t4 [4.191993385s]
Apr 10 16:51:31.272: INFO: Created: latency-svc-cgcrl
Apr 10 16:51:31.272: INFO: Got endpoints: latency-svc-cgcrl [4.2143578s]
Apr 10 16:51:31.561: INFO: Created: latency-svc-tt2x8
Apr 10 16:51:31.569: INFO: Got endpoints: latency-svc-tt2x8 [4.127831183s]
Apr 10 16:51:31.832: INFO: Created: latency-svc-c849d
Apr 10 16:51:31.835: INFO: Got endpoints: latency-svc-c849d [4.075897678s]
Apr 10 16:51:32.117: INFO: Created: latency-svc-p8ghr
Apr 10 16:51:32.175: INFO: Got endpoints: latency-svc-p8ghr [4.107394331s]
Apr 10 16:51:32.176: INFO: Latencies: [368.493313ms 679.954637ms 704.256249ms 1.045937131s 1.390791245s 1.677207373s 2.026837962s 2.397603175s 2.708174847s 3.060084105s 3.381199662s 3.830633894s 3.998131397s 4.000135071s 4.019196355s 4.019722505s 4.035602613s 4.075897678s 4.096518307s 4.107394331s 4.127831183s 4.128313817s 4.144676373s 4.150447175s 4.191428902s 4.191993385s 4.193868788s 4.201277712s 4.2143578s 4.248518866s 4.250817282s 4.250991117s 4.271607269s 4.355003409s 4.358297356s 4.388503261s 4.388554952s 4.403050351s 4.408322276s 4.410490304s 4.432307776s 4.432919532s 4.434372457s 4.445281139s 4.445679521s 4.461270555s 4.497475656s 4.525461451s 4.531068616s 4.535298835s 4.537983644s 4.546962031s 4.569983593s 4.583465201s 4.595689807s 4.607860812s 4.617931515s 4.618459677s 4.646302518s 4.64791386s 4.65720827s 4.664940671s 4.695613005s 4.730424386s 4.738409256s 4.755604439s 4.780647527s 4.784531375s 4.821837249s 4.824057728s 4.844912005s 4.847602052s 4.862883087s 4.872869025s 4.873208746s 4.879623571s 4.893181105s 4.89318743s 4.903318219s 4.911467126s 4.915963085s 4.936395781s 4.954880183s 4.959309935s 4.96289379s 4.966139846s 4.970915767s 4.974468941s 4.974766765s 4.980328246s 4.992526639s 4.996834195s 5.000129932s 5.001084551s 5.00439822s 5.007529036s 5.008880145s 5.010683853s 5.016232545s 5.017291959s 5.022951826s 5.045804207s 5.047407066s 5.050787703s 5.056633444s 5.057072345s 5.058403802s 5.068267347s 5.070734747s 5.073901043s 5.085957138s 5.088630437s 5.091362528s 5.097350143s 5.097981035s 5.099578865s 5.099867709s 5.106190856s 5.110070187s 5.113835896s 5.116507107s 5.119108116s 5.126718365s 5.130521463s 5.131787314s 5.142631334s 5.146620825s 5.147797044s 5.150231103s 5.165797287s 5.171690566s 5.177676301s 5.178812346s 5.182023196s 5.189069423s 5.190647404s 5.20025248s 5.212919804s 5.216453377s 5.221618376s 5.243530699s 5.244941076s 5.269817546s 5.274391239s 5.290210956s 5.293120413s 5.294238232s 5.297462751s 5.301432985s 5.303766023s 5.31087315s 5.320362715s 5.336642951s 5.339216537s 5.346766726s 5.348508171s 5.37700265s 5.390878632s 5.427321258s 5.433011681s 5.433820771s 5.468067836s 5.476175384s 5.482428448s 5.485934137s 5.495034845s 5.499839837s 5.506574883s 5.548103238s 5.551143665s 5.551434835s 5.552268379s 5.56336327s 5.563457662s 5.563792254s 5.570046253s 5.578729157s 5.587004048s 5.587950125s 5.600588792s 5.659286709s 5.660679439s 5.707505698s 5.721934592s 5.744737745s 5.793538599s 5.801200755s 5.814055025s 5.836306765s 5.8423266s 5.856629248s 5.862381689s 5.864517983s 5.891686334s 5.894806921s 5.913056859s 5.932336303s 5.932463979s 6.062251938s 6.163554156s]
Apr 10 16:51:32.176: INFO: 50 %ile: 5.022951826s
Apr 10 16:51:32.176: INFO: 90 %ile: 5.659286709s
Apr 10 16:51:32.176: INFO: 99 %ile: 6.062251938s
Apr 10 16:51:32.176: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:51:32.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7226" for this suite.
Apr 10 16:53:34.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:53:34.730: INFO: namespace svc-latency-7226 deletion completed in 2m2.402503697s

• [SLOW TEST:193.871 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:53:34.731: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-2e21bb01-5bb1-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:53:35.583: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a" in namespace "projected-8080" to be "success or failure"
Apr 10 16:53:35.943: INFO: Pod "pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 359.604886ms
Apr 10 16:53:37.948: INFO: Pod "pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364785596s
Apr 10 16:53:40.183: INFO: Pod "pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.600250195s
STEP: Saw pod success
Apr 10 16:53:40.183: INFO: Pod "pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:53:40.187: INFO: Trying to get logs from node g168 pod pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:53:40.432: INFO: Waiting for pod pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:53:40.504: INFO: Pod pod-projected-secrets-2e2ddeb0-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:53:40.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8080" for this suite.
Apr 10 16:53:48.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:53:48.746: INFO: namespace projected-8080 deletion completed in 8.235152309s

• [SLOW TEST:14.014 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:53:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5946
Apr 10 16:53:53.397: INFO: Started pod liveness-exec in namespace container-probe-5946
STEP: checking the pod's current state and verifying that restartCount is present
Apr 10 16:53:53.420: INFO: Initial restart count of pod liveness-exec is 0
Apr 10 16:54:49.645: INFO: Restart count of pod container-probe-5946/liveness-exec is now 1 (56.224952017s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:54:49.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5946" for this suite.
Apr 10 16:54:58.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:54:58.290: INFO: namespace container-probe-5946 deletion completed in 8.322979433s

• [SLOW TEST:69.542 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:54:58.293: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-5fe6ce67-5bb1-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:54:59.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a" in namespace "projected-1810" to be "success or failure"
Apr 10 16:54:59.159: INFO: Pod "pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 90.040791ms
Apr 10 16:55:01.228: INFO: Pod "pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1585388s
Apr 10 16:55:03.305: INFO: Pod "pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.235368342s
STEP: Saw pod success
Apr 10 16:55:03.305: INFO: Pod "pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:55:03.309: INFO: Trying to get logs from node g168 pod pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 10 16:55:03.395: INFO: Waiting for pod pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:55:03.597: INFO: Pod pod-projected-secrets-5fe767c8-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:55:03.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1810" for this suite.
Apr 10 16:55:11.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:55:11.901: INFO: namespace projected-1810 deletion completed in 8.299331851s

• [SLOW TEST:13.609 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:55:11.903: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 10 16:55:12.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 cluster-info'
Apr 10 16:55:19.276: INFO: stderr: ""
Apr 10 16:55:19.276: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:55:19.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4458" for this suite.
Apr 10 16:55:25.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:55:25.416: INFO: namespace kubectl-4458 deletion completed in 6.133947935s

• [SLOW TEST:13.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:55:25.416: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 10 16:55:26.526: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18501,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 10 16:55:26.527: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18502,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 10 16:55:26.527: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18503,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 10 16:55:37.041: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18520,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 10 16:55:37.041: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18521,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 10 16:55:37.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-150,SelfLink:/api/v1/namespaces/watch-150/configmaps/e2e-watch-test-label-changed,UID:7049d56c-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18522,Generation:0,CreationTimestamp:2019-04-10 16:55:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:55:37.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-150" for this suite.
Apr 10 16:55:43.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:55:43.514: INFO: namespace watch-150 deletion completed in 6.302164903s

• [SLOW TEST:18.097 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:55:43.518: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 10 16:55:44.102: INFO: Waiting up to 5m0s for pod "var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a" in namespace "var-expansion-6474" to be "success or failure"
Apr 10 16:55:44.359: INFO: Pod "var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 257.449945ms
Apr 10 16:55:46.362: INFO: Pod "var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.260242312s
Apr 10 16:55:48.472: INFO: Pod "var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.370189319s
STEP: Saw pod success
Apr 10 16:55:48.472: INFO: Pod "var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:55:48.475: INFO: Trying to get logs from node g168 pod var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 16:55:48.561: INFO: Waiting for pod var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:55:48.744: INFO: Pod var-expansion-7adf7992-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:55:48.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6474" for this suite.
Apr 10 16:55:56.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:55:57.081: INFO: namespace var-expansion-6474 deletion completed in 8.33094897s

• [SLOW TEST:13.563 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:55:57.082: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-4719/secret-test-82f8732b-5bb1-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume secrets
Apr 10 16:55:57.915: INFO: Waiting up to 5m0s for pod "pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a" in namespace "secrets-4719" to be "success or failure"
Apr 10 16:55:57.975: INFO: Pod "pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 59.633196ms
Apr 10 16:56:00.096: INFO: Pod "pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.180041661s
Apr 10 16:56:02.121: INFO: Pod "pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205549537s
STEP: Saw pod success
Apr 10 16:56:02.121: INFO: Pod "pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:56:02.124: INFO: Trying to get logs from node g168 pod pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a container env-test: <nil>
STEP: delete the pod
Apr 10 16:56:02.311: INFO: Waiting for pod pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:56:02.484: INFO: Pod pod-configmaps-82f92399-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:56:02.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4719" for this suite.
Apr 10 16:56:10.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:56:10.618: INFO: namespace secrets-4719 deletion completed in 8.128754755s

• [SLOW TEST:13.536 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:56:10.622: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 10 16:56:11.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-7368'
Apr 10 16:56:11.516: INFO: stderr: ""
Apr 10 16:56:11.516: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 16:56:11.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7368'
Apr 10 16:56:11.688: INFO: stderr: ""
Apr 10 16:56:11.688: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Apr 10 16:56:16.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7368'
Apr 10 16:56:16.760: INFO: stderr: ""
Apr 10 16:56:16.760: INFO: stdout: "update-demo-nautilus-4zjst update-demo-nautilus-nzz6b "
Apr 10 16:56:16.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-4zjst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:16.849: INFO: stderr: ""
Apr 10 16:56:16.849: INFO: stdout: "true"
Apr 10 16:56:16.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-4zjst -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:16.910: INFO: stderr: ""
Apr 10 16:56:16.910: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:56:16.910: INFO: validating pod update-demo-nautilus-4zjst
Apr 10 16:56:16.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:56:16.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:56:16.913: INFO: update-demo-nautilus-4zjst is verified up and running
Apr 10 16:56:16.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-nzz6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:16.973: INFO: stderr: ""
Apr 10 16:56:16.973: INFO: stdout: "true"
Apr 10 16:56:16.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-nautilus-nzz6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:17.032: INFO: stderr: ""
Apr 10 16:56:17.032: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 10 16:56:17.032: INFO: validating pod update-demo-nautilus-nzz6b
Apr 10 16:56:17.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 10 16:56:17.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 10 16:56:17.036: INFO: update-demo-nautilus-nzz6b is verified up and running
STEP: rolling-update to new replication controller
Apr 10 16:56:17.037: INFO: scanned /root for discovery docs: <nil>
Apr 10 16:56:17.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7368'
Apr 10 16:56:52.326: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 10 16:56:52.326: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 10 16:56:52.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7368'
Apr 10 16:56:52.557: INFO: stderr: ""
Apr 10 16:56:52.557: INFO: stdout: "update-demo-kitten-4v9jq update-demo-kitten-hnqsk "
Apr 10 16:56:52.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-kitten-4v9jq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:52.691: INFO: stderr: ""
Apr 10 16:56:52.691: INFO: stdout: "true"
Apr 10 16:56:52.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-kitten-4v9jq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:52.758: INFO: stderr: ""
Apr 10 16:56:52.758: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 10 16:56:52.758: INFO: validating pod update-demo-kitten-4v9jq
Apr 10 16:56:52.761: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 10 16:56:52.761: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 10 16:56:52.761: INFO: update-demo-kitten-4v9jq is verified up and running
Apr 10 16:56:52.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-kitten-hnqsk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:52.827: INFO: stderr: ""
Apr 10 16:56:52.827: INFO: stdout: "true"
Apr 10 16:56:52.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 get pods update-demo-kitten-hnqsk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7368'
Apr 10 16:56:52.996: INFO: stderr: ""
Apr 10 16:56:52.996: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 10 16:56:52.996: INFO: validating pod update-demo-kitten-hnqsk
Apr 10 16:56:53.001: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 10 16:56:53.001: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 10 16:56:53.001: INFO: update-demo-kitten-hnqsk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:56:53.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7368" for this suite.
Apr 10 16:57:21.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:57:21.120: INFO: namespace kubectl-7368 deletion completed in 28.112892818s

• [SLOW TEST:70.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:57:21.122: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 10 16:57:21.677: INFO: Waiting up to 5m0s for pod "pod-b5079a9d-5bb1-11e9-8040-3209cfee711a" in namespace "emptydir-1932" to be "success or failure"
Apr 10 16:57:21.908: INFO: Pod "pod-b5079a9d-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 231.031618ms
Apr 10 16:57:24.069: INFO: Pod "pod-b5079a9d-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39222386s
Apr 10 16:57:26.073: INFO: Pod "pod-b5079a9d-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.396796977s
STEP: Saw pod success
Apr 10 16:57:26.074: INFO: Pod "pod-b5079a9d-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:57:26.078: INFO: Trying to get logs from node g168 pod pod-b5079a9d-5bb1-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 16:57:26.172: INFO: Waiting for pod pod-b5079a9d-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:57:26.332: INFO: Pod pod-b5079a9d-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:57:26.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1932" for this suite.
Apr 10 16:57:34.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:57:34.570: INFO: namespace emptydir-1932 deletion completed in 8.233986258s

• [SLOW TEST:13.448 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:57:34.570: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 10 16:57:35.120: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18940,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 10 16:57:35.120: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18940,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 10 16:57:45.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18957,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 10 16:57:45.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18957,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 10 16:57:55.229: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18974,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 10 16:57:55.229: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18974,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 10 16:58:05.299: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18992,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 10 16:58:05.300: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:bd0ea778-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:18992,Generation:0,CreationTimestamp:2019-04-10 16:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 10 16:58:15.343: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:d50965f9-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:19009,Generation:0,CreationTimestamp:2019-04-10 16:58:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 10 16:58:15.343: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:d50965f9-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:19009,Generation:0,CreationTimestamp:2019-04-10 16:58:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 10 16:58:25.348: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:d50965f9-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:19024,Generation:0,CreationTimestamp:2019-04-10 16:58:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 10 16:58:25.348: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:d50965f9-5bb1-11e9-b4c9-5254005baff5,ResourceVersion:19024,Generation:0,CreationTimestamp:2019-04-10 16:58:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:58:35.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2536" for this suite.
Apr 10 16:58:41.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:58:41.509: INFO: namespace watch-2536 deletion completed in 6.118442852s

• [SLOW TEST:66.939 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:58:41.510: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-4520/configmap-test-e4ed10e2-5bb1-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 16:58:42.032: INFO: Waiting up to 5m0s for pod "pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a" in namespace "configmap-4520" to be "success or failure"
Apr 10 16:58:42.242: INFO: Pod "pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 210.097545ms
Apr 10 16:58:44.246: INFO: Pod "pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213812427s
Apr 10 16:58:46.251: INFO: Pod "pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.218630114s
STEP: Saw pod success
Apr 10 16:58:46.251: INFO: Pod "pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 16:58:46.254: INFO: Trying to get logs from node g168 pod pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a container env-test: <nil>
STEP: delete the pod
Apr 10 16:58:46.337: INFO: Waiting for pod pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a to disappear
Apr 10 16:58:46.497: INFO: Pod pod-configmaps-e4edf97b-5bb1-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:58:46.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4520" for this suite.
Apr 10 16:58:54.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 16:58:54.652: INFO: namespace configmap-4520 deletion completed in 8.152031673s

• [SLOW TEST:13.142 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 16:58:54.653: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 16:59:55.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3163" for this suite.
Apr 10 17:00:19.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:00:19.495: INFO: namespace container-probe-3163 deletion completed in 24.275929922s

• [SLOW TEST:84.842 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:00:19.495: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 10 17:00:20.166: INFO: Waiting up to 5m0s for pod "pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a" in namespace "emptydir-8540" to be "success or failure"
Apr 10 17:00:20.437: INFO: Pod "pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 270.690307ms
Apr 10 17:00:22.482: INFO: Pod "pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.315761293s
Apr 10 17:00:24.717: INFO: Pod "pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.550529699s
STEP: Saw pod success
Apr 10 17:00:24.717: INFO: Pod "pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:00:24.721: INFO: Trying to get logs from node g168 pod pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 17:00:24.809: INFO: Waiting for pod pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:00:24.984: INFO: Pod pod-1f68f9fe-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:00:24.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8540" for this suite.
Apr 10 17:00:33.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:00:33.288: INFO: namespace emptydir-8540 deletion completed in 8.228022493s

• [SLOW TEST:13.793 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:00:33.288: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 10 17:00:38.461: INFO: Successfully updated pod "labelsupdate279b4fb1-5bb2-11e9-8040-3209cfee711a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:00:40.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8682" for this suite.
Apr 10 17:01:04.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:01:04.937: INFO: namespace projected-8682 deletion completed in 24.237648641s

• [SLOW TEST:31.649 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:01:04.938: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 10 17:01:05.538: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 10 17:01:05.781: INFO: Waiting for terminating namespaces to be deleted...
Apr 10 17:01:05.784: INFO: 
Logging pods the kubelet thinks is on node e173 before test
Apr 10 17:01:05.790: INFO: sonobuoy-e2e-job-ec1ea39d8a6e4864 from heptio-sonobuoy started at 2019-04-10 15:27:42 +0000 UTC (2 container statuses recorded)
Apr 10 17:01:05.791: INFO: 	Container e2e ready: true, restart count 0
Apr 10 17:01:05.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 10 17:01:05.791: INFO: kube-proxy-vhwbc from kube-system started at 2019-04-10 15:22:23 +0000 UTC (1 container statuses recorded)
Apr 10 17:01:05.791: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 17:01:05.791: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-h42wp from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 17:01:05.791: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 10 17:01:05.791: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 10 17:01:05.791: INFO: kube-flannel-ds-amd64-rhkjs from kube-system started at 2019-04-10 15:22:24 +0000 UTC (1 container statuses recorded)
Apr 10 17:01:05.791: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 17:01:05.791: INFO: 
Logging pods the kubelet thinks is on node g168 before test
Apr 10 17:01:05.795: INFO: sonobuoy-systemd-logs-daemon-set-87a756505d084484-tmmrt from heptio-sonobuoy started at 2019-04-10 15:27:43 +0000 UTC (2 container statuses recorded)
Apr 10 17:01:05.795: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 10 17:01:05.795: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 10 17:01:05.795: INFO: kube-flannel-ds-amd64-jnsnk from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 17:01:05.795: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 10 17:01:05.795: INFO: kube-proxy-w92n9 from kube-system started at 2019-04-10 15:22:20 +0000 UTC (1 container statuses recorded)
Apr 10 17:01:05.795: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 10 17:01:05.795: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-10 15:27:28 +0000 UTC (1 container statuses recorded)
Apr 10 17:01:05.795: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3d51789b-5bb2-11e9-8040-3209cfee711a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3d51789b-5bb2-11e9-8040-3209cfee711a off the node g168
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3d51789b-5bb2-11e9-8040-3209cfee711a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:01:15.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7733" for this suite.
Apr 10 17:01:31.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:01:31.356: INFO: namespace sched-pred-7733 deletion completed in 16.13814596s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.419 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:01:31.359: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-f2zlg in namespace proxy-498
I0410 17:01:32.208251      19 runners.go:184] Created replication controller with name: proxy-service-f2zlg, namespace: proxy-498, replica count: 1
I0410 17:01:33.258818      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:34.259227      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:35.259523      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:36.259765      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:37.260051      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:38.260261      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:39.260563      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:40.260871      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:41.261160      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0410 17:01:42.261478      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0410 17:01:43.261905      19 runners.go:184] proxy-service-f2zlg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 10 17:01:43.450: INFO: setup took 11.74703551s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 10 17:01:43.465: INFO: (0) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 13.755849ms)
Apr 10 17:01:43.465: INFO: (0) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 13.746267ms)
Apr 10 17:01:43.465: INFO: (0) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 14.597756ms)
Apr 10 17:01:43.469: INFO: (0) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 17.284984ms)
Apr 10 17:01:43.469: INFO: (0) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 17.436021ms)
Apr 10 17:01:43.469: INFO: (0) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 17.754851ms)
Apr 10 17:01:43.475: INFO: (0) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 23.653818ms)
Apr 10 17:01:43.475: INFO: (0) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 24.625195ms)
Apr 10 17:01:43.479: INFO: (0) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 27.659019ms)
Apr 10 17:01:43.479: INFO: (0) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 27.937718ms)
Apr 10 17:01:43.486: INFO: (0) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 35.071998ms)
Apr 10 17:01:43.486: INFO: (0) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 34.659729ms)
Apr 10 17:01:43.486: INFO: (0) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 34.91002ms)
Apr 10 17:01:43.486: INFO: (0) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 34.730748ms)
Apr 10 17:01:43.487: INFO: (0) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 36.246512ms)
Apr 10 17:01:43.488: INFO: (0) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 36.716757ms)
Apr 10 17:01:43.496: INFO: (1) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 8.164475ms)
Apr 10 17:01:43.501: INFO: (1) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 11.392987ms)
Apr 10 17:01:43.501: INFO: (1) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 12.77817ms)
Apr 10 17:01:43.501: INFO: (1) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 11.788245ms)
Apr 10 17:01:43.503: INFO: (1) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 13.462432ms)
Apr 10 17:01:43.503: INFO: (1) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 14.701465ms)
Apr 10 17:01:43.503: INFO: (1) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 15.075398ms)
Apr 10 17:01:43.503: INFO: (1) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 14.517404ms)
Apr 10 17:01:43.503: INFO: (1) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 14.466134ms)
Apr 10 17:01:43.504: INFO: (1) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 14.185305ms)
Apr 10 17:01:43.505: INFO: (1) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 15.251553ms)
Apr 10 17:01:43.505: INFO: (1) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 15.042784ms)
Apr 10 17:01:43.505: INFO: (1) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 15.528049ms)
Apr 10 17:01:43.505: INFO: (1) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 15.628382ms)
Apr 10 17:01:43.506: INFO: (1) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 16.5264ms)
Apr 10 17:01:43.506: INFO: (1) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 17.18302ms)
Apr 10 17:01:43.513: INFO: (2) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 7.202005ms)
Apr 10 17:01:43.514: INFO: (2) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 7.336429ms)
Apr 10 17:01:43.514: INFO: (2) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 7.82893ms)
Apr 10 17:01:43.515: INFO: (2) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.224513ms)
Apr 10 17:01:43.515: INFO: (2) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.643347ms)
Apr 10 17:01:43.516: INFO: (2) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 9.227177ms)
Apr 10 17:01:43.516: INFO: (2) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 10.103853ms)
Apr 10 17:01:43.517: INFO: (2) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 10.392011ms)
Apr 10 17:01:43.518: INFO: (2) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 11.291299ms)
Apr 10 17:01:43.518: INFO: (2) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 12.073827ms)
Apr 10 17:01:43.521: INFO: (2) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 14.355468ms)
Apr 10 17:01:43.521: INFO: (2) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 14.733051ms)
Apr 10 17:01:43.521: INFO: (2) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 14.547673ms)
Apr 10 17:01:43.521: INFO: (2) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 15.051138ms)
Apr 10 17:01:43.521: INFO: (2) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 14.941155ms)
Apr 10 17:01:43.522: INFO: (2) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 15.675013ms)
Apr 10 17:01:43.528: INFO: (3) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.226892ms)
Apr 10 17:01:43.529: INFO: (3) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 7.255366ms)
Apr 10 17:01:43.530: INFO: (3) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 7.594065ms)
Apr 10 17:01:43.531: INFO: (3) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 8.796269ms)
Apr 10 17:01:43.531: INFO: (3) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.745351ms)
Apr 10 17:01:43.533: INFO: (3) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 10.414493ms)
Apr 10 17:01:43.533: INFO: (3) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 10.406536ms)
Apr 10 17:01:43.533: INFO: (3) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 10.833152ms)
Apr 10 17:01:43.533: INFO: (3) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 11.052592ms)
Apr 10 17:01:43.534: INFO: (3) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 11.517969ms)
Apr 10 17:01:43.534: INFO: (3) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 11.97939ms)
Apr 10 17:01:43.534: INFO: (3) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 12.053109ms)
Apr 10 17:01:43.535: INFO: (3) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 12.801198ms)
Apr 10 17:01:43.535: INFO: (3) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 12.866358ms)
Apr 10 17:01:43.535: INFO: (3) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 12.880068ms)
Apr 10 17:01:43.535: INFO: (3) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 12.987594ms)
Apr 10 17:01:43.540: INFO: (4) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 4.402562ms)
Apr 10 17:01:43.540: INFO: (4) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 4.880568ms)
Apr 10 17:01:43.541: INFO: (4) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 4.840754ms)
Apr 10 17:01:43.541: INFO: (4) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 5.389633ms)
Apr 10 17:01:43.543: INFO: (4) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 6.324043ms)
Apr 10 17:01:43.543: INFO: (4) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.739276ms)
Apr 10 17:01:43.545: INFO: (4) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 8.505255ms)
Apr 10 17:01:43.658: INFO: (4) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 122.05227ms)
Apr 10 17:01:43.659: INFO: (4) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 122.566928ms)
Apr 10 17:01:43.659: INFO: (4) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 122.862313ms)
Apr 10 17:01:43.660: INFO: (4) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 124.432302ms)
Apr 10 17:01:43.661: INFO: (4) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 124.992663ms)
Apr 10 17:01:43.661: INFO: (4) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 124.689318ms)
Apr 10 17:01:43.661: INFO: (4) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 124.991787ms)
Apr 10 17:01:43.661: INFO: (4) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 125.748167ms)
Apr 10 17:01:43.661: INFO: (4) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 125.169397ms)
Apr 10 17:01:43.666: INFO: (5) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 3.836503ms)
Apr 10 17:01:43.666: INFO: (5) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 4.295217ms)
Apr 10 17:01:43.672: INFO: (5) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 10.001979ms)
Apr 10 17:01:43.672: INFO: (5) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 10.523299ms)
Apr 10 17:01:43.673: INFO: (5) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 10.80757ms)
Apr 10 17:01:43.673: INFO: (5) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 10.940608ms)
Apr 10 17:01:43.674: INFO: (5) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 11.964815ms)
Apr 10 17:01:43.674: INFO: (5) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 12.858156ms)
Apr 10 17:01:43.676: INFO: (5) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 13.879643ms)
Apr 10 17:01:43.712: INFO: (5) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 50.103223ms)
Apr 10 17:01:43.712: INFO: (5) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 50.138484ms)
Apr 10 17:01:43.712: INFO: (5) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 50.387697ms)
Apr 10 17:01:43.736: INFO: (5) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 73.898749ms)
Apr 10 17:01:43.736: INFO: (5) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 73.922673ms)
Apr 10 17:01:43.736: INFO: (5) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 74.055372ms)
Apr 10 17:01:43.748: INFO: (5) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 86.013191ms)
Apr 10 17:01:43.755: INFO: (6) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 6.522648ms)
Apr 10 17:01:43.755: INFO: (6) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 6.910739ms)
Apr 10 17:01:43.755: INFO: (6) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 6.994923ms)
Apr 10 17:01:43.756: INFO: (6) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 7.209038ms)
Apr 10 17:01:43.760: INFO: (6) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 11.436291ms)
Apr 10 17:01:43.761: INFO: (6) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 12.112657ms)
Apr 10 17:01:43.761: INFO: (6) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 12.311627ms)
Apr 10 17:01:43.761: INFO: (6) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 12.920252ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 12.779633ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 13.002864ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 13.196339ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 13.202876ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 13.808056ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 13.435201ms)
Apr 10 17:01:43.762: INFO: (6) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 13.452827ms)
Apr 10 17:01:43.763: INFO: (6) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 13.492104ms)
Apr 10 17:01:43.771: INFO: (7) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 8.712975ms)
Apr 10 17:01:43.771: INFO: (7) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 8.808578ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 8.877023ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 8.578339ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 9.138178ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 8.925156ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 8.986404ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 9.43206ms)
Apr 10 17:01:43.772: INFO: (7) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 9.05016ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 9.113987ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 9.473577ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 9.527485ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 9.144717ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 9.095574ms)
Apr 10 17:01:43.773: INFO: (7) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 9.409666ms)
Apr 10 17:01:43.774: INFO: (7) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 11.434253ms)
Apr 10 17:01:43.782: INFO: (8) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 6.970309ms)
Apr 10 17:01:43.782: INFO: (8) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 6.786745ms)
Apr 10 17:01:43.782: INFO: (8) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 7.179559ms)
Apr 10 17:01:43.782: INFO: (8) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.99388ms)
Apr 10 17:01:43.783: INFO: (8) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 8.392748ms)
Apr 10 17:01:43.783: INFO: (8) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 8.536198ms)
Apr 10 17:01:43.783: INFO: (8) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 8.54483ms)
Apr 10 17:01:43.784: INFO: (8) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.859864ms)
Apr 10 17:01:43.784: INFO: (8) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.652158ms)
Apr 10 17:01:43.784: INFO: (8) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 8.805396ms)
Apr 10 17:01:43.784: INFO: (8) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 8.910683ms)
Apr 10 17:01:43.784: INFO: (8) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 9.155232ms)
Apr 10 17:01:43.785: INFO: (8) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 10.318162ms)
Apr 10 17:01:43.786: INFO: (8) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 10.650279ms)
Apr 10 17:01:43.786: INFO: (8) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 11.00032ms)
Apr 10 17:01:43.786: INFO: (8) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 10.885364ms)
Apr 10 17:01:43.790: INFO: (9) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 4.347881ms)
Apr 10 17:01:43.791: INFO: (9) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 4.568615ms)
Apr 10 17:01:43.791: INFO: (9) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 5.000253ms)
Apr 10 17:01:43.792: INFO: (9) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 5.622839ms)
Apr 10 17:01:43.792: INFO: (9) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 5.983528ms)
Apr 10 17:01:43.792: INFO: (9) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 5.779543ms)
Apr 10 17:01:43.792: INFO: (9) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 6.096527ms)
Apr 10 17:01:43.792: INFO: (9) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 6.183115ms)
Apr 10 17:01:43.793: INFO: (9) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 6.460652ms)
Apr 10 17:01:43.793: INFO: (9) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 7.06221ms)
Apr 10 17:01:43.794: INFO: (9) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 7.375719ms)
Apr 10 17:01:43.794: INFO: (9) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 7.273929ms)
Apr 10 17:01:43.794: INFO: (9) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.19156ms)
Apr 10 17:01:43.794: INFO: (9) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 7.960556ms)
Apr 10 17:01:43.794: INFO: (9) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 8.022752ms)
Apr 10 17:01:43.796: INFO: (9) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 9.352586ms)
Apr 10 17:01:43.799: INFO: (10) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 3.431496ms)
Apr 10 17:01:43.800: INFO: (10) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 3.546272ms)
Apr 10 17:01:43.800: INFO: (10) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 3.951636ms)
Apr 10 17:01:43.804: INFO: (10) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.089871ms)
Apr 10 17:01:43.804: INFO: (10) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 8.659829ms)
Apr 10 17:01:43.804: INFO: (10) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.536669ms)
Apr 10 17:01:43.805: INFO: (10) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 9.480184ms)
Apr 10 17:01:43.806: INFO: (10) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 9.441301ms)
Apr 10 17:01:43.806: INFO: (10) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 10.324245ms)
Apr 10 17:01:43.806: INFO: (10) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 9.829021ms)
Apr 10 17:01:43.806: INFO: (10) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 10.011595ms)
Apr 10 17:01:43.807: INFO: (10) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 10.665581ms)
Apr 10 17:01:43.807: INFO: (10) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 10.521362ms)
Apr 10 17:01:43.807: INFO: (10) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 10.588738ms)
Apr 10 17:01:43.808: INFO: (10) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 12.030678ms)
Apr 10 17:01:43.808: INFO: (10) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 11.498869ms)
Apr 10 17:01:43.821: INFO: (11) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 12.601378ms)
Apr 10 17:01:43.821: INFO: (11) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 12.172049ms)
Apr 10 17:01:43.821: INFO: (11) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 13.553857ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 13.375319ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 13.177816ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 13.620922ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 13.042633ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 13.501037ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 13.683397ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 12.872868ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 13.563948ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 13.538212ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 13.222731ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 13.451045ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 13.444014ms)
Apr 10 17:01:43.822: INFO: (11) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 13.365543ms)
Apr 10 17:01:43.830: INFO: (12) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.559271ms)
Apr 10 17:01:43.831: INFO: (12) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 7.613737ms)
Apr 10 17:01:43.831: INFO: (12) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 8.624591ms)
Apr 10 17:01:43.831: INFO: (12) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 7.024225ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 9.776513ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 9.737951ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.502748ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 9.126475ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 10.118227ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.682055ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 9.044316ms)
Apr 10 17:01:43.833: INFO: (12) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.988317ms)
Apr 10 17:01:43.834: INFO: (12) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 10.340636ms)
Apr 10 17:01:43.834: INFO: (12) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 10.316973ms)
Apr 10 17:01:43.834: INFO: (12) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 10.05051ms)
Apr 10 17:01:43.835: INFO: (12) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 11.674083ms)
Apr 10 17:01:43.839: INFO: (13) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 4.131888ms)
Apr 10 17:01:43.839: INFO: (13) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 4.46351ms)
Apr 10 17:01:43.840: INFO: (13) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 4.667796ms)
Apr 10 17:01:43.840: INFO: (13) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 4.407444ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 21.032724ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 21.604617ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 21.846123ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 21.146704ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 21.449534ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 21.596659ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 21.436824ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 21.636673ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 21.605898ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 21.470249ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 22.239067ms)
Apr 10 17:01:43.857: INFO: (13) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 21.835717ms)
Apr 10 17:01:43.862: INFO: (14) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 4.803816ms)
Apr 10 17:01:43.862: INFO: (14) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 5.036891ms)
Apr 10 17:01:43.864: INFO: (14) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.128316ms)
Apr 10 17:01:43.864: INFO: (14) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 6.491347ms)
Apr 10 17:01:43.868: INFO: (14) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 9.821802ms)
Apr 10 17:01:43.868: INFO: (14) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 10.063745ms)
Apr 10 17:01:43.868: INFO: (14) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 10.007904ms)
Apr 10 17:01:43.868: INFO: (14) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 10.263037ms)
Apr 10 17:01:43.869: INFO: (14) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 10.316525ms)
Apr 10 17:01:43.869: INFO: (14) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 10.481032ms)
Apr 10 17:01:43.869: INFO: (14) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 11.196289ms)
Apr 10 17:01:43.869: INFO: (14) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 11.230633ms)
Apr 10 17:01:43.870: INFO: (14) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 11.817186ms)
Apr 10 17:01:43.870: INFO: (14) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 12.303537ms)
Apr 10 17:01:43.870: INFO: (14) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 12.53219ms)
Apr 10 17:01:43.870: INFO: (14) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 12.829544ms)
Apr 10 17:01:43.877: INFO: (15) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 5.441105ms)
Apr 10 17:01:43.877: INFO: (15) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 6.031753ms)
Apr 10 17:01:43.878: INFO: (15) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 5.985282ms)
Apr 10 17:01:43.878: INFO: (15) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 6.177396ms)
Apr 10 17:01:43.878: INFO: (15) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 7.880122ms)
Apr 10 17:01:43.879: INFO: (15) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 7.698302ms)
Apr 10 17:01:43.879: INFO: (15) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 7.637266ms)
Apr 10 17:01:43.879: INFO: (15) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.212882ms)
Apr 10 17:01:43.879: INFO: (15) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 7.881149ms)
Apr 10 17:01:43.880: INFO: (15) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 8.851467ms)
Apr 10 17:01:43.882: INFO: (15) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 10.587863ms)
Apr 10 17:01:43.882: INFO: (15) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 11.43387ms)
Apr 10 17:01:43.882: INFO: (15) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 11.258362ms)
Apr 10 17:01:43.883: INFO: (15) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 11.25402ms)
Apr 10 17:01:43.883: INFO: (15) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 11.572286ms)
Apr 10 17:01:43.884: INFO: (15) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 13.037426ms)
Apr 10 17:01:43.891: INFO: (16) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 6.412535ms)
Apr 10 17:01:43.893: INFO: (16) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 7.728106ms)
Apr 10 17:01:43.894: INFO: (16) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 8.775408ms)
Apr 10 17:01:43.894: INFO: (16) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.960249ms)
Apr 10 17:01:43.894: INFO: (16) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 8.860398ms)
Apr 10 17:01:43.895: INFO: (16) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 9.291114ms)
Apr 10 17:01:43.895: INFO: (16) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 9.788298ms)
Apr 10 17:01:43.895: INFO: (16) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 9.461463ms)
Apr 10 17:01:43.895: INFO: (16) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 10.771818ms)
Apr 10 17:01:43.896: INFO: (16) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 10.805064ms)
Apr 10 17:01:43.896: INFO: (16) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 10.790109ms)
Apr 10 17:01:43.897: INFO: (16) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 11.309812ms)
Apr 10 17:01:43.897: INFO: (16) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 11.061156ms)
Apr 10 17:01:43.897: INFO: (16) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 11.931327ms)
Apr 10 17:01:43.897: INFO: (16) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 11.786229ms)
Apr 10 17:01:43.898: INFO: (16) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 12.551719ms)
Apr 10 17:01:43.907: INFO: (17) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 8.529581ms)
Apr 10 17:01:43.908: INFO: (17) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 8.854883ms)
Apr 10 17:01:43.908: INFO: (17) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 8.548511ms)
Apr 10 17:01:43.908: INFO: (17) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 10.040909ms)
Apr 10 17:01:43.909: INFO: (17) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 10.426176ms)
Apr 10 17:01:43.909: INFO: (17) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 10.967536ms)
Apr 10 17:01:43.910: INFO: (17) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 10.588663ms)
Apr 10 17:01:43.910: INFO: (17) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 11.665953ms)
Apr 10 17:01:43.910: INFO: (17) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 11.567724ms)
Apr 10 17:01:43.910: INFO: (17) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 10.909402ms)
Apr 10 17:01:43.910: INFO: (17) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 11.553924ms)
Apr 10 17:01:43.911: INFO: (17) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 11.477679ms)
Apr 10 17:01:43.911: INFO: (17) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 12.631225ms)
Apr 10 17:01:43.911: INFO: (17) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 12.377289ms)
Apr 10 17:01:43.911: INFO: (17) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 13.007889ms)
Apr 10 17:01:43.911: INFO: (17) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 12.950587ms)
Apr 10 17:01:43.918: INFO: (18) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 5.990879ms)
Apr 10 17:01:43.918: INFO: (18) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 5.158482ms)
Apr 10 17:01:43.920: INFO: (18) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 7.544776ms)
Apr 10 17:01:43.920: INFO: (18) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 7.216002ms)
Apr 10 17:01:43.920: INFO: (18) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 8.193577ms)
Apr 10 17:01:43.921: INFO: (18) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 7.428221ms)
Apr 10 17:01:43.921: INFO: (18) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 9.574797ms)
Apr 10 17:01:43.921: INFO: (18) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 8.139307ms)
Apr 10 17:01:43.922: INFO: (18) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 9.948781ms)
Apr 10 17:01:43.922: INFO: (18) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 10.200795ms)
Apr 10 17:01:43.922: INFO: (18) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 9.189264ms)
Apr 10 17:01:43.922: INFO: (18) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 10.519888ms)
Apr 10 17:01:43.923: INFO: (18) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 10.0604ms)
Apr 10 17:01:43.923: INFO: (18) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 9.93668ms)
Apr 10 17:01:43.924: INFO: (18) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 11.551259ms)
Apr 10 17:01:43.924: INFO: (18) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 11.539185ms)
Apr 10 17:01:43.935: INFO: (19) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:462/proxy/: tls qux (200; 10.123711ms)
Apr 10 17:01:43.935: INFO: (19) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:460/proxy/: tls baz (200; 11.431345ms)
Apr 10 17:01:43.938: INFO: (19) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 13.383073ms)
Apr 10 17:01:43.939: INFO: (19) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn/proxy/rewriteme">test</a> (200; 13.366027ms)
Apr 10 17:01:43.939: INFO: (19) /api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/https:proxy-service-f2zlg-hdgxn:443/proxy/tlsrewriteme... (200; 13.383221ms)
Apr 10 17:01:43.940: INFO: (19) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 14.972663ms)
Apr 10 17:01:43.940: INFO: (19) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">t... (200; 14.826042ms)
Apr 10 17:01:43.940: INFO: (19) /api/v1/namespaces/proxy-498/pods/http:proxy-service-f2zlg-hdgxn:162/proxy/: bar (200; 15.067033ms)
Apr 10 17:01:43.940: INFO: (19) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:160/proxy/: foo (200; 15.461949ms)
Apr 10 17:01:43.940: INFO: (19) /api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/: <a href="/api/v1/namespaces/proxy-498/pods/proxy-service-f2zlg-hdgxn:1080/proxy/rewriteme">test</... (200; 15.774589ms)
Apr 10 17:01:44.123: INFO: (19) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname1/proxy/: foo (200; 197.555905ms)
Apr 10 17:01:44.124: INFO: (19) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname2/proxy/: tls qux (200; 198.725652ms)
Apr 10 17:01:44.124: INFO: (19) /api/v1/namespaces/proxy-498/services/http:proxy-service-f2zlg:portname2/proxy/: bar (200; 200.061517ms)
Apr 10 17:01:44.125: INFO: (19) /api/v1/namespaces/proxy-498/services/https:proxy-service-f2zlg:tlsportname1/proxy/: tls baz (200; 200.515422ms)
Apr 10 17:01:44.125: INFO: (19) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname2/proxy/: bar (200; 199.186265ms)
Apr 10 17:01:44.125: INFO: (19) /api/v1/namespaces/proxy-498/services/proxy-service-f2zlg:portname1/proxy/: foo (200; 199.538041ms)
STEP: deleting ReplicationController proxy-service-f2zlg in namespace proxy-498, will wait for the garbage collector to delete the pods
Apr 10 17:01:44.372: INFO: Deleting ReplicationController proxy-service-f2zlg took: 193.014082ms
Apr 10 17:01:44.672: INFO: Terminating ReplicationController proxy-service-f2zlg pods took: 300.26785ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:01:57.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-498" for this suite.
Apr 10 17:02:05.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:02:06.004: INFO: namespace proxy-498 deletion completed in 8.267770577s

• [SLOW TEST:34.645 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:02:06.005: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 10 17:02:06.607: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-646907027 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:02:06.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5285" for this suite.
Apr 10 17:02:12.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:02:13.110: INFO: namespace kubectl-5285 deletion completed in 6.435880016s

• [SLOW TEST:7.105 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:02:13.111: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:02:13.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a" in namespace "projected-3158" to be "success or failure"
Apr 10 17:02:14.009: INFO: Pod "downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 264.107269ms
Apr 10 17:02:16.092: INFO: Pod "downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.346363444s
Apr 10 17:02:18.097: INFO: Pod "downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.35117382s
STEP: Saw pod success
Apr 10 17:02:18.097: INFO: Pod "downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:02:18.100: INFO: Trying to get logs from node g168 pod downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:02:18.315: INFO: Waiting for pod downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:02:18.401: INFO: Pod downwardapi-volume-631d8d68-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:02:18.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3158" for this suite.
Apr 10 17:02:26.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:02:26.708: INFO: namespace projected-3158 deletion completed in 8.301973041s

• [SLOW TEST:13.597 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:02:26.709: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-473
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 10 17:02:27.184: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 10 17:02:47.858: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.84 8081 | grep -v '^\s*$'] Namespace:pod-network-test-473 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 17:02:47.858: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 17:02:48.916: INFO: Found all expected endpoints: [netserver-0]
Apr 10 17:02:49.105: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.180 8081 | grep -v '^\s*$'] Namespace:pod-network-test-473 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 17:02:49.105: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 17:02:50.163: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:02:50.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-473" for this suite.
Apr 10 17:03:18.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:03:18.482: INFO: namespace pod-network-test-473 deletion completed in 28.314196121s

• [SLOW TEST:51.773 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:03:18.483: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:03:19.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a" in namespace "downward-api-665" to be "success or failure"
Apr 10 17:03:19.345: INFO: Pod "downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 260.092443ms
Apr 10 17:03:21.350: INFO: Pod "downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264744907s
Apr 10 17:03:23.380: INFO: Pod "downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.295362552s
STEP: Saw pod success
Apr 10 17:03:23.380: INFO: Pod "downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:03:23.630: INFO: Trying to get logs from node g168 pod downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:03:23.717: INFO: Waiting for pod downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:03:23.929: INFO: Pod downwardapi-volume-8a11e1c9-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:03:23.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-665" for this suite.
Apr 10 17:03:32.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:03:32.300: INFO: namespace downward-api-665 deletion completed in 8.366725289s

• [SLOW TEST:13.817 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:03:32.301: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:03:32.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a" in namespace "downward-api-1852" to be "success or failure"
Apr 10 17:03:32.999: INFO: Pod "downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 80.455312ms
Apr 10 17:03:35.229: INFO: Pod "downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311380463s
Apr 10 17:03:37.262: INFO: Pod "downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.344170812s
STEP: Saw pod success
Apr 10 17:03:37.262: INFO: Pod "downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:03:37.340: INFO: Trying to get logs from node g168 pod downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:03:37.503: INFO: Waiting for pod downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:03:37.575: INFO: Pod downwardapi-volume-9230d702-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:03:37.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1852" for this suite.
Apr 10 17:03:45.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:03:45.990: INFO: namespace downward-api-1852 deletion completed in 8.413402196s

• [SLOW TEST:13.690 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:03:45.995: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 10 17:03:46.651: INFO: Waiting up to 5m0s for pod "pod-9a7c8176-5bb2-11e9-8040-3209cfee711a" in namespace "emptydir-6894" to be "success or failure"
Apr 10 17:03:46.932: INFO: Pod "pod-9a7c8176-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 279.962599ms
Apr 10 17:03:49.008: INFO: Pod "pod-9a7c8176-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.356020132s
Apr 10 17:03:51.156: INFO: Pod "pod-9a7c8176-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.504611689s
STEP: Saw pod success
Apr 10 17:03:51.156: INFO: Pod "pod-9a7c8176-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:03:51.160: INFO: Trying to get logs from node g168 pod pod-9a7c8176-5bb2-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 17:03:51.379: INFO: Waiting for pod pod-9a7c8176-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:03:51.461: INFO: Pod pod-9a7c8176-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:03:51.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6894" for this suite.
Apr 10 17:03:59.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:04:00.193: INFO: namespace emptydir-6894 deletion completed in 8.542123213s

• [SLOW TEST:14.199 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:04:00.195: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:04:30.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2270" for this suite.
Apr 10 17:04:36.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:04:36.360: INFO: namespace namespaces-2270 deletion completed in 6.29759793s
STEP: Destroying namespace "nsdeletetest-233" for this suite.
Apr 10 17:04:36.362: INFO: Namespace nsdeletetest-233 was already deleted
STEP: Destroying namespace "nsdeletetest-8775" for this suite.
Apr 10 17:04:42.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:04:42.592: INFO: namespace nsdeletetest-8775 deletion completed in 6.229785372s

• [SLOW TEST:42.397 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:04:42.592: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 10 17:04:43.171: INFO: Waiting up to 5m0s for pod "client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a" in namespace "containers-5817" to be "success or failure"
Apr 10 17:04:43.443: INFO: Pod "client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 271.031436ms
Apr 10 17:04:45.449: INFO: Pod "client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277584018s
Apr 10 17:04:47.455: INFO: Pod "client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.283612898s
STEP: Saw pod success
Apr 10 17:04:47.455: INFO: Pod "client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:04:47.653: INFO: Trying to get logs from node g168 pod client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 17:04:47.947: INFO: Waiting for pod client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:04:48.024: INFO: Pod client-containers-bc2c53ca-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:04:48.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5817" for this suite.
Apr 10 17:04:56.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:04:56.313: INFO: namespace containers-5817 deletion completed in 8.284266856s

• [SLOW TEST:13.720 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:04:56.313: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:04:56.887: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a" in namespace "downward-api-1416" to be "success or failure"
Apr 10 17:04:56.949: INFO: Pod "downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 61.722349ms
Apr 10 17:04:58.954: INFO: Pod "downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066254271s
Apr 10 17:05:00.958: INFO: Pod "downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070714511s
STEP: Saw pod success
Apr 10 17:05:00.958: INFO: Pod "downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:05:00.962: INFO: Trying to get logs from node g168 pod downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:05:01.156: INFO: Waiting for pod downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:05:01.448: INFO: Pod downwardapi-volume-c46521d5-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:05:01.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1416" for this suite.
Apr 10 17:05:09.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:05:09.578: INFO: namespace downward-api-1416 deletion completed in 8.125590248s

• [SLOW TEST:13.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:05:09.578: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-cc505f06-5bb2-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:05:10.410: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a" in namespace "configmap-8844" to be "success or failure"
Apr 10 17:05:10.482: INFO: Pod "pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 71.659481ms
Apr 10 17:05:12.485: INFO: Pod "pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074709817s
Apr 10 17:05:14.694: INFO: Pod "pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.283357712s
STEP: Saw pod success
Apr 10 17:05:14.694: INFO: Pod "pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:05:14.697: INFO: Trying to get logs from node g168 pod pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:05:14.793: INFO: Waiting for pod pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:05:15.004: INFO: Pod pod-configmaps-cc746ea0-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:05:15.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8844" for this suite.
Apr 10 17:05:23.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:05:23.332: INFO: namespace configmap-8844 deletion completed in 8.323245879s

• [SLOW TEST:13.754 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:05:23.333: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 10 17:05:23.863: INFO: Waiting up to 5m0s for pod "pod-d45e165a-5bb2-11e9-8040-3209cfee711a" in namespace "emptydir-9941" to be "success or failure"
Apr 10 17:05:23.930: INFO: Pod "pod-d45e165a-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 66.849893ms
Apr 10 17:05:25.962: INFO: Pod "pod-d45e165a-5bb2-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098497063s
Apr 10 17:05:27.966: INFO: Pod "pod-d45e165a-5bb2-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.102505144s
STEP: Saw pod success
Apr 10 17:05:27.966: INFO: Pod "pod-d45e165a-5bb2-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:05:27.969: INFO: Trying to get logs from node g168 pod pod-d45e165a-5bb2-11e9-8040-3209cfee711a container test-container: <nil>
STEP: delete the pod
Apr 10 17:05:28.070: INFO: Waiting for pod pod-d45e165a-5bb2-11e9-8040-3209cfee711a to disappear
Apr 10 17:05:28.239: INFO: Pod pod-d45e165a-5bb2-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:05:28.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9941" for this suite.
Apr 10 17:05:36.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:05:36.549: INFO: namespace emptydir-9941 deletion completed in 8.30687102s

• [SLOW TEST:13.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:05:36.549: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0410 17:05:47.209613      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 17:05:47.209: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:05:47.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8418" for this suite.
Apr 10 17:05:55.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:05:55.503: INFO: namespace gc-8418 deletion completed in 8.271950366s

• [SLOW TEST:18.954 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:05:55.504: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:05:56.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2082" for this suite.
Apr 10 17:06:20.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:06:20.996: INFO: namespace pods-2082 deletion completed in 24.372192407s

• [SLOW TEST:25.492 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:06:20.996: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9221
Apr 10 17:06:25.799: INFO: Started pod liveness-http in namespace container-probe-9221
STEP: checking the pod's current state and verifying that restartCount is present
Apr 10 17:06:25.802: INFO: Initial restart count of pod liveness-http is 0
Apr 10 17:06:46.099: INFO: Restart count of pod container-probe-9221/liveness-http is now 1 (20.29631184s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:06:46.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9221" for this suite.
Apr 10 17:06:54.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:06:54.805: INFO: namespace container-probe-9221 deletion completed in 8.457919884s

• [SLOW TEST:33.809 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:06:54.807: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:06:55.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a" in namespace "downward-api-7737" to be "success or failure"
Apr 10 17:06:55.645: INFO: Pod "downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 253.105189ms
Apr 10 17:06:57.715: INFO: Pod "downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.322977457s
Apr 10 17:06:59.720: INFO: Pod "downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.327734076s
STEP: Saw pod success
Apr 10 17:06:59.720: INFO: Pod "downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:06:59.724: INFO: Trying to get logs from node g168 pod downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:06:59.822: INFO: Waiting for pod downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a to disappear
Apr 10 17:07:00.056: INFO: Pod downwardapi-volume-0afcffbc-5bb3-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:07:00.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7737" for this suite.
Apr 10 17:07:08.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:07:08.446: INFO: namespace downward-api-7737 deletion completed in 8.306708514s

• [SLOW TEST:13.639 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:07:08.447: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 10 17:07:17.292: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 10 17:07:17.364: INFO: Pod pod-with-prestop-http-hook still exists
Apr 10 17:07:19.365: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 10 17:07:19.449: INFO: Pod pod-with-prestop-http-hook still exists
Apr 10 17:07:21.365: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 10 17:07:21.369: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:07:21.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8192" for this suite.
Apr 10 17:07:47.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:07:47.670: INFO: namespace container-lifecycle-hook-8192 deletion completed in 26.27473726s

• [SLOW TEST:39.224 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:07:47.673: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 17:07:48.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7734'
Apr 10 17:07:55.641: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 10 17:07:55.641: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 10 17:07:55.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete jobs e2e-test-nginx-job --namespace=kubectl-7734'
Apr 10 17:07:56.612: INFO: stderr: ""
Apr 10 17:07:56.612: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:07:56.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7734" for this suite.
Apr 10 17:08:04.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:08:04.752: INFO: namespace kubectl-7734 deletion completed in 8.137182058s

• [SLOW TEST:17.078 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:08:04.752: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9871/configmap-test-34b3159d-5bb3-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:08:05.905: INFO: Waiting up to 5m0s for pod "pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a" in namespace "configmap-9871" to be "success or failure"
Apr 10 17:08:06.193: INFO: Pod "pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 287.935952ms
Apr 10 17:08:08.350: INFO: Pod "pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.444514615s
Apr 10 17:08:10.353: INFO: Pod "pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.448373669s
STEP: Saw pod success
Apr 10 17:08:10.354: INFO: Pod "pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:08:10.358: INFO: Trying to get logs from node g168 pod pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a container env-test: <nil>
STEP: delete the pod
Apr 10 17:08:10.562: INFO: Waiting for pod pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a to disappear
Apr 10 17:08:10.632: INFO: Pod pod-configmaps-34be1088-5bb3-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:08:10.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9871" for this suite.
Apr 10 17:08:18.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:08:19.094: INFO: namespace configmap-9871 deletion completed in 8.45783113s

• [SLOW TEST:14.342 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:08:19.095: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0410 17:08:31.805220      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 10 17:08:31.805: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:08:31.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6260" for this suite.
Apr 10 17:08:48.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:08:48.942: INFO: namespace gc-6260 deletion completed in 16.704448887s

• [SLOW TEST:29.848 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:08:48.942: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-4677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4677 to expose endpoints map[]
Apr 10 17:08:49.999: INFO: Get endpoints failed (9.393547ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 10 17:08:51.030: INFO: successfully validated that service endpoint-test2 in namespace services-4677 exposes endpoints map[] (1.040826508s elapsed)
STEP: Creating pod pod1 in namespace services-4677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4677 to expose endpoints map[pod1:[80]]
Apr 10 17:08:54.726: INFO: successfully validated that service endpoint-test2 in namespace services-4677 exposes endpoints map[pod1:[80]] (3.689078161s elapsed)
STEP: Creating pod pod2 in namespace services-4677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4677 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 10 17:08:58.404: INFO: successfully validated that service endpoint-test2 in namespace services-4677 exposes endpoints map[pod1:[80] pod2:[80]] (3.52307009s elapsed)
STEP: Deleting pod pod1 in namespace services-4677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4677 to expose endpoints map[pod2:[80]]
Apr 10 17:08:58.724: INFO: successfully validated that service endpoint-test2 in namespace services-4677 exposes endpoints map[pod2:[80]] (314.245806ms elapsed)
STEP: Deleting pod pod2 in namespace services-4677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4677 to expose endpoints map[]
Apr 10 17:08:59.108: INFO: successfully validated that service endpoint-test2 in namespace services-4677 exposes endpoints map[] (304.974636ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:08:59.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4677" for this suite.
Apr 10 17:09:24.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:09:24.663: INFO: namespace services-4677 deletion completed in 24.512322189s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:35.721 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:09:24.666: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 10 17:09:25.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-1116'
Apr 10 17:09:25.553: INFO: stderr: ""
Apr 10 17:09:25.553: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 10 17:09:26.557: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:26.557: INFO: Found 0 / 1
Apr 10 17:09:27.569: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:27.569: INFO: Found 0 / 1
Apr 10 17:09:28.557: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:28.557: INFO: Found 0 / 1
Apr 10 17:09:29.605: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:29.605: INFO: Found 1 / 1
Apr 10 17:09:29.605: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 10 17:09:29.608: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:29.608: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 10 17:09:29.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 patch pod redis-master-x6fnq --namespace=kubectl-1116 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 10 17:09:29.686: INFO: stderr: ""
Apr 10 17:09:29.686: INFO: stdout: "pod/redis-master-x6fnq patched\n"
STEP: checking annotations
Apr 10 17:09:29.905: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:09:29.905: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:09:29.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1116" for this suite.
Apr 10 17:09:53.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:09:54.043: INFO: namespace kubectl-1116 deletion completed in 24.134749782s

• [SLOW TEST:29.377 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:09:54.044: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-7m6h
STEP: Creating a pod to test atomic-volume-subpath
Apr 10 17:09:55.076: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7m6h" in namespace "subpath-3984" to be "success or failure"
Apr 10 17:09:55.349: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Pending", Reason="", readiness=false. Elapsed: 273.825795ms
Apr 10 17:09:57.353: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277515974s
Apr 10 17:09:59.358: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 4.282255794s
Apr 10 17:10:01.362: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 6.286709138s
Apr 10 17:10:03.497: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 8.420989758s
Apr 10 17:10:05.501: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 10.424984617s
Apr 10 17:10:07.505: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 12.429240637s
Apr 10 17:10:09.615: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 14.539126357s
Apr 10 17:10:11.620: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 16.544131026s
Apr 10 17:10:13.624: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 18.54813305s
Apr 10 17:10:15.627: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 20.551741168s
Apr 10 17:10:17.631: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Running", Reason="", readiness=true. Elapsed: 22.55583869s
Apr 10 17:10:19.636: INFO: Pod "pod-subpath-test-projected-7m6h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.560038794s
STEP: Saw pod success
Apr 10 17:10:19.636: INFO: Pod "pod-subpath-test-projected-7m6h" satisfied condition "success or failure"
Apr 10 17:10:19.639: INFO: Trying to get logs from node g168 pod pod-subpath-test-projected-7m6h container test-container-subpath-projected-7m6h: <nil>
STEP: delete the pod
Apr 10 17:10:19.880: INFO: Waiting for pod pod-subpath-test-projected-7m6h to disappear
Apr 10 17:10:20.128: INFO: Pod pod-subpath-test-projected-7m6h no longer exists
STEP: Deleting pod pod-subpath-test-projected-7m6h
Apr 10 17:10:20.128: INFO: Deleting pod "pod-subpath-test-projected-7m6h" in namespace "subpath-3984"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:10:20.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3984" for this suite.
Apr 10 17:10:28.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:10:28.333: INFO: namespace subpath-3984 deletion completed in 8.197475474s

• [SLOW TEST:34.289 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:10:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 17:10:28.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-2663'
Apr 10 17:10:28.959: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 10 17:10:28.959: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 10 17:10:31.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2663'
Apr 10 17:10:31.710: INFO: stderr: ""
Apr 10 17:10:31.710: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:10:31.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2663" for this suite.
Apr 10 17:10:56.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:10:56.337: INFO: namespace kubectl-2663 deletion completed in 24.380486139s

• [SLOW TEST:28.004 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:10:56.338: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-9af32e23-5bb3-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9af32e23-5bb3-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:11:01.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2188" for this suite.
Apr 10 17:11:25.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:11:25.842: INFO: namespace configmap-2188 deletion completed in 24.139960832s

• [SLOW TEST:29.504 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:11:25.843: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:11:31.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5441" for this suite.
Apr 10 17:11:58.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:11:58.141: INFO: namespace replication-controller-5441 deletion completed in 26.242648909s

• [SLOW TEST:32.297 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:11:58.141: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-6p9z
STEP: Creating a pod to test atomic-volume-subpath
Apr 10 17:11:58.925: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6p9z" in namespace "subpath-5261" to be "success or failure"
Apr 10 17:11:59.001: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Pending", Reason="", readiness=false. Elapsed: 75.900466ms
Apr 10 17:12:01.006: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080436903s
Apr 10 17:12:03.181: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 4.255790441s
Apr 10 17:12:05.186: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 6.260561913s
Apr 10 17:12:07.191: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 8.265189483s
Apr 10 17:12:09.195: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 10.269682434s
Apr 10 17:12:11.198: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 12.272515048s
Apr 10 17:12:13.202: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 14.276829311s
Apr 10 17:12:15.206: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 16.280739193s
Apr 10 17:12:17.209: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 18.283388142s
Apr 10 17:12:19.213: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 20.287747233s
Apr 10 17:12:21.218: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Running", Reason="", readiness=true. Elapsed: 22.292060263s
Apr 10 17:12:23.223: INFO: Pod "pod-subpath-test-secret-6p9z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.297269248s
STEP: Saw pod success
Apr 10 17:12:23.223: INFO: Pod "pod-subpath-test-secret-6p9z" satisfied condition "success or failure"
Apr 10 17:12:23.227: INFO: Trying to get logs from node g168 pod pod-subpath-test-secret-6p9z container test-container-subpath-secret-6p9z: <nil>
STEP: delete the pod
Apr 10 17:12:23.497: INFO: Waiting for pod pod-subpath-test-secret-6p9z to disappear
Apr 10 17:12:23.659: INFO: Pod pod-subpath-test-secret-6p9z no longer exists
STEP: Deleting pod pod-subpath-test-secret-6p9z
Apr 10 17:12:23.660: INFO: Deleting pod "pod-subpath-test-secret-6p9z" in namespace "subpath-5261"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:12:23.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5261" for this suite.
Apr 10 17:12:31.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:12:31.811: INFO: namespace subpath-5261 deletion completed in 8.145436482s

• [SLOW TEST:33.670 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:12:31.812: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 10 17:12:32.236: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:12:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2707" for this suite.
Apr 10 17:12:49.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:12:49.361: INFO: namespace init-container-2707 deletion completed in 8.410554256s

• [SLOW TEST:17.548 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:12:49.361: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-de510eca-5bb3-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:12:50.109: INFO: Waiting up to 5m0s for pod "pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a" in namespace "configmap-6753" to be "success or failure"
Apr 10 17:12:50.178: INFO: Pod "pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 69.397055ms
Apr 10 17:12:52.198: INFO: Pod "pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088999821s
Apr 10 17:12:54.459: INFO: Pod "pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.350426038s
STEP: Saw pod success
Apr 10 17:12:54.459: INFO: Pod "pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:12:54.526: INFO: Trying to get logs from node g168 pod pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:12:54.796: INFO: Waiting for pod pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a to disappear
Apr 10 17:12:54.984: INFO: Pod pod-configmaps-de74bfba-5bb3-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:12:54.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6753" for this suite.
Apr 10 17:13:03.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:13:03.127: INFO: namespace configmap-6753 deletion completed in 8.139328212s

• [SLOW TEST:13.767 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:13:03.128: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e6925c9e-5bb3-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:13:03.964: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a" in namespace "projected-6303" to be "success or failure"
Apr 10 17:13:04.042: INFO: Pod "pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 78.483491ms
Apr 10 17:13:06.245: INFO: Pod "pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281402304s
Apr 10 17:13:08.316: INFO: Pod "pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.352716345s
STEP: Saw pod success
Apr 10 17:13:08.317: INFO: Pod "pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:13:08.320: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:13:08.501: INFO: Waiting for pod pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a to disappear
Apr 10 17:13:08.667: INFO: Pod pod-projected-configmaps-e6b7547f-5bb3-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:13:08.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6303" for this suite.
Apr 10 17:13:16.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:13:16.807: INFO: namespace projected-6303 deletion completed in 8.137797134s

• [SLOW TEST:13.679 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:13:16.807: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:13:53.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7786" for this suite.
Apr 10 17:14:03.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:14:03.732: INFO: namespace container-runtime-7786 deletion completed in 10.136476628s

• [SLOW TEST:46.924 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:14:03.737: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 10 17:14:04.235: INFO: Waiting up to 5m0s for pod "var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a" in namespace "var-expansion-9219" to be "success or failure"
Apr 10 17:14:04.308: INFO: Pod "var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 73.276377ms
Apr 10 17:14:06.311: INFO: Pod "var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075968955s
Apr 10 17:14:08.315: INFO: Pod "var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.08012785s
STEP: Saw pod success
Apr 10 17:14:08.315: INFO: Pod "var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:14:08.319: INFO: Trying to get logs from node g168 pod var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 17:14:08.414: INFO: Waiting for pod var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:14:08.579: INFO: Pod var-expansion-0aa47402-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:14:08.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9219" for this suite.
Apr 10 17:14:16.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:14:16.714: INFO: namespace var-expansion-9219 deletion completed in 8.132582395s

• [SLOW TEST:12.978 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:14:16.715: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 10 17:14:17.241: INFO: Waiting up to 5m0s for pod "downward-api-12647edf-5bb4-11e9-8040-3209cfee711a" in namespace "downward-api-8196" to be "success or failure"
Apr 10 17:14:17.311: INFO: Pod "downward-api-12647edf-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 69.926673ms
Apr 10 17:14:19.315: INFO: Pod "downward-api-12647edf-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074044465s
Apr 10 17:14:21.455: INFO: Pod "downward-api-12647edf-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214164004s
STEP: Saw pod success
Apr 10 17:14:21.456: INFO: Pod "downward-api-12647edf-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:14:21.547: INFO: Trying to get logs from node g168 pod downward-api-12647edf-5bb4-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 17:14:22.317: INFO: Waiting for pod downward-api-12647edf-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:14:22.396: INFO: Pod downward-api-12647edf-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:14:22.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8196" for this suite.
Apr 10 17:14:30.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:14:30.784: INFO: namespace downward-api-8196 deletion completed in 8.149427859s

• [SLOW TEST:14.069 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:14:30.785: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 10 17:14:31.597: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2229,SelfLink:/api/v1/namespaces/watch-2229/configmaps/e2e-watch-test-watch-closed,UID:1acb209b-5bb4-11e9-b4c9-5254005baff5,ResourceVersion:22013,Generation:0,CreationTimestamp:2019-04-10 17:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 10 17:14:31.597: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2229,SelfLink:/api/v1/namespaces/watch-2229/configmaps/e2e-watch-test-watch-closed,UID:1acb209b-5bb4-11e9-b4c9-5254005baff5,ResourceVersion:22014,Generation:0,CreationTimestamp:2019-04-10 17:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 10 17:14:31.862: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2229,SelfLink:/api/v1/namespaces/watch-2229/configmaps/e2e-watch-test-watch-closed,UID:1acb209b-5bb4-11e9-b4c9-5254005baff5,ResourceVersion:22015,Generation:0,CreationTimestamp:2019-04-10 17:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 10 17:14:31.863: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2229,SelfLink:/api/v1/namespaces/watch-2229/configmaps/e2e-watch-test-watch-closed,UID:1acb209b-5bb4-11e9-b4c9-5254005baff5,ResourceVersion:22016,Generation:0,CreationTimestamp:2019-04-10 17:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:14:31.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2229" for this suite.
Apr 10 17:14:38.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:14:38.405: INFO: namespace watch-2229 deletion completed in 6.478867649s

• [SLOW TEST:7.621 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:14:38.406: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:14:43.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8197" for this suite.
Apr 10 17:14:51.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:14:51.782: INFO: namespace kubelet-test-8197 deletion completed in 8.377556022s

• [SLOW TEST:13.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:14:51.782: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-2749d774-5bb4-11e9-8040-3209cfee711a
STEP: Creating secret with name s-test-opt-upd-2749d874-5bb4-11e9-8040-3209cfee711a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2749d774-5bb4-11e9-8040-3209cfee711a
STEP: Updating secret s-test-opt-upd-2749d874-5bb4-11e9-8040-3209cfee711a
STEP: Creating secret with name s-test-opt-create-2749d889-5bb4-11e9-8040-3209cfee711a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:16:16.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2552" for this suite.
Apr 10 17:16:42.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:16:42.723: INFO: namespace projected-2552 deletion completed in 26.243404134s

• [SLOW TEST:110.940 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:16:42.726: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6271.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6271.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6271.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6271.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6271.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6271.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 10 17:16:49.728: INFO: DNS probes using dns-6271/dns-test-6983f8b6-5bb4-11e9-8040-3209cfee711a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:16:49.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6271" for this suite.
Apr 10 17:16:58.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:16:58.695: INFO: namespace dns-6271 deletion completed in 8.403117415s

• [SLOW TEST:15.970 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:16:58.697: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-72f06210-5bb4-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:16:59.451: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a" in namespace "projected-8643" to be "success or failure"
Apr 10 17:16:59.513: INFO: Pod "pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 61.555482ms
Apr 10 17:17:01.517: INFO: Pod "pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06566914s
Apr 10 17:17:03.701: INFO: Pod "pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.249435585s
STEP: Saw pod success
Apr 10 17:17:03.701: INFO: Pod "pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:17:03.706: INFO: Trying to get logs from node g168 pod pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:17:03.798: INFO: Waiting for pod pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:17:03.974: INFO: Pod pod-projected-configmaps-73136c82-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:17:03.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8643" for this suite.
Apr 10 17:17:12.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:17:12.319: INFO: namespace projected-8643 deletion completed in 8.265772502s

• [SLOW TEST:13.622 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:17:12.319: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 10 17:17:12.806: INFO: Waiting up to 5m0s for pod "downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a" in namespace "downward-api-1807" to be "success or failure"
Apr 10 17:17:12.873: INFO: Pod "downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 65.99514ms
Apr 10 17:17:14.877: INFO: Pod "downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070106952s
Apr 10 17:17:16.966: INFO: Pod "downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.159679102s
STEP: Saw pod success
Apr 10 17:17:16.966: INFO: Pod "downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:17:16.968: INFO: Trying to get logs from node g168 pod downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 17:17:17.064: INFO: Waiting for pod downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:17:17.239: INFO: Pod downward-api-7b09872d-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:17:17.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1807" for this suite.
Apr 10 17:17:25.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:17:25.380: INFO: namespace downward-api-1807 deletion completed in 8.136502384s

• [SLOW TEST:13.061 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:17:25.381: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 10 17:17:30.289: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-82e0702d-5bb4-11e9-8040-3209cfee711a,GenerateName:,Namespace:events-626,SelfLink:/api/v1/namespaces/events-626/pods/send-events-82e0702d-5bb4-11e9-8040-3209cfee711a,UID:8306c02a-5bb4-11e9-b4c9-5254005baff5,ResourceVersion:22470,Generation:0,CreationTimestamp:2019-04-10 17:17:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 949861861,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jt7ps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jt7ps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-jt7ps true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:17:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:17:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:17:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:17:26 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.221,StartTime:2019-04-10 17:17:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-10 17:17:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:53c28beabd3509fb5b1d1185b2962e8204384cef7562982d8b216b71292aabf9 cri-o://1d9775bf9e1f075a08fea4c7c120f6195265c863e8b9044163e38f130f071acb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 10 17:17:32.295: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 10 17:17:34.453: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:17:34.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-626" for this suite.
Apr 10 17:18:19.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:18:19.074: INFO: namespace events-626 deletion completed in 44.304825175s

• [SLOW TEST:53.693 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:18:19.074: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 10 17:18:20.143: INFO: Waiting up to 5m0s for pod "downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a" in namespace "downward-api-2660" to be "success or failure"
Apr 10 17:18:20.145: INFO: Pod "downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030337ms
Apr 10 17:18:22.335: INFO: Pod "downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192314004s
Apr 10 17:18:24.344: INFO: Pod "downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.200886046s
STEP: Saw pod success
Apr 10 17:18:24.344: INFO: Pod "downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:18:24.406: INFO: Trying to get logs from node g168 pod downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a container dapi-container: <nil>
STEP: delete the pod
Apr 10 17:18:24.661: INFO: Waiting for pod downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:18:24.836: INFO: Pod downward-api-a2fc7647-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:18:24.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2660" for this suite.
Apr 10 17:18:33.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:18:33.141: INFO: namespace downward-api-2660 deletion completed in 8.299610811s

• [SLOW TEST:14.067 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:18:33.144: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-ab3a1161-5bb4-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:18:33.725: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a" in namespace "configmap-4304" to be "success or failure"
Apr 10 17:18:34.001: INFO: Pod "pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 275.892752ms
Apr 10 17:18:36.006: INFO: Pod "pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.280129255s
Apr 10 17:18:38.041: INFO: Pod "pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.315619477s
STEP: Saw pod success
Apr 10 17:18:38.041: INFO: Pod "pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:18:38.044: INFO: Trying to get logs from node g168 pod pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:18:38.131: INFO: Waiting for pod pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:18:38.327: INFO: Pod pod-configmaps-ab3ab24a-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:18:38.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4304" for this suite.
Apr 10 17:18:46.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:18:46.795: INFO: namespace configmap-4304 deletion completed in 8.392284897s

• [SLOW TEST:13.652 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:18:46.797: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:18:51.972: INFO: Waiting up to 5m0s for pod "client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a" in namespace "pods-5959" to be "success or failure"
Apr 10 17:18:52.246: INFO: Pod "client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 273.459004ms
Apr 10 17:18:54.459: INFO: Pod "client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4863836s
Apr 10 17:18:56.552: INFO: Pod "client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.580017693s
STEP: Saw pod success
Apr 10 17:18:56.553: INFO: Pod "client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:18:56.560: INFO: Trying to get logs from node g168 pod client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a container env3cont: <nil>
STEP: delete the pod
Apr 10 17:18:56.856: INFO: Waiting for pod client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a to disappear
Apr 10 17:18:56.859: INFO: Pod client-envvars-b61aed5e-5bb4-11e9-8040-3209cfee711a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:18:56.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5959" for this suite.
Apr 10 17:19:38.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:19:39.000: INFO: namespace pods-5959 deletion completed in 42.135513413s

• [SLOW TEST:52.202 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:19:39.000: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1999
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 10 17:19:39.985: INFO: Found 0 stateful pods, waiting for 3
Apr 10 17:19:50.078: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:19:50.079: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:19:50.079: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 10 17:20:00.051: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:20:00.051: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:20:00.051: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 10 17:20:00.072: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 10 17:20:10.390: INFO: Updating stateful set ss2
Apr 10 17:20:10.652: INFO: Waiting for Pod statefulset-1999/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 10 17:20:22.304: INFO: Found 2 stateful pods, waiting for 3
Apr 10 17:20:32.391: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:20:32.391: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 10 17:20:32.391: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 10 17:20:32.415: INFO: Updating stateful set ss2
Apr 10 17:20:32.725: INFO: Waiting for Pod statefulset-1999/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 17:20:42.753: INFO: Updating stateful set ss2
Apr 10 17:20:43.044: INFO: Waiting for StatefulSet statefulset-1999/ss2 to complete update
Apr 10 17:20:43.044: INFO: Waiting for Pod statefulset-1999/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 10 17:20:53.051: INFO: Waiting for StatefulSet statefulset-1999/ss2 to complete update
Apr 10 17:20:53.051: INFO: Waiting for Pod statefulset-1999/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 10 17:21:03.053: INFO: Deleting all statefulset in ns statefulset-1999
Apr 10 17:21:03.056: INFO: Scaling statefulset ss2 to 0
Apr 10 17:21:23.406: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 17:21:23.410: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:21:23.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1999" for this suite.
Apr 10 17:21:40.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:21:40.326: INFO: namespace statefulset-1999 deletion completed in 16.646851167s

• [SLOW TEST:121.327 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:21:40.327: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 10 17:21:41.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a" in namespace "downward-api-6253" to be "success or failure"
Apr 10 17:21:41.134: INFO: Pod "downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 71.957304ms
Apr 10 17:21:43.139: INFO: Pod "downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077198754s
Apr 10 17:21:45.201: INFO: Pod "downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138617214s
STEP: Saw pod success
Apr 10 17:21:45.201: INFO: Pod "downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:21:45.205: INFO: Trying to get logs from node g168 pod downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a container client-container: <nil>
STEP: delete the pod
Apr 10 17:21:45.407: INFO: Waiting for pod downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a to disappear
Apr 10 17:21:45.664: INFO: Pod downwardapi-volume-1ad15b13-5bb5-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:21:45.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6253" for this suite.
Apr 10 17:21:53.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:21:53.969: INFO: namespace downward-api-6253 deletion completed in 8.302460343s

• [SLOW TEST:13.643 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:21:53.974: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:21:54.371: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:21:58.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3497" for this suite.
Apr 10 17:22:39.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:22:39.550: INFO: namespace pods-3497 deletion completed in 40.610101047s

• [SLOW TEST:45.576 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:22:39.551: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 10 17:22:40.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9258'
Apr 10 17:22:47.748: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 10 17:22:47.748: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 10 17:22:48.050: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-v8zfg]
Apr 10 17:22:48.050: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-v8zfg" in namespace "kubectl-9258" to be "running and ready"
Apr 10 17:22:48.298: INFO: Pod "e2e-test-nginx-rc-v8zfg": Phase="Pending", Reason="", readiness=false. Elapsed: 247.498145ms
Apr 10 17:22:50.302: INFO: Pod "e2e-test-nginx-rc-v8zfg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.251302209s
Apr 10 17:22:52.319: INFO: Pod "e2e-test-nginx-rc-v8zfg": Phase="Running", Reason="", readiness=true. Elapsed: 4.268769734s
Apr 10 17:22:52.319: INFO: Pod "e2e-test-nginx-rc-v8zfg" satisfied condition "running and ready"
Apr 10 17:22:52.319: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-v8zfg]
Apr 10 17:22:52.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 logs rc/e2e-test-nginx-rc --namespace=kubectl-9258'
Apr 10 17:22:52.514: INFO: stderr: ""
Apr 10 17:22:52.514: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 10 17:22:52.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 delete rc e2e-test-nginx-rc --namespace=kubectl-9258'
Apr 10 17:22:52.661: INFO: stderr: ""
Apr 10 17:22:52.661: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:22:52.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9258" for this suite.
Apr 10 17:23:00.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:23:00.915: INFO: namespace kubectl-9258 deletion completed in 8.248745255s

• [SLOW TEST:21.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:23:00.915: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:23:01.441: INFO: Creating deployment "test-recreate-deployment"
Apr 10 17:23:01.447: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 10 17:23:01.774: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 10 17:23:03.823: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 10 17:23:04.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690513781, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690513781, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690513782, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690513781, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:23:06.018: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 10 17:23:06.030: INFO: Updating deployment test-recreate-deployment
Apr 10 17:23:06.030: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 10 17:23:08.231: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7576,SelfLink:/apis/apps/v1/namespaces/deployment-7576/deployments/test-recreate-deployment,UID:4ad885a8-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:23545,Generation:2,CreationTimestamp:2019-04-10 17:23:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-10 17:23:07 +0000 UTC 2019-04-10 17:23:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-10 17:23:07 +0000 UTC 2019-04-10 17:23:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 10 17:23:08.464: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-7576,SelfLink:/apis/apps/v1/namespaces/deployment-7576/replicasets/test-recreate-deployment-c9cbd8684,UID:4e2b69c1-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:23542,Generation:1,CreationTimestamp:2019-04-10 17:23:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4ad885a8-5bb5-11e9-b4c9-5254005baff5 0xc002774e70 0xc002774e71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 17:23:08.464: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 10 17:23:08.464: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-7576,SelfLink:/apis/apps/v1/namespaces/deployment-7576/replicasets/test-recreate-deployment-7d57d5ff7c,UID:4ad98a5e-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:23529,Generation:2,CreationTimestamp:2019-04-10 17:23:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4ad885a8-5bb5-11e9-b4c9-5254005baff5 0xc002774da7 0xc002774da8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 17:23:08.745: INFO: Pod "test-recreate-deployment-c9cbd8684-rsc4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-rsc4p,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-7576,SelfLink:/api/v1/namespaces/deployment-7576/pods/test-recreate-deployment-c9cbd8684-rsc4p,UID:4e34ffbf-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:23543,Generation:0,CreationTimestamp:2019-04-10 17:23:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 4e2b69c1-5bb5-11e9-b4c9-5254005baff5 0xc0027756c0 0xc0027756c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jdzgr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jdzgr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jdzgr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002775750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:23:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:23:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:23:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:23:07 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:,StartTime:2019-04-10 17:23:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:23:08.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7576" for this suite.
Apr 10 17:23:19.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:23:19.152: INFO: namespace deployment-7576 deletion completed in 10.401089364s

• [SLOW TEST:18.237 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:23:19.152: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:23:19.709: INFO: (0) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 4.365536ms)
Apr 10 17:23:19.713: INFO: (1) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 3.235747ms)
Apr 10 17:23:19.716: INFO: (2) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 3.523352ms)
Apr 10 17:23:19.720: INFO: (3) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 3.594034ms)
Apr 10 17:23:19.723: INFO: (4) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 3.311979ms)
Apr 10 17:23:19.726: INFO: (5) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.41614ms)
Apr 10 17:23:19.728: INFO: (6) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.921253ms)
Apr 10 17:23:19.730: INFO: (7) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.810112ms)
Apr 10 17:23:19.732: INFO: (8) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.013414ms)
Apr 10 17:23:19.734: INFO: (9) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.809599ms)
Apr 10 17:23:19.736: INFO: (10) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.978846ms)
Apr 10 17:23:19.738: INFO: (11) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.19141ms)
Apr 10 17:23:19.740: INFO: (12) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.002822ms)
Apr 10 17:23:19.742: INFO: (13) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.634785ms)
Apr 10 17:23:19.744: INFO: (14) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.642239ms)
Apr 10 17:23:19.745: INFO: (15) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.676538ms)
Apr 10 17:23:19.748: INFO: (16) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.983091ms)
Apr 10 17:23:19.750: INFO: (17) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.894095ms)
Apr 10 17:23:19.752: INFO: (18) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 2.14982ms)
Apr 10 17:23:19.754: INFO: (19) /api/v1/nodes/e173:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apparm... (200; 1.823143ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:23:19.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8346" for this suite.
Apr 10 17:23:26.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:23:26.305: INFO: namespace proxy-8346 deletion completed in 6.548742152s

• [SLOW TEST:7.153 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:23:26.305: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-955
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 10 17:23:26.848: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 10 17:23:55.665: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.238:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-955 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 17:23:55.665: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 17:23:55.727: INFO: Found all expected endpoints: [netserver-0]
Apr 10 17:23:55.729: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.95:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-955 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 10 17:23:55.729: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
Apr 10 17:23:55.787: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:23:55.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-955" for this suite.
Apr 10 17:24:24.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:24:24.120: INFO: namespace pod-network-test-955 deletion completed in 28.329463716s

• [SLOW TEST:57.815 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:24:24.120: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-7c79f7e3-5bb5-11e9-8040-3209cfee711a
STEP: Creating a pod to test consume configMaps
Apr 10 17:24:25.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a" in namespace "configmap-1322" to be "success or failure"
Apr 10 17:24:25.089: INFO: Pod "pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 83.602127ms
Apr 10 17:24:27.194: INFO: Pod "pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.187957726s
Apr 10 17:24:29.281: INFO: Pod "pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.27564143s
STEP: Saw pod success
Apr 10 17:24:29.282: INFO: Pod "pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a" satisfied condition "success or failure"
Apr 10 17:24:29.348: INFO: Trying to get logs from node g168 pod pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 10 17:24:29.624: INFO: Waiting for pod pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a to disappear
Apr 10 17:24:29.811: INFO: Pod pod-configmaps-7c8735ab-5bb5-11e9-8040-3209cfee711a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:24:29.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1322" for this suite.
Apr 10 17:24:37.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:24:37.957: INFO: namespace configmap-1322 deletion completed in 8.14209113s

• [SLOW TEST:13.837 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:24:37.960: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:24:38.488: INFO: Creating ReplicaSet my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a
Apr 10 17:24:38.853: INFO: Pod name my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a: Found 0 pods out of 1
Apr 10 17:24:43.858: INFO: Pod name my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a: Found 1 pods out of 1
Apr 10 17:24:43.858: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a" is running
Apr 10 17:24:43.862: INFO: Pod "my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a-wmrpk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 17:24:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 17:24:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 17:24:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-10 17:24:38 +0000 UTC Reason: Message:}])
Apr 10 17:24:43.862: INFO: Trying to dial the pod
Apr 10 17:24:49.064: INFO: Controller my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a: Got expected result from replica 1 [my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a-wmrpk]: "my-hostname-basic-84b08d58-5bb5-11e9-8040-3209cfee711a-wmrpk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:24:49.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1319" for this suite.
Apr 10 17:24:57.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:24:57.258: INFO: namespace replicaset-1319 deletion completed in 8.19100457s

• [SLOW TEST:19.299 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:24:57.258: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3991
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3991
STEP: Creating statefulset with conflicting port in namespace statefulset-3991
STEP: Waiting until pod test-pod will start running in namespace statefulset-3991
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3991
Apr 10 17:25:02.873: INFO: Observed stateful pod in namespace: statefulset-3991, name: ss-0, uid: 932c0734-5bb5-11e9-b4c9-5254005baff5, status phase: Pending. Waiting for statefulset controller to delete.
Apr 10 17:25:03.151: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3991
STEP: Removing pod with conflicting port in namespace statefulset-3991
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3991 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 10 17:25:08.519: INFO: Deleting all statefulset in ns statefulset-3991
Apr 10 17:25:08.522: INFO: Scaling statefulset ss to 0
Apr 10 17:25:18.726: INFO: Waiting for statefulset status.replicas updated to 0
Apr 10 17:25:18.729: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:25:18.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3991" for this suite.
Apr 10 17:25:29.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:25:29.337: INFO: namespace statefulset-3991 deletion completed in 10.36840702s

• [SLOW TEST:32.079 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:25:29.338: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 10 17:25:30.541: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:30.543: INFO: Number of nodes with available pods: 0
Apr 10 17:25:30.543: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:31.749: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:31.755: INFO: Number of nodes with available pods: 0
Apr 10 17:25:31.755: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:32.607: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:33.047: INFO: Number of nodes with available pods: 0
Apr 10 17:25:33.047: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:33.741: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:34.061: INFO: Number of nodes with available pods: 0
Apr 10 17:25:34.061: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:34.551: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:34.626: INFO: Number of nodes with available pods: 1
Apr 10 17:25:34.626: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:35.677: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:35.682: INFO: Number of nodes with available pods: 2
Apr 10 17:25:35.682: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 10 17:25:35.988: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:36.059: INFO: Number of nodes with available pods: 1
Apr 10 17:25:36.059: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:37.122: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:37.194: INFO: Number of nodes with available pods: 1
Apr 10 17:25:37.194: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:38.063: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:38.066: INFO: Number of nodes with available pods: 1
Apr 10 17:25:38.066: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:39.064: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:39.066: INFO: Number of nodes with available pods: 1
Apr 10 17:25:39.066: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:40.070: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:40.073: INFO: Number of nodes with available pods: 1
Apr 10 17:25:40.073: INFO: Node e173 is running more than one daemon pod
Apr 10 17:25:41.064: INFO: DaemonSet pods can't tolerate node d101 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 10 17:25:41.069: INFO: Number of nodes with available pods: 2
Apr 10 17:25:41.069: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5343, will wait for the garbage collector to delete the pods
Apr 10 17:25:41.138: INFO: Deleting DaemonSet.extensions daemon-set took: 10.010528ms
Apr 10 17:25:41.439: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.179966ms
Apr 10 17:25:44.046: INFO: Number of nodes with available pods: 0
Apr 10 17:25:44.046: INFO: Number of running nodes: 0, number of available pods: 0
Apr 10 17:25:44.048: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5343/daemonsets","resourceVersion":"24142"},"items":null}

Apr 10 17:25:44.050: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5343/pods","resourceVersion":"24142"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:25:44.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5343" for this suite.
Apr 10 17:25:54.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:25:54.578: INFO: namespace daemonsets-5343 deletion completed in 10.517475789s

• [SLOW TEST:25.240 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:25:54.578: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:25:55.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 version --client'
Apr 10 17:25:55.419: INFO: stderr: ""
Apr 10 17:25:55.419: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 10 17:25:55.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-6627'
Apr 10 17:25:55.942: INFO: stderr: ""
Apr 10 17:25:55.942: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 10 17:25:55.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 create -f - --namespace=kubectl-6627'
Apr 10 17:25:56.980: INFO: stderr: ""
Apr 10 17:25:56.980: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 10 17:25:57.984: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:25:57.984: INFO: Found 0 / 1
Apr 10 17:25:59.160: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:25:59.160: INFO: Found 0 / 1
Apr 10 17:26:00.098: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:26:00.098: INFO: Found 1 / 1
Apr 10 17:26:00.099: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 10 17:26:00.102: INFO: Selector matched 1 pods for map[app:redis]
Apr 10 17:26:00.102: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 10 17:26:00.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 describe pod redis-master-njrzh --namespace=kubectl-6627'
Apr 10 17:26:00.356: INFO: stderr: ""
Apr 10 17:26:00.356: INFO: stdout: "Name:               redis-master-njrzh\nNamespace:          kubectl-6627\nPriority:           0\nPriorityClassName:  <none>\nNode:               g168/10.160.67.168\nStart Time:         Wed, 10 Apr 2019 17:25:56 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.243\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   cri-o://89e28feb2b328908f41bd392b153f576a1e0c1f80305d856a54df13b6b275478\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 10 Apr 2019 17:25:58 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ffw7f (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-ffw7f:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-ffw7f\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason            Age              From               Message\n  ----     ------            ----             ----               -------\n  Normal   Scheduled         4s               default-scheduler  Successfully assigned kubectl-6627/redis-master-njrzh to g168\n  Normal   Pulled            2s               kubelet, g168      Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal   Created           2s               kubelet, g168      Created container redis-master\n  Warning  DNSConfigForming  1s (x3 over 3s)  kubelet, g168      Search Line limits were exceeded, some search paths have been omitted, the applied search line is: kubectl-6627.svc.cluster.local svc.cluster.local cluster.local suse.de arch.suse.de nue.suse.com\n  Normal   Started           1s               kubelet, g168      Started container redis-master\n"
Apr 10 17:26:00.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 describe rc redis-master --namespace=kubectl-6627'
Apr 10 17:26:00.446: INFO: stderr: ""
Apr 10 17:26:00.446: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6627\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-njrzh\n"
Apr 10 17:26:00.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 describe service redis-master --namespace=kubectl-6627'
Apr 10 17:26:00.536: INFO: stderr: ""
Apr 10 17:26:00.536: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6627\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.111.134.103\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.243:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 10 17:26:00.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 describe node d101'
Apr 10 17:26:01.039: INFO: stderr: ""
Apr 10 17:26:01.039: INFO: stdout: "Name:               d101\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=d101\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"0a:cd:0e:3b:0a:be\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.160.64.101\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 10 Apr 2019 15:18:00 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 10 Apr 2019 17:25:46 +0000   Wed, 10 Apr 2019 15:17:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 10 Apr 2019 17:25:46 +0000   Wed, 10 Apr 2019 15:17:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 10 Apr 2019 17:25:46 +0000   Wed, 10 Apr 2019 15:17:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 10 Apr 2019 17:25:46 +0000   Wed, 10 Apr 2019 15:21:50 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.160.64.101\n  Hostname:    d101\nCapacity:\n cpu:                2\n ephemeral-storage:  20615148Ki\n hugepages-2Mi:      0\n memory:             3794880Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  18998920366\n hugepages-2Mi:      0\n memory:             3692480Ki\n pods:               110\nSystem Info:\n Machine ID:                 e1978cfcfe9b4fcc9b375d82a244e512\n System UUID:                e1978cfc-fe9b-4fcc-9b37-5d82a244e512\n Boot ID:                    aede0576-e090-47b0-8b17-75e77ca0c4dc\n Kernel Version:             5.0.6-1-default\n OS Image:                   openSUSE MicroOS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  cri-o://1.14.0\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-87a756505d084484-d926j    0 (0%)        0 (0%)      0 (0%)           0 (0%)         118m\n  kube-system                coredns-fb8b8dccf-6prp7                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     127m\n  kube-system                coredns-fb8b8dccf-fmv5b                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     127m\n  kube-system                etcd-d101                                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  kube-system                kube-apiserver-d101                                        250m (12%)    0 (0%)      0 (0%)           0 (0%)         126m\n  kube-system                kube-controller-manager-d101                               200m (10%)    0 (0%)      0 (0%)           0 (0%)         126m\n  kube-system                kube-flannel-ds-amd64-r6nqz                                100m (5%)     100m (5%)   50Mi (1%)        50Mi (1%)      124m\n  kube-system                kube-proxy-htxgj                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  kube-system                kube-scheduler-d101                                        100m (5%)     0 (0%)      0 (0%)           0 (0%)         126m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (42%)  100m (5%)\n  memory             190Mi (5%)  390Mi (10%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr 10 17:26:01.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 describe namespace kubectl-6627'
Apr 10 17:26:01.133: INFO: stderr: ""
Apr 10 17:26:01.133: INFO: stdout: "Name:         kubectl-6627\nLabels:       e2e-framework=kubectl\n              e2e-run=47f1ac0b-5ba5-11e9-8040-3209cfee711a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:26:01.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6627" for this suite.
Apr 10 17:26:27.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:26:27.257: INFO: namespace kubectl-6627 deletion completed in 26.122169772s

• [SLOW TEST:32.679 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:26:27.258: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-2168
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2168
STEP: Deleting pre-stop pod
Apr 10 17:26:45.501: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:26:45.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2168" for this suite.
Apr 10 17:27:28.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:27:28.198: INFO: namespace prestop-2168 deletion completed in 42.36746586s

• [SLOW TEST:60.941 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:27:28.198: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:27:28.791: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 10 17:27:33.796: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 10 17:27:33.796: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 10 17:27:35.800: INFO: Creating deployment "test-rollover-deployment"
Apr 10 17:27:35.984: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 10 17:27:38.108: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 10 17:27:38.189: INFO: Ensure that both replica sets have 1 created replica
Apr 10 17:27:38.196: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 10 17:27:38.203: INFO: Updating deployment test-rollover-deployment
Apr 10 17:27:38.203: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 10 17:27:40.412: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 10 17:27:40.484: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 10 17:27:40.488: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:40.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514059, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:42.689: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:42.690: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:44.496: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:44.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:46.587: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:46.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:48.497: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:48.497: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:50.606: INFO: all replica sets need to contain the pod-template-hash label
Apr 10 17:27:50.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:52.998: INFO: 
Apr 10 17:27:52.998: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514062, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690514056, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 10 17:27:54.579: INFO: 
Apr 10 17:27:54.579: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 10 17:27:54.587: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6360,SelfLink:/apis/apps/v1/namespaces/deployment-6360/deployments/test-rollover-deployment,UID:ee60661f-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:24556,Generation:2,CreationTimestamp:2019-04-10 17:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-10 17:27:36 +0000 UTC 2019-04-10 17:27:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-10 17:27:53 +0000 UTC 2019-04-10 17:27:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 10 17:27:54.591: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-6360,SelfLink:/apis/apps/v1/namespaces/deployment-6360/replicasets/test-rollover-deployment-766b4d6c9d,UID:efcf1c3f-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:24543,Generation:2,CreationTimestamp:2019-04-10 17:27:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee60661f-5bb5-11e9-b4c9-5254005baff5 0xc0027a9347 0xc0027a9348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 10 17:27:54.591: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 10 17:27:54.591: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6360,SelfLink:/apis/apps/v1/namespaces/deployment-6360/replicasets/test-rollover-controller,UID:ea0cda04-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:24554,Generation:2,CreationTimestamp:2019-04-10 17:27:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee60661f-5bb5-11e9-b4c9-5254005baff5 0xc0027a9167 0xc0027a9168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 17:27:54.591: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-6360,SelfLink:/apis/apps/v1/namespaces/deployment-6360/replicasets/test-rollover-deployment-6455657675,UID:ee87f0fb-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:24509,Generation:2,CreationTimestamp:2019-04-10 17:27:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee60661f-5bb5-11e9-b4c9-5254005baff5 0xc0027a9247 0xc0027a9248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 10 17:27:54.594: INFO: Pod "test-rollover-deployment-766b4d6c9d-6gl27" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-6gl27,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-6360,SelfLink:/api/v1/namespaces/deployment-6360/pods/test-rollover-deployment-766b4d6c9d-6gl27,UID:f0555177-5bb5-11e9-b4c9-5254005baff5,ResourceVersion:24522,Generation:0,CreationTimestamp:2019-04-10 17:27:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d efcf1c3f-5bb5-11e9-b4c9-5254005baff5 0xc0024ec177 0xc0024ec178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-455pt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-455pt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-455pt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:g168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ec1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ec290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:27:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-10 17:27:39 +0000 UTC  }],Message:,Reason:,HostIP:10.160.67.168,PodIP:10.244.1.246,StartTime:2019-04-10 17:27:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-10 17:27:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://c5c25f30c00b27884b911fb0199bbca6b9799b4b5e88faa468093f9224b22bad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:27:54.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6360" for this suite.
Apr 10 17:28:08.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:28:08.936: INFO: namespace deployment-6360 deletion completed in 14.338209396s

• [SLOW TEST:40.737 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:28:08.937: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:28:15.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4620" for this suite.
Apr 10 17:28:55.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:28:55.444: INFO: namespace kubelet-test-4620 deletion completed in 40.357403692s

• [SLOW TEST:46.507 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:28:55.446: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 10 17:28:56.086: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-646907027 proxy --unix-socket=/tmp/kubectl-proxy-unix405959786/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:28:56.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8549" for this suite.
Apr 10 17:29:02.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:29:02.927: INFO: namespace kubectl-8549 deletion completed in 6.570558766s

• [SLOW TEST:7.482 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 10 17:29:02.927: INFO: >>> kubeConfig: /tmp/kubeconfig-646907027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 10 17:29:03.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-646907027 version'
Apr 10 17:29:03.712: INFO: stderr: ""
Apr 10 17:29:03.712: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 10 17:29:03.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7346" for this suite.
Apr 10 17:29:09.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 10 17:29:09.958: INFO: namespace kubectl-7346 deletion completed in 6.24121258s

• [SLOW TEST:7.031 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSApr 10 17:29:09.959: INFO: Running AfterSuite actions on all nodes
Apr 10 17:29:09.960: INFO: Running AfterSuite actions on node 1
Apr 10 17:29:09.960: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 7244.428 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 2h0m45.453950673s
Test Suite Passed
