I0423 08:52:00.770019      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-994727835
I0423 08:52:00.770579      16 e2e.go:240] Starting e2e run "0e303eb1-65a5-11e9-b8ea-e2349624188d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556009519 - Will randomize all specs
Will run 204 of 3584 specs

Apr 23 08:52:01.119: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 08:52:01.125: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 23 08:52:01.164: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 23 08:52:01.205: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 23 08:52:01.205: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Apr 23 08:52:01.205: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 23 08:52:01.214: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 23 08:52:01.214: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 23 08:52:01.214: INFO: e2e test version: v1.14.1
Apr 23 08:52:01.216: INFO: kube-apiserver version: v1.14.1
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:52:01.216: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename namespaces
Apr 23 08:52:01.265: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:52:07.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1555" for this suite.
Apr 23 08:52:13.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:52:13.500: INFO: namespace namespaces-1555 deletion completed in 6.123530223s
STEP: Destroying namespace "nsdeletetest-5713" for this suite.
Apr 23 08:52:13.503: INFO: Namespace nsdeletetest-5713 was already deleted
STEP: Destroying namespace "nsdeletetest-293" for this suite.
Apr 23 08:52:19.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:52:19.608: INFO: namespace nsdeletetest-293 deletion completed in 6.104891505s

• [SLOW TEST:18.392 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:52:19.608: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 08:52:19.661: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:52:25.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2093" for this suite.
Apr 23 08:53:15.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:53:15.856: INFO: namespace pods-2093 deletion completed in 50.150456129s

• [SLOW TEST:56.248 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:53:15.857: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:53:42.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5405" for this suite.
Apr 23 08:53:48.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:53:48.185: INFO: namespace namespaces-5405 deletion completed in 6.117011493s
STEP: Destroying namespace "nsdeletetest-8322" for this suite.
Apr 23 08:53:48.188: INFO: Namespace nsdeletetest-8322 was already deleted
STEP: Destroying namespace "nsdeletetest-1439" for this suite.
Apr 23 08:53:54.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:53:54.326: INFO: namespace nsdeletetest-1439 deletion completed in 6.138043861s

• [SLOW TEST:38.469 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:53:54.327: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 08:53:54.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-824'
Apr 23 08:53:54.728: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 23 08:53:54.729: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 23 08:53:54.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete jobs e2e-test-nginx-job --namespace=kubectl-824'
Apr 23 08:53:54.833: INFO: stderr: ""
Apr 23 08:53:54.834: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:53:54.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-824" for this suite.
Apr 23 08:54:00.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:54:00.950: INFO: namespace kubectl-824 deletion completed in 6.110063971s

• [SLOW TEST:6.623 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:54:00.950: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 08:54:01.002: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d" in namespace "projected-9950" to be "success or failure"
Apr 23 08:54:01.008: INFO: Pod "downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.683107ms
Apr 23 08:54:03.012: INFO: Pod "downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009425531s
Apr 23 08:54:05.021: INFO: Pod "downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018944484s
STEP: Saw pod success
Apr 23 08:54:05.021: INFO: Pod "downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 08:54:05.025: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 08:54:05.077: INFO: Waiting for pod downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d to disappear
Apr 23 08:54:05.079: INFO: Pod downwardapi-volume-56b06228-65a5-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:54:05.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9950" for this suite.
Apr 23 08:54:11.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:54:11.181: INFO: namespace projected-9950 deletion completed in 6.098804924s

• [SLOW TEST:10.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:54:11.181: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 08:54:11.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-157'
Apr 23 08:54:11.302: INFO: stderr: ""
Apr 23 08:54:11.302: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 23 08:54:11.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete pods e2e-test-nginx-pod --namespace=kubectl-157'
Apr 23 08:54:23.329: INFO: stderr: ""
Apr 23 08:54:23.329: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:54:23.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-157" for this suite.
Apr 23 08:54:29.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:54:29.433: INFO: namespace kubectl-157 deletion completed in 6.099941848s

• [SLOW TEST:18.252 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:54:29.434: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 23 08:54:36.010: INFO: Successfully updated pod "pod-update-67aa1648-65a5-11e9-b8ea-e2349624188d"
STEP: verifying the updated pod is in kubernetes
Apr 23 08:54:36.018: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:54:36.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1193" for this suite.
Apr 23 08:55:08.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:55:08.123: INFO: namespace pods-1193 deletion completed in 32.100561126s

• [SLOW TEST:38.689 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:55:08.123: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 23 08:55:12.708: INFO: Successfully updated pod "annotationupdate7eba3078-65a5-11e9-b8ea-e2349624188d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:55:14.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4145" for this suite.
Apr 23 08:55:36.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:55:36.849: INFO: namespace downward-api-4145 deletion completed in 22.113883492s

• [SLOW TEST:28.726 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:55:36.849: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 23 08:55:37.124: INFO: Pod name wrapped-volume-race-8ffaf04d-65a5-11e9-b8ea-e2349624188d: Found 0 pods out of 5
Apr 23 08:55:42.133: INFO: Pod name wrapped-volume-race-8ffaf04d-65a5-11e9-b8ea-e2349624188d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8ffaf04d-65a5-11e9-b8ea-e2349624188d in namespace emptydir-wrapper-6568, will wait for the garbage collector to delete the pods
Apr 23 08:55:56.231: INFO: Deleting ReplicationController wrapped-volume-race-8ffaf04d-65a5-11e9-b8ea-e2349624188d took: 9.10614ms
Apr 23 08:55:56.631: INFO: Terminating ReplicationController wrapped-volume-race-8ffaf04d-65a5-11e9-b8ea-e2349624188d pods took: 400.349242ms
STEP: Creating RC which spawns configmap-volume pods
Apr 23 08:56:33.848: INFO: Pod name wrapped-volume-race-b1c9de65-65a5-11e9-b8ea-e2349624188d: Found 0 pods out of 5
Apr 23 08:56:38.853: INFO: Pod name wrapped-volume-race-b1c9de65-65a5-11e9-b8ea-e2349624188d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b1c9de65-65a5-11e9-b8ea-e2349624188d in namespace emptydir-wrapper-6568, will wait for the garbage collector to delete the pods
Apr 23 08:56:50.960: INFO: Deleting ReplicationController wrapped-volume-race-b1c9de65-65a5-11e9-b8ea-e2349624188d took: 14.224325ms
Apr 23 08:56:51.260: INFO: Terminating ReplicationController wrapped-volume-race-b1c9de65-65a5-11e9-b8ea-e2349624188d pods took: 300.263426ms
STEP: Creating RC which spawns configmap-volume pods
Apr 23 08:57:34.382: INFO: Pod name wrapped-volume-race-d5ddebb2-65a5-11e9-b8ea-e2349624188d: Found 0 pods out of 5
Apr 23 08:57:39.387: INFO: Pod name wrapped-volume-race-d5ddebb2-65a5-11e9-b8ea-e2349624188d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d5ddebb2-65a5-11e9-b8ea-e2349624188d in namespace emptydir-wrapper-6568, will wait for the garbage collector to delete the pods
Apr 23 08:57:51.487: INFO: Deleting ReplicationController wrapped-volume-race-d5ddebb2-65a5-11e9-b8ea-e2349624188d took: 12.580337ms
Apr 23 08:57:51.887: INFO: Terminating ReplicationController wrapped-volume-race-d5ddebb2-65a5-11e9-b8ea-e2349624188d pods took: 400.281448ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:58:34.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6568" for this suite.
Apr 23 08:58:42.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:58:42.840: INFO: namespace emptydir-wrapper-6568 deletion completed in 8.095872777s

• [SLOW TEST:185.991 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:58:42.841: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-feb48de2-65a5-11e9-b8ea-e2349624188d
STEP: Creating secret with name s-test-opt-upd-feb48e26-65a5-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-feb48de2-65a5-11e9-b8ea-e2349624188d
STEP: Updating secret s-test-opt-upd-feb48e26-65a5-11e9-b8ea-e2349624188d
STEP: Creating secret with name s-test-opt-create-feb48e3a-65a5-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:58:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9581" for this suite.
Apr 23 08:59:13.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:59:13.118: INFO: namespace secrets-9581 deletion completed in 22.121301024s

• [SLOW TEST:30.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:59:13.118: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 23 08:59:13.200: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 08:59:13.207: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 08:59:13.210: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-1 before test
Apr 23 08:59:13.216: INFO: calico-node-4l587 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.216: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 08:59:13.216: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 08:59:13.216: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-n6xl5 from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.216: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 08:59:13.216: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 08:59:13.217: INFO: kube-proxy-j8vr9 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.217: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 08:59:13.217: INFO: tiller-deploy-548df79d66-dltk9 from kube-system started at 2019-04-23 08:46:23 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.217: INFO: 	Container tiller ready: true, restart count 0
Apr 23 08:59:13.217: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-2 before test
Apr 23 08:59:13.232: INFO: kube-proxy-h6snt from kube-system started at 2019-04-23 08:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.232: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 08:59:13.232: INFO: calico-node-fzh7c from kube-system started at 2019-04-23 08:45:47 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.232: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 08:59:13.232: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 08:59:13.232: INFO: kubernetes-dashboard-b7c58947-55jg6 from kube-system started at 2019-04-23 08:46:48 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.232: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 23 08:59:13.232: INFO: sonobuoy-e2e-job-831cbf02ea2f4cb0 from heptio-sonobuoy started at 2019-04-23 08:51:32 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.232: INFO: 	Container e2e ready: true, restart count 0
Apr 23 08:59:13.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 08:59:13.232: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-zxr7k from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.232: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 08:59:13.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 08:59:13.232: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-3 before test
Apr 23 08:59:13.241: INFO: calico-node-l4kn7 from kube-system started at 2019-04-23 08:45:34 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.241: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 08:59:13.241: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 08:59:13.241: INFO: kube-proxy-jchgb from kube-system started at 2019-04-23 08:45:34 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.241: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 08:59:13.241: INFO: heapster-f7fb9fb4f-85kn9 from kube-system started at 2019-04-23 08:46:47 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.241: INFO: 	Container heapster ready: true, restart count 0
Apr 23 08:59:13.241: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-23 08:51:27 +0000 UTC (1 container statuses recorded)
Apr 23 08:59:13.241: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 08:59:13.241: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-72vdb from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 08:59:13.241: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 08:59:13.241: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-13360bd2-65a6-11e9-b8ea-e2349624188d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-13360bd2-65a6-11e9-b8ea-e2349624188d off the node net1a83gn1-worker-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-13360bd2-65a6-11e9-b8ea-e2349624188d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:59:21.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3373" for this suite.
Apr 23 08:59:35.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:59:35.458: INFO: namespace sched-pred-3373 deletion completed in 14.118693665s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.340 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:59:35.458: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 23 08:59:35.494: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994727835 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 08:59:35.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-123" for this suite.
Apr 23 08:59:41.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 08:59:41.673: INFO: namespace kubectl-123 deletion completed in 6.105479713s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 08:59:41.674: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:00:41.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9273" for this suite.
Apr 23 09:01:03.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:01:03.836: INFO: namespace container-probe-9273 deletion completed in 22.099678096s

• [SLOW TEST:82.162 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:01:03.836: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 23 09:01:03.888: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 23 09:01:03.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:04.155: INFO: stderr: ""
Apr 23 09:01:04.155: INFO: stdout: "service/redis-slave created\n"
Apr 23 09:01:04.155: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 23 09:01:04.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:04.377: INFO: stderr: ""
Apr 23 09:01:04.377: INFO: stdout: "service/redis-master created\n"
Apr 23 09:01:04.377: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 23 09:01:04.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:04.593: INFO: stderr: ""
Apr 23 09:01:04.593: INFO: stdout: "service/frontend created\n"
Apr 23 09:01:04.593: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 23 09:01:04.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:04.797: INFO: stderr: ""
Apr 23 09:01:04.797: INFO: stdout: "deployment.apps/frontend created\n"
Apr 23 09:01:04.797: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 23 09:01:04.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:05.025: INFO: stderr: ""
Apr 23 09:01:05.025: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 23 09:01:05.025: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 23 09:01:05.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-8174'
Apr 23 09:01:05.300: INFO: stderr: ""
Apr 23 09:01:05.300: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 23 09:01:05.300: INFO: Waiting for all frontend pods to be Running.
Apr 23 09:01:25.351: INFO: Waiting for frontend to serve content.
Apr 23 09:01:25.364: INFO: Trying to add a new entry to the guestbook.
Apr 23 09:01:25.378: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 23 09:01:25.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:25.487: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:25.487: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 23 09:01:25.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:25.619: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:25.619: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 23 09:01:25.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:25.741: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:25.741: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 23 09:01:25.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:25.850: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:25.850: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 23 09:01:25.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:25.935: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:25.935: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 23 09:01:25.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-8174'
Apr 23 09:01:26.014: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:01:26.014: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:01:26.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8174" for this suite.
Apr 23 09:02:06.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:02:06.119: INFO: namespace kubectl-8174 deletion completed in 40.100803984s

• [SLOW TEST:62.283 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:02:06.119: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-77de18da-65a6-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:02:06.165: INFO: Waiting up to 5m0s for pod "pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d" in namespace "secrets-9089" to be "success or failure"
Apr 23 09:02:06.172: INFO: Pod "pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.02276ms
Apr 23 09:02:08.175: INFO: Pod "pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01065376s
Apr 23 09:02:10.181: INFO: Pod "pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016516741s
STEP: Saw pod success
Apr 23 09:02:10.181: INFO: Pod "pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:02:10.184: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:02:10.204: INFO: Waiting for pod pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d to disappear
Apr 23 09:02:10.207: INFO: Pod pod-secrets-77deb864-65a6-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:02:10.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9089" for this suite.
Apr 23 09:02:16.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:02:16.303: INFO: namespace secrets-9089 deletion completed in 6.09219398s

• [SLOW TEST:10.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:02:16.303: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-7df07b99-65a6-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:02:16.353: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d" in namespace "projected-8004" to be "success or failure"
Apr 23 09:02:16.356: INFO: Pod "pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.030537ms
Apr 23 09:02:18.360: INFO: Pod "pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007024824s
Apr 23 09:02:20.364: INFO: Pod "pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011069377s
STEP: Saw pod success
Apr 23 09:02:20.364: INFO: Pod "pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:02:20.367: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:02:20.388: INFO: Waiting for pod pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d to disappear
Apr 23 09:02:20.391: INFO: Pod pod-projected-configmaps-7df145d2-65a6-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:02:20.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8004" for this suite.
Apr 23 09:02:26.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:02:26.545: INFO: namespace projected-8004 deletion completed in 6.15045895s

• [SLOW TEST:10.243 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:02:26.546: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 23 09:02:26.596: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:02:31.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3858" for this suite.
Apr 23 09:02:53.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:02:53.112: INFO: namespace init-container-3858 deletion completed in 22.10113441s

• [SLOW TEST:26.567 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:02:53.112: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-4528/configmap-test-93e20879-65a6-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:02:53.168: INFO: Waiting up to 5m0s for pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d" in namespace "configmap-4528" to be "success or failure"
Apr 23 09:02:53.175: INFO: Pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.210582ms
Apr 23 09:02:55.179: INFO: Pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011304765s
Apr 23 09:02:57.183: INFO: Pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015087413s
Apr 23 09:02:59.187: INFO: Pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019138467s
STEP: Saw pod success
Apr 23 09:02:59.187: INFO: Pod "pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:02:59.190: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d container env-test: <nil>
STEP: delete the pod
Apr 23 09:02:59.210: INFO: Waiting for pod pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d to disappear
Apr 23 09:02:59.213: INFO: Pod pod-configmaps-93e2bb0f-65a6-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:02:59.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4528" for this suite.
Apr 23 09:03:05.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:03:05.319: INFO: namespace configmap-4528 deletion completed in 6.103084632s

• [SLOW TEST:12.207 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:03:05.319: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:03:29.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1095" for this suite.
Apr 23 09:03:35.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:03:35.696: INFO: namespace container-runtime-1095 deletion completed in 6.10936655s

• [SLOW TEST:30.376 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:03:35.696: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:03:35.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d" in namespace "projected-1512" to be "success or failure"
Apr 23 09:03:35.772: INFO: Pod "downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.524669ms
Apr 23 09:03:37.776: INFO: Pod "downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00636006s
Apr 23 09:03:39.779: INFO: Pod "downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010001372s
STEP: Saw pod success
Apr 23 09:03:39.779: INFO: Pod "downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:03:39.782: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:03:39.802: INFO: Waiting for pod downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d to disappear
Apr 23 09:03:39.804: INFO: Pod downwardapi-volume-ad4707af-65a6-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:03:39.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1512" for this suite.
Apr 23 09:03:45.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:03:45.910: INFO: namespace projected-1512 deletion completed in 6.101924831s

• [SLOW TEST:10.214 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:03:45.911: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 09:03:45.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4347'
Apr 23 09:03:46.031: INFO: stderr: ""
Apr 23 09:03:46.031: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 23 09:03:56.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pod e2e-test-nginx-pod --namespace=kubectl-4347 -o json'
Apr 23 09:03:56.351: INFO: stderr: ""
Apr 23 09:03:56.351: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.1.29/32\"\n        },\n        \"creationTimestamp\": \"2019-04-23T09:03:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4347\",\n        \"resourceVersion\": \"4461\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4347/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b3646a5e-65a6-11e9-be4b-42010a8a0fda\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2tncd\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"net1a83gn1-worker-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2tncd\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2tncd\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-23T09:03:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-23T09:03:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-23T09:03:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-23T09:03:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://3f2226ab5619da896f185ca59faf24cd19f717c43fb6cf0ab349432575f63ae9\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-23T09:03:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.138.15.219\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.1.29\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-23T09:03:46Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 23 09:03:56.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 replace -f - --namespace=kubectl-4347'
Apr 23 09:03:56.573: INFO: stderr: ""
Apr 23 09:03:56.573: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 23 09:03:56.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete pods e2e-test-nginx-pod --namespace=kubectl-4347'
Apr 23 09:04:03.329: INFO: stderr: ""
Apr 23 09:04:03.329: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:04:03.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4347" for this suite.
Apr 23 09:04:09.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:04:09.443: INFO: namespace kubectl-4347 deletion completed in 6.108530319s

• [SLOW TEST:23.533 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:04:09.444: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:04:09.501: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d" in namespace "projected-7172" to be "success or failure"
Apr 23 09:04:09.508: INFO: Pod "downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.713784ms
Apr 23 09:04:11.512: INFO: Pod "downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011185635s
Apr 23 09:04:13.516: INFO: Pod "downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015295597s
STEP: Saw pod success
Apr 23 09:04:13.516: INFO: Pod "downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:04:13.519: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:04:13.542: INFO: Waiting for pod downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d to disappear
Apr 23 09:04:13.545: INFO: Pod downwardapi-volume-c161d8c4-65a6-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:04:13.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7172" for this suite.
Apr 23 09:04:19.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:04:19.666: INFO: namespace projected-7172 deletion completed in 6.116584413s

• [SLOW TEST:10.222 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:04:19.666: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 23 09:04:24.256: INFO: Successfully updated pod "labelsupdatec77974c0-65a6-11e9-b8ea-e2349624188d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:04:26.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9499" for this suite.
Apr 23 09:04:48.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:04:48.386: INFO: namespace projected-9499 deletion completed in 22.103057098s

• [SLOW TEST:28.720 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:04:48.387: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 23 09:04:48.443: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9057,SelfLink:/api/v1/namespaces/watch-9057/configmaps/e2e-watch-test-watch-closed,UID:d89761bb-65a6-11e9-be4b-42010a8a0fda,ResourceVersion:4639,Generation:0,CreationTimestamp:2019-04-23 09:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 23 09:04:48.443: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9057,SelfLink:/api/v1/namespaces/watch-9057/configmaps/e2e-watch-test-watch-closed,UID:d89761bb-65a6-11e9-be4b-42010a8a0fda,ResourceVersion:4640,Generation:0,CreationTimestamp:2019-04-23 09:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 23 09:04:48.466: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9057,SelfLink:/api/v1/namespaces/watch-9057/configmaps/e2e-watch-test-watch-closed,UID:d89761bb-65a6-11e9-be4b-42010a8a0fda,ResourceVersion:4641,Generation:0,CreationTimestamp:2019-04-23 09:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 23 09:04:48.467: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9057,SelfLink:/api/v1/namespaces/watch-9057/configmaps/e2e-watch-test-watch-closed,UID:d89761bb-65a6-11e9-be4b-42010a8a0fda,ResourceVersion:4642,Generation:0,CreationTimestamp:2019-04-23 09:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:04:48.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9057" for this suite.
Apr 23 09:04:54.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:04:54.578: INFO: namespace watch-9057 deletion completed in 6.107819675s

• [SLOW TEST:6.192 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:04:54.579: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4379
Apr 23 09:04:58.635: INFO: Started pod liveness-http in namespace container-probe-4379
STEP: checking the pod's current state and verifying that restartCount is present
Apr 23 09:04:58.637: INFO: Initial restart count of pod liveness-http is 0
Apr 23 09:05:12.666: INFO: Restart count of pod container-probe-4379/liveness-http is now 1 (14.028859223s elapsed)
Apr 23 09:05:32.706: INFO: Restart count of pod container-probe-4379/liveness-http is now 2 (34.06907969s elapsed)
Apr 23 09:05:52.763: INFO: Restart count of pod container-probe-4379/liveness-http is now 3 (54.125508614s elapsed)
Apr 23 09:06:12.805: INFO: Restart count of pod container-probe-4379/liveness-http is now 4 (1m14.167337473s elapsed)
Apr 23 09:07:12.924: INFO: Restart count of pod container-probe-4379/liveness-http is now 5 (2m14.287101757s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:07:12.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4379" for this suite.
Apr 23 09:07:18.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:07:19.067: INFO: namespace container-probe-4379 deletion completed in 6.110579388s

• [SLOW TEST:144.489 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:07:19.067: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 23 09:07:19.118: INFO: PodSpec: initContainers in spec.initContainers
Apr 23 09:08:04.169: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3268cc1f-65a7-11e9-b8ea-e2349624188d", GenerateName:"", Namespace:"init-container-1886", SelfLink:"/api/v1/namespaces/init-container-1886/pods/pod-init-3268cc1f-65a7-11e9-b8ea-e2349624188d", UID:"3269593c-65a7-11e9-be4b-42010a8a0fda", ResourceVersion:"5069", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691607239, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"118343717"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.1.31/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kj82v", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002410040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kj82v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kj82v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kj82v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0023cc788), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"net1a83gn1-worker-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002340000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023cc800)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023cc820)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0023cc828), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0023cc82c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691607239, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691607239, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691607239, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691607239, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.138.15.219", PodIP:"10.2.1.31", StartTime:(*v1.Time)(0xc0019a21a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00256c1c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00256c230)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://58f6388f4ab3d91ba3d54253475424b56a8bf85e9e4321df8a02205c0e4109e6"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0019a22a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0019a2220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:08:04.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1886" for this suite.
Apr 23 09:08:26.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:08:26.286: INFO: namespace init-container-1886 deletion completed in 22.107563462s

• [SLOW TEST:67.219 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:08:26.286: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 23 09:08:26.329: INFO: Waiting up to 5m0s for pod "client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d" in namespace "containers-7357" to be "success or failure"
Apr 23 09:08:26.332: INFO: Pod "client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.714698ms
Apr 23 09:08:28.336: INFO: Pod "client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006791013s
Apr 23 09:08:30.341: INFO: Pod "client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011156602s
STEP: Saw pod success
Apr 23 09:08:30.341: INFO: Pod "client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:08:30.343: INFO: Trying to get logs from node net1a83gn1-worker-3 pod client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:08:30.372: INFO: Waiting for pod client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:08:30.375: INFO: Pod client-containers-5a777bd8-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:08:30.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7357" for this suite.
Apr 23 09:08:36.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:08:36.482: INFO: namespace containers-7357 deletion completed in 6.102811171s

• [SLOW TEST:10.195 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:08:36.482: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1824
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 23 09:08:36.536: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 23 09:09:04.645: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.33:8080/dial?request=hostName&protocol=udp&host=10.2.2.17&port=8081&tries=1'] Namespace:pod-network-test-1824 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:09:04.645: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:09:04.870: INFO: Waiting for endpoints: map[]
Apr 23 09:09:04.873: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.33:8080/dial?request=hostName&protocol=udp&host=10.2.3.6&port=8081&tries=1'] Namespace:pod-network-test-1824 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:09:04.873: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:09:05.258: INFO: Waiting for endpoints: map[]
Apr 23 09:09:05.261: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.33:8080/dial?request=hostName&protocol=udp&host=10.2.1.32&port=8081&tries=1'] Namespace:pod-network-test-1824 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:09:05.261: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:09:05.558: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:09:05.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1824" for this suite.
Apr 23 09:09:27.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:09:27.689: INFO: namespace pod-network-test-1824 deletion completed in 22.124710871s

• [SLOW TEST:51.207 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:09:27.689: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-7f13b7d9-65a7-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:09:27.761: INFO: Waiting up to 5m0s for pod "pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d" in namespace "secrets-6866" to be "success or failure"
Apr 23 09:09:27.768: INFO: Pod "pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.048564ms
Apr 23 09:09:29.772: INFO: Pod "pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01105149s
Apr 23 09:09:31.776: INFO: Pod "pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015242297s
STEP: Saw pod success
Apr 23 09:09:31.776: INFO: Pod "pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:09:31.779: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:09:31.808: INFO: Waiting for pod pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:09:31.814: INFO: Pod pod-secrets-7f14c157-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:09:31.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6866" for this suite.
Apr 23 09:09:37.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:09:37.929: INFO: namespace secrets-6866 deletion completed in 6.110836881s

• [SLOW TEST:10.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:09:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 23 09:09:37.985: INFO: Waiting up to 5m0s for pod "downward-api-852c0840-65a7-11e9-b8ea-e2349624188d" in namespace "downward-api-3757" to be "success or failure"
Apr 23 09:09:37.991: INFO: Pod "downward-api-852c0840-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.878983ms
Apr 23 09:09:39.996: INFO: Pod "downward-api-852c0840-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010238063s
Apr 23 09:09:42.000: INFO: Pod "downward-api-852c0840-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014288544s
STEP: Saw pod success
Apr 23 09:09:42.000: INFO: Pod "downward-api-852c0840-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:09:42.003: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downward-api-852c0840-65a7-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:09:42.027: INFO: Waiting for pod downward-api-852c0840-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:09:42.031: INFO: Pod downward-api-852c0840-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:09:42.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3757" for this suite.
Apr 23 09:09:48.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:09:48.157: INFO: namespace downward-api-3757 deletion completed in 6.122577047s

• [SLOW TEST:10.228 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:09:48.158: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8b439d01-65a7-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:09:48.204: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d" in namespace "configmap-8038" to be "success or failure"
Apr 23 09:09:48.211: INFO: Pod "pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060382ms
Apr 23 09:09:50.215: INFO: Pod "pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01009684s
Apr 23 09:09:52.219: INFO: Pod "pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01404415s
STEP: Saw pod success
Apr 23 09:09:52.219: INFO: Pod "pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:09:52.221: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:09:52.245: INFO: Waiting for pod pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:09:52.248: INFO: Pod pod-configmaps-8b44463a-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:09:52.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8038" for this suite.
Apr 23 09:09:58.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:09:58.355: INFO: namespace configmap-8038 deletion completed in 6.102919721s

• [SLOW TEST:10.197 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:09:58.355: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:09:58.398: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d" in namespace "downward-api-2022" to be "success or failure"
Apr 23 09:09:58.405: INFO: Pod "downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.104484ms
Apr 23 09:10:00.410: INFO: Pod "downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011285344s
Apr 23 09:10:02.414: INFO: Pod "downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015496451s
STEP: Saw pod success
Apr 23 09:10:02.414: INFO: Pod "downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:02.417: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:10:02.484: INFO: Waiting for pod downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:02.489: INFO: Pod downwardapi-volume-9157b7e5-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:02.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2022" for this suite.
Apr 23 09:10:08.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:08.609: INFO: namespace downward-api-2022 deletion completed in 6.106353146s

• [SLOW TEST:10.254 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:08.610: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:10:08.656: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d" in namespace "downward-api-6470" to be "success or failure"
Apr 23 09:10:08.659: INFO: Pod "downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.262013ms
Apr 23 09:10:10.663: INFO: Pod "downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007192659s
Apr 23 09:10:12.667: INFO: Pod "downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011473392s
STEP: Saw pod success
Apr 23 09:10:12.667: INFO: Pod "downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:12.670: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:10:12.698: INFO: Waiting for pod downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:12.701: INFO: Pod downwardapi-volume-9774efdb-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:12.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6470" for this suite.
Apr 23 09:10:18.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:18.824: INFO: namespace downward-api-6470 deletion completed in 6.119439214s

• [SLOW TEST:10.214 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:18.824: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 23 09:10:18.868: INFO: Waiting up to 5m0s for pod "pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d" in namespace "emptydir-8851" to be "success or failure"
Apr 23 09:10:18.876: INFO: Pod "pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.818402ms
Apr 23 09:10:20.880: INFO: Pod "pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011742432s
Apr 23 09:10:22.884: INFO: Pod "pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015540101s
STEP: Saw pod success
Apr 23 09:10:22.884: INFO: Pod "pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:22.886: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:10:22.907: INFO: Waiting for pod pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:22.909: INFO: Pod pod-9d8b4a07-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:22.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8851" for this suite.
Apr 23 09:10:28.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:29.021: INFO: namespace emptydir-8851 deletion completed in 6.108102736s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:29.021: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 23 09:10:29.068: INFO: Waiting up to 5m0s for pod "client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d" in namespace "containers-92" to be "success or failure"
Apr 23 09:10:29.073: INFO: Pod "client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.431498ms
Apr 23 09:10:31.076: INFO: Pod "client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008074972s
Apr 23 09:10:33.080: INFO: Pod "client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011697132s
STEP: Saw pod success
Apr 23 09:10:33.080: INFO: Pod "client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:33.082: INFO: Trying to get logs from node net1a83gn1-worker-1 pod client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:10:33.107: INFO: Waiting for pod client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:33.110: INFO: Pod client-containers-a39fc987-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:33.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-92" for this suite.
Apr 23 09:10:39.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:39.214: INFO: namespace containers-92 deletion completed in 6.09982704s

• [SLOW TEST:10.193 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:39.214: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a9b4a0ba-65a7-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:10:39.280: INFO: Waiting up to 5m0s for pod "pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d" in namespace "configmap-8010" to be "success or failure"
Apr 23 09:10:39.292: INFO: Pod "pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.800483ms
Apr 23 09:10:41.296: INFO: Pod "pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015816849s
Apr 23 09:10:43.300: INFO: Pod "pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020025908s
STEP: Saw pod success
Apr 23 09:10:43.300: INFO: Pod "pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:43.303: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:10:43.334: INFO: Waiting for pod pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:43.336: INFO: Pod pod-configmaps-a9b57123-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:43.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8010" for this suite.
Apr 23 09:10:49.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:49.449: INFO: namespace configmap-8010 deletion completed in 6.109627168s

• [SLOW TEST:10.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:49.449: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:10:49.498: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d" in namespace "downward-api-9676" to be "success or failure"
Apr 23 09:10:49.503: INFO: Pod "downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.868035ms
Apr 23 09:10:51.507: INFO: Pod "downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009783579s
Apr 23 09:10:53.511: INFO: Pod "downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013917802s
STEP: Saw pod success
Apr 23 09:10:53.512: INFO: Pod "downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:10:53.514: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:10:53.555: INFO: Waiting for pod downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d to disappear
Apr 23 09:10:53.565: INFO: Pod downwardapi-volume-afcc5cea-65a7-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:10:53.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9676" for this suite.
Apr 23 09:10:59.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:10:59.674: INFO: namespace downward-api-9676 deletion completed in 6.103888448s

• [SLOW TEST:10.225 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:10:59.674: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5518
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 23 09:10:59.741: INFO: Found 0 stateful pods, waiting for 3
Apr 23 09:11:09.745: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:11:09.745: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:11:09.745: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Apr 23 09:11:19.745: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:11:19.745: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:11:19.745: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:11:19.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-5518 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:11:20.055: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:11:20.055: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:11:20.055: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 23 09:11:30.092: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 23 09:11:40.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-5518 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 09:11:40.397: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 09:11:40.397: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 09:11:40.397: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 09:11:50.417: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:11:50.417: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:11:50.417: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:11:50.417: INFO: Waiting for Pod statefulset-5518/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:12:00.424: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:12:00.424: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:12:00.424: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:12:10.424: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:12:10.424: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 09:12:10.424: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr 23 09:12:30.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-5518 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:12:30.733: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:12:30.733: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:12:30.733: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 09:12:40.769: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 23 09:12:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-5518 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 09:12:51.134: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 09:12:51.135: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 09:12:51.135: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 09:12:51.146: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:12:51.146: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:12:51.146: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:12:51.146: INFO: Waiting for Pod statefulset-5518/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:01.160: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:13:01.160: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:01.160: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:01.160: INFO: Waiting for Pod statefulset-5518/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:11.154: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:13:11.154: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:11.154: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 23 09:13:21.153: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Apr 23 09:13:21.153: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 23 09:13:31.154: INFO: Deleting all statefulset in ns statefulset-5518
Apr 23 09:13:31.156: INFO: Scaling statefulset ss2 to 0
Apr 23 09:14:11.171: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 09:14:11.174: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:14:11.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5518" for this suite.
Apr 23 09:14:17.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:14:17.318: INFO: namespace statefulset-5518 deletion completed in 6.126133161s

• [SLOW TEST:197.644 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:14:17.318: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-2bb4d29f-65a8-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:14:17.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d" in namespace "projected-7176" to be "success or failure"
Apr 23 09:14:17.390: INFO: Pod "pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.189348ms
Apr 23 09:14:19.393: INFO: Pod "pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007083856s
Apr 23 09:14:21.398: INFO: Pod "pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011880087s
STEP: Saw pod success
Apr 23 09:14:21.398: INFO: Pod "pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:14:21.401: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:14:21.431: INFO: Waiting for pod pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d to disappear
Apr 23 09:14:21.434: INFO: Pod pod-projected-configmaps-2bb59b4c-65a8-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:14:21.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7176" for this suite.
Apr 23 09:14:27.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:14:27.536: INFO: namespace projected-7176 deletion completed in 6.097215328s

• [SLOW TEST:10.217 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:14:27.536: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-4785
Apr 23 09:14:31.597: INFO: Started pod liveness-exec in namespace container-probe-4785
STEP: checking the pod's current state and verifying that restartCount is present
Apr 23 09:14:31.600: INFO: Initial restart count of pod liveness-exec is 0
Apr 23 09:15:17.697: INFO: Restart count of pod container-probe-4785/liveness-exec is now 1 (46.097045085s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:15:17.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4785" for this suite.
Apr 23 09:15:23.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:15:23.821: INFO: namespace container-probe-4785 deletion completed in 6.106388569s

• [SLOW TEST:56.286 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:15:23.822: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 23 09:15:23.895: INFO: Waiting up to 5m0s for pod "pod-53594b2c-65a8-11e9-b8ea-e2349624188d" in namespace "emptydir-5407" to be "success or failure"
Apr 23 09:15:23.900: INFO: Pod "pod-53594b2c-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133373ms
Apr 23 09:15:25.903: INFO: Pod "pod-53594b2c-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007334959s
Apr 23 09:15:27.911: INFO: Pod "pod-53594b2c-65a8-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015528211s
STEP: Saw pod success
Apr 23 09:15:27.911: INFO: Pod "pod-53594b2c-65a8-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:15:27.914: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-53594b2c-65a8-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:15:27.940: INFO: Waiting for pod pod-53594b2c-65a8-11e9-b8ea-e2349624188d to disappear
Apr 23 09:15:27.944: INFO: Pod pod-53594b2c-65a8-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:15:27.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5407" for this suite.
Apr 23 09:15:33.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:15:34.046: INFO: namespace emptydir-5407 deletion completed in 6.09749527s

• [SLOW TEST:10.224 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:15:34.046: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 23 09:15:34.136: INFO: Waiting up to 5m0s for pod "pod-5974cacc-65a8-11e9-b8ea-e2349624188d" in namespace "emptydir-9811" to be "success or failure"
Apr 23 09:15:34.139: INFO: Pod "pod-5974cacc-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.190149ms
Apr 23 09:15:36.150: INFO: Pod "pod-5974cacc-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013670199s
Apr 23 09:15:38.154: INFO: Pod "pod-5974cacc-65a8-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017443155s
STEP: Saw pod success
Apr 23 09:15:38.154: INFO: Pod "pod-5974cacc-65a8-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:15:38.156: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-5974cacc-65a8-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:15:38.185: INFO: Waiting for pod pod-5974cacc-65a8-11e9-b8ea-e2349624188d to disappear
Apr 23 09:15:38.188: INFO: Pod pod-5974cacc-65a8-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:15:38.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9811" for this suite.
Apr 23 09:15:44.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:15:44.323: INFO: namespace emptydir-9811 deletion completed in 6.125991065s

• [SLOW TEST:10.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:15:44.324: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 23 09:15:44.402: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 09:15:44.411: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 09:15:44.414: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-1 before test
Apr 23 09:15:44.419: INFO: calico-node-4l587 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.419: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 09:15:44.419: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 09:15:44.419: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-n6xl5 from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.419: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 09:15:44.419: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 09:15:44.419: INFO: kube-proxy-j8vr9 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.419: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 09:15:44.419: INFO: tiller-deploy-548df79d66-dltk9 from kube-system started at 2019-04-23 08:46:23 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.419: INFO: 	Container tiller ready: true, restart count 0
Apr 23 09:15:44.419: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-2 before test
Apr 23 09:15:44.426: INFO: kube-proxy-h6snt from kube-system started at 2019-04-23 08:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.426: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 09:15:44.426: INFO: calico-node-fzh7c from kube-system started at 2019-04-23 08:45:47 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.426: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 09:15:44.426: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 09:15:44.426: INFO: kubernetes-dashboard-b7c58947-55jg6 from kube-system started at 2019-04-23 08:46:48 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.426: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 23 09:15:44.426: INFO: sonobuoy-e2e-job-831cbf02ea2f4cb0 from heptio-sonobuoy started at 2019-04-23 08:51:32 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.426: INFO: 	Container e2e ready: true, restart count 0
Apr 23 09:15:44.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 09:15:44.426: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-zxr7k from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.426: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 09:15:44.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 09:15:44.426: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-3 before test
Apr 23 09:15:44.430: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-72vdb from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.431: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 23 09:15:44.431: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 09:15:44.431: INFO: calico-node-l4kn7 from kube-system started at 2019-04-23 08:45:34 +0000 UTC (2 container statuses recorded)
Apr 23 09:15:44.431: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 09:15:44.431: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 09:15:44.431: INFO: kube-proxy-jchgb from kube-system started at 2019-04-23 08:45:34 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.431: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 09:15:44.431: INFO: heapster-f7fb9fb4f-85kn9 from kube-system started at 2019-04-23 08:46:47 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.431: INFO: 	Container heapster ready: true, restart count 0
Apr 23 09:15:44.431: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-23 08:51:27 +0000 UTC (1 container statuses recorded)
Apr 23 09:15:44.431: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node net1a83gn1-worker-1
STEP: verifying the node has the label node net1a83gn1-worker-2
STEP: verifying the node has the label node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod sonobuoy requesting resource cpu=0m on Node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod sonobuoy-e2e-job-831cbf02ea2f4cb0 requesting resource cpu=0m on Node net1a83gn1-worker-2
Apr 23 09:15:44.504: INFO: Pod sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-72vdb requesting resource cpu=0m on Node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-n6xl5 requesting resource cpu=0m on Node net1a83gn1-worker-1
Apr 23 09:15:44.504: INFO: Pod sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-zxr7k requesting resource cpu=0m on Node net1a83gn1-worker-2
Apr 23 09:15:44.504: INFO: Pod calico-node-4l587 requesting resource cpu=250m on Node net1a83gn1-worker-1
Apr 23 09:15:44.504: INFO: Pod calico-node-fzh7c requesting resource cpu=250m on Node net1a83gn1-worker-2
Apr 23 09:15:44.504: INFO: Pod calico-node-l4kn7 requesting resource cpu=250m on Node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod heapster-f7fb9fb4f-85kn9 requesting resource cpu=0m on Node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod kube-proxy-h6snt requesting resource cpu=0m on Node net1a83gn1-worker-2
Apr 23 09:15:44.504: INFO: Pod kube-proxy-j8vr9 requesting resource cpu=0m on Node net1a83gn1-worker-1
Apr 23 09:15:44.504: INFO: Pod kube-proxy-jchgb requesting resource cpu=0m on Node net1a83gn1-worker-3
Apr 23 09:15:44.504: INFO: Pod kubernetes-dashboard-b7c58947-55jg6 requesting resource cpu=0m on Node net1a83gn1-worker-2
Apr 23 09:15:44.504: INFO: Pod tiller-deploy-548df79d66-dltk9 requesting resource cpu=0m on Node net1a83gn1-worker-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d.15980fb5bf5e0363], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2717/filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d to net1a83gn1-worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d.15980fb615e6a0d9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d.15980fb61db000a2], Reason = [Created], Message = [Created container filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d.15980fb631f07b99], Reason = [Started], Message = [Started container filler-pod-5fa49d32-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d.15980fb5bffee530], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2717/filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d to net1a83gn1-worker-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d.15980fb60dd3e0bd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d.15980fb6162f419b], Reason = [Created], Message = [Created container filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d.15980fb629c7cf11], Reason = [Started], Message = [Started container filler-pod-5fa67e4e-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d.15980fb5c08cd470], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2717/filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d to net1a83gn1-worker-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d.15980fb618e1b071], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d.15980fb620fe501b], Reason = [Created], Message = [Created container filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d.15980fb638e47e37], Reason = [Started], Message = [Started container filler-pod-5fa7e609-65a8-11e9-b8ea-e2349624188d]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15980fb6b00fdd6e], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node net1a83gn1-worker-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node net1a83gn1-worker-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node net1a83gn1-worker-1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:15:49.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2717" for this suite.
Apr 23 09:15:55.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:15:55.782: INFO: namespace sched-pred-2717 deletion completed in 6.122322942s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.459 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:15:55.783: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:15:55.834: INFO: Creating deployment "nginx-deployment"
Apr 23 09:15:55.839: INFO: Waiting for observed generation 1
Apr 23 09:15:57.847: INFO: Waiting for all required pods to come up
Apr 23 09:15:57.851: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 23 09:16:01.861: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 23 09:16:01.867: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 23 09:16:01.879: INFO: Updating deployment nginx-deployment
Apr 23 09:16:01.879: INFO: Waiting for observed generation 2
Apr 23 09:16:03.897: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 23 09:16:03.900: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 23 09:16:03.902: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 23 09:16:03.911: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 23 09:16:03.911: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 23 09:16:03.913: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 23 09:16:03.918: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 23 09:16:03.918: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 23 09:16:03.926: INFO: Updating deployment nginx-deployment
Apr 23 09:16:03.926: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 23 09:16:03.933: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 23 09:16:03.950: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 23 09:16:03.996: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2768,SelfLink:/apis/apps/v1/namespaces/deployment-2768/deployments/nginx-deployment,UID:66658c82-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6986,Generation:3,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-04-23 09:16:02 +0000 UTC 2019-04-23 09:15:55 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-04-23 09:16:03 +0000 UTC 2019-04-23 09:16:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 23 09:16:04.021: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-2768,SelfLink:/apis/apps/v1/namespaces/deployment-2768/replicasets/nginx-deployment-5f9595f595,UID:69ffdf89-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6979,Generation:3,CreationTimestamp:2019-04-23 09:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 66658c82-65a8-11e9-be4b-42010a8a0fda 0xc001ebd667 0xc001ebd668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:16:04.021: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 23 09:16:04.022: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-2768,SelfLink:/apis/apps/v1/namespaces/deployment-2768/replicasets/nginx-deployment-6f478d8d8,UID:66665932-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6976,Generation:3,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 66658c82-65a8-11e9-be4b-42010a8a0fda 0xc001ebd737 0xc001ebd738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 23 09:16:04.063: INFO: Pod "nginx-deployment-5f9595f595-29tlm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-29tlm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-29tlm,UID:6a128feb-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6959,Generation:0,CreationTimestamp:2019-04-23 09:16:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc001ebdff0 0xc001ebdff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f80c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:,StartTime:2019-04-23 09:16:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-4967j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4967j,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-4967j,UID:6a147cb0-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6970,Generation:0,CreationTimestamp:2019-04-23 09:16:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.49/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8360 0xc0016f8361}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:02 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:,StartTime:2019-04-23 09:16:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-5xtlp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5xtlp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-5xtlp,UID:6b419d80-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7030,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f85f0 0xc0016f85f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-6n474" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6n474,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-6n474,UID:6b3e7c5a-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7016,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8780 0xc0016f8781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f87f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-b6lx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b6lx5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-b6lx5,UID:6b3b82d2-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6995,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8890 0xc0016f8891}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-bwwhm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-bwwhm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-bwwhm,UID:6b4188c8-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7019,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8af0 0xc0016f8af1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.064: INFO: Pod "nginx-deployment-5f9595f595-d2s9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-d2s9x,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-d2s9x,UID:6a023a57-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6968,Generation:0,CreationTimestamp:2019-04-23 09:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.48/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8d10 0xc0016f8d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f8e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f8ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:,StartTime:2019-04-23 09:16:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-dg9cl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dg9cl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-dg9cl,UID:6a034af8-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6966,Generation:0,CreationTimestamp:2019-04-23 09:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f8ff0 0xc0016f8ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f90f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.220,PodIP:,StartTime:2019-04-23 09:16:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-hrvv9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hrvv9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-hrvv9,UID:6b410b9a-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7023,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f9300 0xc0016f9301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f9430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-sgbjk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-sgbjk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-sgbjk,UID:6a03676a-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6973,Generation:0,CreationTimestamp:2019-04-23 09:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.2.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f9560 0xc0016f9561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f9630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:01 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:,StartTime:2019-04-23 09:16:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-vz8vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vz8vg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-vz8vg,UID:6b48cfb2-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7027,Generation:0,CreationTimestamp:2019-04-23 09:16:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f9810 0xc0016f9811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f98f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-w9ttt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-w9ttt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-w9ttt,UID:6b3e9696-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7012,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f99f7 0xc0016f99f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f9ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-5f9595f595-xwjs5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xwjs5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-5f9595f595-xwjs5,UID:6b41946a-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7028,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 69ffdf89-65a8-11e9-be4b-42010a8a0fda 0xc0016f9ba0 0xc0016f9ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f9d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-6f478d8d8-46x6q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-46x6q,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-46x6q,UID:666e53f6-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6866,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.46/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0016f9e20 0xc0016f9e21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016f9ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016f9f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.46,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3c9b54f26be84e70ffb7087d59ec8ddada037a9b37c095ddec1fe650996b4bea}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.065: INFO: Pod "nginx-deployment-6f478d8d8-64qmr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-64qmr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-64qmr,UID:6b3d2912-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7014,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0016f9fd0 0xc0016f9fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.066: INFO: Pod "nginx-deployment-6f478d8d8-77755" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-77755,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-77755,UID:6b3a6b31-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6993,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0012900f0 0xc0012900f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012901e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.066: INFO: Pod "nginx-deployment-6f478d8d8-9d9vg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9d9vg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-9d9vg,UID:666e6ce0-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6906,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.12/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290310 0xc001290311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012903d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.220,PodIP:10.2.3.12,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e609ae78d517b4fa6fdfb2867be33786463c4311be621687154d5fac96d6c7ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.067: INFO: Pod "nginx-deployment-6f478d8d8-b2h57" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-b2h57,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-b2h57,UID:6b3d3264-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7011,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290530 0xc001290531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012905b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.067: INFO: Pod "nginx-deployment-6f478d8d8-cqbzn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cqbzn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-cqbzn,UID:6b3900fd-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7001,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0012906f0 0xc0012906f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:,StartTime:2019-04-23 09:16:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.067: INFO: Pod "nginx-deployment-6f478d8d8-gplk9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gplk9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-gplk9,UID:6b4084bb-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7017,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290830 0xc001290831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012908b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.067: INFO: Pod "nginx-deployment-6f478d8d8-htdv8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-htdv8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-htdv8,UID:6b40baec-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7024,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290a00 0xc001290a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-j9vvc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j9vvc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-j9vvc,UID:6b40c7dc-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7020,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290cc0 0xc001290cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-kz6bn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kz6bn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-kz6bn,UID:666b404f-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6872,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.2.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290e60 0xc001290e61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001290ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001290ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:10.2.2.28,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0a5f174223a3170dc86359bc3c0c60ab883b5dc0535b70e3254b80200b8c2a1f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-l9xf8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-l9xf8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-l9xf8,UID:666b72ae-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6889,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001290fd0 0xc001290fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.220,PodIP:10.2.3.11,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://eccf196a5508387553f208fa126bd84c3fa8e5f0dcd24caec3d6829ced7edc7f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-lqzpz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lqzpz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-lqzpz,UID:66729948-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6908,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291130 0xc001291131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012911b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.220,PodIP:10.2.3.13,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://344f213ee89cf10acd0c24a14e618a2d1208300ef47f05a424629771e152efda}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-lrg5t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lrg5t,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-lrg5t,UID:666e669f-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6895,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.47/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291290 0xc001291291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012912f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.47,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://955346a1c0e84cd7475e3942562b134cd00298b997a46a1d777cb1612d70688f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-nbw7j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nbw7j,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-nbw7j,UID:6b3a8133-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7018,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0012913e0 0xc0012913e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.220,PodIP:,StartTime:2019-04-23 09:16:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.068: INFO: Pod "nginx-deployment-6f478d8d8-ndjd8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ndjd8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-ndjd8,UID:666a30f1-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6868,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.45/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291530 0xc001291531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012915b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.45,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6a926acae956db9303d4467c3139847dc36889630c1adf57a052344e5dffc4f0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.069: INFO: Pod "nginx-deployment-6f478d8d8-pkdc8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pkdc8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-pkdc8,UID:6b40d684-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7021,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291680 0xc001291681}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012916e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.069: INFO: Pod "nginx-deployment-6f478d8d8-pqkns" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pqkns,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-pqkns,UID:6b3d1978-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7013,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291780 0xc001291781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012917e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.070: INFO: Pod "nginx-deployment-6f478d8d8-qlbx7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qlbx7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-qlbx7,UID:666e5905-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:6875,Generation:0,CreationTimestamp:2019-04-23 09:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.2.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291890 0xc001291891}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012918f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:10.2.2.29,StartTime:2019-04-23 09:15:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:15:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7f526368537c81c750af08582833d71b7da94a6613f44bd61cf85a9e901e3b86}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.070: INFO: Pod "nginx-deployment-6f478d8d8-snt9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-snt9n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-snt9n,UID:6b3cef69-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7031,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc0012919e0 0xc0012919e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:03 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:,StartTime:2019-04-23 09:16:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:16:04.070: INFO: Pod "nginx-deployment-6f478d8d8-vhrnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vhrnf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2768,SelfLink:/api/v1/namespaces/deployment-2768/pods/nginx-deployment-6f478d8d8-vhrnf,UID:6b40df2e-65a8-11e9-be4b-42010a8a0fda,ResourceVersion:7022,Generation:0,CreationTimestamp:2019-04-23 09:16:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 66665932-65a8-11e9-be4b-42010a8a0fda 0xc001291b20 0xc001291b21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8tv8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8tv8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8tv8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001291b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001291ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:16:04 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:16:04.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2768" for this suite.
Apr 23 09:16:12.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:16:12.231: INFO: namespace deployment-2768 deletion completed in 8.142593484s

• [SLOW TEST:16.449 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:16:12.232: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 23 09:16:20.341: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:20.341: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:20.576: INFO: Exec stderr: ""
Apr 23 09:16:20.576: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:20.576: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:20.871: INFO: Exec stderr: ""
Apr 23 09:16:20.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:20.872: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:21.187: INFO: Exec stderr: ""
Apr 23 09:16:21.187: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:21.187: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:21.476: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 23 09:16:21.476: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:21.476: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:21.759: INFO: Exec stderr: ""
Apr 23 09:16:21.759: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:21.759: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:22.065: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 23 09:16:22.065: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:22.065: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:22.294: INFO: Exec stderr: ""
Apr 23 09:16:22.294: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:22.294: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:22.599: INFO: Exec stderr: ""
Apr 23 09:16:22.599: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:22.860: INFO: Exec stderr: ""
Apr 23 09:16:22.860: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-824 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:16:22.860: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:16:23.146: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:16:23.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-824" for this suite.
Apr 23 09:17:05.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:17:05.245: INFO: namespace e2e-kubelet-etc-hosts-824 deletion completed in 42.09416565s

• [SLOW TEST:53.013 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:17:05.245: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 23 09:17:05.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-5537'
Apr 23 09:17:05.731: INFO: stderr: ""
Apr 23 09:17:05.731: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 09:17:05.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5537'
Apr 23 09:17:05.822: INFO: stderr: ""
Apr 23 09:17:05.822: INFO: stdout: "update-demo-nautilus-gwzj7 update-demo-nautilus-p8f7l "
Apr 23 09:17:05.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-gwzj7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:05.902: INFO: stderr: ""
Apr 23 09:17:05.902: INFO: stdout: ""
Apr 23 09:17:05.902: INFO: update-demo-nautilus-gwzj7 is created but not running
Apr 23 09:17:10.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5537'
Apr 23 09:17:10.986: INFO: stderr: ""
Apr 23 09:17:10.986: INFO: stdout: "update-demo-nautilus-gwzj7 update-demo-nautilus-p8f7l "
Apr 23 09:17:10.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-gwzj7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:11.072: INFO: stderr: ""
Apr 23 09:17:11.072: INFO: stdout: "true"
Apr 23 09:17:11.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-gwzj7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:11.153: INFO: stderr: ""
Apr 23 09:17:11.153: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:17:11.153: INFO: validating pod update-demo-nautilus-gwzj7
Apr 23 09:17:11.159: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:17:11.159: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:17:11.159: INFO: update-demo-nautilus-gwzj7 is verified up and running
Apr 23 09:17:11.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-p8f7l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:11.251: INFO: stderr: ""
Apr 23 09:17:11.251: INFO: stdout: "true"
Apr 23 09:17:11.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-p8f7l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:11.335: INFO: stderr: ""
Apr 23 09:17:11.335: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:17:11.335: INFO: validating pod update-demo-nautilus-p8f7l
Apr 23 09:17:11.341: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:17:11.341: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:17:11.341: INFO: update-demo-nautilus-p8f7l is verified up and running
STEP: rolling-update to new replication controller
Apr 23 09:17:11.342: INFO: scanned /root for discovery docs: <nil>
Apr 23 09:17:11.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5537'
Apr 23 09:17:33.832: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 23 09:17:33.832: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 09:17:33.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5537'
Apr 23 09:17:33.914: INFO: stderr: ""
Apr 23 09:17:33.914: INFO: stdout: "update-demo-kitten-5k884 update-demo-kitten-rxmwn "
Apr 23 09:17:33.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-kitten-5k884 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:33.988: INFO: stderr: ""
Apr 23 09:17:33.988: INFO: stdout: "true"
Apr 23 09:17:33.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-kitten-5k884 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:34.062: INFO: stderr: ""
Apr 23 09:17:34.062: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 23 09:17:34.062: INFO: validating pod update-demo-kitten-5k884
Apr 23 09:17:34.068: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 23 09:17:34.068: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 23 09:17:34.068: INFO: update-demo-kitten-5k884 is verified up and running
Apr 23 09:17:34.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-kitten-rxmwn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:34.145: INFO: stderr: ""
Apr 23 09:17:34.145: INFO: stdout: "true"
Apr 23 09:17:34.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-kitten-rxmwn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5537'
Apr 23 09:17:34.219: INFO: stderr: ""
Apr 23 09:17:34.219: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 23 09:17:34.219: INFO: validating pod update-demo-kitten-rxmwn
Apr 23 09:17:34.225: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 23 09:17:34.225: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 23 09:17:34.225: INFO: update-demo-kitten-rxmwn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:17:34.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5537" for this suite.
Apr 23 09:17:56.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:17:56.336: INFO: namespace kubectl-5537 deletion completed in 22.10564251s

• [SLOW TEST:51.091 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:17:56.336: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-p9wg
STEP: Creating a pod to test atomic-volume-subpath
Apr 23 09:17:56.406: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p9wg" in namespace "subpath-2532" to be "success or failure"
Apr 23 09:17:56.410: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Pending", Reason="", readiness=false. Elapsed: 3.580814ms
Apr 23 09:17:58.414: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007553488s
Apr 23 09:18:00.418: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 4.011359476s
Apr 23 09:18:02.422: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 6.015258869s
Apr 23 09:18:04.426: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 8.019327953s
Apr 23 09:18:06.430: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 10.02328818s
Apr 23 09:18:08.433: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 12.027118415s
Apr 23 09:18:10.438: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 14.031261859s
Apr 23 09:18:12.441: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 16.035127108s
Apr 23 09:18:14.446: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 18.039387804s
Apr 23 09:18:16.449: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 20.04313616s
Apr 23 09:18:18.454: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Running", Reason="", readiness=true. Elapsed: 22.047205231s
Apr 23 09:18:20.457: INFO: Pod "pod-subpath-test-configmap-p9wg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050813169s
STEP: Saw pod success
Apr 23 09:18:20.457: INFO: Pod "pod-subpath-test-configmap-p9wg" satisfied condition "success or failure"
Apr 23 09:18:20.460: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-subpath-test-configmap-p9wg container test-container-subpath-configmap-p9wg: <nil>
STEP: delete the pod
Apr 23 09:18:20.486: INFO: Waiting for pod pod-subpath-test-configmap-p9wg to disappear
Apr 23 09:18:20.489: INFO: Pod pod-subpath-test-configmap-p9wg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-p9wg
Apr 23 09:18:20.489: INFO: Deleting pod "pod-subpath-test-configmap-p9wg" in namespace "subpath-2532"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:18:20.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2532" for this suite.
Apr 23 09:18:26.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:18:26.607: INFO: namespace subpath-2532 deletion completed in 6.109685636s

• [SLOW TEST:30.271 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:18:26.607: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c0497e64-65a8-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:18:26.664: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d" in namespace "projected-3625" to be "success or failure"
Apr 23 09:18:26.669: INFO: Pod "pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584098ms
Apr 23 09:18:28.673: INFO: Pod "pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00922906s
Apr 23 09:18:30.677: INFO: Pod "pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012794238s
STEP: Saw pod success
Apr 23 09:18:30.677: INFO: Pod "pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:18:30.679: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:18:30.700: INFO: Waiting for pod pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d to disappear
Apr 23 09:18:30.703: INFO: Pod pod-projected-configmaps-c04aa1c7-65a8-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:18:30.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3625" for this suite.
Apr 23 09:18:36.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:18:36.807: INFO: namespace projected-3625 deletion completed in 6.099544576s

• [SLOW TEST:10.199 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:18:36.807: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-82
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-82
STEP: Creating statefulset with conflicting port in namespace statefulset-82
STEP: Waiting until pod test-pod will start running in namespace statefulset-82
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-82
Apr 23 09:18:40.952: INFO: Observed stateful pod in namespace: statefulset-82, name: ss-0, uid: c680fbef-65a8-11e9-be4b-42010a8a0fda, status phase: Pending. Waiting for statefulset controller to delete.
Apr 23 09:18:43.319: INFO: Observed stateful pod in namespace: statefulset-82, name: ss-0, uid: c680fbef-65a8-11e9-be4b-42010a8a0fda, status phase: Failed. Waiting for statefulset controller to delete.
Apr 23 09:18:43.329: INFO: Observed stateful pod in namespace: statefulset-82, name: ss-0, uid: c680fbef-65a8-11e9-be4b-42010a8a0fda, status phase: Failed. Waiting for statefulset controller to delete.
Apr 23 09:18:43.336: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-82
STEP: Removing pod with conflicting port in namespace statefulset-82
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-82 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 23 09:18:57.399: INFO: Deleting all statefulset in ns statefulset-82
Apr 23 09:18:57.402: INFO: Scaling statefulset ss to 0
Apr 23 09:19:07.419: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 09:19:07.423: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:19:07.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-82" for this suite.
Apr 23 09:19:13.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:19:13.544: INFO: namespace statefulset-82 deletion completed in 6.103519831s

• [SLOW TEST:36.737 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:19:13.544: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-dc45119c-65a8-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:19:17.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4099" for this suite.
Apr 23 09:19:39.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:19:39.757: INFO: namespace configmap-4099 deletion completed in 22.108744457s

• [SLOW TEST:26.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:19:39.757: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:19:39.847: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 23 09:19:39.857: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:39.859: INFO: Number of nodes with available pods: 0
Apr 23 09:19:39.859: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:19:40.865: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:40.868: INFO: Number of nodes with available pods: 0
Apr 23 09:19:40.868: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:19:41.865: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:41.868: INFO: Number of nodes with available pods: 0
Apr 23 09:19:41.868: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:19:42.864: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:42.868: INFO: Number of nodes with available pods: 2
Apr 23 09:19:42.868: INFO: Node net1a83gn1-worker-3 is running more than one daemon pod
Apr 23 09:19:43.864: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:43.867: INFO: Number of nodes with available pods: 3
Apr 23 09:19:43.867: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 23 09:19:43.898: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:43.898: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:43.898: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:43.901: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:44.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:44.905: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:44.905: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:44.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:45.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:45.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:45.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:45.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:46.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:46.905: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:46.905: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:46.905: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:46.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:47.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:47.905: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:47.905: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:47.905: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:47.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:48.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:48.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:48.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:48.906: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:48.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:49.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:49.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:49.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:49.906: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:49.911: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:50.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:50.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:50.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:50.906: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:50.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:51.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:51.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:51.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:51.906: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:51.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:52.908: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:52.919: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:52.920: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:52.920: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:52.925: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:53.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:53.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:53.906: INFO: Wrong image for pod: daemon-set-sb8mv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:53.906: INFO: Pod daemon-set-sb8mv is not available
Apr 23 09:19:53.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:54.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:54.906: INFO: Pod daemon-set-q5vk7 is not available
Apr 23 09:19:54.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:54.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:55.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:55.906: INFO: Pod daemon-set-q5vk7 is not available
Apr 23 09:19:55.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:55.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:56.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:56.906: INFO: Pod daemon-set-q5vk7 is not available
Apr 23 09:19:56.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:56.911: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:57.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:57.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:57.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:58.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:58.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:58.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:19:59.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:59.905: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:19:59.905: INFO: Pod daemon-set-rlgxk is not available
Apr 23 09:19:59.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:00.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:00.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:00.906: INFO: Pod daemon-set-rlgxk is not available
Apr 23 09:20:00.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:01.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:01.906: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:01.906: INFO: Pod daemon-set-rlgxk is not available
Apr 23 09:20:01.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:02.908: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:02.908: INFO: Wrong image for pod: daemon-set-rlgxk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:02.908: INFO: Pod daemon-set-rlgxk is not available
Apr 23 09:20:02.913: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:03.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:03.906: INFO: Pod daemon-set-k7xvf is not available
Apr 23 09:20:03.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:04.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:04.905: INFO: Pod daemon-set-k7xvf is not available
Apr 23 09:20:04.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:05.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:05.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:06.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:06.914: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:07.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:07.906: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:07.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:08.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:08.905: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:08.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:09.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:09.905: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:09.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:10.911: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:10.911: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:10.916: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:11.906: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:11.906: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:11.910: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:12.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:12.905: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:12.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:13.905: INFO: Wrong image for pod: daemon-set-gvd7m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 23 09:20:13.905: INFO: Pod daemon-set-gvd7m is not available
Apr 23 09:20:13.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:14.905: INFO: Pod daemon-set-7nsjp is not available
Apr 23 09:20:14.909: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 23 09:20:14.912: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:14.915: INFO: Number of nodes with available pods: 2
Apr 23 09:20:14.915: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:20:15.934: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:15.937: INFO: Number of nodes with available pods: 2
Apr 23 09:20:15.937: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:20:16.920: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:16.923: INFO: Number of nodes with available pods: 2
Apr 23 09:20:16.923: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:20:17.920: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:20:17.924: INFO: Number of nodes with available pods: 3
Apr 23 09:20:17.924: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-228, will wait for the garbage collector to delete the pods
Apr 23 09:20:18.001: INFO: Deleting DaemonSet.extensions daemon-set took: 9.051867ms
Apr 23 09:20:18.302: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.270094ms
Apr 23 09:20:24.605: INFO: Number of nodes with available pods: 0
Apr 23 09:20:24.605: INFO: Number of running nodes: 0, number of available pods: 0
Apr 23 09:20:24.608: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-228/daemonsets","resourceVersion":"8226"},"items":null}

Apr 23 09:20:24.610: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-228/pods","resourceVersion":"8226"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:20:24.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-228" for this suite.
Apr 23 09:20:30.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:20:30.726: INFO: namespace daemonsets-228 deletion completed in 6.099718343s

• [SLOW TEST:50.969 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:20:30.726: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 09:20:30.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-623'
Apr 23 09:20:30.868: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 23 09:20:30.868: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 23 09:20:30.880: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-2phb7]
Apr 23 09:20:30.880: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-2phb7" in namespace "kubectl-623" to be "running and ready"
Apr 23 09:20:30.887: INFO: Pod "e2e-test-nginx-rc-2phb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.935559ms
Apr 23 09:20:32.891: INFO: Pod "e2e-test-nginx-rc-2phb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010738984s
Apr 23 09:20:34.895: INFO: Pod "e2e-test-nginx-rc-2phb7": Phase="Running", Reason="", readiness=true. Elapsed: 4.014085146s
Apr 23 09:20:34.895: INFO: Pod "e2e-test-nginx-rc-2phb7" satisfied condition "running and ready"
Apr 23 09:20:34.895: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-2phb7]
Apr 23 09:20:34.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 logs rc/e2e-test-nginx-rc --namespace=kubectl-623'
Apr 23 09:20:34.990: INFO: stderr: ""
Apr 23 09:20:34.990: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 23 09:20:34.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete rc e2e-test-nginx-rc --namespace=kubectl-623'
Apr 23 09:20:35.075: INFO: stderr: ""
Apr 23 09:20:35.075: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:20:35.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-623" for this suite.
Apr 23 09:20:57.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:20:57.185: INFO: namespace kubectl-623 deletion completed in 22.104409222s

• [SLOW TEST:26.459 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:20:57.185: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:20:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8193" for this suite.
Apr 23 09:21:19.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:21:19.415: INFO: namespace pods-8193 deletion completed in 22.141180798s

• [SLOW TEST:22.230 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:21:19.415: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 23 09:21:24.011: INFO: Successfully updated pod "annotationupdate274c4989-65a9-11e9-b8ea-e2349624188d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:21:26.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3188" for this suite.
Apr 23 09:21:48.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:21:48.151: INFO: namespace projected-3188 deletion completed in 22.116841698s

• [SLOW TEST:28.736 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:21:48.152: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 23 09:21:48.202: INFO: Waiting up to 5m0s for pod "pod-386a4089-65a9-11e9-b8ea-e2349624188d" in namespace "emptydir-6226" to be "success or failure"
Apr 23 09:21:48.212: INFO: Pod "pod-386a4089-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.505948ms
Apr 23 09:21:50.216: INFO: Pod "pod-386a4089-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013560541s
Apr 23 09:21:52.220: INFO: Pod "pod-386a4089-65a9-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017669533s
STEP: Saw pod success
Apr 23 09:21:52.220: INFO: Pod "pod-386a4089-65a9-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:21:52.223: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-386a4089-65a9-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:21:52.267: INFO: Waiting for pod pod-386a4089-65a9-11e9-b8ea-e2349624188d to disappear
Apr 23 09:21:52.269: INFO: Pod pod-386a4089-65a9-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:21:52.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6226" for this suite.
Apr 23 09:21:58.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:21:58.383: INFO: namespace emptydir-6226 deletion completed in 6.109484673s

• [SLOW TEST:10.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:21:58.383: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 23 09:21:58.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-3093'
Apr 23 09:21:58.660: INFO: stderr: ""
Apr 23 09:21:58.660: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 09:21:58.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:21:58.746: INFO: stderr: ""
Apr 23 09:21:58.746: INFO: stdout: "update-demo-nautilus-h9gwj update-demo-nautilus-xdfvj "
Apr 23 09:21:58.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-h9gwj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:21:58.824: INFO: stderr: ""
Apr 23 09:21:58.824: INFO: stdout: ""
Apr 23 09:21:58.824: INFO: update-demo-nautilus-h9gwj is created but not running
Apr 23 09:22:03.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:03.901: INFO: stderr: ""
Apr 23 09:22:03.901: INFO: stdout: "update-demo-nautilus-h9gwj update-demo-nautilus-xdfvj "
Apr 23 09:22:03.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-h9gwj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:03.978: INFO: stderr: ""
Apr 23 09:22:03.978: INFO: stdout: "true"
Apr 23 09:22:03.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-h9gwj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:04.052: INFO: stderr: ""
Apr 23 09:22:04.052: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:22:04.052: INFO: validating pod update-demo-nautilus-h9gwj
Apr 23 09:22:04.058: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:22:04.058: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:22:04.058: INFO: update-demo-nautilus-h9gwj is verified up and running
Apr 23 09:22:04.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:04.136: INFO: stderr: ""
Apr 23 09:22:04.136: INFO: stdout: "true"
Apr 23 09:22:04.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:04.211: INFO: stderr: ""
Apr 23 09:22:04.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:22:04.212: INFO: validating pod update-demo-nautilus-xdfvj
Apr 23 09:22:04.217: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:22:04.217: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:22:04.217: INFO: update-demo-nautilus-xdfvj is verified up and running
STEP: scaling down the replication controller
Apr 23 09:22:04.219: INFO: scanned /root for discovery docs: <nil>
Apr 23 09:22:04.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3093'
Apr 23 09:22:05.343: INFO: stderr: ""
Apr 23 09:22:05.343: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 09:22:05.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:05.425: INFO: stderr: ""
Apr 23 09:22:05.425: INFO: stdout: "update-demo-nautilus-h9gwj update-demo-nautilus-xdfvj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 23 09:22:10.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:10.508: INFO: stderr: ""
Apr 23 09:22:10.509: INFO: stdout: "update-demo-nautilus-h9gwj update-demo-nautilus-xdfvj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 23 09:22:15.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:15.586: INFO: stderr: ""
Apr 23 09:22:15.586: INFO: stdout: "update-demo-nautilus-xdfvj "
Apr 23 09:22:15.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:15.666: INFO: stderr: ""
Apr 23 09:22:15.666: INFO: stdout: "true"
Apr 23 09:22:15.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:15.745: INFO: stderr: ""
Apr 23 09:22:15.745: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:22:15.745: INFO: validating pod update-demo-nautilus-xdfvj
Apr 23 09:22:15.749: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:22:15.749: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:22:15.750: INFO: update-demo-nautilus-xdfvj is verified up and running
STEP: scaling up the replication controller
Apr 23 09:22:15.752: INFO: scanned /root for discovery docs: <nil>
Apr 23 09:22:15.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3093'
Apr 23 09:22:16.869: INFO: stderr: ""
Apr 23 09:22:16.870: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 09:22:16.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:16.945: INFO: stderr: ""
Apr 23 09:22:16.945: INFO: stdout: "update-demo-nautilus-mf8nv update-demo-nautilus-xdfvj "
Apr 23 09:22:16.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-mf8nv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:17.020: INFO: stderr: ""
Apr 23 09:22:17.020: INFO: stdout: ""
Apr 23 09:22:17.020: INFO: update-demo-nautilus-mf8nv is created but not running
Apr 23 09:22:22.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3093'
Apr 23 09:22:22.098: INFO: stderr: ""
Apr 23 09:22:22.098: INFO: stdout: "update-demo-nautilus-mf8nv update-demo-nautilus-xdfvj "
Apr 23 09:22:22.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-mf8nv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:22.171: INFO: stderr: ""
Apr 23 09:22:22.171: INFO: stdout: "true"
Apr 23 09:22:22.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-mf8nv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:22.248: INFO: stderr: ""
Apr 23 09:22:22.248: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:22:22.248: INFO: validating pod update-demo-nautilus-mf8nv
Apr 23 09:22:22.254: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:22:22.254: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:22:22.254: INFO: update-demo-nautilus-mf8nv is verified up and running
Apr 23 09:22:22.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:22.328: INFO: stderr: ""
Apr 23 09:22:22.328: INFO: stdout: "true"
Apr 23 09:22:22.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-xdfvj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3093'
Apr 23 09:22:22.404: INFO: stderr: ""
Apr 23 09:22:22.404: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 09:22:22.404: INFO: validating pod update-demo-nautilus-xdfvj
Apr 23 09:22:22.409: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 09:22:22.409: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 09:22:22.409: INFO: update-demo-nautilus-xdfvj is verified up and running
STEP: using delete to clean up resources
Apr 23 09:22:22.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-3093'
Apr 23 09:22:22.495: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:22:22.495: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 23 09:22:22.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3093'
Apr 23 09:22:22.578: INFO: stderr: "No resources found.\n"
Apr 23 09:22:22.578: INFO: stdout: ""
Apr 23 09:22:22.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=update-demo --namespace=kubectl-3093 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 09:22:22.655: INFO: stderr: ""
Apr 23 09:22:22.655: INFO: stdout: "update-demo-nautilus-mf8nv\nupdate-demo-nautilus-xdfvj\n"
Apr 23 09:22:23.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3093'
Apr 23 09:22:23.235: INFO: stderr: "No resources found.\n"
Apr 23 09:22:23.235: INFO: stdout: ""
Apr 23 09:22:23.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=update-demo --namespace=kubectl-3093 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 09:22:23.312: INFO: stderr: ""
Apr 23 09:22:23.312: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:22:23.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3093" for this suite.
Apr 23 09:22:45.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:22:45.435: INFO: namespace kubectl-3093 deletion completed in 22.11905151s

• [SLOW TEST:47.052 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:22:45.435: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-9765
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9765 to expose endpoints map[]
Apr 23 09:22:45.486: INFO: Get endpoints failed (5.234644ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr 23 09:22:46.490: INFO: successfully validated that service multi-endpoint-test in namespace services-9765 exposes endpoints map[] (1.009142843s elapsed)
STEP: Creating pod pod1 in namespace services-9765
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9765 to expose endpoints map[pod1:[100]]
Apr 23 09:22:49.532: INFO: successfully validated that service multi-endpoint-test in namespace services-9765 exposes endpoints map[pod1:[100]] (3.030225728s elapsed)
STEP: Creating pod pod2 in namespace services-9765
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9765 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 23 09:22:52.578: INFO: successfully validated that service multi-endpoint-test in namespace services-9765 exposes endpoints map[pod1:[100] pod2:[101]] (3.039922368s elapsed)
STEP: Deleting pod pod1 in namespace services-9765
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9765 to expose endpoints map[pod2:[101]]
Apr 23 09:22:53.611: INFO: successfully validated that service multi-endpoint-test in namespace services-9765 exposes endpoints map[pod2:[101]] (1.021769598s elapsed)
STEP: Deleting pod pod2 in namespace services-9765
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9765 to expose endpoints map[]
Apr 23 09:22:53.627: INFO: successfully validated that service multi-endpoint-test in namespace services-9765 exposes endpoints map[] (6.327487ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:22:53.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9765" for this suite.
Apr 23 09:22:59.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:22:59.816: INFO: namespace services-9765 deletion completed in 6.128952766s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:14.381 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:22:59.816: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:22:59.889: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d" in namespace "projected-7113" to be "success or failure"
Apr 23 09:22:59.893: INFO: Pod "downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752692ms
Apr 23 09:23:01.897: INFO: Pod "downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007804366s
Apr 23 09:23:03.901: INFO: Pod "downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012076767s
STEP: Saw pod success
Apr 23 09:23:03.901: INFO: Pod "downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:23:03.904: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:23:03.937: INFO: Waiting for pod downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d to disappear
Apr 23 09:23:03.939: INFO: Pod downwardapi-volume-63253f3d-65a9-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:23:03.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7113" for this suite.
Apr 23 09:23:09.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:23:10.059: INFO: namespace projected-7113 deletion completed in 6.113902789s

• [SLOW TEST:10.243 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:23:10.059: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 23 09:23:10.121: INFO: Waiting up to 5m0s for pod "var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d" in namespace "var-expansion-788" to be "success or failure"
Apr 23 09:23:10.142: INFO: Pod "var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.584736ms
Apr 23 09:23:12.146: INFO: Pod "var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024964004s
Apr 23 09:23:14.151: INFO: Pod "var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029452208s
STEP: Saw pod success
Apr 23 09:23:14.151: INFO: Pod "var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:23:14.154: INFO: Trying to get logs from node net1a83gn1-worker-1 pod var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:23:14.178: INFO: Waiting for pod var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d to disappear
Apr 23 09:23:14.181: INFO: Pod var-expansion-693ced12-65a9-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:23:14.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-788" for this suite.
Apr 23 09:23:20.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:23:20.290: INFO: namespace var-expansion-788 deletion completed in 6.104601052s

• [SLOW TEST:10.230 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:23:20.290: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-6f558aaf-65a9-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:23:20.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d" in namespace "configmap-1123" to be "success or failure"
Apr 23 09:23:20.349: INFO: Pod "pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.94411ms
Apr 23 09:23:22.353: INFO: Pod "pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008038883s
Apr 23 09:23:24.357: INFO: Pod "pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011990143s
STEP: Saw pod success
Apr 23 09:23:24.357: INFO: Pod "pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:23:24.359: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:23:24.385: INFO: Waiting for pod pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d to disappear
Apr 23 09:23:24.389: INFO: Pod pod-configmaps-6f56db1b-65a9-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:23:24.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1123" for this suite.
Apr 23 09:23:30.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:23:30.503: INFO: namespace configmap-1123 deletion completed in 6.110118469s

• [SLOW TEST:10.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:23:30.503: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-7574a826-65a9-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:23:30.610: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d" in namespace "projected-3027" to be "success or failure"
Apr 23 09:23:30.613: INFO: Pod "pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.865802ms
Apr 23 09:23:32.617: INFO: Pod "pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006803225s
Apr 23 09:23:34.621: INFO: Pod "pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011001274s
STEP: Saw pod success
Apr 23 09:23:34.621: INFO: Pod "pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:23:34.624: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:23:34.649: INFO: Waiting for pod pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d to disappear
Apr 23 09:23:34.651: INFO: Pod pod-projected-configmaps-75759e78-65a9-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:23:34.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3027" for this suite.
Apr 23 09:23:40.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:23:40.768: INFO: namespace projected-3027 deletion completed in 6.113236555s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:23:40.768: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3717
Apr 23 09:23:44.825: INFO: Started pod liveness-exec in namespace container-probe-3717
STEP: checking the pod's current state and verifying that restartCount is present
Apr 23 09:23:44.827: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:27:45.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3717" for this suite.
Apr 23 09:27:51.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:27:51.467: INFO: namespace container-probe-3717 deletion completed in 6.105937541s

• [SLOW TEST:250.699 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:27:51.467: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:27:51.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d" in namespace "downward-api-470" to be "success or failure"
Apr 23 09:27:51.534: INFO: Pod "downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.016583ms
Apr 23 09:27:53.538: INFO: Pod "downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009015691s
Apr 23 09:27:55.544: INFO: Pod "downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015416657s
STEP: Saw pod success
Apr 23 09:27:55.544: INFO: Pod "downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:27:55.548: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:27:55.585: INFO: Waiting for pod downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d to disappear
Apr 23 09:27:55.591: INFO: Pod downwardapi-volume-10fa44d8-65aa-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:27:55.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-470" for this suite.
Apr 23 09:28:01.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:28:01.704: INFO: namespace downward-api-470 deletion completed in 6.107524109s

• [SLOW TEST:10.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:28:01.705: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 23 09:28:01.779: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:01.782: INFO: Number of nodes with available pods: 0
Apr 23 09:28:01.782: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:28:02.788: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:02.791: INFO: Number of nodes with available pods: 0
Apr 23 09:28:02.791: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:28:03.787: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:03.790: INFO: Number of nodes with available pods: 0
Apr 23 09:28:03.790: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:28:04.787: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:04.791: INFO: Number of nodes with available pods: 1
Apr 23 09:28:04.791: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:28:05.787: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:05.790: INFO: Number of nodes with available pods: 3
Apr 23 09:28:05.790: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 23 09:28:05.816: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:05.819: INFO: Number of nodes with available pods: 2
Apr 23 09:28:05.819: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:06.825: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:06.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:06.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:07.825: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:07.829: INFO: Number of nodes with available pods: 2
Apr 23 09:28:07.829: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:08.824: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:08.827: INFO: Number of nodes with available pods: 2
Apr 23 09:28:08.827: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:09.824: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:09.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:09.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:10.825: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:10.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:10.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:11.825: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:11.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:11.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:12.825: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:12.830: INFO: Number of nodes with available pods: 2
Apr 23 09:28:12.830: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:13.824: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:13.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:13.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:14.824: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:14.828: INFO: Number of nodes with available pods: 2
Apr 23 09:28:14.828: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:15.827: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:15.832: INFO: Number of nodes with available pods: 2
Apr 23 09:28:15.832: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:28:16.824: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:28:16.828: INFO: Number of nodes with available pods: 3
Apr 23 09:28:16.828: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5998, will wait for the garbage collector to delete the pods
Apr 23 09:28:16.902: INFO: Deleting DaemonSet.extensions daemon-set took: 17.06294ms
Apr 23 09:28:17.302: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.421135ms
Apr 23 09:28:20.706: INFO: Number of nodes with available pods: 0
Apr 23 09:28:20.706: INFO: Number of running nodes: 0, number of available pods: 0
Apr 23 09:28:20.709: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5998/daemonsets","resourceVersion":"9553"},"items":null}

Apr 23 09:28:20.711: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5998/pods","resourceVersion":"9553"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:28:20.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5998" for this suite.
Apr 23 09:28:26.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:28:26.860: INFO: namespace daemonsets-5998 deletion completed in 6.130691783s

• [SLOW TEST:25.155 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:28:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3364
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 23 09:28:26.955: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 23 09:28:53.062: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.3.25:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3364 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:28:53.062: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:28:53.304: INFO: Found all expected endpoints: [netserver-0]
Apr 23 09:28:53.308: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.1.74:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3364 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:28:53.308: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:28:53.609: INFO: Found all expected endpoints: [netserver-1]
Apr 23 09:28:53.613: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.2.55:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3364 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:28:53.613: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:28:53.900: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:28:53.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3364" for this suite.
Apr 23 09:29:15.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:29:16.021: INFO: namespace pod-network-test-3364 deletion completed in 22.116034509s

• [SLOW TEST:49.160 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:29:16.021: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-43611cd2-65aa-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:29:16.093: INFO: Waiting up to 5m0s for pod "pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d" in namespace "secrets-9549" to be "success or failure"
Apr 23 09:29:16.096: INFO: Pod "pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.749994ms
Apr 23 09:29:18.101: INFO: Pod "pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007434017s
Apr 23 09:29:20.105: INFO: Pod "pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011466356s
STEP: Saw pod success
Apr 23 09:29:20.105: INFO: Pod "pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:29:20.107: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:29:20.143: INFO: Waiting for pod pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d to disappear
Apr 23 09:29:20.145: INFO: Pod pod-secrets-4361db9c-65aa-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:29:20.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9549" for this suite.
Apr 23 09:29:26.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:29:26.262: INFO: namespace secrets-9549 deletion completed in 6.1128293s

• [SLOW TEST:10.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:29:26.263: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:29:30.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7848" for this suite.
Apr 23 09:30:08.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:30:08.471: INFO: namespace kubelet-test-7848 deletion completed in 38.120317715s

• [SLOW TEST:42.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:30:08.471: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5443.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5443.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5443.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5443.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5443.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5443.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 23 09:30:20.579: INFO: DNS probes using dns-5443/dns-test-62a30a67-65aa-11e9-b8ea-e2349624188d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:30:20.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5443" for this suite.
Apr 23 09:30:26.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:30:26.710: INFO: namespace dns-5443 deletion completed in 6.10176596s

• [SLOW TEST:18.239 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:30:26.710: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6d830712-65aa-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6d830712-65aa-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:31:43.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3766" for this suite.
Apr 23 09:32:05.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:32:05.300: INFO: namespace projected-3766 deletion completed in 22.104491133s

• [SLOW TEST:98.590 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:32:05.300: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 23 09:32:05.336: INFO: namespace kubectl-9864
Apr 23 09:32:05.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-9864'
Apr 23 09:32:05.862: INFO: stderr: ""
Apr 23 09:32:05.862: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 23 09:32:06.867: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:32:06.867: INFO: Found 0 / 1
Apr 23 09:32:07.867: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:32:07.867: INFO: Found 0 / 1
Apr 23 09:32:08.866: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:32:08.866: INFO: Found 1 / 1
Apr 23 09:32:08.866: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 23 09:32:08.869: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:32:08.869: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 09:32:08.869: INFO: wait on redis-master startup in kubectl-9864 
Apr 23 09:32:08.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 logs redis-master-9z6xr redis-master --namespace=kubectl-9864'
Apr 23 09:32:08.953: INFO: stderr: ""
Apr 23 09:32:08.953: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Apr 09:32:07.639 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Apr 09:32:07.639 # Server started, Redis version 3.2.12\n1:M 23 Apr 09:32:07.639 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Apr 09:32:07.639 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 23 09:32:08.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9864'
Apr 23 09:32:09.051: INFO: stderr: ""
Apr 23 09:32:09.051: INFO: stdout: "service/rm2 exposed\n"
Apr 23 09:32:09.055: INFO: Service rm2 in namespace kubectl-9864 found.
STEP: exposing service
Apr 23 09:32:11.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9864'
Apr 23 09:32:11.152: INFO: stderr: ""
Apr 23 09:32:11.152: INFO: stdout: "service/rm3 exposed\n"
Apr 23 09:32:11.158: INFO: Service rm3 in namespace kubectl-9864 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:32:13.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9864" for this suite.
Apr 23 09:32:35.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:32:35.301: INFO: namespace kubectl-9864 deletion completed in 22.122651469s

• [SLOW TEST:30.001 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:32:35.301: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9075
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9075
STEP: Deleting pre-stop pod
Apr 23 09:32:48.406: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:32:48.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9075" for this suite.
Apr 23 09:33:26.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:33:26.527: INFO: namespace prestop-9075 deletion completed in 38.103512005s

• [SLOW TEST:51.225 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:33:26.527: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:33:26.594: INFO: Create a RollingUpdate DaemonSet
Apr 23 09:33:26.613: INFO: Check that daemon pods launch on every node of the cluster
Apr 23 09:33:26.619: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:26.622: INFO: Number of nodes with available pods: 0
Apr 23 09:33:26.622: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:33:27.627: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:27.630: INFO: Number of nodes with available pods: 0
Apr 23 09:33:27.630: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:33:28.628: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:28.633: INFO: Number of nodes with available pods: 0
Apr 23 09:33:28.633: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:33:29.628: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:29.630: INFO: Number of nodes with available pods: 2
Apr 23 09:33:29.630: INFO: Node net1a83gn1-worker-2 is running more than one daemon pod
Apr 23 09:33:30.626: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:30.629: INFO: Number of nodes with available pods: 3
Apr 23 09:33:30.629: INFO: Number of running nodes: 3, number of available pods: 3
Apr 23 09:33:30.629: INFO: Update the DaemonSet to trigger a rollout
Apr 23 09:33:30.638: INFO: Updating DaemonSet daemon-set
Apr 23 09:33:44.649: INFO: Roll back the DaemonSet before rollout is complete
Apr 23 09:33:44.658: INFO: Updating DaemonSet daemon-set
Apr 23 09:33:44.658: INFO: Make sure DaemonSet rollback is complete
Apr 23 09:33:44.660: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:44.660: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:44.670: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:45.674: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:45.674: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:45.678: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:46.674: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:46.674: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:46.684: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:47.675: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:47.675: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:47.680: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:48.674: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:48.674: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:48.678: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:49.674: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:49.674: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:49.679: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:50.675: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:50.675: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:50.679: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:51.674: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:51.674: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:51.679: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:52.675: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:52.675: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:52.679: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:53.675: INFO: Wrong image for pod: daemon-set-97r6k. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 23 09:33:53.675: INFO: Pod daemon-set-97r6k is not available
Apr 23 09:33:53.679: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:33:54.674: INFO: Pod daemon-set-vkm47 is not available
Apr 23 09:33:54.678: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9629, will wait for the garbage collector to delete the pods
Apr 23 09:33:54.747: INFO: Deleting DaemonSet.extensions daemon-set took: 9.172372ms
Apr 23 09:33:55.047: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.320673ms
Apr 23 09:34:03.350: INFO: Number of nodes with available pods: 0
Apr 23 09:34:03.350: INFO: Number of running nodes: 0, number of available pods: 0
Apr 23 09:34:03.354: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9629/daemonsets","resourceVersion":"10566"},"items":null}

Apr 23 09:34:03.356: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9629/pods","resourceVersion":"10566"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:34:03.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9629" for this suite.
Apr 23 09:34:09.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:34:09.470: INFO: namespace daemonsets-9629 deletion completed in 6.096908838s

• [SLOW TEST:42.943 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:34:09.470: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 23 09:34:09.517: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 23 09:34:14.522: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:34:14.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9586" for this suite.
Apr 23 09:34:20.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:34:20.671: INFO: namespace replication-controller-9586 deletion completed in 6.113963642s

• [SLOW TEST:11.200 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:34:20.671: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0423 09:34:51.243197      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:34:51.243: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:34:51.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9933" for this suite.
Apr 23 09:34:57.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:34:57.353: INFO: namespace gc-9933 deletion completed in 6.106388987s

• [SLOW TEST:36.683 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:34:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8279/configmap-test-0ed3340a-65ab-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:34:57.423: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d" in namespace "configmap-8279" to be "success or failure"
Apr 23 09:34:57.429: INFO: Pod "pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.336315ms
Apr 23 09:34:59.433: INFO: Pod "pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010078537s
Apr 23 09:35:01.437: INFO: Pod "pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014102226s
STEP: Saw pod success
Apr 23 09:35:01.437: INFO: Pod "pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:35:01.440: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d container env-test: <nil>
STEP: delete the pod
Apr 23 09:35:01.468: INFO: Waiting for pod pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:35:01.472: INFO: Pod pod-configmaps-0ed4256f-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:35:01.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8279" for this suite.
Apr 23 09:35:07.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:35:07.590: INFO: namespace configmap-8279 deletion completed in 6.113625382s

• [SLOW TEST:10.236 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:35:07.590: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 23 09:35:08.071: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 23 09:35:10.141: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:35:12.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:35:14.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:35:16.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608908, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:35:18.977: INFO: Waited 823.017207ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:35:19.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1524" for this suite.
Apr 23 09:35:25.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:35:25.678: INFO: namespace aggregator-1524 deletion completed in 6.200095515s

• [SLOW TEST:18.088 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:35:25.679: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:35:29.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2366" for this suite.
Apr 23 09:36:15.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:36:15.865: INFO: namespace kubelet-test-2366 deletion completed in 46.105307075s

• [SLOW TEST:50.187 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:36:15.866: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3d9d03f4-65ab-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:36:15.916: INFO: Waiting up to 5m0s for pod "pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d" in namespace "secrets-3955" to be "success or failure"
Apr 23 09:36:15.921: INFO: Pod "pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.849493ms
Apr 23 09:36:17.925: INFO: Pod "pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008891351s
Apr 23 09:36:19.929: INFO: Pod "pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012818259s
STEP: Saw pod success
Apr 23 09:36:19.929: INFO: Pod "pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:36:19.932: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:36:19.957: INFO: Waiting for pod pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:36:19.961: INFO: Pod pod-secrets-3d9de911-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:36:19.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3955" for this suite.
Apr 23 09:36:25.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:36:26.073: INFO: namespace secrets-3955 deletion completed in 6.108358534s

• [SLOW TEST:10.208 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:36:26.073: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:36:26.109: INFO: Creating deployment "test-recreate-deployment"
Apr 23 09:36:26.115: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 23 09:36:26.136: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 23 09:36:28.149: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 23 09:36:28.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608986, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608986, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608986, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691608986, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:36:30.156: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 23 09:36:30.165: INFO: Updating deployment test-recreate-deployment
Apr 23 09:36:30.165: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 23 09:36:30.244: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2809,SelfLink:/apis/apps/v1/namespaces/deployment-2809/deployments/test-recreate-deployment,UID:43b2a40a-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:11160,Generation:2,CreationTimestamp:2019-04-23 09:36:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-23 09:36:30 +0000 UTC 2019-04-23 09:36:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-23 09:36:30 +0000 UTC 2019-04-23 09:36:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 23 09:36:30.247: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-2809,SelfLink:/apis/apps/v1/namespaces/deployment-2809/replicasets/test-recreate-deployment-c9cbd8684,UID:4622d6fd-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:11157,Generation:1,CreationTimestamp:2019-04-23 09:36:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 43b2a40a-65ab-11e9-be4b-42010a8a0fda 0xc002357350 0xc002357351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:36:30.247: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 23 09:36:30.247: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-2809,SelfLink:/apis/apps/v1/namespaces/deployment-2809/replicasets/test-recreate-deployment-7d57d5ff7c,UID:43b38786-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:11148,Generation:2,CreationTimestamp:2019-04-23 09:36:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 43b2a40a-65ab-11e9-be4b-42010a8a0fda 0xc002357287 0xc002357288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:36:30.250: INFO: Pod "test-recreate-deployment-c9cbd8684-5rvzk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-5rvzk,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-2809,SelfLink:/api/v1/namespaces/deployment-2809/pods/test-recreate-deployment-c9cbd8684-5rvzk,UID:46239919-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:11158,Generation:0,CreationTimestamp:2019-04-23 09:36:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 4622d6fd-65ab-11e9-be4b-42010a8a0fda 0xc0028c5440 0xc0028c5441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbz6r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbz6r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbz6r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028c54c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028c54e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:30 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:,StartTime:2019-04-23 09:36:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:36:30.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2809" for this suite.
Apr 23 09:36:36.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:36:36.350: INFO: namespace deployment-2809 deletion completed in 6.096466518s

• [SLOW TEST:10.276 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:36:36.350: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 23 09:36:36.396: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2022" to be "success or failure"
Apr 23 09:36:36.402: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.775259ms
Apr 23 09:36:38.406: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00988121s
Apr 23 09:36:40.410: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013954s
STEP: Saw pod success
Apr 23 09:36:40.410: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 23 09:36:40.413: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 23 09:36:40.441: INFO: Waiting for pod pod-host-path-test to disappear
Apr 23 09:36:40.444: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:36:40.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2022" for this suite.
Apr 23 09:36:46.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:36:46.562: INFO: namespace hostpath-2022 deletion completed in 6.111398148s

• [SLOW TEST:10.213 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:36:46.563: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 23 09:36:51.138: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-553 pod-service-account-503850ad-65ab-11e9-b8ea-e2349624188d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 23 09:36:51.428: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-553 pod-service-account-503850ad-65ab-11e9-b8ea-e2349624188d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 23 09:36:51.721: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-553 pod-service-account-503850ad-65ab-11e9-b8ea-e2349624188d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:36:52.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-553" for this suite.
Apr 23 09:36:58.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:36:58.132: INFO: namespace svcaccounts-553 deletion completed in 6.103065607s

• [SLOW TEST:11.570 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:36:58.132: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 23 09:37:02.249: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-56d6ec6d-65ab-11e9-b8ea-e2349624188d,GenerateName:,Namespace:events-8411,SelfLink:/api/v1/namespaces/events-8411/pods/send-events-56d6ec6d-65ab-11e9-b8ea-e2349624188d,UID:56d7825a-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:11319,Generation:0,CreationTimestamp:2019-04-23 09:36:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 224962112,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.89/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-97sd9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-97sd9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-97sd9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030841b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030841d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:37:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:37:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:36:58 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.89,StartTime:2019-04-23 09:36:58 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-23 09:37:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d9920f582df4f42e64cbc01e6881d9dc49086c878107b2e46a365f48bb90d0de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 23 09:37:04.254: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 23 09:37:06.258: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:37:06.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8411" for this suite.
Apr 23 09:37:44.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:37:44.382: INFO: namespace events-8411 deletion completed in 38.108240549s

• [SLOW TEST:46.249 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:37:44.382: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8619.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8619.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 23 09:37:48.463: INFO: DNS probes using dns-8619/dns-test-725feba1-65ab-11e9-b8ea-e2349624188d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:37:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8619" for this suite.
Apr 23 09:37:54.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:37:54.587: INFO: namespace dns-8619 deletion completed in 6.10395039s

• [SLOW TEST:10.205 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:37:54.587: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:37:54.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d" in namespace "downward-api-8145" to be "success or failure"
Apr 23 09:37:54.634: INFO: Pod "downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.986095ms
Apr 23 09:37:56.638: INFO: Pod "downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007205919s
Apr 23 09:37:58.645: INFO: Pod "downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013683174s
STEP: Saw pod success
Apr 23 09:37:58.645: INFO: Pod "downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:37:58.649: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:37:58.677: INFO: Waiting for pod downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:37:58.680: INFO: Pod downwardapi-volume-7874c1bf-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:37:58.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8145" for this suite.
Apr 23 09:38:04.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:38:04.786: INFO: namespace downward-api-8145 deletion completed in 6.101825455s

• [SLOW TEST:10.199 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:38:04.786: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 23 09:38:12.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:12.882: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:14.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:14.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:16.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:16.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:18.883: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:18.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:20.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:20.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:22.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:22.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:24.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:24.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:26.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:26.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:28.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:28.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 09:38:30.882: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 09:38:30.886: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:38:30.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6373" for this suite.
Apr 23 09:38:52.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:38:53.000: INFO: namespace container-lifecycle-hook-6373 deletion completed in 22.100169399s

• [SLOW TEST:48.214 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:38:53.000: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-9b466ad5-65ab-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:38:53.054: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d" in namespace "configmap-251" to be "success or failure"
Apr 23 09:38:53.061: INFO: Pod "pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.371556ms
Apr 23 09:38:55.065: INFO: Pod "pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010391245s
Apr 23 09:38:57.068: INFO: Pod "pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014190131s
STEP: Saw pod success
Apr 23 09:38:57.069: INFO: Pod "pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:38:57.071: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:38:57.096: INFO: Waiting for pod pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:38:57.098: INFO: Pod pod-configmaps-9b4744fd-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:38:57.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-251" for this suite.
Apr 23 09:39:03.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:39:03.208: INFO: namespace configmap-251 deletion completed in 6.106374965s

• [SLOW TEST:10.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:39:03.209: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-a15cc6ef-65ab-11e9-b8ea-e2349624188d
STEP: Creating configMap with name cm-test-opt-upd-a15cc725-65ab-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a15cc6ef-65ab-11e9-b8ea-e2349624188d
STEP: Updating configmap cm-test-opt-upd-a15cc725-65ab-11e9-b8ea-e2349624188d
STEP: Creating configMap with name cm-test-opt-create-a15cc73a-65ab-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:39:11.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7810" for this suite.
Apr 23 09:39:33.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:39:33.477: INFO: namespace projected-7810 deletion completed in 22.109041886s

• [SLOW TEST:30.269 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:39:33.478: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b367491a-65ab-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:39:33.540: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d" in namespace "projected-2130" to be "success or failure"
Apr 23 09:39:33.544: INFO: Pod "pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.504554ms
Apr 23 09:39:35.548: INFO: Pod "pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007646646s
Apr 23 09:39:37.552: INFO: Pod "pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011631707s
STEP: Saw pod success
Apr 23 09:39:37.552: INFO: Pod "pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:39:37.555: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:39:37.591: INFO: Waiting for pod pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:39:37.593: INFO: Pod pod-projected-secrets-b367e94d-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:39:37.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2130" for this suite.
Apr 23 09:39:43.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:39:43.700: INFO: namespace projected-2130 deletion completed in 6.103011726s

• [SLOW TEST:10.223 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:39:43.701: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:39:43.750: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d" in namespace "projected-8761" to be "success or failure"
Apr 23 09:39:43.753: INFO: Pod "downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865273ms
Apr 23 09:39:45.758: INFO: Pod "downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008098364s
Apr 23 09:39:47.761: INFO: Pod "downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011858068s
STEP: Saw pod success
Apr 23 09:39:47.762: INFO: Pod "downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:39:47.764: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:39:47.790: INFO: Waiting for pod downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:39:47.793: INFO: Pod downwardapi-volume-b97ea3c4-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:39:47.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8761" for this suite.
Apr 23 09:39:53.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:39:53.918: INFO: namespace projected-8761 deletion completed in 6.120716395s

• [SLOW TEST:10.218 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:39:53.919: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-9001/secret-test-bf96908e-65ab-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:39:53.986: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d" in namespace "secrets-9001" to be "success or failure"
Apr 23 09:39:53.992: INFO: Pod "pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019715ms
Apr 23 09:39:55.997: INFO: Pod "pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010204728s
Apr 23 09:39:58.002: INFO: Pod "pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015239581s
STEP: Saw pod success
Apr 23 09:39:58.002: INFO: Pod "pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:39:58.005: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d container env-test: <nil>
STEP: delete the pod
Apr 23 09:39:58.037: INFO: Waiting for pod pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:39:58.040: INFO: Pod pod-configmaps-bf97a083-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:39:58.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9001" for this suite.
Apr 23 09:40:04.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:04.158: INFO: namespace secrets-9001 deletion completed in 6.113652018s

• [SLOW TEST:10.240 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:04.159: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 23 09:40:04.251: INFO: Waiting up to 5m0s for pod "downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d" in namespace "downward-api-4392" to be "success or failure"
Apr 23 09:40:04.254: INFO: Pod "downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251201ms
Apr 23 09:40:06.258: INFO: Pod "downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007236743s
Apr 23 09:40:08.263: INFO: Pod "downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011497967s
STEP: Saw pod success
Apr 23 09:40:08.263: INFO: Pod "downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:40:08.266: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:40:08.292: INFO: Waiting for pod downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:40:08.296: INFO: Pod downward-api-c5b45ea7-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:40:08.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4392" for this suite.
Apr 23 09:40:14.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:14.406: INFO: namespace downward-api-4392 deletion completed in 6.106567358s

• [SLOW TEST:10.248 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:14.406: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 23 09:40:14.526: INFO: Waiting up to 5m0s for pod "pod-cbd358bd-65ab-11e9-b8ea-e2349624188d" in namespace "emptydir-3531" to be "success or failure"
Apr 23 09:40:14.531: INFO: Pod "pod-cbd358bd-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.452115ms
Apr 23 09:40:16.535: INFO: Pod "pod-cbd358bd-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008697227s
Apr 23 09:40:18.539: INFO: Pod "pod-cbd358bd-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013154595s
STEP: Saw pod success
Apr 23 09:40:18.540: INFO: Pod "pod-cbd358bd-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:40:18.542: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-cbd358bd-65ab-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:40:18.572: INFO: Waiting for pod pod-cbd358bd-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:40:18.575: INFO: Pod pod-cbd358bd-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:40:18.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3531" for this suite.
Apr 23 09:40:24.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:24.683: INFO: namespace emptydir-3531 deletion completed in 6.103932381s

• [SLOW TEST:10.277 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:24.683: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:40:24.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d" in namespace "projected-8608" to be "success or failure"
Apr 23 09:40:24.736: INFO: Pod "downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.436424ms
Apr 23 09:40:26.740: INFO: Pod "downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008558106s
Apr 23 09:40:28.744: INFO: Pod "downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012420948s
STEP: Saw pod success
Apr 23 09:40:28.744: INFO: Pod "downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:40:28.747: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:40:28.772: INFO: Waiting for pod downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:40:28.776: INFO: Pod downwardapi-volume-d1ec17a9-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:40:28.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8608" for this suite.
Apr 23 09:40:34.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:34.896: INFO: namespace projected-8608 deletion completed in 6.116048449s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:34.896: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:40:34.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d" in namespace "downward-api-8089" to be "success or failure"
Apr 23 09:40:34.983: INFO: Pod "downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.287549ms
Apr 23 09:40:36.987: INFO: Pod "downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0082141s
Apr 23 09:40:38.991: INFO: Pod "downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012883411s
STEP: Saw pod success
Apr 23 09:40:38.991: INFO: Pod "downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:40:38.994: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:40:39.025: INFO: Waiting for pod downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:40:39.030: INFO: Pod downwardapi-volume-d80695bc-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:40:39.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8089" for this suite.
Apr 23 09:40:45.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:45.164: INFO: namespace downward-api-8089 deletion completed in 6.130267142s

• [SLOW TEST:10.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:45.165: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 23 09:40:45.236: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3624,SelfLink:/api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-resource-version,UID:de218ce4-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:12079,Generation:0,CreationTimestamp:2019-04-23 09:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 23 09:40:45.236: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3624,SelfLink:/api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-resource-version,UID:de218ce4-65ab-11e9-be4b-42010a8a0fda,ResourceVersion:12080,Generation:0,CreationTimestamp:2019-04-23 09:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:40:45.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3624" for this suite.
Apr 23 09:40:51.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:40:51.350: INFO: namespace watch-3624 deletion completed in 6.109123237s

• [SLOW TEST:6.185 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:40:51.350: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0423 09:41:01.422250      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:41:01.422: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:41:01.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3166" for this suite.
Apr 23 09:41:07.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:41:07.534: INFO: namespace gc-3166 deletion completed in 6.108682084s

• [SLOW TEST:16.185 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:41:07.535: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 23 09:41:07.697: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:41:07.707: INFO: Number of nodes with available pods: 0
Apr 23 09:41:07.707: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:41:08.712: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:41:08.716: INFO: Number of nodes with available pods: 0
Apr 23 09:41:08.716: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:41:09.722: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:41:09.725: INFO: Number of nodes with available pods: 0
Apr 23 09:41:09.725: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 09:41:10.712: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:41:10.715: INFO: Number of nodes with available pods: 3
Apr 23 09:41:10.715: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 23 09:41:10.736: INFO: DaemonSet pods can't tolerate node net1a83gn1-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 23 09:41:10.742: INFO: Number of nodes with available pods: 3
Apr 23 09:41:10.742: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7122, will wait for the garbage collector to delete the pods
Apr 23 09:41:11.814: INFO: Deleting DaemonSet.extensions daemon-set took: 8.907673ms
Apr 23 09:41:12.114: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.244072ms
Apr 23 09:41:24.318: INFO: Number of nodes with available pods: 0
Apr 23 09:41:24.318: INFO: Number of running nodes: 0, number of available pods: 0
Apr 23 09:41:24.321: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7122/daemonsets","resourceVersion":"12279"},"items":null}

Apr 23 09:41:24.324: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7122/pods","resourceVersion":"12279"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:41:24.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7122" for this suite.
Apr 23 09:41:30.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:41:30.448: INFO: namespace daemonsets-7122 deletion completed in 6.105391669s

• [SLOW TEST:22.913 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:41:30.448: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 23 09:41:30.501: INFO: Waiting up to 5m0s for pod "pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d" in namespace "emptydir-4933" to be "success or failure"
Apr 23 09:41:30.507: INFO: Pod "pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462384ms
Apr 23 09:41:32.511: INFO: Pod "pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010393519s
Apr 23 09:41:34.515: INFO: Pod "pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014476928s
STEP: Saw pod success
Apr 23 09:41:34.515: INFO: Pod "pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:41:34.518: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:41:34.537: INFO: Waiting for pod pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d to disappear
Apr 23 09:41:34.540: INFO: Pod pod-f91eb7cf-65ab-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:41:34.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4933" for this suite.
Apr 23 09:41:40.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:41:40.645: INFO: namespace emptydir-4933 deletion completed in 6.101061744s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:41:40.646: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1281
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 23 09:41:40.685: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 23 09:42:04.803: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.101:8080/dial?request=hostName&protocol=http&host=10.2.1.100&port=8080&tries=1'] Namespace:pod-network-test-1281 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:42:04.803: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:42:05.097: INFO: Waiting for endpoints: map[]
Apr 23 09:42:05.102: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.101:8080/dial?request=hostName&protocol=http&host=10.2.3.29&port=8080&tries=1'] Namespace:pod-network-test-1281 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:42:05.102: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:42:05.436: INFO: Waiting for endpoints: map[]
Apr 23 09:42:05.440: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.101:8080/dial?request=hostName&protocol=http&host=10.2.2.73&port=8080&tries=1'] Namespace:pod-network-test-1281 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 09:42:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 09:42:05.771: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:42:05.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1281" for this suite.
Apr 23 09:42:27.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:42:27.876: INFO: namespace pod-network-test-1281 deletion completed in 22.100546869s

• [SLOW TEST:47.231 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:42:27.876: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 23 09:42:27.936: INFO: Waiting up to 5m0s for pod "downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d" in namespace "downward-api-8162" to be "success or failure"
Apr 23 09:42:27.939: INFO: Pod "downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.816871ms
Apr 23 09:42:29.943: INFO: Pod "downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00666358s
Apr 23 09:42:31.946: INFO: Pod "downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009980307s
STEP: Saw pod success
Apr 23 09:42:31.946: INFO: Pod "downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:42:31.949: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:42:31.972: INFO: Waiting for pod downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:42:31.974: INFO: Pod downward-api-1b5b7fd4-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:42:31.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8162" for this suite.
Apr 23 09:42:37.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:42:38.079: INFO: namespace downward-api-8162 deletion completed in 6.100390025s

• [SLOW TEST:10.202 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:42:38.079: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:42:38.122: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 23 09:42:43.126: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 23 09:42:43.126: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 23 09:42:45.131: INFO: Creating deployment "test-rollover-deployment"
Apr 23 09:42:45.144: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 23 09:42:47.151: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 23 09:42:47.158: INFO: Ensure that both replica sets have 1 created replica
Apr 23 09:42:47.164: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 23 09:42:47.172: INFO: Updating deployment test-rollover-deployment
Apr 23 09:42:47.172: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 23 09:42:49.178: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 23 09:42:49.184: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 23 09:42:49.191: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:49.191: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609367, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:42:51.199: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:51.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609369, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:42:53.199: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:53.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609369, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:42:55.198: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:55.198: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609369, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:42:57.199: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:57.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609369, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:42:59.199: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 09:42:59.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609369, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691609365, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 09:43:01.199: INFO: 
Apr 23 09:43:01.199: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 23 09:43:01.207: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3954,SelfLink:/apis/apps/v1/namespaces/deployment-3954/deployments/test-rollover-deployment,UID:259cc9fa-65ac-11e9-be4b-42010a8a0fda,ResourceVersion:12685,Generation:2,CreationTimestamp:2019-04-23 09:42:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-23 09:42:45 +0000 UTC 2019-04-23 09:42:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-23 09:42:59 +0000 UTC 2019-04-23 09:42:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 09:43:01.210: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-3954,SelfLink:/apis/apps/v1/namespaces/deployment-3954/replicasets/test-rollover-deployment-766b4d6c9d,UID:26d43bfc-65ac-11e9-be4b-42010a8a0fda,ResourceVersion:12675,Generation:2,CreationTimestamp:2019-04-23 09:42:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 259cc9fa-65ac-11e9-be4b-42010a8a0fda 0xc0016a1107 0xc0016a1108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 23 09:43:01.210: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 23 09:43:01.211: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3954,SelfLink:/apis/apps/v1/namespaces/deployment-3954/replicasets/test-rollover-controller,UID:216e1ff4-65ac-11e9-be4b-42010a8a0fda,ResourceVersion:12684,Generation:2,CreationTimestamp:2019-04-23 09:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 259cc9fa-65ac-11e9-be4b-42010a8a0fda 0xc0016a0f57 0xc0016a0f58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:43:01.211: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-3954,SelfLink:/apis/apps/v1/namespaces/deployment-3954/replicasets/test-rollover-deployment-6455657675,UID:259f19b9-65ac-11e9-be4b-42010a8a0fda,ResourceVersion:12646,Generation:2,CreationTimestamp:2019-04-23 09:42:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 259cc9fa-65ac-11e9-be4b-42010a8a0fda 0xc0016a1027 0xc0016a1028}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:43:01.214: INFO: Pod "test-rollover-deployment-766b4d6c9d-89mvv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-89mvv,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-3954,SelfLink:/api/v1/namespaces/deployment-3954/pods/test-rollover-deployment-766b4d6c9d-89mvv,UID:26d8d961-65ac-11e9-be4b-42010a8a0fda,ResourceVersion:12654,Generation:0,CreationTimestamp:2019-04-23 09:42:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.103/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 26d43bfc-65ac-11e9-be4b-42010a8a0fda 0xc0016a1cc7 0xc0016a1cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rkq4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rkq4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rkq4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016a1d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016a1d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:42:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:42:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:42:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:42:47 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.103,StartTime:2019-04-23 09:42:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-23 09:42:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://96f99aa6c46cdba6d0d9607b1fc7d5aaba64021ec90503d2c57e701031621020}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:43:01.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3954" for this suite.
Apr 23 09:43:07.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:43:07.320: INFO: namespace deployment-3954 deletion completed in 6.102568503s

• [SLOW TEST:29.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:43:07.320: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 09:43:07.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7474'
Apr 23 09:43:07.651: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 23 09:43:07.651: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 23 09:43:07.658: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr 23 09:43:07.662: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 23 09:43:07.679: INFO: scanned /root for discovery docs: <nil>
Apr 23 09:43:07.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7474'
Apr 23 09:43:23.484: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 23 09:43:23.484: INFO: stdout: "Created e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3\nScaling up e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 23 09:43:23.484: INFO: stdout: "Created e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3\nScaling up e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 23 09:43:23.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7474'
Apr 23 09:43:23.568: INFO: stderr: ""
Apr 23 09:43:23.568: INFO: stdout: "e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3-dklbm "
Apr 23 09:43:23.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3-dklbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7474'
Apr 23 09:43:23.646: INFO: stderr: ""
Apr 23 09:43:23.646: INFO: stdout: "true"
Apr 23 09:43:23.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3-dklbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7474'
Apr 23 09:43:23.725: INFO: stderr: ""
Apr 23 09:43:23.725: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 23 09:43:23.725: INFO: e2e-test-nginx-rc-5cdb6bec014ed87cacbb7d6c4c4ff0e3-dklbm is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 23 09:43:23.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete rc e2e-test-nginx-rc --namespace=kubectl-7474'
Apr 23 09:43:23.817: INFO: stderr: ""
Apr 23 09:43:23.817: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:43:23.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7474" for this suite.
Apr 23 09:43:29.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:43:29.940: INFO: namespace kubectl-7474 deletion completed in 6.11695597s

• [SLOW TEST:22.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:43:29.940: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 23 09:43:29.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-4241'
Apr 23 09:43:30.195: INFO: stderr: ""
Apr 23 09:43:30.195: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 23 09:43:31.199: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:43:31.199: INFO: Found 0 / 1
Apr 23 09:43:32.199: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:43:32.199: INFO: Found 0 / 1
Apr 23 09:43:33.199: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:43:33.199: INFO: Found 1 / 1
Apr 23 09:43:33.199: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 23 09:43:33.202: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:43:33.202: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 23 09:43:33.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 logs redis-master-d928x redis-master --namespace=kubectl-4241'
Apr 23 09:43:33.291: INFO: stderr: ""
Apr 23 09:43:33.291: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Apr 09:43:31.838 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Apr 09:43:31.838 # Server started, Redis version 3.2.12\n1:M 23 Apr 09:43:31.838 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Apr 09:43:31.838 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 23 09:43:33.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 log redis-master-d928x redis-master --namespace=kubectl-4241 --tail=1'
Apr 23 09:43:33.375: INFO: stderr: ""
Apr 23 09:43:33.375: INFO: stdout: "1:M 23 Apr 09:43:31.838 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 23 09:43:33.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 log redis-master-d928x redis-master --namespace=kubectl-4241 --limit-bytes=1'
Apr 23 09:43:33.461: INFO: stderr: ""
Apr 23 09:43:33.461: INFO: stdout: " "
STEP: exposing timestamps
Apr 23 09:43:33.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 log redis-master-d928x redis-master --namespace=kubectl-4241 --tail=1 --timestamps'
Apr 23 09:43:33.546: INFO: stderr: ""
Apr 23 09:43:33.546: INFO: stdout: "2019-04-23T09:43:31.839339053Z 1:M 23 Apr 09:43:31.838 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 23 09:43:36.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 log redis-master-d928x redis-master --namespace=kubectl-4241 --since=1s'
Apr 23 09:43:36.136: INFO: stderr: ""
Apr 23 09:43:36.136: INFO: stdout: ""
Apr 23 09:43:36.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 log redis-master-d928x redis-master --namespace=kubectl-4241 --since=24h'
Apr 23 09:43:36.220: INFO: stderr: ""
Apr 23 09:43:36.220: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Apr 09:43:31.838 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Apr 09:43:31.838 # Server started, Redis version 3.2.12\n1:M 23 Apr 09:43:31.838 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Apr 09:43:31.838 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 23 09:43:36.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-4241'
Apr 23 09:43:36.299: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:43:36.299: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 23 09:43:36.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4241'
Apr 23 09:43:36.380: INFO: stderr: "No resources found.\n"
Apr 23 09:43:36.380: INFO: stdout: ""
Apr 23 09:43:36.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=nginx --namespace=kubectl-4241 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 09:43:36.451: INFO: stderr: ""
Apr 23 09:43:36.451: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:43:36.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4241" for this suite.
Apr 23 09:43:42.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:43:42.563: INFO: namespace kubectl-4241 deletion completed in 6.107530933s

• [SLOW TEST:12.623 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:43:42.563: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-47dd9838-65ac-11e9-b8ea-e2349624188d
STEP: Creating configMap with name cm-test-opt-upd-47dd9877-65ac-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-47dd9838-65ac-11e9-b8ea-e2349624188d
STEP: Updating configmap cm-test-opt-upd-47dd9877-65ac-11e9-b8ea-e2349624188d
STEP: Creating configMap with name cm-test-opt-create-47dd988c-65ac-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:43:50.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8253" for this suite.
Apr 23 09:44:12.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:44:12.815: INFO: namespace configmap-8253 deletion completed in 22.105555577s

• [SLOW TEST:30.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:44:12.815: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 09:44:12.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2316'
Apr 23 09:44:12.945: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 23 09:44:12.945: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 23 09:44:14.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2316'
Apr 23 09:44:15.051: INFO: stderr: ""
Apr 23 09:44:15.051: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:44:15.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2316" for this suite.
Apr 23 09:44:37.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:44:37.197: INFO: namespace kubectl-2316 deletion completed in 22.132180896s

• [SLOW TEST:24.382 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:44:37.198: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 23 09:44:37.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-5397'
Apr 23 09:44:37.461: INFO: stderr: ""
Apr 23 09:44:37.461: INFO: stdout: "pod/pause created\n"
Apr 23 09:44:37.461: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 23 09:44:37.461: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5397" to be "running and ready"
Apr 23 09:44:37.485: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 23.989034ms
Apr 23 09:44:39.489: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02777761s
Apr 23 09:44:41.492: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.03142025s
Apr 23 09:44:41.492: INFO: Pod "pause" satisfied condition "running and ready"
Apr 23 09:44:41.492: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 23 09:44:41.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 label pods pause testing-label=testing-label-value --namespace=kubectl-5397'
Apr 23 09:44:41.579: INFO: stderr: ""
Apr 23 09:44:41.579: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 23 09:44:41.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pod pause -L testing-label --namespace=kubectl-5397'
Apr 23 09:44:41.654: INFO: stderr: ""
Apr 23 09:44:41.654: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 23 09:44:41.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 label pods pause testing-label- --namespace=kubectl-5397'
Apr 23 09:44:41.741: INFO: stderr: ""
Apr 23 09:44:41.741: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 23 09:44:41.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pod pause -L testing-label --namespace=kubectl-5397'
Apr 23 09:44:41.815: INFO: stderr: ""
Apr 23 09:44:41.816: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 23 09:44:41.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-5397'
Apr 23 09:44:41.906: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 09:44:41.906: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 23 09:44:41.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=pause --no-headers --namespace=kubectl-5397'
Apr 23 09:44:41.984: INFO: stderr: "No resources found.\n"
Apr 23 09:44:41.984: INFO: stdout: ""
Apr 23 09:44:41.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=pause --namespace=kubectl-5397 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 09:44:42.063: INFO: stderr: ""
Apr 23 09:44:42.063: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:44:42.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5397" for this suite.
Apr 23 09:44:48.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:44:48.179: INFO: namespace kubectl-5397 deletion completed in 6.111426986s

• [SLOW TEST:10.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:44:48.180: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-1863
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1863 to expose endpoints map[]
Apr 23 09:44:48.262: INFO: Get endpoints failed (7.732293ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 23 09:44:49.265: INFO: successfully validated that service endpoint-test2 in namespace services-1863 exposes endpoints map[] (1.011437815s elapsed)
STEP: Creating pod pod1 in namespace services-1863
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1863 to expose endpoints map[pod1:[80]]
Apr 23 09:44:52.327: INFO: successfully validated that service endpoint-test2 in namespace services-1863 exposes endpoints map[pod1:[80]] (3.051263857s elapsed)
STEP: Creating pod pod2 in namespace services-1863
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1863 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 23 09:44:55.379: INFO: successfully validated that service endpoint-test2 in namespace services-1863 exposes endpoints map[pod1:[80] pod2:[80]] (3.042389645s elapsed)
STEP: Deleting pod pod1 in namespace services-1863
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1863 to expose endpoints map[pod2:[80]]
Apr 23 09:44:55.397: INFO: successfully validated that service endpoint-test2 in namespace services-1863 exposes endpoints map[pod2:[80]] (7.127453ms elapsed)
STEP: Deleting pod pod2 in namespace services-1863
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1863 to expose endpoints map[]
Apr 23 09:44:55.418: INFO: successfully validated that service endpoint-test2 in namespace services-1863 exposes endpoints map[] (4.234589ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:44:55.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1863" for this suite.
Apr 23 09:45:17.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:45:17.556: INFO: namespace services-1863 deletion completed in 22.109041493s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.377 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:45:17.556: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 23 09:45:17.610: INFO: Waiting up to 5m0s for pod "pod-807de6b2-65ac-11e9-b8ea-e2349624188d" in namespace "emptydir-3731" to be "success or failure"
Apr 23 09:45:17.614: INFO: Pod "pod-807de6b2-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.779077ms
Apr 23 09:45:19.618: INFO: Pod "pod-807de6b2-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00774928s
Apr 23 09:45:21.622: INFO: Pod "pod-807de6b2-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011758237s
STEP: Saw pod success
Apr 23 09:45:21.622: INFO: Pod "pod-807de6b2-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:45:21.625: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-807de6b2-65ac-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:45:21.646: INFO: Waiting for pod pod-807de6b2-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:45:21.650: INFO: Pod pod-807de6b2-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:45:21.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3731" for this suite.
Apr 23 09:45:27.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:45:27.754: INFO: namespace emptydir-3731 deletion completed in 6.098464742s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:45:27.754: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 23 09:45:35.864: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:35.868: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:37.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:37.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:39.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:39.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:41.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:41.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:43.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:43.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:45.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:45.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:47.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:47.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:49.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:49.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:51.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:51.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:53.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:53.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:55.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:55.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:57.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:57.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:45:59.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:45:59.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:46:01.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:46:01.883: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:46:03.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:46:03.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 09:46:05.868: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 09:46:05.872: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:46:05.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6842" for this suite.
Apr 23 09:46:27.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:46:27.971: INFO: namespace container-lifecycle-hook-6842 deletion completed in 22.094477587s

• [SLOW TEST:60.217 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:46:27.971: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:46:28.064: INFO: (0) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.466843ms)
Apr 23 09:46:28.068: INFO: (1) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.624512ms)
Apr 23 09:46:28.071: INFO: (2) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.363425ms)
Apr 23 09:46:28.074: INFO: (3) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.323814ms)
Apr 23 09:46:28.078: INFO: (4) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.229723ms)
Apr 23 09:46:28.081: INFO: (5) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.746305ms)
Apr 23 09:46:28.085: INFO: (6) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.441122ms)
Apr 23 09:46:28.088: INFO: (7) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.170973ms)
Apr 23 09:46:28.091: INFO: (8) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.288977ms)
Apr 23 09:46:28.095: INFO: (9) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.164043ms)
Apr 23 09:46:28.098: INFO: (10) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.928891ms)
Apr 23 09:46:28.101: INFO: (11) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.285952ms)
Apr 23 09:46:28.104: INFO: (12) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.23874ms)
Apr 23 09:46:28.107: INFO: (13) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.27787ms)
Apr 23 09:46:28.111: INFO: (14) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.252916ms)
Apr 23 09:46:28.114: INFO: (15) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.261625ms)
Apr 23 09:46:28.118: INFO: (16) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.248923ms)
Apr 23 09:46:28.122: INFO: (17) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.355626ms)
Apr 23 09:46:28.125: INFO: (18) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.687073ms)
Apr 23 09:46:28.129: INFO: (19) /api/v1/nodes/net1a83gn1-worker-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.199856ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:46:28.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3830" for this suite.
Apr 23 09:46:34.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:46:34.238: INFO: namespace proxy-3830 deletion completed in 6.10568765s

• [SLOW TEST:6.267 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:46:34.239: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:46:34.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d" in namespace "projected-1731" to be "success or failure"
Apr 23 09:46:34.286: INFO: Pod "downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.643871ms
Apr 23 09:46:36.290: INFO: Pod "downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007431616s
Apr 23 09:46:38.294: INFO: Pod "downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011357736s
STEP: Saw pod success
Apr 23 09:46:38.294: INFO: Pod "downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:46:38.297: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:46:38.317: INFO: Waiting for pod downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:46:38.322: INFO: Pod downwardapi-volume-ae31578e-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:46:38.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1731" for this suite.
Apr 23 09:46:44.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:46:44.429: INFO: namespace projected-1731 deletion completed in 6.103064466s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:46:44.429: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:46:49.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6845" for this suite.
Apr 23 09:47:11.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:47:11.612: INFO: namespace replication-controller-6845 deletion completed in 22.107851267s

• [SLOW TEST:27.182 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:47:11.612: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 23 09:47:11.649: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:47:14.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1872" for this suite.
Apr 23 09:47:20.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:47:21.075: INFO: namespace init-container-1872 deletion completed in 6.099491459s

• [SLOW TEST:9.463 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:47:21.076: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 23 09:47:21.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-5682'
Apr 23 09:47:21.328: INFO: stderr: ""
Apr 23 09:47:21.328: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 23 09:47:22.332: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:47:22.332: INFO: Found 0 / 1
Apr 23 09:47:23.332: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:47:23.332: INFO: Found 0 / 1
Apr 23 09:47:24.332: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:47:24.332: INFO: Found 1 / 1
Apr 23 09:47:24.332: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 23 09:47:24.335: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:47:24.335: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 09:47:24.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 patch pod redis-master-q5bbl --namespace=kubectl-5682 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 23 09:47:24.414: INFO: stderr: ""
Apr 23 09:47:24.414: INFO: stdout: "pod/redis-master-q5bbl patched\n"
STEP: checking annotations
Apr 23 09:47:24.417: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 09:47:24.417: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:47:24.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5682" for this suite.
Apr 23 09:47:46.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:47:46.524: INFO: namespace kubectl-5682 deletion completed in 22.102411319s

• [SLOW TEST:25.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:47:46.524: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 23 09:47:46.578: INFO: Waiting up to 5m0s for pod "pod-d9486bb4-65ac-11e9-b8ea-e2349624188d" in namespace "emptydir-1316" to be "success or failure"
Apr 23 09:47:46.583: INFO: Pod "pod-d9486bb4-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.389002ms
Apr 23 09:47:48.587: INFO: Pod "pod-d9486bb4-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008429267s
Apr 23 09:47:50.591: INFO: Pod "pod-d9486bb4-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012326362s
STEP: Saw pod success
Apr 23 09:47:50.591: INFO: Pod "pod-d9486bb4-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:47:50.593: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-d9486bb4-65ac-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:47:50.616: INFO: Waiting for pod pod-d9486bb4-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:47:50.620: INFO: Pod pod-d9486bb4-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:47:50.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1316" for this suite.
Apr 23 09:47:56.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:47:56.722: INFO: namespace emptydir-1316 deletion completed in 6.098648501s

• [SLOW TEST:10.198 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:47:56.722: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0423 09:48:06.850076      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:48:06.850: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:48:06.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8368" for this suite.
Apr 23 09:48:12.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:48:12.952: INFO: namespace gc-8368 deletion completed in 6.099033306s

• [SLOW TEST:16.230 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:48:12.956: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 23 09:48:13.000: INFO: Waiting up to 5m0s for pod "pod-e9084dbe-65ac-11e9-b8ea-e2349624188d" in namespace "emptydir-9974" to be "success or failure"
Apr 23 09:48:13.004: INFO: Pod "pod-e9084dbe-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.812377ms
Apr 23 09:48:15.007: INFO: Pod "pod-e9084dbe-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006857148s
Apr 23 09:48:17.011: INFO: Pod "pod-e9084dbe-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010714775s
STEP: Saw pod success
Apr 23 09:48:17.011: INFO: Pod "pod-e9084dbe-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:48:17.013: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-e9084dbe-65ac-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:48:17.034: INFO: Waiting for pod pod-e9084dbe-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:48:17.036: INFO: Pod pod-e9084dbe-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:48:17.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9974" for this suite.
Apr 23 09:48:23.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:48:23.126: INFO: namespace emptydir-9974 deletion completed in 6.086500994s

• [SLOW TEST:10.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:48:23.126: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-ef20fb04-65ac-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:48:23.234: INFO: Waiting up to 5m0s for pod "pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d" in namespace "secrets-8869" to be "success or failure"
Apr 23 09:48:23.237: INFO: Pod "pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.913326ms
Apr 23 09:48:25.241: INFO: Pod "pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006822084s
Apr 23 09:48:27.245: INFO: Pod "pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010876944s
STEP: Saw pod success
Apr 23 09:48:27.245: INFO: Pod "pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:48:27.247: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d container secret-env-test: <nil>
STEP: delete the pod
Apr 23 09:48:27.267: INFO: Waiting for pod pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:48:27.269: INFO: Pod pod-secrets-ef21f080-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:48:27.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8869" for this suite.
Apr 23 09:48:33.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:48:33.368: INFO: namespace secrets-8869 deletion completed in 6.09577048s

• [SLOW TEST:10.242 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:48:33.368: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:48:33.420: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d" in namespace "projected-7702" to be "success or failure"
Apr 23 09:48:33.424: INFO: Pod "downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.899399ms
Apr 23 09:48:35.428: INFO: Pod "downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007670209s
Apr 23 09:48:37.431: INFO: Pod "downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011604161s
STEP: Saw pod success
Apr 23 09:48:37.432: INFO: Pod "downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:48:37.434: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:48:37.467: INFO: Waiting for pod downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d to disappear
Apr 23 09:48:37.469: INFO: Pod downwardapi-volume-f5334b69-65ac-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:48:37.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7702" for this suite.
Apr 23 09:48:43.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:48:43.576: INFO: namespace projected-7702 deletion completed in 6.102411586s

• [SLOW TEST:10.207 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:48:43.576: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:48:43.626: INFO: Creating ReplicaSet my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d
Apr 23 09:48:43.638: INFO: Pod name my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d: Found 0 pods out of 1
Apr 23 09:48:48.642: INFO: Pod name my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d: Found 1 pods out of 1
Apr 23 09:48:48.642: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d" is running
Apr 23 09:48:48.645: INFO: Pod "my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d-q2v5s" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:48:43 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:48:45 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:48:45 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:48:43 +0000 UTC Reason: Message:}])
Apr 23 09:48:48.645: INFO: Trying to dial the pod
Apr 23 09:48:53.656: INFO: Controller my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d: Got expected result from replica 1 [my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d-q2v5s]: "my-hostname-basic-fb4ab8f5-65ac-11e9-b8ea-e2349624188d-q2v5s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:48:53.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3375" for this suite.
Apr 23 09:48:59.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:48:59.761: INFO: namespace replicaset-3375 deletion completed in 6.100228929s

• [SLOW TEST:16.185 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:48:59.761: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 23 09:48:59.805: INFO: Waiting up to 5m0s for pod "pod-04ee176d-65ad-11e9-b8ea-e2349624188d" in namespace "emptydir-4491" to be "success or failure"
Apr 23 09:48:59.809: INFO: Pod "pod-04ee176d-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.690521ms
Apr 23 09:49:01.813: INFO: Pod "pod-04ee176d-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008117595s
Apr 23 09:49:03.817: INFO: Pod "pod-04ee176d-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01201826s
STEP: Saw pod success
Apr 23 09:49:03.817: INFO: Pod "pod-04ee176d-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:49:03.819: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-04ee176d-65ad-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:49:03.839: INFO: Waiting for pod pod-04ee176d-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:49:03.841: INFO: Pod pod-04ee176d-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:49:03.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4491" for this suite.
Apr 23 09:49:09.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:49:09.943: INFO: namespace emptydir-4491 deletion completed in 6.098207087s

• [SLOW TEST:10.182 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:49:09.943: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-0affd27b-65ad-11e9-b8ea-e2349624188d
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:49:09.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2700" for this suite.
Apr 23 09:49:15.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:49:16.080: INFO: namespace configmap-2700 deletion completed in 6.09648588s

• [SLOW TEST:6.137 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:49:16.081: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:49:16.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5377" for this suite.
Apr 23 09:49:22.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:49:22.220: INFO: namespace services-5377 deletion completed in 6.099085996s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.139 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:49:22.220: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0423 09:50:02.286710      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:50:02.286: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:50:02.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6314" for this suite.
Apr 23 09:50:08.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:50:08.407: INFO: namespace gc-6314 deletion completed in 6.116441269s

• [SLOW TEST:46.187 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:50:08.407: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 23 09:50:08.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 --namespace=kubectl-517 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 23 09:50:10.849: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 23 09:50:10.849: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:50:12.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-517" for this suite.
Apr 23 09:50:24.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:50:24.956: INFO: namespace kubectl-517 deletion completed in 12.096481056s

• [SLOW TEST:16.549 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:50:24.956: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 23 09:50:25.006: INFO: Waiting up to 5m0s for pod "pod-37b629ad-65ad-11e9-b8ea-e2349624188d" in namespace "emptydir-3448" to be "success or failure"
Apr 23 09:50:25.009: INFO: Pod "pod-37b629ad-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.786218ms
Apr 23 09:50:27.013: INFO: Pod "pod-37b629ad-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006677079s
Apr 23 09:50:29.017: INFO: Pod "pod-37b629ad-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01064147s
STEP: Saw pod success
Apr 23 09:50:29.017: INFO: Pod "pod-37b629ad-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:50:29.019: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-37b629ad-65ad-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:50:29.040: INFO: Waiting for pod pod-37b629ad-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:50:29.042: INFO: Pod pod-37b629ad-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:50:29.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3448" for this suite.
Apr 23 09:50:35.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:50:35.146: INFO: namespace emptydir-3448 deletion completed in 6.099211799s

• [SLOW TEST:10.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:50:35.146: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3dc90e3b-65ad-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:50:35.197: INFO: Waiting up to 5m0s for pod "pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d" in namespace "configmap-8306" to be "success or failure"
Apr 23 09:50:35.207: INFO: Pod "pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.914274ms
Apr 23 09:50:37.211: INFO: Pod "pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013787418s
Apr 23 09:50:39.215: INFO: Pod "pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017699631s
STEP: Saw pod success
Apr 23 09:50:39.215: INFO: Pod "pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:50:39.218: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:50:39.240: INFO: Waiting for pod pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:50:39.243: INFO: Pod pod-configmaps-3dc9b6a3-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:50:39.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8306" for this suite.
Apr 23 09:50:45.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:50:45.352: INFO: namespace configmap-8306 deletion completed in 6.104980036s

• [SLOW TEST:10.206 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:50:45.352: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 23 09:50:49.936: INFO: Successfully updated pod "pod-update-activedeadlineseconds-43dff953-65ad-11e9-b8ea-e2349624188d"
Apr 23 09:50:49.936: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-43dff953-65ad-11e9-b8ea-e2349624188d" in namespace "pods-7590" to be "terminated due to deadline exceeded"
Apr 23 09:50:49.939: INFO: Pod "pod-update-activedeadlineseconds-43dff953-65ad-11e9-b8ea-e2349624188d": Phase="Running", Reason="", readiness=true. Elapsed: 2.915306ms
Apr 23 09:50:51.943: INFO: Pod "pod-update-activedeadlineseconds-43dff953-65ad-11e9-b8ea-e2349624188d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006591097s
Apr 23 09:50:51.943: INFO: Pod "pod-update-activedeadlineseconds-43dff953-65ad-11e9-b8ea-e2349624188d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:50:51.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7590" for this suite.
Apr 23 09:50:57.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:50:58.062: INFO: namespace pods-7590 deletion completed in 6.114976537s

• [SLOW TEST:12.710 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:50:58.062: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wnb9v in namespace proxy-2830
I0423 09:50:58.128798      16 runners.go:184] Created replication controller with name: proxy-service-wnb9v, namespace: proxy-2830, replica count: 1
I0423 09:50:59.179238      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 09:51:00.179593      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 09:51:01.179805      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 09:51:02.180050      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0423 09:51:03.180276      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0423 09:51:04.180517      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0423 09:51:05.180751      16 runners.go:184] proxy-service-wnb9v Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 09:51:05.185: INFO: setup took 7.084428425s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 23 09:51:05.201: INFO: (0) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 15.707712ms)
Apr 23 09:51:05.203: INFO: (0) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 17.399463ms)
Apr 23 09:51:05.205: INFO: (0) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 19.583076ms)
Apr 23 09:51:05.205: INFO: (0) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 20.250278ms)
Apr 23 09:51:05.205: INFO: (0) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 20.046086ms)
Apr 23 09:51:05.206: INFO: (0) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 20.677811ms)
Apr 23 09:51:05.206: INFO: (0) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 21.202328ms)
Apr 23 09:51:05.206: INFO: (0) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 21.294409ms)
Apr 23 09:51:05.207: INFO: (0) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 22.26076ms)
Apr 23 09:51:05.208: INFO: (0) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 22.490305ms)
Apr 23 09:51:05.208: INFO: (0) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 22.276509ms)
Apr 23 09:51:05.208: INFO: (0) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 22.351636ms)
Apr 23 09:51:05.208: INFO: (0) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 23.020189ms)
Apr 23 09:51:05.209: INFO: (0) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 23.159891ms)
Apr 23 09:51:05.209: INFO: (0) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 23.225614ms)
Apr 23 09:51:05.211: INFO: (0) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 25.43557ms)
Apr 23 09:51:05.216: INFO: (1) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 4.590544ms)
Apr 23 09:51:05.222: INFO: (1) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 9.97495ms)
Apr 23 09:51:05.222: INFO: (1) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.612654ms)
Apr 23 09:51:05.222: INFO: (1) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 10.952715ms)
Apr 23 09:51:05.222: INFO: (1) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.885847ms)
Apr 23 09:51:05.223: INFO: (1) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 10.979526ms)
Apr 23 09:51:05.223: INFO: (1) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 11.009837ms)
Apr 23 09:51:05.223: INFO: (1) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.122054ms)
Apr 23 09:51:05.223: INFO: (1) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 11.184256ms)
Apr 23 09:51:05.223: INFO: (1) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 12.115104ms)
Apr 23 09:51:05.224: INFO: (1) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.469209ms)
Apr 23 09:51:05.224: INFO: (1) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.162879ms)
Apr 23 09:51:05.224: INFO: (1) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 12.762241ms)
Apr 23 09:51:05.224: INFO: (1) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 12.66271ms)
Apr 23 09:51:05.224: INFO: (1) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 12.587488ms)
Apr 23 09:51:05.227: INFO: (1) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 14.891772ms)
Apr 23 09:51:05.235: INFO: (2) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 7.864688ms)
Apr 23 09:51:05.235: INFO: (2) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 8.43799ms)
Apr 23 09:51:05.237: INFO: (2) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.518797ms)
Apr 23 09:51:05.237: INFO: (2) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 9.646724ms)
Apr 23 09:51:05.237: INFO: (2) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 10.01176ms)
Apr 23 09:51:05.237: INFO: (2) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 9.869766ms)
Apr 23 09:51:05.237: INFO: (2) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.818393ms)
Apr 23 09:51:05.238: INFO: (2) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.705816ms)
Apr 23 09:51:05.238: INFO: (2) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.020292ms)
Apr 23 09:51:05.238: INFO: (2) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 10.675862ms)
Apr 23 09:51:05.238: INFO: (2) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 10.806183ms)
Apr 23 09:51:05.239: INFO: (2) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.129302ms)
Apr 23 09:51:05.239: INFO: (2) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 11.465141ms)
Apr 23 09:51:05.239: INFO: (2) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.911907ms)
Apr 23 09:51:05.239: INFO: (2) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 11.767321ms)
Apr 23 09:51:05.239: INFO: (2) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.004068ms)
Apr 23 09:51:05.247: INFO: (3) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 7.224598ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 10.019889ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.131259ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 10.570782ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 10.479096ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.442559ms)
Apr 23 09:51:05.250: INFO: (3) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.395384ms)
Apr 23 09:51:05.251: INFO: (3) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 10.888367ms)
Apr 23 09:51:05.252: INFO: (3) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 11.878304ms)
Apr 23 09:51:05.252: INFO: (3) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.270582ms)
Apr 23 09:51:05.252: INFO: (3) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 12.534641ms)
Apr 23 09:51:05.253: INFO: (3) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 13.710027ms)
Apr 23 09:51:05.254: INFO: (3) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 13.752618ms)
Apr 23 09:51:05.254: INFO: (3) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 13.776984ms)
Apr 23 09:51:05.254: INFO: (3) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 14.048166ms)
Apr 23 09:51:05.254: INFO: (3) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 13.902402ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 7.955692ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 7.567265ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 8.069939ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.090706ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 8.194613ms)
Apr 23 09:51:05.262: INFO: (4) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 7.887214ms)
Apr 23 09:51:05.263: INFO: (4) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.350057ms)
Apr 23 09:51:05.263: INFO: (4) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.17499ms)
Apr 23 09:51:05.263: INFO: (4) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.095282ms)
Apr 23 09:51:05.263: INFO: (4) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 8.741631ms)
Apr 23 09:51:05.265: INFO: (4) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 11.203171ms)
Apr 23 09:51:05.266: INFO: (4) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 11.965317ms)
Apr 23 09:51:05.266: INFO: (4) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 12.026099ms)
Apr 23 09:51:05.267: INFO: (4) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.72027ms)
Apr 23 09:51:05.267: INFO: (4) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 12.243925ms)
Apr 23 09:51:05.267: INFO: (4) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.355531ms)
Apr 23 09:51:05.271: INFO: (5) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 4.36663ms)
Apr 23 09:51:05.273: INFO: (5) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 5.991608ms)
Apr 23 09:51:05.273: INFO: (5) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 6.50861ms)
Apr 23 09:51:05.274: INFO: (5) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 6.618563ms)
Apr 23 09:51:05.274: INFO: (5) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 6.511017ms)
Apr 23 09:51:05.275: INFO: (5) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 7.045349ms)
Apr 23 09:51:05.275: INFO: (5) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 7.588133ms)
Apr 23 09:51:05.275: INFO: (5) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 7.649484ms)
Apr 23 09:51:05.275: INFO: (5) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 7.717698ms)
Apr 23 09:51:05.275: INFO: (5) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 7.821562ms)
Apr 23 09:51:05.277: INFO: (5) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 9.772996ms)
Apr 23 09:51:05.277: INFO: (5) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 10.148213ms)
Apr 23 09:51:05.278: INFO: (5) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 10.120679ms)
Apr 23 09:51:05.278: INFO: (5) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.134539ms)
Apr 23 09:51:05.278: INFO: (5) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 10.96882ms)
Apr 23 09:51:05.279: INFO: (5) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.33332ms)
Apr 23 09:51:05.285: INFO: (6) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 5.982984ms)
Apr 23 09:51:05.285: INFO: (6) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 6.169299ms)
Apr 23 09:51:05.285: INFO: (6) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 6.157744ms)
Apr 23 09:51:05.285: INFO: (6) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 6.335853ms)
Apr 23 09:51:05.286: INFO: (6) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 6.457034ms)
Apr 23 09:51:05.289: INFO: (6) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 9.335311ms)
Apr 23 09:51:05.289: INFO: (6) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.41588ms)
Apr 23 09:51:05.289: INFO: (6) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 9.60956ms)
Apr 23 09:51:05.289: INFO: (6) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.933795ms)
Apr 23 09:51:05.289: INFO: (6) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.839909ms)
Apr 23 09:51:05.291: INFO: (6) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 11.034713ms)
Apr 23 09:51:05.291: INFO: (6) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.38452ms)
Apr 23 09:51:05.291: INFO: (6) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 12.1314ms)
Apr 23 09:51:05.291: INFO: (6) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.05327ms)
Apr 23 09:51:05.293: INFO: (6) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 13.504494ms)
Apr 23 09:51:05.293: INFO: (6) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 13.874749ms)
Apr 23 09:51:05.299: INFO: (7) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 5.821489ms)
Apr 23 09:51:05.299: INFO: (7) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 5.930934ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.206672ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 11.015995ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 10.692203ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 10.618313ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.610486ms)
Apr 23 09:51:05.304: INFO: (7) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.121108ms)
Apr 23 09:51:05.305: INFO: (7) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.762034ms)
Apr 23 09:51:05.305: INFO: (7) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.683791ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 12.208865ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 12.403485ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.388418ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 12.431821ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.686661ms)
Apr 23 09:51:05.306: INFO: (7) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.375685ms)
Apr 23 09:51:05.314: INFO: (8) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 7.248705ms)
Apr 23 09:51:05.316: INFO: (8) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 9.291175ms)
Apr 23 09:51:05.316: INFO: (8) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.231292ms)
Apr 23 09:51:05.317: INFO: (8) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 9.980281ms)
Apr 23 09:51:05.317: INFO: (8) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 9.939959ms)
Apr 23 09:51:05.317: INFO: (8) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 9.951838ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.27325ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.540621ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 10.90871ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.177428ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 11.179783ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.924385ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 11.34262ms)
Apr 23 09:51:05.318: INFO: (8) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 11.177383ms)
Apr 23 09:51:05.319: INFO: (8) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.376353ms)
Apr 23 09:51:05.320: INFO: (8) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 13.322605ms)
Apr 23 09:51:05.331: INFO: (9) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 10.465389ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.836812ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.779659ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 11.076261ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.967549ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 11.022913ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 11.164541ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 11.254021ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 10.956623ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.062513ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.615027ms)
Apr 23 09:51:05.332: INFO: (9) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.672824ms)
Apr 23 09:51:05.333: INFO: (9) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 11.955581ms)
Apr 23 09:51:05.333: INFO: (9) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 12.086365ms)
Apr 23 09:51:05.333: INFO: (9) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 12.343161ms)
Apr 23 09:51:05.333: INFO: (9) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 11.915221ms)
Apr 23 09:51:05.341: INFO: (10) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 8.003167ms)
Apr 23 09:51:05.342: INFO: (10) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.537512ms)
Apr 23 09:51:05.342: INFO: (10) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.451013ms)
Apr 23 09:51:05.342: INFO: (10) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.013561ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.524092ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 9.642925ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.630167ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 9.639032ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.749452ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 10.355635ms)
Apr 23 09:51:05.343: INFO: (10) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 10.570051ms)
Apr 23 09:51:05.344: INFO: (10) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 11.281244ms)
Apr 23 09:51:05.344: INFO: (10) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 11.544878ms)
Apr 23 09:51:05.345: INFO: (10) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 11.942755ms)
Apr 23 09:51:05.345: INFO: (10) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.076008ms)
Apr 23 09:51:05.345: INFO: (10) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 12.246131ms)
Apr 23 09:51:05.353: INFO: (11) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 7.091672ms)
Apr 23 09:51:05.356: INFO: (11) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.246825ms)
Apr 23 09:51:05.356: INFO: (11) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 10.372106ms)
Apr 23 09:51:05.356: INFO: (11) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.399358ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 13.173076ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 13.413748ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 13.401332ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 13.255993ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 13.207651ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 13.696276ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 13.633781ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 13.512314ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 13.806429ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 13.682013ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 13.489949ms)
Apr 23 09:51:05.359: INFO: (11) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 13.566759ms)
Apr 23 09:51:05.366: INFO: (12) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 6.804452ms)
Apr 23 09:51:05.368: INFO: (12) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.025523ms)
Apr 23 09:51:05.368: INFO: (12) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.399062ms)
Apr 23 09:51:05.368: INFO: (12) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.566263ms)
Apr 23 09:51:05.368: INFO: (12) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 8.667006ms)
Apr 23 09:51:05.368: INFO: (12) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 8.871359ms)
Apr 23 09:51:05.369: INFO: (12) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.179058ms)
Apr 23 09:51:05.369: INFO: (12) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.06749ms)
Apr 23 09:51:05.369: INFO: (12) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 9.312398ms)
Apr 23 09:51:05.369: INFO: (12) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.611253ms)
Apr 23 09:51:05.371: INFO: (12) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 11.274002ms)
Apr 23 09:51:05.371: INFO: (12) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 11.241354ms)
Apr 23 09:51:05.371: INFO: (12) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.636386ms)
Apr 23 09:51:05.372: INFO: (12) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 12.408449ms)
Apr 23 09:51:05.372: INFO: (12) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 12.80243ms)
Apr 23 09:51:05.372: INFO: (12) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.752434ms)
Apr 23 09:51:05.380: INFO: (13) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 7.320168ms)
Apr 23 09:51:05.380: INFO: (13) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 7.347536ms)
Apr 23 09:51:05.380: INFO: (13) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 7.371464ms)
Apr 23 09:51:05.381: INFO: (13) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.937573ms)
Apr 23 09:51:05.381: INFO: (13) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 8.766741ms)
Apr 23 09:51:05.383: INFO: (13) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.757383ms)
Apr 23 09:51:05.383: INFO: (13) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 10.982066ms)
Apr 23 09:51:05.383: INFO: (13) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 11.1517ms)
Apr 23 09:51:05.383: INFO: (13) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.442811ms)
Apr 23 09:51:05.384: INFO: (13) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 10.749177ms)
Apr 23 09:51:05.384: INFO: (13) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 10.826163ms)
Apr 23 09:51:05.384: INFO: (13) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 11.460357ms)
Apr 23 09:51:05.385: INFO: (13) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 11.604331ms)
Apr 23 09:51:05.385: INFO: (13) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.695106ms)
Apr 23 09:51:05.385: INFO: (13) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.201167ms)
Apr 23 09:51:05.385: INFO: (13) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 12.468687ms)
Apr 23 09:51:05.393: INFO: (14) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.103753ms)
Apr 23 09:51:05.393: INFO: (14) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.136832ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 8.132537ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 8.032677ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.149061ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 8.079988ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.429166ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 8.999396ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.432266ms)
Apr 23 09:51:05.394: INFO: (14) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.244061ms)
Apr 23 09:51:05.398: INFO: (14) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.557401ms)
Apr 23 09:51:05.398: INFO: (14) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 13.023628ms)
Apr 23 09:51:05.398: INFO: (14) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 13.359811ms)
Apr 23 09:51:05.398: INFO: (14) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 12.748095ms)
Apr 23 09:51:05.399: INFO: (14) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 13.19576ms)
Apr 23 09:51:05.399: INFO: (14) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.949363ms)
Apr 23 09:51:05.408: INFO: (15) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.604537ms)
Apr 23 09:51:05.408: INFO: (15) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 8.880411ms)
Apr 23 09:51:05.408: INFO: (15) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 8.935904ms)
Apr 23 09:51:05.408: INFO: (15) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.510742ms)
Apr 23 09:51:05.408: INFO: (15) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.303504ms)
Apr 23 09:51:05.409: INFO: (15) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.401415ms)
Apr 23 09:51:05.409: INFO: (15) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 9.454359ms)
Apr 23 09:51:05.409: INFO: (15) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 9.78862ms)
Apr 23 09:51:05.409: INFO: (15) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 9.453445ms)
Apr 23 09:51:05.409: INFO: (15) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 10.016082ms)
Apr 23 09:51:05.410: INFO: (15) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 11.238008ms)
Apr 23 09:51:05.410: INFO: (15) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 11.710259ms)
Apr 23 09:51:05.411: INFO: (15) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 11.289482ms)
Apr 23 09:51:05.411: INFO: (15) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 11.440809ms)
Apr 23 09:51:05.411: INFO: (15) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 11.678604ms)
Apr 23 09:51:05.411: INFO: (15) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 12.341375ms)
Apr 23 09:51:05.418: INFO: (16) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 6.398942ms)
Apr 23 09:51:05.419: INFO: (16) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 7.019679ms)
Apr 23 09:51:05.419: INFO: (16) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 7.772573ms)
Apr 23 09:51:05.421: INFO: (16) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.839995ms)
Apr 23 09:51:05.421: INFO: (16) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 9.095634ms)
Apr 23 09:51:05.421: INFO: (16) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.045116ms)
Apr 23 09:51:05.421: INFO: (16) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.157641ms)
Apr 23 09:51:05.422: INFO: (16) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.839532ms)
Apr 23 09:51:05.422: INFO: (16) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 9.983962ms)
Apr 23 09:51:05.422: INFO: (16) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.027428ms)
Apr 23 09:51:05.423: INFO: (16) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 11.169766ms)
Apr 23 09:51:05.425: INFO: (16) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 12.530876ms)
Apr 23 09:51:05.425: INFO: (16) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 12.510187ms)
Apr 23 09:51:05.425: INFO: (16) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 13.121405ms)
Apr 23 09:51:05.425: INFO: (16) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.879613ms)
Apr 23 09:51:05.425: INFO: (16) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 13.0838ms)
Apr 23 09:51:05.434: INFO: (17) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.128577ms)
Apr 23 09:51:05.434: INFO: (17) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 8.331339ms)
Apr 23 09:51:05.434: INFO: (17) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 8.631271ms)
Apr 23 09:51:05.434: INFO: (17) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 8.662133ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 9.255832ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 9.761831ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 9.214013ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 9.821669ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 10.123693ms)
Apr 23 09:51:05.435: INFO: (17) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 10.060786ms)
Apr 23 09:51:05.436: INFO: (17) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 10.632083ms)
Apr 23 09:51:05.439: INFO: (17) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 13.30084ms)
Apr 23 09:51:05.439: INFO: (17) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 12.922759ms)
Apr 23 09:51:05.439: INFO: (17) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 13.388512ms)
Apr 23 09:51:05.439: INFO: (17) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 13.806899ms)
Apr 23 09:51:05.440: INFO: (17) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 14.926216ms)
Apr 23 09:51:05.447: INFO: (18) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 6.062091ms)
Apr 23 09:51:05.466: INFO: (18) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 24.925922ms)
Apr 23 09:51:05.467: INFO: (18) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 25.987067ms)
Apr 23 09:51:05.470: INFO: (18) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 29.375637ms)
Apr 23 09:51:05.471: INFO: (18) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 30.432157ms)
Apr 23 09:51:05.472: INFO: (18) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 30.665234ms)
Apr 23 09:51:05.475: INFO: (18) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 33.813732ms)
Apr 23 09:51:05.476: INFO: (18) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 34.991097ms)
Apr 23 09:51:05.477: INFO: (18) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 36.485733ms)
Apr 23 09:51:05.478: INFO: (18) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 37.433166ms)
Apr 23 09:51:05.480: INFO: (18) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 38.77643ms)
Apr 23 09:51:05.483: INFO: (18) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 42.396815ms)
Apr 23 09:51:05.484: INFO: (18) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 42.782788ms)
Apr 23 09:51:05.487: INFO: (18) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 46.094906ms)
Apr 23 09:51:05.488: INFO: (18) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 47.032431ms)
Apr 23 09:51:05.489: INFO: (18) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 47.728367ms)
Apr 23 09:51:05.511: INFO: (19) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:1080/proxy/rewriteme">test<... (200; 22.267169ms)
Apr 23 09:51:05.513: INFO: (19) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:160/proxy/: foo (200; 24.129372ms)
Apr 23 09:51:05.515: INFO: (19) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:443/proxy/tlsrewritem... (200; 25.395307ms)
Apr 23 09:51:05.516: INFO: (19) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb/proxy/rewriteme">test</a> (200; 26.709841ms)
Apr 23 09:51:05.516: INFO: (19) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname2/proxy/: tls qux (200; 27.463861ms)
Apr 23 09:51:05.518: INFO: (19) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:462/proxy/: tls qux (200; 28.798713ms)
Apr 23 09:51:05.520: INFO: (19) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:160/proxy/: foo (200; 30.372175ms)
Apr 23 09:51:05.520: INFO: (19) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname1/proxy/: foo (200; 30.802303ms)
Apr 23 09:51:05.521: INFO: (19) /api/v1/namespaces/proxy-2830/services/http:proxy-service-wnb9v:portname2/proxy/: bar (200; 31.711798ms)
Apr 23 09:51:05.521: INFO: (19) /api/v1/namespaces/proxy-2830/services/https:proxy-service-wnb9v:tlsportname1/proxy/: tls baz (200; 31.99936ms)
Apr 23 09:51:05.524: INFO: (19) /api/v1/namespaces/proxy-2830/pods/https:proxy-service-wnb9v-445vb:460/proxy/: tls baz (200; 33.881893ms)
Apr 23 09:51:05.524: INFO: (19) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname1/proxy/: foo (200; 34.369411ms)
Apr 23 09:51:05.524: INFO: (19) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:162/proxy/: bar (200; 34.978283ms)
Apr 23 09:51:05.525: INFO: (19) /api/v1/namespaces/proxy-2830/pods/proxy-service-wnb9v-445vb:162/proxy/: bar (200; 35.315791ms)
Apr 23 09:51:05.525: INFO: (19) /api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/: <a href="/api/v1/namespaces/proxy-2830/pods/http:proxy-service-wnb9v-445vb:1080/proxy/rewriteme">... (200; 35.816271ms)
Apr 23 09:51:05.532: INFO: (19) /api/v1/namespaces/proxy-2830/services/proxy-service-wnb9v:portname2/proxy/: bar (200; 42.945263ms)
STEP: deleting ReplicationController proxy-service-wnb9v in namespace proxy-2830, will wait for the garbage collector to delete the pods
Apr 23 09:51:05.609: INFO: Deleting ReplicationController proxy-service-wnb9v took: 22.359936ms
Apr 23 09:51:05.909: INFO: Terminating ReplicationController proxy-service-wnb9v pods took: 300.214212ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:51:13.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2830" for this suite.
Apr 23 09:51:19.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:51:19.518: INFO: namespace proxy-2830 deletion completed in 6.103531629s

• [SLOW TEST:21.456 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:51:19.518: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-jlt2
STEP: Creating a pod to test atomic-volume-subpath
Apr 23 09:51:19.624: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jlt2" in namespace "subpath-4070" to be "success or failure"
Apr 23 09:51:19.634: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.961376ms
Apr 23 09:51:21.638: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014294192s
Apr 23 09:51:23.642: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 4.017904065s
Apr 23 09:51:25.646: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 6.021913405s
Apr 23 09:51:27.650: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 8.026130874s
Apr 23 09:51:29.654: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 10.030032145s
Apr 23 09:51:31.658: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 12.034012832s
Apr 23 09:51:33.662: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 14.037987775s
Apr 23 09:51:35.666: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 16.042552155s
Apr 23 09:51:37.670: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 18.04650833s
Apr 23 09:51:39.674: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 20.0501679s
Apr 23 09:51:41.678: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Running", Reason="", readiness=true. Elapsed: 22.053749174s
Apr 23 09:51:43.682: INFO: Pod "pod-subpath-test-configmap-jlt2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057723568s
STEP: Saw pod success
Apr 23 09:51:43.682: INFO: Pod "pod-subpath-test-configmap-jlt2" satisfied condition "success or failure"
Apr 23 09:51:43.685: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-subpath-test-configmap-jlt2 container test-container-subpath-configmap-jlt2: <nil>
STEP: delete the pod
Apr 23 09:51:43.708: INFO: Waiting for pod pod-subpath-test-configmap-jlt2 to disappear
Apr 23 09:51:43.711: INFO: Pod pod-subpath-test-configmap-jlt2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jlt2
Apr 23 09:51:43.711: INFO: Deleting pod "pod-subpath-test-configmap-jlt2" in namespace "subpath-4070"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:51:43.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4070" for this suite.
Apr 23 09:51:49.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:51:49.815: INFO: namespace subpath-4070 deletion completed in 6.097795432s

• [SLOW TEST:30.297 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:51:49.815: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:51:49.854: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 23 09:51:54.858: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 23 09:51:54.858: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 23 09:51:54.876: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-3591,SelfLink:/apis/apps/v1/namespaces/deployment-3591/deployments/test-cleanup-deployment,UID:6d46e69e-65ad-11e9-be4b-42010a8a0fda,ResourceVersion:14997,Generation:1,CreationTimestamp:2019-04-23 09:51:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 23 09:51:54.882: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-3591,SelfLink:/apis/apps/v1/namespaces/deployment-3591/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:6d48fe4f-65ad-11e9-be4b-42010a8a0fda,ResourceVersion:14999,Generation:1,CreationTimestamp:2019-04-23 09:51:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6d46e69e-65ad-11e9-be4b-42010a8a0fda 0xc002ae8397 0xc002ae8398}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 09:51:54.882: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 23 09:51:54.882: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-3591,SelfLink:/apis/apps/v1/namespaces/deployment-3591/replicasets/test-cleanup-controller,UID:6a49ebd9-65ad-11e9-be4b-42010a8a0fda,ResourceVersion:14998,Generation:1,CreationTimestamp:2019-04-23 09:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6d46e69e-65ad-11e9-be4b-42010a8a0fda 0xc002ae82c7 0xc002ae82c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 23 09:51:54.886: INFO: Pod "test-cleanup-controller-snt57" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-snt57,GenerateName:test-cleanup-controller-,Namespace:deployment-3591,SelfLink:/api/v1/namespaces/deployment-3591/pods/test-cleanup-controller-snt57,UID:6a4b0da5-65ad-11e9-be4b-42010a8a0fda,ResourceVersion:14990,Generation:0,CreationTimestamp:2019-04-23 09:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.124/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 6a49ebd9-65ad-11e9-be4b-42010a8a0fda 0xc002ae8c07 0xc002ae8c08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8kcst {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8kcst,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8kcst true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ae8c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ae8c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:51:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:51:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:51:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:51:49 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.219,PodIP:10.2.1.124,StartTime:2019-04-23 09:51:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-23 09:51:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e18064e692db472a16ad917a2e42b6e7a0373b4c110a86fcbd3c802d4a4855de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 23 09:51:54.887: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-vrhnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-vrhnn,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-3591,SelfLink:/api/v1/namespaces/deployment-3591/pods/test-cleanup-deployment-55cbfbc8f5-vrhnn,UID:6d49bdf1-65ad-11e9-be4b-42010a8a0fda,ResourceVersion:15000,Generation:0,CreationTimestamp:2019-04-23 09:51:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 6d48fe4f-65ad-11e9-be4b-42010a8a0fda 0xc002ae8d67 0xc002ae8d68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8kcst {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8kcst,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8kcst true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ae8dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ae8df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:51:54.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3591" for this suite.
Apr 23 09:52:00.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:01.001: INFO: namespace deployment-3591 deletion completed in 6.098076249s

• [SLOW TEST:11.186 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:01.001: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:52:05.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4389" for this suite.
Apr 23 09:52:11.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:11.170: INFO: namespace kubelet-test-4389 deletion completed in 6.099901423s

• [SLOW TEST:10.169 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:11.170: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:52:11.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4652" for this suite.
Apr 23 09:52:17.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:17.340: INFO: namespace kubelet-test-4652 deletion completed in 6.105014407s

• [SLOW TEST:6.170 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:17.340: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 23 09:52:17.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 cluster-info'
Apr 23 09:52:17.454: INFO: stderr: ""
Apr 23 09:52:17.454: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:52:17.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6399" for this suite.
Apr 23 09:52:23.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:23.575: INFO: namespace kubectl-6399 deletion completed in 6.11729141s

• [SLOW TEST:6.236 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:23.576: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 23 09:52:23.615: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr 23 09:52:32.650: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:52:32.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1100" for this suite.
Apr 23 09:52:38.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:38.762: INFO: namespace pods-1100 deletion completed in 6.104786762s

• [SLOW TEST:15.186 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:38.762: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-8777acc5-65ad-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:52:38.816: INFO: Waiting up to 5m0s for pod "pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d" in namespace "secrets-211" to be "success or failure"
Apr 23 09:52:38.821: INFO: Pod "pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.566092ms
Apr 23 09:52:40.826: INFO: Pod "pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009882707s
Apr 23 09:52:42.829: INFO: Pod "pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013570233s
STEP: Saw pod success
Apr 23 09:52:42.830: INFO: Pod "pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:52:42.832: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:52:42.854: INFO: Waiting for pod pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:52:42.858: INFO: Pod pod-secrets-87787153-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:52:42.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-211" for this suite.
Apr 23 09:52:48.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:52:48.958: INFO: namespace secrets-211 deletion completed in 6.095508433s

• [SLOW TEST:10.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:52:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-24z6
STEP: Creating a pod to test atomic-volume-subpath
Apr 23 09:52:49.022: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-24z6" in namespace "subpath-79" to be "success or failure"
Apr 23 09:52:49.027: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.946796ms
Apr 23 09:52:51.031: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008966026s
Apr 23 09:52:53.034: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 4.012029749s
Apr 23 09:52:55.038: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 6.015707048s
Apr 23 09:52:57.044: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 8.022304404s
Apr 23 09:52:59.049: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 10.027149667s
Apr 23 09:53:01.054: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 12.031574279s
Apr 23 09:53:03.058: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 14.035531686s
Apr 23 09:53:05.062: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 16.039534115s
Apr 23 09:53:07.065: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 18.043490908s
Apr 23 09:53:09.069: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 20.047504055s
Apr 23 09:53:11.073: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Running", Reason="", readiness=true. Elapsed: 22.051098936s
Apr 23 09:53:13.077: INFO: Pod "pod-subpath-test-projected-24z6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054588171s
STEP: Saw pod success
Apr 23 09:53:13.077: INFO: Pod "pod-subpath-test-projected-24z6" satisfied condition "success or failure"
Apr 23 09:53:13.080: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-subpath-test-projected-24z6 container test-container-subpath-projected-24z6: <nil>
STEP: delete the pod
Apr 23 09:53:13.106: INFO: Waiting for pod pod-subpath-test-projected-24z6 to disappear
Apr 23 09:53:13.109: INFO: Pod pod-subpath-test-projected-24z6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-24z6
Apr 23 09:53:13.109: INFO: Deleting pod "pod-subpath-test-projected-24z6" in namespace "subpath-79"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:53:13.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-79" for this suite.
Apr 23 09:53:19.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:53:19.222: INFO: namespace subpath-79 deletion completed in 6.107106121s

• [SLOW TEST:30.264 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:53:19.222: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:53:19.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d" in namespace "downward-api-2951" to be "success or failure"
Apr 23 09:53:19.274: INFO: Pod "downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.443597ms
Apr 23 09:53:21.278: INFO: Pod "downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007315693s
Apr 23 09:53:23.282: INFO: Pod "downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011354648s
STEP: Saw pod success
Apr 23 09:53:23.282: INFO: Pod "downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:53:23.285: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:53:23.322: INFO: Waiting for pod downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:53:23.325: INFO: Pod downwardapi-volume-9f95a076-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:53:23.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2951" for this suite.
Apr 23 09:53:29.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:53:29.430: INFO: namespace downward-api-2951 deletion completed in 6.101200215s

• [SLOW TEST:10.207 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:53:29.430: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-a5aa14f8-65ad-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 09:53:29.477: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d" in namespace "projected-1518" to be "success or failure"
Apr 23 09:53:29.487: INFO: Pod "pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.707837ms
Apr 23 09:53:31.491: INFO: Pod "pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014093574s
Apr 23 09:53:33.495: INFO: Pod "pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018045291s
STEP: Saw pod success
Apr 23 09:53:33.495: INFO: Pod "pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:53:33.498: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 09:53:33.524: INFO: Waiting for pod pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:53:33.527: INFO: Pod pod-projected-secrets-a5aaa735-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:53:33.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1518" for this suite.
Apr 23 09:53:39.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:53:39.640: INFO: namespace projected-1518 deletion completed in 6.108632333s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:53:39.640: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 23 09:53:39.686: INFO: Waiting up to 5m0s for pod "downward-api-abc05881-65ad-11e9-b8ea-e2349624188d" in namespace "downward-api-3492" to be "success or failure"
Apr 23 09:53:39.691: INFO: Pod "downward-api-abc05881-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.535107ms
Apr 23 09:53:41.695: INFO: Pod "downward-api-abc05881-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009639588s
Apr 23 09:53:43.699: INFO: Pod "downward-api-abc05881-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01366924s
STEP: Saw pod success
Apr 23 09:53:43.700: INFO: Pod "downward-api-abc05881-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:53:43.702: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downward-api-abc05881-65ad-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:53:43.735: INFO: Waiting for pod downward-api-abc05881-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:53:43.740: INFO: Pod downward-api-abc05881-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:53:43.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3492" for this suite.
Apr 23 09:53:49.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:53:49.846: INFO: namespace downward-api-3492 deletion completed in 6.101150956s

• [SLOW TEST:10.205 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:53:49.846: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-rf5j
STEP: Creating a pod to test atomic-volume-subpath
Apr 23 09:53:49.896: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rf5j" in namespace "subpath-6545" to be "success or failure"
Apr 23 09:53:49.901: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Pending", Reason="", readiness=false. Elapsed: 4.927137ms
Apr 23 09:53:51.905: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009117262s
Apr 23 09:53:53.909: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.013264553s
Apr 23 09:53:55.913: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 6.017056885s
Apr 23 09:53:57.917: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 8.021025719s
Apr 23 09:53:59.921: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 10.024994606s
Apr 23 09:54:01.925: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 12.029013275s
Apr 23 09:54:03.929: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 14.033289385s
Apr 23 09:54:05.934: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 16.038069422s
Apr 23 09:54:07.938: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 18.042350893s
Apr 23 09:54:09.942: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 20.046301904s
Apr 23 09:54:11.946: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Running", Reason="", readiness=true. Elapsed: 22.050391506s
Apr 23 09:54:13.950: INFO: Pod "pod-subpath-test-downwardapi-rf5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054568497s
STEP: Saw pod success
Apr 23 09:54:13.950: INFO: Pod "pod-subpath-test-downwardapi-rf5j" satisfied condition "success or failure"
Apr 23 09:54:13.953: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-subpath-test-downwardapi-rf5j container test-container-subpath-downwardapi-rf5j: <nil>
STEP: delete the pod
Apr 23 09:54:13.976: INFO: Waiting for pod pod-subpath-test-downwardapi-rf5j to disappear
Apr 23 09:54:13.979: INFO: Pod pod-subpath-test-downwardapi-rf5j no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rf5j
Apr 23 09:54:13.979: INFO: Deleting pod "pod-subpath-test-downwardapi-rf5j" in namespace "subpath-6545"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:54:13.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6545" for this suite.
Apr 23 09:54:19.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:54:20.080: INFO: namespace subpath-6545 deletion completed in 6.095258968s

• [SLOW TEST:30.234 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:54:20.080: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 23 09:54:20.133: INFO: Waiting up to 5m0s for pod "pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d" in namespace "emptydir-9396" to be "success or failure"
Apr 23 09:54:20.138: INFO: Pod "pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.222332ms
Apr 23 09:54:22.144: INFO: Pod "pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011179684s
Apr 23 09:54:24.148: INFO: Pod "pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015192491s
STEP: Saw pod success
Apr 23 09:54:24.148: INFO: Pod "pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:54:24.151: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:54:24.174: INFO: Waiting for pod pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:54:24.176: INFO: Pod pod-c3dc0f80-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:54:24.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9396" for this suite.
Apr 23 09:54:30.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:54:30.293: INFO: namespace emptydir-9396 deletion completed in 6.112717377s

• [SLOW TEST:10.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:54:30.293: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 23 09:54:30.336: INFO: Waiting up to 5m0s for pod "downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d" in namespace "downward-api-71" to be "success or failure"
Apr 23 09:54:30.340: INFO: Pod "downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.713435ms
Apr 23 09:54:32.343: INFO: Pod "downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007493214s
Apr 23 09:54:34.347: INFO: Pod "downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011469s
STEP: Saw pod success
Apr 23 09:54:34.348: INFO: Pod "downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:54:34.350: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 09:54:34.369: INFO: Waiting for pod downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:54:34.376: INFO: Pod downward-api-c9f1080d-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:54:34.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-71" for this suite.
Apr 23 09:54:40.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:54:40.480: INFO: namespace downward-api-71 deletion completed in 6.098528428s

• [SLOW TEST:10.186 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:54:40.480: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 23 09:54:48.552: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 09:54:48.555: INFO: Pod pod-with-prestop-http-hook still exists
Apr 23 09:54:50.555: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 09:54:50.559: INFO: Pod pod-with-prestop-http-hook still exists
Apr 23 09:54:52.555: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 09:54:52.559: INFO: Pod pod-with-prestop-http-hook still exists
Apr 23 09:54:54.555: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 09:54:54.559: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:54:54.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-514" for this suite.
Apr 23 09:55:16.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:55:16.687: INFO: namespace container-lifecycle-hook-514 deletion completed in 22.115897545s

• [SLOW TEST:36.207 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:55:16.687: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:55:16.765: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e59c5454-65ad-11e9-be4b-42010a8a0fda", Controller:(*bool)(0xc002883216), BlockOwnerDeletion:(*bool)(0xc002883217)}}
Apr 23 09:55:16.778: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e599b3a1-65ad-11e9-be4b-42010a8a0fda", Controller:(*bool)(0xc0028833b6), BlockOwnerDeletion:(*bool)(0xc0028833b7)}}
Apr 23 09:55:16.785: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e59a58a2-65ad-11e9-be4b-42010a8a0fda", Controller:(*bool)(0xc00269a36e), BlockOwnerDeletion:(*bool)(0xc00269a36f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:55:21.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4493" for this suite.
Apr 23 09:55:27.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:55:27.906: INFO: namespace gc-4493 deletion completed in 6.103270764s

• [SLOW TEST:11.222 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:55:27.909: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:55:27.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d" in namespace "projected-2849" to be "success or failure"
Apr 23 09:55:27.963: INFO: Pod "downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.508517ms
Apr 23 09:55:29.967: INFO: Pod "downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009348717s
Apr 23 09:55:31.972: INFO: Pod "downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013693633s
STEP: Saw pod success
Apr 23 09:55:31.972: INFO: Pod "downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:55:31.974: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:55:31.999: INFO: Waiting for pod downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d to disappear
Apr 23 09:55:32.001: INFO: Pod downwardapi-volume-ec49109b-65ad-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:55:32.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2849" for this suite.
Apr 23 09:55:38.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:55:38.102: INFO: namespace projected-2849 deletion completed in 6.096295555s

• [SLOW TEST:10.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:55:38.103: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:55:38.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 version'
Apr 23 09:55:38.231: INFO: stderr: ""
Apr 23 09:55:38.231: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:55:38.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2396" for this suite.
Apr 23 09:55:44.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:55:44.367: INFO: namespace kubectl-2396 deletion completed in 6.131705228s

• [SLOW TEST:6.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:55:44.367: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8834
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-8834
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8834
Apr 23 09:55:44.433: INFO: Found 0 stateful pods, waiting for 1
Apr 23 09:55:54.437: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 23 09:55:54.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:55:54.729: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:55:54.729: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:55:54.729: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 09:55:54.733: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 23 09:56:04.737: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 09:56:04.737: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 09:56:04.752: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:04.752: INFO: ss-0  net1a83gn1-worker-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  }]
Apr 23 09:56:04.752: INFO: 
Apr 23 09:56:04.752: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 23 09:56:05.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995582228s
Apr 23 09:56:06.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992078034s
Apr 23 09:56:07.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985598001s
Apr 23 09:56:08.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981688801s
Apr 23 09:56:09.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977085247s
Apr 23 09:56:10.779: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97231601s
Apr 23 09:56:11.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96801308s
Apr 23 09:56:12.788: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963463198s
Apr 23 09:56:13.792: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.982854ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8834
Apr 23 09:56:14.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 09:56:15.081: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 09:56:15.081: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 09:56:15.081: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 09:56:15.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 09:56:15.385: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 23 09:56:15.385: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 09:56:15.385: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 09:56:15.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 09:56:15.674: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 23 09:56:15.674: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 09:56:15.674: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 09:56:15.678: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:56:15.678: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 09:56:15.678: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 23 09:56:15.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:56:16.020: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:56:16.020: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:56:16.020: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 09:56:16.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:56:16.360: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:56:16.360: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:56:16.360: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 09:56:16.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-8834 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 09:56:16.676: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 09:56:16.676: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 09:56:16.676: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 09:56:16.676: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 09:56:16.680: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 23 09:56:26.687: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 09:56:26.687: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 09:56:26.687: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 09:56:26.700: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:26.700: INFO: ss-0  net1a83gn1-worker-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  }]
Apr 23 09:56:26.700: INFO: ss-1  net1a83gn1-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:26.700: INFO: ss-2  net1a83gn1-worker-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:26.700: INFO: 
Apr 23 09:56:26.700: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 23 09:56:27.704: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:27.704: INFO: ss-0  net1a83gn1-worker-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  }]
Apr 23 09:56:27.704: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:27.704: INFO: ss-2  net1a83gn1-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:27.704: INFO: 
Apr 23 09:56:27.704: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 23 09:56:28.708: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:28.708: INFO: ss-0  net1a83gn1-worker-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:55:44 +0000 UTC  }]
Apr 23 09:56:28.708: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:28.708: INFO: ss-2  net1a83gn1-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:28.708: INFO: 
Apr 23 09:56:28.708: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 23 09:56:29.712: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:29.712: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:29.712: INFO: 
Apr 23 09:56:29.712: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 23 09:56:30.716: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:30.716: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:30.716: INFO: 
Apr 23 09:56:30.716: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 23 09:56:31.720: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:31.720: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:31.721: INFO: 
Apr 23 09:56:31.721: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 23 09:56:32.724: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 23 09:56:32.724: INFO: ss-1  net1a83gn1-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 09:56:04 +0000 UTC  }]
Apr 23 09:56:32.724: INFO: 
Apr 23 09:56:32.724: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 23 09:56:33.728: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.970017592s
Apr 23 09:56:34.732: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.966063598s
Apr 23 09:56:35.736: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.346412ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8834
Apr 23 09:56:36.740: INFO: Scaling statefulset ss to 0
Apr 23 09:56:36.747: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 23 09:56:36.750: INFO: Deleting all statefulset in ns statefulset-8834
Apr 23 09:56:36.752: INFO: Scaling statefulset ss to 0
Apr 23 09:56:36.759: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 09:56:36.761: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:56:36.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8834" for this suite.
Apr 23 09:56:42.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:56:42.876: INFO: namespace statefulset-8834 deletion completed in 6.097513225s

• [SLOW TEST:58.508 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:56:42.876: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-18f80631-65ae-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:56:42.935: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d" in namespace "projected-6931" to be "success or failure"
Apr 23 09:56:42.939: INFO: Pod "pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.61932ms
Apr 23 09:56:44.947: INFO: Pod "pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012232269s
Apr 23 09:56:46.951: INFO: Pod "pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016081218s
STEP: Saw pod success
Apr 23 09:56:46.951: INFO: Pod "pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:56:46.954: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:56:46.983: INFO: Waiting for pod pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:56:46.985: INFO: Pod pod-projected-configmaps-18f8ec2d-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:56:46.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6931" for this suite.
Apr 23 09:56:53.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:56:53.092: INFO: namespace projected-6931 deletion completed in 6.102745578s

• [SLOW TEST:10.217 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:56:53.092: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0423 09:56:53.718944      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:56:53.718: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:56:53.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3414" for this suite.
Apr 23 09:56:59.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:56:59.840: INFO: namespace gc-3414 deletion completed in 6.117332037s

• [SLOW TEST:6.747 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:56:59.840: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 23 09:57:00.428: INFO: created pod pod-service-account-defaultsa
Apr 23 09:57:00.428: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 23 09:57:00.439: INFO: created pod pod-service-account-mountsa
Apr 23 09:57:00.439: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 23 09:57:00.444: INFO: created pod pod-service-account-nomountsa
Apr 23 09:57:00.444: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 23 09:57:00.451: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 23 09:57:00.451: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 23 09:57:00.466: INFO: created pod pod-service-account-mountsa-mountspec
Apr 23 09:57:00.466: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 23 09:57:00.478: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 23 09:57:00.478: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 23 09:57:00.495: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 23 09:57:00.495: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 23 09:57:00.505: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 23 09:57:00.505: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 23 09:57:00.516: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 23 09:57:00.516: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:57:00.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5842" for this suite.
Apr 23 09:57:06.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:57:06.670: INFO: namespace svcaccounts-5842 deletion completed in 6.125535368s

• [SLOW TEST:6.830 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:57:06.670: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d
Apr 23 09:57:06.803: INFO: Pod name my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d: Found 0 pods out of 1
Apr 23 09:57:11.806: INFO: Pod name my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d: Found 1 pods out of 1
Apr 23 09:57:11.806: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d" are running
Apr 23 09:57:11.809: INFO: Pod "my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d-9plfk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:57:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:57:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:57:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-23 09:57:06 +0000 UTC Reason: Message:}])
Apr 23 09:57:11.809: INFO: Trying to dial the pod
Apr 23 09:57:16.821: INFO: Controller my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d: Got expected result from replica 1 [my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d-9plfk]: "my-hostname-basic-2733c568-65ae-11e9-b8ea-e2349624188d-9plfk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:57:16.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7712" for this suite.
Apr 23 09:57:22.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:57:22.926: INFO: namespace replication-controller-7712 deletion completed in 6.102153609s

• [SLOW TEST:16.256 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:57:22.926: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0423 09:57:28.996132      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 23 09:57:28.996: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:57:28.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8464" for this suite.
Apr 23 09:57:35.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:57:35.095: INFO: namespace gc-8464 deletion completed in 6.095508896s

• [SLOW TEST:12.169 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:57:35.095: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 09:57:35.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d" in namespace "downward-api-3723" to be "success or failure"
Apr 23 09:57:35.149: INFO: Pod "downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.71488ms
Apr 23 09:57:37.153: INFO: Pod "downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009314992s
Apr 23 09:57:39.157: INFO: Pod "downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013036048s
STEP: Saw pod success
Apr 23 09:57:39.157: INFO: Pod "downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:57:39.159: INFO: Trying to get logs from node net1a83gn1-worker-3 pod downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 09:57:39.184: INFO: Waiting for pod downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:57:39.186: INFO: Pod downwardapi-volume-3818bb28-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:57:39.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3723" for this suite.
Apr 23 09:57:45.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:57:45.301: INFO: namespace downward-api-3723 deletion completed in 6.110804143s

• [SLOW TEST:10.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:57:45.301: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:57:49.384: INFO: Waiting up to 5m0s for pod "client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d" in namespace "pods-723" to be "success or failure"
Apr 23 09:57:49.388: INFO: Pod "client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125824ms
Apr 23 09:57:51.392: INFO: Pod "client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008220218s
Apr 23 09:57:53.397: INFO: Pod "client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01238243s
STEP: Saw pod success
Apr 23 09:57:53.397: INFO: Pod "client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:57:53.400: INFO: Trying to get logs from node net1a83gn1-worker-3 pod client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d container env3cont: <nil>
STEP: delete the pod
Apr 23 09:57:53.421: INFO: Waiting for pod client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:57:53.425: INFO: Pod client-envvars-4094a801-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:57:53.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-723" for this suite.
Apr 23 09:58:35.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:58:35.529: INFO: namespace pods-723 deletion completed in 42.100675265s

• [SLOW TEST:50.229 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:58:35.530: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-5c1f626c-65ae-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:58:35.598: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d" in namespace "projected-2729" to be "success or failure"
Apr 23 09:58:35.609: INFO: Pod "pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.967858ms
Apr 23 09:58:37.612: INFO: Pod "pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014759572s
Apr 23 09:58:39.616: INFO: Pod "pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018634431s
STEP: Saw pod success
Apr 23 09:58:39.616: INFO: Pod "pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:58:39.619: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:58:39.644: INFO: Waiting for pod pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:58:39.648: INFO: Pod pod-projected-configmaps-5c20c9b8-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:58:39.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2729" for this suite.
Apr 23 09:58:45.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:58:45.755: INFO: namespace projected-2729 deletion completed in 6.103033656s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:58:45.755: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 09:59:09.810: INFO: Container started at 2019-04-23 09:58:47 +0000 UTC, pod became ready at 2019-04-23 09:59:08 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:59:09.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7553" for this suite.
Apr 23 09:59:31.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:59:31.912: INFO: namespace container-probe-7553 deletion completed in 22.097937444s

• [SLOW TEST:46.157 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:59:31.912: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 23 09:59:31.969: INFO: Waiting up to 5m0s for pod "client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d" in namespace "containers-5722" to be "success or failure"
Apr 23 09:59:31.977: INFO: Pod "client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.609623ms
Apr 23 09:59:33.981: INFO: Pod "client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011644992s
Apr 23 09:59:35.985: INFO: Pod "client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015244763s
STEP: Saw pod success
Apr 23 09:59:35.985: INFO: Pod "client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:59:35.987: INFO: Trying to get logs from node net1a83gn1-worker-1 pod client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 09:59:36.005: INFO: Waiting for pod client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:59:36.009: INFO: Pod client-containers-7dba8487-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:59:36.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5722" for this suite.
Apr 23 09:59:42.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:59:42.110: INFO: namespace containers-5722 deletion completed in 6.096968087s

• [SLOW TEST:10.198 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:59:42.110: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-83cd6dd1-65ae-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 09:59:42.161: INFO: Waiting up to 5m0s for pod "pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d" in namespace "configmap-3989" to be "success or failure"
Apr 23 09:59:42.173: INFO: Pod "pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.552062ms
Apr 23 09:59:44.178: INFO: Pod "pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016751631s
Apr 23 09:59:46.182: INFO: Pod "pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02061279s
STEP: Saw pod success
Apr 23 09:59:46.182: INFO: Pod "pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 09:59:46.184: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 09:59:46.210: INFO: Waiting for pod pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 09:59:46.212: INFO: Pod pod-configmaps-83ce13cc-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:59:46.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3989" for this suite.
Apr 23 09:59:52.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:59:52.320: INFO: namespace configmap-3989 deletion completed in 6.104142163s

• [SLOW TEST:10.210 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:59:52.320: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 23 09:59:52.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 api-versions'
Apr 23 09:59:52.432: INFO: stderr: ""
Apr 23 09:59:52.432: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 09:59:52.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7746" for this suite.
Apr 23 09:59:58.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 09:59:58.537: INFO: namespace kubectl-7746 deletion completed in 6.100856953s

• [SLOW TEST:6.217 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 09:59:58.538: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 23 09:59:58.584: INFO: Waiting up to 5m0s for pod "client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d" in namespace "containers-9584" to be "success or failure"
Apr 23 09:59:58.587: INFO: Pod "client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.698663ms
Apr 23 10:00:00.591: INFO: Pod "client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006758642s
Apr 23 10:00:02.595: INFO: Pod "client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010884749s
STEP: Saw pod success
Apr 23 10:00:02.595: INFO: Pod "client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:00:02.598: INFO: Trying to get logs from node net1a83gn1-worker-1 pod client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 10:00:02.638: INFO: Waiting for pod client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 10:00:02.642: INFO: Pod client-containers-8d97e5f4-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:00:02.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9584" for this suite.
Apr 23 10:00:08.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:00:08.762: INFO: namespace containers-9584 deletion completed in 6.108688989s

• [SLOW TEST:10.224 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:00:08.762: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8804
I0423 10:00:08.804259      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8804, replica count: 1
I0423 10:00:09.854793      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 10:00:10.855065      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 10:00:11.855341      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 10:00:11.968: INFO: Created: latency-svc-b25bp
Apr 23 10:00:11.975: INFO: Got endpoints: latency-svc-b25bp [20.237455ms]
Apr 23 10:00:11.996: INFO: Created: latency-svc-vqjmr
Apr 23 10:00:11.998: INFO: Got endpoints: latency-svc-vqjmr [22.102492ms]
Apr 23 10:00:12.000: INFO: Created: latency-svc-whwk9
Apr 23 10:00:12.007: INFO: Got endpoints: latency-svc-whwk9 [31.202705ms]
Apr 23 10:00:12.019: INFO: Created: latency-svc-lbzw5
Apr 23 10:00:12.022: INFO: Got endpoints: latency-svc-lbzw5 [45.189768ms]
Apr 23 10:00:12.027: INFO: Created: latency-svc-crm4c
Apr 23 10:00:12.035: INFO: Got endpoints: latency-svc-crm4c [58.65734ms]
Apr 23 10:00:12.039: INFO: Created: latency-svc-tgc5c
Apr 23 10:00:12.047: INFO: Got endpoints: latency-svc-tgc5c [70.751936ms]
Apr 23 10:00:12.049: INFO: Created: latency-svc-qr8f4
Apr 23 10:00:12.055: INFO: Got endpoints: latency-svc-qr8f4 [78.092998ms]
Apr 23 10:00:12.065: INFO: Created: latency-svc-dxtfp
Apr 23 10:00:12.068: INFO: Got endpoints: latency-svc-dxtfp [90.490817ms]
Apr 23 10:00:12.074: INFO: Created: latency-svc-bw8px
Apr 23 10:00:12.095: INFO: Created: latency-svc-7r4kz
Apr 23 10:00:12.099: INFO: Got endpoints: latency-svc-bw8px [121.932215ms]
Apr 23 10:00:12.112: INFO: Got endpoints: latency-svc-7r4kz [133.469699ms]
Apr 23 10:00:12.115: INFO: Created: latency-svc-jt867
Apr 23 10:00:12.129: INFO: Got endpoints: latency-svc-jt867 [149.671847ms]
Apr 23 10:00:12.131: INFO: Created: latency-svc-wgxrz
Apr 23 10:00:12.136: INFO: Created: latency-svc-snmbb
Apr 23 10:00:12.140: INFO: Got endpoints: latency-svc-wgxrz [160.554837ms]
Apr 23 10:00:12.147: INFO: Created: latency-svc-nxh4s
Apr 23 10:00:12.150: INFO: Got endpoints: latency-svc-snmbb [170.770294ms]
Apr 23 10:00:12.160: INFO: Got endpoints: latency-svc-nxh4s [181.153027ms]
Apr 23 10:00:12.163: INFO: Created: latency-svc-dvxnv
Apr 23 10:00:12.167: INFO: Got endpoints: latency-svc-dvxnv [187.816061ms]
Apr 23 10:00:12.175: INFO: Created: latency-svc-wl7v9
Apr 23 10:00:12.181: INFO: Got endpoints: latency-svc-wl7v9 [200.873581ms]
Apr 23 10:00:12.185: INFO: Created: latency-svc-hmgl5
Apr 23 10:00:12.191: INFO: Got endpoints: latency-svc-hmgl5 [193.128235ms]
Apr 23 10:00:12.202: INFO: Created: latency-svc-qrnjj
Apr 23 10:00:12.206: INFO: Got endpoints: latency-svc-qrnjj [198.224165ms]
Apr 23 10:00:12.211: INFO: Created: latency-svc-gv8wm
Apr 23 10:00:12.216: INFO: Got endpoints: latency-svc-gv8wm [193.855526ms]
Apr 23 10:00:12.221: INFO: Created: latency-svc-59xtg
Apr 23 10:00:12.230: INFO: Got endpoints: latency-svc-59xtg [194.822213ms]
Apr 23 10:00:12.234: INFO: Created: latency-svc-nzm7h
Apr 23 10:00:12.237: INFO: Got endpoints: latency-svc-nzm7h [189.800793ms]
Apr 23 10:00:12.245: INFO: Created: latency-svc-68hvt
Apr 23 10:00:12.249: INFO: Got endpoints: latency-svc-68hvt [193.913998ms]
Apr 23 10:00:12.255: INFO: Created: latency-svc-ztzxj
Apr 23 10:00:12.260: INFO: Got endpoints: latency-svc-ztzxj [192.39226ms]
Apr 23 10:00:12.262: INFO: Created: latency-svc-bzhsh
Apr 23 10:00:12.264: INFO: Got endpoints: latency-svc-bzhsh [164.821923ms]
Apr 23 10:00:12.267: INFO: Created: latency-svc-clfhn
Apr 23 10:00:12.272: INFO: Got endpoints: latency-svc-clfhn [159.941351ms]
Apr 23 10:00:12.278: INFO: Created: latency-svc-frvq4
Apr 23 10:00:12.283: INFO: Got endpoints: latency-svc-frvq4 [154.134507ms]
Apr 23 10:00:12.287: INFO: Created: latency-svc-2xchf
Apr 23 10:00:12.293: INFO: Got endpoints: latency-svc-2xchf [153.063394ms]
Apr 23 10:00:12.295: INFO: Created: latency-svc-852f2
Apr 23 10:00:12.301: INFO: Got endpoints: latency-svc-852f2 [151.131314ms]
Apr 23 10:00:12.307: INFO: Created: latency-svc-wzjss
Apr 23 10:00:12.311: INFO: Got endpoints: latency-svc-wzjss [150.734928ms]
Apr 23 10:00:12.318: INFO: Created: latency-svc-qjgg8
Apr 23 10:00:12.319: INFO: Got endpoints: latency-svc-qjgg8 [151.946973ms]
Apr 23 10:00:12.327: INFO: Created: latency-svc-2p4rj
Apr 23 10:00:12.330: INFO: Got endpoints: latency-svc-2p4rj [149.199373ms]
Apr 23 10:00:12.339: INFO: Created: latency-svc-rdtw2
Apr 23 10:00:12.348: INFO: Got endpoints: latency-svc-rdtw2 [156.61314ms]
Apr 23 10:00:12.352: INFO: Created: latency-svc-5h4kl
Apr 23 10:00:12.359: INFO: Got endpoints: latency-svc-5h4kl [153.651463ms]
Apr 23 10:00:12.363: INFO: Created: latency-svc-8xcnl
Apr 23 10:00:12.367: INFO: Created: latency-svc-bd6qz
Apr 23 10:00:12.368: INFO: Got endpoints: latency-svc-8xcnl [151.274977ms]
Apr 23 10:00:12.373: INFO: Got endpoints: latency-svc-bd6qz [143.729473ms]
Apr 23 10:00:12.378: INFO: Created: latency-svc-jn89j
Apr 23 10:00:12.385: INFO: Created: latency-svc-ft97t
Apr 23 10:00:12.385: INFO: Got endpoints: latency-svc-jn89j [148.141187ms]
Apr 23 10:00:12.394: INFO: Got endpoints: latency-svc-ft97t [145.216944ms]
Apr 23 10:00:12.395: INFO: Created: latency-svc-7k4dx
Apr 23 10:00:12.400: INFO: Got endpoints: latency-svc-7k4dx [139.716111ms]
Apr 23 10:00:12.406: INFO: Created: latency-svc-x75xn
Apr 23 10:00:12.412: INFO: Created: latency-svc-6fkq6
Apr 23 10:00:12.419: INFO: Created: latency-svc-tljt2
Apr 23 10:00:12.423: INFO: Got endpoints: latency-svc-x75xn [159.071882ms]
Apr 23 10:00:12.429: INFO: Created: latency-svc-hv4hj
Apr 23 10:00:12.436: INFO: Created: latency-svc-8g5pg
Apr 23 10:00:12.443: INFO: Created: latency-svc-z9s7s
Apr 23 10:00:12.449: INFO: Created: latency-svc-sddnw
Apr 23 10:00:12.459: INFO: Created: latency-svc-9lbc5
Apr 23 10:00:12.465: INFO: Created: latency-svc-9n5fv
Apr 23 10:00:12.469: INFO: Created: latency-svc-bmzcc
Apr 23 10:00:12.475: INFO: Got endpoints: latency-svc-6fkq6 [202.446248ms]
Apr 23 10:00:12.482: INFO: Created: latency-svc-r4rr2
Apr 23 10:00:12.492: INFO: Created: latency-svc-kql92
Apr 23 10:00:12.497: INFO: Created: latency-svc-hgz5h
Apr 23 10:00:12.506: INFO: Created: latency-svc-4fw9n
Apr 23 10:00:12.512: INFO: Created: latency-svc-vnl4w
Apr 23 10:00:12.516: INFO: Created: latency-svc-r4qzm
Apr 23 10:00:12.527: INFO: Created: latency-svc-cjkc5
Apr 23 10:00:12.527: INFO: Got endpoints: latency-svc-tljt2 [244.445433ms]
Apr 23 10:00:12.542: INFO: Created: latency-svc-4sjkd
Apr 23 10:00:12.575: INFO: Got endpoints: latency-svc-hv4hj [281.981982ms]
Apr 23 10:00:12.586: INFO: Created: latency-svc-xdnpv
Apr 23 10:00:12.622: INFO: Got endpoints: latency-svc-8g5pg [321.31074ms]
Apr 23 10:00:12.632: INFO: Created: latency-svc-w6nzk
Apr 23 10:00:12.674: INFO: Got endpoints: latency-svc-z9s7s [362.842453ms]
Apr 23 10:00:12.685: INFO: Created: latency-svc-929rt
Apr 23 10:00:12.724: INFO: Got endpoints: latency-svc-sddnw [404.456334ms]
Apr 23 10:00:12.734: INFO: Created: latency-svc-gjfrb
Apr 23 10:00:12.775: INFO: Got endpoints: latency-svc-9lbc5 [444.806954ms]
Apr 23 10:00:12.784: INFO: Created: latency-svc-sb67b
Apr 23 10:00:12.824: INFO: Got endpoints: latency-svc-9n5fv [476.112828ms]
Apr 23 10:00:12.835: INFO: Created: latency-svc-m6rqb
Apr 23 10:00:12.877: INFO: Got endpoints: latency-svc-bmzcc [516.95279ms]
Apr 23 10:00:12.885: INFO: Created: latency-svc-b2bvg
Apr 23 10:00:12.924: INFO: Got endpoints: latency-svc-r4rr2 [556.492727ms]
Apr 23 10:00:12.940: INFO: Created: latency-svc-v77md
Apr 23 10:00:12.973: INFO: Got endpoints: latency-svc-kql92 [599.753644ms]
Apr 23 10:00:12.986: INFO: Created: latency-svc-mbns8
Apr 23 10:00:13.023: INFO: Got endpoints: latency-svc-hgz5h [638.354906ms]
Apr 23 10:00:13.035: INFO: Created: latency-svc-zgghr
Apr 23 10:00:13.073: INFO: Got endpoints: latency-svc-4fw9n [678.833284ms]
Apr 23 10:00:13.083: INFO: Created: latency-svc-986b9
Apr 23 10:00:13.123: INFO: Got endpoints: latency-svc-vnl4w [723.092185ms]
Apr 23 10:00:13.134: INFO: Created: latency-svc-jdb72
Apr 23 10:00:13.173: INFO: Got endpoints: latency-svc-r4qzm [749.17034ms]
Apr 23 10:00:13.181: INFO: Created: latency-svc-2md4q
Apr 23 10:00:13.225: INFO: Got endpoints: latency-svc-cjkc5 [750.199485ms]
Apr 23 10:00:13.239: INFO: Created: latency-svc-29qtw
Apr 23 10:00:13.274: INFO: Got endpoints: latency-svc-4sjkd [746.96836ms]
Apr 23 10:00:13.283: INFO: Created: latency-svc-f4pj5
Apr 23 10:00:13.325: INFO: Got endpoints: latency-svc-xdnpv [749.9371ms]
Apr 23 10:00:13.337: INFO: Created: latency-svc-xxcxx
Apr 23 10:00:13.373: INFO: Got endpoints: latency-svc-w6nzk [750.586665ms]
Apr 23 10:00:13.384: INFO: Created: latency-svc-ccx2m
Apr 23 10:00:13.427: INFO: Got endpoints: latency-svc-929rt [752.61913ms]
Apr 23 10:00:13.435: INFO: Created: latency-svc-cdrr5
Apr 23 10:00:13.481: INFO: Got endpoints: latency-svc-gjfrb [757.252532ms]
Apr 23 10:00:13.494: INFO: Created: latency-svc-8fvkr
Apr 23 10:00:13.525: INFO: Got endpoints: latency-svc-sb67b [750.221414ms]
Apr 23 10:00:13.538: INFO: Created: latency-svc-tjnpt
Apr 23 10:00:13.577: INFO: Got endpoints: latency-svc-m6rqb [752.387487ms]
Apr 23 10:00:13.589: INFO: Created: latency-svc-9db2c
Apr 23 10:00:13.623: INFO: Got endpoints: latency-svc-b2bvg [746.534787ms]
Apr 23 10:00:13.636: INFO: Created: latency-svc-bzg6z
Apr 23 10:00:13.673: INFO: Got endpoints: latency-svc-v77md [748.73096ms]
Apr 23 10:00:13.683: INFO: Created: latency-svc-q4g42
Apr 23 10:00:13.724: INFO: Got endpoints: latency-svc-mbns8 [750.840157ms]
Apr 23 10:00:13.737: INFO: Created: latency-svc-7jzgh
Apr 23 10:00:13.772: INFO: Got endpoints: latency-svc-zgghr [748.992921ms]
Apr 23 10:00:13.784: INFO: Created: latency-svc-52w7s
Apr 23 10:00:13.825: INFO: Got endpoints: latency-svc-986b9 [751.687912ms]
Apr 23 10:00:13.834: INFO: Created: latency-svc-mrzvd
Apr 23 10:00:13.874: INFO: Got endpoints: latency-svc-jdb72 [750.783377ms]
Apr 23 10:00:13.883: INFO: Created: latency-svc-nxbht
Apr 23 10:00:13.923: INFO: Got endpoints: latency-svc-2md4q [750.122011ms]
Apr 23 10:00:13.934: INFO: Created: latency-svc-ck5dz
Apr 23 10:00:13.976: INFO: Got endpoints: latency-svc-29qtw [751.364361ms]
Apr 23 10:00:13.987: INFO: Created: latency-svc-ldcmx
Apr 23 10:00:14.023: INFO: Got endpoints: latency-svc-f4pj5 [748.849629ms]
Apr 23 10:00:14.032: INFO: Created: latency-svc-nz5nq
Apr 23 10:00:14.075: INFO: Got endpoints: latency-svc-xxcxx [749.737297ms]
Apr 23 10:00:14.084: INFO: Created: latency-svc-kmh7r
Apr 23 10:00:14.125: INFO: Got endpoints: latency-svc-ccx2m [752.387447ms]
Apr 23 10:00:14.135: INFO: Created: latency-svc-f5mhn
Apr 23 10:00:14.174: INFO: Got endpoints: latency-svc-cdrr5 [747.254434ms]
Apr 23 10:00:14.185: INFO: Created: latency-svc-z7tcb
Apr 23 10:00:14.224: INFO: Got endpoints: latency-svc-8fvkr [742.846447ms]
Apr 23 10:00:14.235: INFO: Created: latency-svc-pwgd6
Apr 23 10:00:14.302: INFO: Got endpoints: latency-svc-tjnpt [776.335165ms]
Apr 23 10:00:14.324: INFO: Created: latency-svc-fjfx2
Apr 23 10:00:14.331: INFO: Got endpoints: latency-svc-9db2c [754.393155ms]
Apr 23 10:00:14.342: INFO: Created: latency-svc-kfkkz
Apr 23 10:00:14.374: INFO: Got endpoints: latency-svc-bzg6z [750.663645ms]
Apr 23 10:00:14.387: INFO: Created: latency-svc-xlk8h
Apr 23 10:00:14.428: INFO: Got endpoints: latency-svc-q4g42 [755.016989ms]
Apr 23 10:00:14.439: INFO: Created: latency-svc-q78kl
Apr 23 10:00:14.473: INFO: Got endpoints: latency-svc-7jzgh [748.16959ms]
Apr 23 10:00:14.486: INFO: Created: latency-svc-xrx9v
Apr 23 10:00:14.524: INFO: Got endpoints: latency-svc-52w7s [751.602648ms]
Apr 23 10:00:14.536: INFO: Created: latency-svc-rk9xn
Apr 23 10:00:14.575: INFO: Got endpoints: latency-svc-mrzvd [750.363445ms]
Apr 23 10:00:14.585: INFO: Created: latency-svc-fzsg5
Apr 23 10:00:14.625: INFO: Got endpoints: latency-svc-nxbht [750.993601ms]
Apr 23 10:00:14.637: INFO: Created: latency-svc-29ftz
Apr 23 10:00:14.673: INFO: Got endpoints: latency-svc-ck5dz [750.005551ms]
Apr 23 10:00:14.685: INFO: Created: latency-svc-w9s2c
Apr 23 10:00:14.724: INFO: Got endpoints: latency-svc-ldcmx [747.889669ms]
Apr 23 10:00:14.734: INFO: Created: latency-svc-mkxsf
Apr 23 10:00:14.774: INFO: Got endpoints: latency-svc-nz5nq [751.112984ms]
Apr 23 10:00:14.785: INFO: Created: latency-svc-fcpxr
Apr 23 10:00:14.824: INFO: Got endpoints: latency-svc-kmh7r [748.67039ms]
Apr 23 10:00:14.836: INFO: Created: latency-svc-kqvmj
Apr 23 10:00:14.873: INFO: Got endpoints: latency-svc-f5mhn [747.927757ms]
Apr 23 10:00:14.884: INFO: Created: latency-svc-g4lt5
Apr 23 10:00:14.927: INFO: Got endpoints: latency-svc-z7tcb [752.98136ms]
Apr 23 10:00:14.938: INFO: Created: latency-svc-kttvg
Apr 23 10:00:14.974: INFO: Got endpoints: latency-svc-pwgd6 [749.852402ms]
Apr 23 10:00:14.987: INFO: Created: latency-svc-b5ntz
Apr 23 10:00:15.024: INFO: Got endpoints: latency-svc-fjfx2 [722.115358ms]
Apr 23 10:00:15.035: INFO: Created: latency-svc-k6zk5
Apr 23 10:00:15.074: INFO: Got endpoints: latency-svc-kfkkz [742.857287ms]
Apr 23 10:00:15.085: INFO: Created: latency-svc-k8rk7
Apr 23 10:00:15.128: INFO: Got endpoints: latency-svc-xlk8h [753.658021ms]
Apr 23 10:00:15.145: INFO: Created: latency-svc-vb9hn
Apr 23 10:00:15.174: INFO: Got endpoints: latency-svc-q78kl [745.717721ms]
Apr 23 10:00:15.184: INFO: Created: latency-svc-lq4h6
Apr 23 10:00:15.226: INFO: Got endpoints: latency-svc-xrx9v [753.15435ms]
Apr 23 10:00:15.239: INFO: Created: latency-svc-d2cjm
Apr 23 10:00:15.276: INFO: Got endpoints: latency-svc-rk9xn [751.233131ms]
Apr 23 10:00:15.288: INFO: Created: latency-svc-n25dv
Apr 23 10:00:15.324: INFO: Got endpoints: latency-svc-fzsg5 [748.490307ms]
Apr 23 10:00:15.338: INFO: Created: latency-svc-dckl7
Apr 23 10:00:15.375: INFO: Got endpoints: latency-svc-29ftz [749.886013ms]
Apr 23 10:00:15.390: INFO: Created: latency-svc-lrpsj
Apr 23 10:00:15.423: INFO: Got endpoints: latency-svc-w9s2c [750.08635ms]
Apr 23 10:00:15.434: INFO: Created: latency-svc-kx24b
Apr 23 10:00:15.476: INFO: Got endpoints: latency-svc-mkxsf [751.556188ms]
Apr 23 10:00:15.486: INFO: Created: latency-svc-b8465
Apr 23 10:00:15.527: INFO: Got endpoints: latency-svc-fcpxr [752.781484ms]
Apr 23 10:00:15.542: INFO: Created: latency-svc-xrbn8
Apr 23 10:00:15.574: INFO: Got endpoints: latency-svc-kqvmj [750.294887ms]
Apr 23 10:00:15.582: INFO: Created: latency-svc-ptpss
Apr 23 10:00:15.624: INFO: Got endpoints: latency-svc-g4lt5 [750.276164ms]
Apr 23 10:00:15.639: INFO: Created: latency-svc-b5j97
Apr 23 10:00:15.676: INFO: Got endpoints: latency-svc-kttvg [748.954641ms]
Apr 23 10:00:15.689: INFO: Created: latency-svc-2tqsj
Apr 23 10:00:15.727: INFO: Got endpoints: latency-svc-b5ntz [752.877883ms]
Apr 23 10:00:15.740: INFO: Created: latency-svc-dswb8
Apr 23 10:00:15.774: INFO: Got endpoints: latency-svc-k6zk5 [749.9827ms]
Apr 23 10:00:15.788: INFO: Created: latency-svc-kqvjm
Apr 23 10:00:15.827: INFO: Got endpoints: latency-svc-k8rk7 [753.025217ms]
Apr 23 10:00:15.840: INFO: Created: latency-svc-mmlr7
Apr 23 10:00:15.874: INFO: Got endpoints: latency-svc-vb9hn [745.843998ms]
Apr 23 10:00:15.887: INFO: Created: latency-svc-vrzxb
Apr 23 10:00:15.927: INFO: Got endpoints: latency-svc-lq4h6 [752.723257ms]
Apr 23 10:00:15.940: INFO: Created: latency-svc-7sl4m
Apr 23 10:00:15.974: INFO: Got endpoints: latency-svc-d2cjm [747.8141ms]
Apr 23 10:00:15.985: INFO: Created: latency-svc-bt77d
Apr 23 10:00:16.026: INFO: Got endpoints: latency-svc-n25dv [749.511656ms]
Apr 23 10:00:16.036: INFO: Created: latency-svc-zqbb2
Apr 23 10:00:16.074: INFO: Got endpoints: latency-svc-dckl7 [749.427629ms]
Apr 23 10:00:16.085: INFO: Created: latency-svc-72q2m
Apr 23 10:00:16.131: INFO: Got endpoints: latency-svc-lrpsj [755.880446ms]
Apr 23 10:00:16.144: INFO: Created: latency-svc-684n9
Apr 23 10:00:16.173: INFO: Got endpoints: latency-svc-kx24b [750.094105ms]
Apr 23 10:00:16.186: INFO: Created: latency-svc-tszhf
Apr 23 10:00:16.224: INFO: Got endpoints: latency-svc-b8465 [748.263663ms]
Apr 23 10:00:16.238: INFO: Created: latency-svc-78xg6
Apr 23 10:00:16.273: INFO: Got endpoints: latency-svc-xrbn8 [745.850206ms]
Apr 23 10:00:16.285: INFO: Created: latency-svc-trqbb
Apr 23 10:00:16.323: INFO: Got endpoints: latency-svc-ptpss [749.008917ms]
Apr 23 10:00:16.336: INFO: Created: latency-svc-rhdgv
Apr 23 10:00:16.374: INFO: Got endpoints: latency-svc-b5j97 [749.751686ms]
Apr 23 10:00:16.386: INFO: Created: latency-svc-b5k9z
Apr 23 10:00:16.424: INFO: Got endpoints: latency-svc-2tqsj [747.277594ms]
Apr 23 10:00:16.435: INFO: Created: latency-svc-54fwd
Apr 23 10:00:16.473: INFO: Got endpoints: latency-svc-dswb8 [746.233604ms]
Apr 23 10:00:16.484: INFO: Created: latency-svc-m9v7z
Apr 23 10:00:16.524: INFO: Got endpoints: latency-svc-kqvjm [749.834101ms]
Apr 23 10:00:16.536: INFO: Created: latency-svc-wsc2n
Apr 23 10:00:16.573: INFO: Got endpoints: latency-svc-mmlr7 [745.557782ms]
Apr 23 10:00:16.580: INFO: Created: latency-svc-vkbqw
Apr 23 10:00:16.623: INFO: Got endpoints: latency-svc-vrzxb [748.732497ms]
Apr 23 10:00:16.634: INFO: Created: latency-svc-xtcgv
Apr 23 10:00:16.673: INFO: Got endpoints: latency-svc-7sl4m [746.567138ms]
Apr 23 10:00:16.684: INFO: Created: latency-svc-j9jqm
Apr 23 10:00:16.726: INFO: Got endpoints: latency-svc-bt77d [751.88524ms]
Apr 23 10:00:16.738: INFO: Created: latency-svc-54lrj
Apr 23 10:00:16.774: INFO: Got endpoints: latency-svc-zqbb2 [748.399712ms]
Apr 23 10:00:16.785: INFO: Created: latency-svc-lklpb
Apr 23 10:00:16.828: INFO: Got endpoints: latency-svc-72q2m [754.305254ms]
Apr 23 10:00:16.840: INFO: Created: latency-svc-hz9ll
Apr 23 10:00:16.875: INFO: Got endpoints: latency-svc-684n9 [743.831171ms]
Apr 23 10:00:16.886: INFO: Created: latency-svc-85qpp
Apr 23 10:00:16.925: INFO: Got endpoints: latency-svc-tszhf [751.298197ms]
Apr 23 10:00:16.935: INFO: Created: latency-svc-6bhcd
Apr 23 10:00:16.979: INFO: Got endpoints: latency-svc-78xg6 [754.340488ms]
Apr 23 10:00:16.990: INFO: Created: latency-svc-jq866
Apr 23 10:00:17.025: INFO: Got endpoints: latency-svc-trqbb [751.7061ms]
Apr 23 10:00:17.034: INFO: Created: latency-svc-9xgl8
Apr 23 10:00:17.074: INFO: Got endpoints: latency-svc-rhdgv [750.721022ms]
Apr 23 10:00:17.086: INFO: Created: latency-svc-dm4dx
Apr 23 10:00:17.125: INFO: Got endpoints: latency-svc-b5k9z [750.79722ms]
Apr 23 10:00:17.140: INFO: Created: latency-svc-t79vt
Apr 23 10:00:17.173: INFO: Got endpoints: latency-svc-54fwd [749.278543ms]
Apr 23 10:00:17.185: INFO: Created: latency-svc-2j2g9
Apr 23 10:00:17.224: INFO: Got endpoints: latency-svc-m9v7z [750.722407ms]
Apr 23 10:00:17.235: INFO: Created: latency-svc-98vhm
Apr 23 10:00:17.274: INFO: Got endpoints: latency-svc-wsc2n [749.329183ms]
Apr 23 10:00:17.284: INFO: Created: latency-svc-74zqq
Apr 23 10:00:17.324: INFO: Got endpoints: latency-svc-vkbqw [751.691071ms]
Apr 23 10:00:17.334: INFO: Created: latency-svc-j7qs4
Apr 23 10:00:17.373: INFO: Got endpoints: latency-svc-xtcgv [749.563152ms]
Apr 23 10:00:17.384: INFO: Created: latency-svc-z585f
Apr 23 10:00:17.425: INFO: Got endpoints: latency-svc-j9jqm [751.271347ms]
Apr 23 10:00:17.433: INFO: Created: latency-svc-4czhb
Apr 23 10:00:17.473: INFO: Got endpoints: latency-svc-54lrj [747.314653ms]
Apr 23 10:00:17.494: INFO: Created: latency-svc-ghvfz
Apr 23 10:00:17.524: INFO: Got endpoints: latency-svc-lklpb [749.472996ms]
Apr 23 10:00:17.539: INFO: Created: latency-svc-shxnd
Apr 23 10:00:17.578: INFO: Got endpoints: latency-svc-hz9ll [749.201921ms]
Apr 23 10:00:17.599: INFO: Created: latency-svc-755h7
Apr 23 10:00:17.626: INFO: Got endpoints: latency-svc-85qpp [751.021471ms]
Apr 23 10:00:17.638: INFO: Created: latency-svc-rqqvp
Apr 23 10:00:17.676: INFO: Got endpoints: latency-svc-6bhcd [750.442202ms]
Apr 23 10:00:17.693: INFO: Created: latency-svc-2xj8d
Apr 23 10:00:17.724: INFO: Got endpoints: latency-svc-jq866 [745.054826ms]
Apr 23 10:00:17.736: INFO: Created: latency-svc-8qhxp
Apr 23 10:00:17.776: INFO: Got endpoints: latency-svc-9xgl8 [751.263768ms]
Apr 23 10:00:17.790: INFO: Created: latency-svc-5fl2h
Apr 23 10:00:17.824: INFO: Got endpoints: latency-svc-dm4dx [749.408352ms]
Apr 23 10:00:17.838: INFO: Created: latency-svc-wp7th
Apr 23 10:00:17.874: INFO: Got endpoints: latency-svc-t79vt [748.91271ms]
Apr 23 10:00:17.891: INFO: Created: latency-svc-hth5f
Apr 23 10:00:17.924: INFO: Got endpoints: latency-svc-2j2g9 [750.896085ms]
Apr 23 10:00:17.940: INFO: Created: latency-svc-4ll9j
Apr 23 10:00:17.977: INFO: Got endpoints: latency-svc-98vhm [752.500974ms]
Apr 23 10:00:17.991: INFO: Created: latency-svc-k9lfc
Apr 23 10:00:18.026: INFO: Got endpoints: latency-svc-74zqq [752.391945ms]
Apr 23 10:00:18.035: INFO: Created: latency-svc-7p99d
Apr 23 10:00:18.076: INFO: Got endpoints: latency-svc-j7qs4 [751.349138ms]
Apr 23 10:00:18.091: INFO: Created: latency-svc-z7zg4
Apr 23 10:00:18.128: INFO: Got endpoints: latency-svc-z585f [755.419567ms]
Apr 23 10:00:18.145: INFO: Created: latency-svc-7njpk
Apr 23 10:00:18.176: INFO: Got endpoints: latency-svc-4czhb [750.621482ms]
Apr 23 10:00:18.185: INFO: Created: latency-svc-fcqqj
Apr 23 10:00:18.224: INFO: Got endpoints: latency-svc-ghvfz [750.276426ms]
Apr 23 10:00:18.234: INFO: Created: latency-svc-c4f9t
Apr 23 10:00:18.273: INFO: Got endpoints: latency-svc-shxnd [749.239997ms]
Apr 23 10:00:18.287: INFO: Created: latency-svc-pzdtt
Apr 23 10:00:18.325: INFO: Got endpoints: latency-svc-755h7 [747.611241ms]
Apr 23 10:00:18.339: INFO: Created: latency-svc-rfqt6
Apr 23 10:00:18.374: INFO: Got endpoints: latency-svc-rqqvp [747.90758ms]
Apr 23 10:00:18.385: INFO: Created: latency-svc-8j7tl
Apr 23 10:00:18.424: INFO: Got endpoints: latency-svc-2xj8d [748.643749ms]
Apr 23 10:00:18.432: INFO: Created: latency-svc-qzb44
Apr 23 10:00:18.481: INFO: Got endpoints: latency-svc-8qhxp [756.16103ms]
Apr 23 10:00:18.494: INFO: Created: latency-svc-vqzpx
Apr 23 10:00:18.527: INFO: Got endpoints: latency-svc-5fl2h [750.705234ms]
Apr 23 10:00:18.544: INFO: Created: latency-svc-d8p62
Apr 23 10:00:18.573: INFO: Got endpoints: latency-svc-wp7th [749.683778ms]
Apr 23 10:00:18.585: INFO: Created: latency-svc-bgj9v
Apr 23 10:00:18.624: INFO: Got endpoints: latency-svc-hth5f [749.495595ms]
Apr 23 10:00:18.634: INFO: Created: latency-svc-tkgb4
Apr 23 10:00:18.674: INFO: Got endpoints: latency-svc-4ll9j [749.756988ms]
Apr 23 10:00:18.684: INFO: Created: latency-svc-24jr7
Apr 23 10:00:18.724: INFO: Got endpoints: latency-svc-k9lfc [747.027873ms]
Apr 23 10:00:18.733: INFO: Created: latency-svc-2kmvh
Apr 23 10:00:18.773: INFO: Got endpoints: latency-svc-7p99d [747.118283ms]
Apr 23 10:00:18.782: INFO: Created: latency-svc-nf44k
Apr 23 10:00:18.823: INFO: Got endpoints: latency-svc-z7zg4 [747.15937ms]
Apr 23 10:00:18.834: INFO: Created: latency-svc-sq8xx
Apr 23 10:00:18.874: INFO: Got endpoints: latency-svc-7njpk [745.288589ms]
Apr 23 10:00:18.883: INFO: Created: latency-svc-8hddk
Apr 23 10:00:18.924: INFO: Got endpoints: latency-svc-fcqqj [748.324101ms]
Apr 23 10:00:18.936: INFO: Created: latency-svc-wm9gz
Apr 23 10:00:18.975: INFO: Got endpoints: latency-svc-c4f9t [751.067749ms]
Apr 23 10:00:18.992: INFO: Created: latency-svc-62xt2
Apr 23 10:00:19.025: INFO: Got endpoints: latency-svc-pzdtt [750.842378ms]
Apr 23 10:00:19.038: INFO: Created: latency-svc-wrlcm
Apr 23 10:00:19.078: INFO: Got endpoints: latency-svc-rfqt6 [752.791282ms]
Apr 23 10:00:19.088: INFO: Created: latency-svc-m4w4s
Apr 23 10:00:19.125: INFO: Got endpoints: latency-svc-8j7tl [750.678378ms]
Apr 23 10:00:19.138: INFO: Created: latency-svc-snk94
Apr 23 10:00:19.175: INFO: Got endpoints: latency-svc-qzb44 [750.452396ms]
Apr 23 10:00:19.185: INFO: Created: latency-svc-87sjs
Apr 23 10:00:19.224: INFO: Got endpoints: latency-svc-vqzpx [743.150431ms]
Apr 23 10:00:19.236: INFO: Created: latency-svc-5prf6
Apr 23 10:00:19.277: INFO: Got endpoints: latency-svc-d8p62 [750.220595ms]
Apr 23 10:00:19.290: INFO: Created: latency-svc-jhlnh
Apr 23 10:00:19.325: INFO: Got endpoints: latency-svc-bgj9v [751.033486ms]
Apr 23 10:00:19.333: INFO: Created: latency-svc-l94l4
Apr 23 10:00:19.373: INFO: Got endpoints: latency-svc-tkgb4 [749.0723ms]
Apr 23 10:00:19.386: INFO: Created: latency-svc-6tlc6
Apr 23 10:00:19.429: INFO: Got endpoints: latency-svc-24jr7 [755.245938ms]
Apr 23 10:00:19.439: INFO: Created: latency-svc-chtxq
Apr 23 10:00:19.475: INFO: Got endpoints: latency-svc-2kmvh [750.883886ms]
Apr 23 10:00:19.486: INFO: Created: latency-svc-nfmbn
Apr 23 10:00:19.525: INFO: Got endpoints: latency-svc-nf44k [751.871141ms]
Apr 23 10:00:19.539: INFO: Created: latency-svc-sdr7x
Apr 23 10:00:19.576: INFO: Got endpoints: latency-svc-sq8xx [752.757787ms]
Apr 23 10:00:19.585: INFO: Created: latency-svc-txkv5
Apr 23 10:00:19.624: INFO: Got endpoints: latency-svc-8hddk [750.258202ms]
Apr 23 10:00:19.635: INFO: Created: latency-svc-5s96j
Apr 23 10:00:19.675: INFO: Got endpoints: latency-svc-wm9gz [751.260483ms]
Apr 23 10:00:19.688: INFO: Created: latency-svc-gb5t9
Apr 23 10:00:19.725: INFO: Got endpoints: latency-svc-62xt2 [750.269928ms]
Apr 23 10:00:19.743: INFO: Created: latency-svc-84624
Apr 23 10:00:19.775: INFO: Got endpoints: latency-svc-wrlcm [750.177507ms]
Apr 23 10:00:19.787: INFO: Created: latency-svc-zxc82
Apr 23 10:00:19.825: INFO: Got endpoints: latency-svc-m4w4s [746.751907ms]
Apr 23 10:00:19.874: INFO: Got endpoints: latency-svc-snk94 [748.486155ms]
Apr 23 10:00:19.925: INFO: Got endpoints: latency-svc-87sjs [749.916879ms]
Apr 23 10:00:19.974: INFO: Got endpoints: latency-svc-5prf6 [748.962596ms]
Apr 23 10:00:20.027: INFO: Got endpoints: latency-svc-jhlnh [749.229397ms]
Apr 23 10:00:20.074: INFO: Got endpoints: latency-svc-l94l4 [748.94891ms]
Apr 23 10:00:20.126: INFO: Got endpoints: latency-svc-6tlc6 [752.677384ms]
Apr 23 10:00:20.182: INFO: Got endpoints: latency-svc-chtxq [751.996963ms]
Apr 23 10:00:20.226: INFO: Got endpoints: latency-svc-nfmbn [751.136876ms]
Apr 23 10:00:20.279: INFO: Got endpoints: latency-svc-sdr7x [753.735546ms]
Apr 23 10:00:20.324: INFO: Got endpoints: latency-svc-txkv5 [747.631889ms]
Apr 23 10:00:20.375: INFO: Got endpoints: latency-svc-5s96j [751.01972ms]
Apr 23 10:00:20.425: INFO: Got endpoints: latency-svc-gb5t9 [749.584772ms]
Apr 23 10:00:20.476: INFO: Got endpoints: latency-svc-84624 [750.930361ms]
Apr 23 10:00:20.524: INFO: Got endpoints: latency-svc-zxc82 [749.026514ms]
Apr 23 10:00:20.524: INFO: Latencies: [22.102492ms 31.202705ms 45.189768ms 58.65734ms 70.751936ms 78.092998ms 90.490817ms 121.932215ms 133.469699ms 139.716111ms 143.729473ms 145.216944ms 148.141187ms 149.199373ms 149.671847ms 150.734928ms 151.131314ms 151.274977ms 151.946973ms 153.063394ms 153.651463ms 154.134507ms 156.61314ms 159.071882ms 159.941351ms 160.554837ms 164.821923ms 170.770294ms 181.153027ms 187.816061ms 189.800793ms 192.39226ms 193.128235ms 193.855526ms 193.913998ms 194.822213ms 198.224165ms 200.873581ms 202.446248ms 244.445433ms 281.981982ms 321.31074ms 362.842453ms 404.456334ms 444.806954ms 476.112828ms 516.95279ms 556.492727ms 599.753644ms 638.354906ms 678.833284ms 722.115358ms 723.092185ms 742.846447ms 742.857287ms 743.150431ms 743.831171ms 745.054826ms 745.288589ms 745.557782ms 745.717721ms 745.843998ms 745.850206ms 746.233604ms 746.534787ms 746.567138ms 746.751907ms 746.96836ms 747.027873ms 747.118283ms 747.15937ms 747.254434ms 747.277594ms 747.314653ms 747.611241ms 747.631889ms 747.8141ms 747.889669ms 747.90758ms 747.927757ms 748.16959ms 748.263663ms 748.324101ms 748.399712ms 748.486155ms 748.490307ms 748.643749ms 748.67039ms 748.73096ms 748.732497ms 748.849629ms 748.91271ms 748.94891ms 748.954641ms 748.962596ms 748.992921ms 749.008917ms 749.026514ms 749.0723ms 749.17034ms 749.201921ms 749.229397ms 749.239997ms 749.278543ms 749.329183ms 749.408352ms 749.427629ms 749.472996ms 749.495595ms 749.511656ms 749.563152ms 749.584772ms 749.683778ms 749.737297ms 749.751686ms 749.756988ms 749.834101ms 749.852402ms 749.886013ms 749.916879ms 749.9371ms 749.9827ms 750.005551ms 750.08635ms 750.094105ms 750.122011ms 750.177507ms 750.199485ms 750.220595ms 750.221414ms 750.258202ms 750.269928ms 750.276164ms 750.276426ms 750.294887ms 750.363445ms 750.442202ms 750.452396ms 750.586665ms 750.621482ms 750.663645ms 750.678378ms 750.705234ms 750.721022ms 750.722407ms 750.783377ms 750.79722ms 750.840157ms 750.842378ms 750.883886ms 750.896085ms 750.930361ms 750.993601ms 751.01972ms 751.021471ms 751.033486ms 751.067749ms 751.112984ms 751.136876ms 751.233131ms 751.260483ms 751.263768ms 751.271347ms 751.298197ms 751.349138ms 751.364361ms 751.556188ms 751.602648ms 751.687912ms 751.691071ms 751.7061ms 751.871141ms 751.88524ms 751.996963ms 752.387447ms 752.387487ms 752.391945ms 752.500974ms 752.61913ms 752.677384ms 752.723257ms 752.757787ms 752.781484ms 752.791282ms 752.877883ms 752.98136ms 753.025217ms 753.15435ms 753.658021ms 753.735546ms 754.305254ms 754.340488ms 754.393155ms 755.016989ms 755.245938ms 755.419567ms 755.880446ms 756.16103ms 757.252532ms 776.335165ms]
Apr 23 10:00:20.525: INFO: 50 %ile: 749.201921ms
Apr 23 10:00:20.525: INFO: 90 %ile: 752.723257ms
Apr 23 10:00:20.525: INFO: 99 %ile: 757.252532ms
Apr 23 10:00:20.525: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:00:20.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8804" for this suite.
Apr 23 10:00:34.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:00:34.627: INFO: namespace svc-latency-8804 deletion completed in 14.097721578s

• [SLOW TEST:25.866 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:00:34.628: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 23 10:00:34.677: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d" in namespace "downward-api-5647" to be "success or failure"
Apr 23 10:00:34.679: INFO: Pod "downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550328ms
Apr 23 10:00:36.683: INFO: Pod "downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006457771s
Apr 23 10:00:38.687: INFO: Pod "downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010171793s
STEP: Saw pod success
Apr 23 10:00:38.687: INFO: Pod "downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:00:38.689: INFO: Trying to get logs from node net1a83gn1-worker-1 pod downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d container client-container: <nil>
STEP: delete the pod
Apr 23 10:00:38.714: INFO: Waiting for pod downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 10:00:38.717: INFO: Pod downwardapi-volume-a31b4b91-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:00:38.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5647" for this suite.
Apr 23 10:00:44.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:00:44.831: INFO: namespace downward-api-5647 deletion completed in 6.109586609s

• [SLOW TEST:10.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:00:44.831: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 23 10:00:44.865: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 10:00:44.872: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 10:00:44.875: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-1 before test
Apr 23 10:00:44.880: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-n6xl5 from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.880: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 23 10:00:44.880: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 23 10:00:44.880: INFO: calico-node-4l587 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.880: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 10:00:44.880: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 10:00:44.880: INFO: kube-proxy-j8vr9 from kube-system started at 2019-04-23 08:45:33 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.880: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 10:00:44.880: INFO: tiller-deploy-548df79d66-dltk9 from kube-system started at 2019-04-23 08:46:23 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.880: INFO: 	Container tiller ready: true, restart count 0
Apr 23 10:00:44.880: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-2 before test
Apr 23 10:00:44.886: INFO: sonobuoy-e2e-job-831cbf02ea2f4cb0 from heptio-sonobuoy started at 2019-04-23 08:51:32 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.887: INFO: 	Container e2e ready: true, restart count 0
Apr 23 10:00:44.887: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 10:00:44.887: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-zxr7k from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.887: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 23 10:00:44.887: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 23 10:00:44.887: INFO: kube-proxy-h6snt from kube-system started at 2019-04-23 08:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.887: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 10:00:44.887: INFO: calico-node-fzh7c from kube-system started at 2019-04-23 08:45:47 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.887: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 10:00:44.887: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 10:00:44.887: INFO: kubernetes-dashboard-b7c58947-55jg6 from kube-system started at 2019-04-23 08:46:48 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.887: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 23 10:00:44.887: INFO: 
Logging pods the kubelet thinks is on node net1a83gn1-worker-3 before test
Apr 23 10:00:44.892: INFO: heapster-f7fb9fb4f-85kn9 from kube-system started at 2019-04-23 08:46:47 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.892: INFO: 	Container heapster ready: true, restart count 0
Apr 23 10:00:44.892: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-23 08:51:27 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.892: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 10:00:44.892: INFO: calico-node-l4kn7 from kube-system started at 2019-04-23 08:45:34 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.892: INFO: 	Container calico-node ready: true, restart count 0
Apr 23 10:00:44.892: INFO: 	Container install-cni ready: true, restart count 0
Apr 23 10:00:44.892: INFO: sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-72vdb from heptio-sonobuoy started at 2019-04-23 08:51:33 +0000 UTC (2 container statuses recorded)
Apr 23 10:00:44.892: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 23 10:00:44.892: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 23 10:00:44.892: INFO: kube-proxy-jchgb from kube-system started at 2019-04-23 08:45:34 +0000 UTC (1 container statuses recorded)
Apr 23 10:00:44.892: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1598122a7a7c8f7c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:00:45.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5056" for this suite.
Apr 23 10:00:51.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:00:52.016: INFO: namespace sched-pred-5056 deletion completed in 6.100034935s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.185 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:00:52.017: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 23 10:00:52.061: INFO: Waiting up to 5m0s for pod "var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d" in namespace "var-expansion-6421" to be "success or failure"
Apr 23 10:00:52.068: INFO: Pod "var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.557009ms
Apr 23 10:00:54.072: INFO: Pod "var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010784302s
Apr 23 10:00:56.076: INFO: Pod "var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014446594s
STEP: Saw pod success
Apr 23 10:00:56.076: INFO: Pod "var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:00:56.078: INFO: Trying to get logs from node net1a83gn1-worker-1 pod var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 10:00:56.106: INFO: Waiting for pod var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d to disappear
Apr 23 10:00:56.112: INFO: Pod var-expansion-ad778d15-65ae-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:00:56.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6421" for this suite.
Apr 23 10:01:02.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:01:02.221: INFO: namespace var-expansion-6421 deletion completed in 6.098892136s

• [SLOW TEST:10.205 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:01:02.222: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:01:02.271: INFO: (0) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.818581ms)
Apr 23 10:01:02.275: INFO: (1) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.69692ms)
Apr 23 10:01:02.279: INFO: (2) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.61943ms)
Apr 23 10:01:02.282: INFO: (3) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.687951ms)
Apr 23 10:01:02.286: INFO: (4) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.092183ms)
Apr 23 10:01:02.290: INFO: (5) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.393129ms)
Apr 23 10:01:02.293: INFO: (6) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.410989ms)
Apr 23 10:01:02.297: INFO: (7) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.366555ms)
Apr 23 10:01:02.300: INFO: (8) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.368693ms)
Apr 23 10:01:02.303: INFO: (9) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.339108ms)
Apr 23 10:01:02.307: INFO: (10) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.256582ms)
Apr 23 10:01:02.310: INFO: (11) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.40771ms)
Apr 23 10:01:02.314: INFO: (12) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.436804ms)
Apr 23 10:01:02.317: INFO: (13) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.270575ms)
Apr 23 10:01:02.320: INFO: (14) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.479377ms)
Apr 23 10:01:02.324: INFO: (15) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.173509ms)
Apr 23 10:01:02.327: INFO: (16) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.339792ms)
Apr 23 10:01:02.330: INFO: (17) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.270962ms)
Apr 23 10:01:02.334: INFO: (18) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.499099ms)
Apr 23 10:01:02.337: INFO: (19) /api/v1/nodes/net1a83gn1-worker-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.103879ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:01:02.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6652" for this suite.
Apr 23 10:01:08.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:01:08.440: INFO: namespace proxy-6652 deletion completed in 6.100021474s

• [SLOW TEST:6.219 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:01:08.441: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 23 10:01:13.503: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:01:14.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9499" for this suite.
Apr 23 10:01:36.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:01:36.620: INFO: namespace replicaset-9499 deletion completed in 22.097092132s

• [SLOW TEST:28.179 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:01:36.620: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-c80e59e5-65ae-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c80e59e5-65ae-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:02:51.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7275" for this suite.
Apr 23 10:03:13.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:03:13.181: INFO: namespace configmap-7275 deletion completed in 22.109979196s

• [SLOW TEST:96.561 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:03:13.182: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 23 10:03:13.222: INFO: Waiting up to 5m0s for pod "pod-019b7f4a-65af-11e9-b8ea-e2349624188d" in namespace "emptydir-2980" to be "success or failure"
Apr 23 10:03:13.225: INFO: Pod "pod-019b7f4a-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646616ms
Apr 23 10:03:15.229: INFO: Pod "pod-019b7f4a-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006427419s
Apr 23 10:03:17.233: INFO: Pod "pod-019b7f4a-65af-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010529375s
STEP: Saw pod success
Apr 23 10:03:17.233: INFO: Pod "pod-019b7f4a-65af-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:03:17.236: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-019b7f4a-65af-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 10:03:17.256: INFO: Waiting for pod pod-019b7f4a-65af-11e9-b8ea-e2349624188d to disappear
Apr 23 10:03:17.259: INFO: Pod pod-019b7f4a-65af-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:03:17.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2980" for this suite.
Apr 23 10:03:23.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:03:23.365: INFO: namespace emptydir-2980 deletion completed in 6.102275058s

• [SLOW TEST:10.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:03:23.365: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 23 10:03:23.419: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18838,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 23 10:03:23.420: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18838,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 23 10:03:33.430: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18854,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 23 10:03:33.431: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18854,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 23 10:03:43.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18871,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 23 10:03:43.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18871,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 23 10:03:53.449: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18888,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 23 10:03:53.449: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-a,UID:07afe0f9-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18888,Generation:0,CreationTimestamp:2019-04-23 10:03:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 23 10:04:03.459: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-b,UID:1f8ccff2-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18908,Generation:0,CreationTimestamp:2019-04-23 10:04:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 23 10:04:03.459: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-b,UID:1f8ccff2-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18908,Generation:0,CreationTimestamp:2019-04-23 10:04:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 23 10:04:13.470: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-b,UID:1f8ccff2-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18926,Generation:0,CreationTimestamp:2019-04-23 10:04:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 23 10:04:13.470: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1486,SelfLink:/api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-configmap-b,UID:1f8ccff2-65af-11e9-be4b-42010a8a0fda,ResourceVersion:18926,Generation:0,CreationTimestamp:2019-04-23 10:04:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:04:23.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1486" for this suite.
Apr 23 10:04:29.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:04:29.578: INFO: namespace watch-1486 deletion completed in 6.103622652s

• [SLOW TEST:66.213 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:04:29.579: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:04:33.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8780" for this suite.
Apr 23 10:05:15.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:05:15.736: INFO: namespace kubelet-test-8780 deletion completed in 42.0903934s

• [SLOW TEST:46.157 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:05:15.737: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 23 10:05:15.773: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994727835 proxy --unix-socket=/tmp/kubectl-proxy-unix620063826/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:05:15.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9725" for this suite.
Apr 23 10:05:21.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:05:21.938: INFO: namespace kubectl-9725 deletion completed in 6.102766771s

• [SLOW TEST:6.202 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:05:21.938: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-4e5a2435-65af-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 10:05:21.984: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d" in namespace "configmap-4775" to be "success or failure"
Apr 23 10:05:21.987: INFO: Pod "pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.70078ms
Apr 23 10:05:23.991: INFO: Pod "pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006665181s
Apr 23 10:05:25.994: INFO: Pod "pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010486784s
STEP: Saw pod success
Apr 23 10:05:25.994: INFO: Pod "pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:05:25.997: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 10:05:26.019: INFO: Waiting for pod pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d to disappear
Apr 23 10:05:26.022: INFO: Pod pod-configmaps-4e5abdfa-65af-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:05:26.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4775" for this suite.
Apr 23 10:05:32.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:05:32.120: INFO: namespace configmap-4775 deletion completed in 6.094563487s

• [SLOW TEST:10.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:05:32.120: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 23 10:05:32.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-2747'
Apr 23 10:05:32.516: INFO: stderr: ""
Apr 23 10:05:32.516: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 23 10:05:32.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2747'
Apr 23 10:05:32.603: INFO: stderr: ""
Apr 23 10:05:32.603: INFO: stdout: "update-demo-nautilus-7dzmk update-demo-nautilus-tkz8w "
Apr 23 10:05:32.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-7dzmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2747'
Apr 23 10:05:32.676: INFO: stderr: ""
Apr 23 10:05:32.676: INFO: stdout: ""
Apr 23 10:05:32.676: INFO: update-demo-nautilus-7dzmk is created but not running
Apr 23 10:05:37.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2747'
Apr 23 10:05:37.752: INFO: stderr: ""
Apr 23 10:05:37.752: INFO: stdout: "update-demo-nautilus-7dzmk update-demo-nautilus-tkz8w "
Apr 23 10:05:37.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-7dzmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2747'
Apr 23 10:05:37.825: INFO: stderr: ""
Apr 23 10:05:37.825: INFO: stdout: "true"
Apr 23 10:05:37.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-7dzmk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2747'
Apr 23 10:05:37.899: INFO: stderr: ""
Apr 23 10:05:37.899: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 10:05:37.899: INFO: validating pod update-demo-nautilus-7dzmk
Apr 23 10:05:37.905: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 10:05:37.905: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 10:05:37.905: INFO: update-demo-nautilus-7dzmk is verified up and running
Apr 23 10:05:37.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-tkz8w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2747'
Apr 23 10:05:37.979: INFO: stderr: ""
Apr 23 10:05:37.979: INFO: stdout: "true"
Apr 23 10:05:37.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods update-demo-nautilus-tkz8w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2747'
Apr 23 10:05:38.055: INFO: stderr: ""
Apr 23 10:05:38.055: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 23 10:05:38.055: INFO: validating pod update-demo-nautilus-tkz8w
Apr 23 10:05:38.061: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 10:05:38.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 10:05:38.061: INFO: update-demo-nautilus-tkz8w is verified up and running
STEP: using delete to clean up resources
Apr 23 10:05:38.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete --grace-period=0 --force -f - --namespace=kubectl-2747'
Apr 23 10:05:38.139: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 10:05:38.139: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 23 10:05:38.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2747'
Apr 23 10:05:38.219: INFO: stderr: "No resources found.\n"
Apr 23 10:05:38.219: INFO: stdout: ""
Apr 23 10:05:38.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=update-demo --namespace=kubectl-2747 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 10:05:38.298: INFO: stderr: ""
Apr 23 10:05:38.298: INFO: stdout: "update-demo-nautilus-7dzmk\nupdate-demo-nautilus-tkz8w\n"
Apr 23 10:05:38.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2747'
Apr 23 10:05:38.880: INFO: stderr: "No resources found.\n"
Apr 23 10:05:38.880: INFO: stdout: ""
Apr 23 10:05:38.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 get pods -l name=update-demo --namespace=kubectl-2747 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 10:05:38.953: INFO: stderr: ""
Apr 23 10:05:38.953: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:05:38.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2747" for this suite.
Apr 23 10:05:44.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:05:45.062: INFO: namespace kubectl-2747 deletion completed in 6.104094119s

• [SLOW TEST:12.942 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:05:45.062: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7774
Apr 23 10:05:49.124: INFO: Started pod liveness-http in namespace container-probe-7774
STEP: checking the pod's current state and verifying that restartCount is present
Apr 23 10:05:49.127: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:09:49.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7774" for this suite.
Apr 23 10:09:55.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:09:55.730: INFO: namespace container-probe-7774 deletion completed in 6.097988039s

• [SLOW TEST:250.669 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:09:55.731: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-f18cb506-65af-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:09:55.785: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d" in namespace "projected-4134" to be "success or failure"
Apr 23 10:09:55.792: INFO: Pod "pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.190892ms
Apr 23 10:09:57.795: INFO: Pod "pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01006526s
Apr 23 10:09:59.799: INFO: Pod "pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013695007s
STEP: Saw pod success
Apr 23 10:09:59.799: INFO: Pod "pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:09:59.802: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:09:59.825: INFO: Waiting for pod pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d to disappear
Apr 23 10:09:59.827: INFO: Pod pod-projected-secrets-f18d473e-65af-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:09:59.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4134" for this suite.
Apr 23 10:10:05.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:10:05.928: INFO: namespace projected-4134 deletion completed in 6.096920586s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:10:05.928: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:10:05.963: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:10:07.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2329" for this suite.
Apr 23 10:10:13.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:10:13.117: INFO: namespace custom-resource-definition-2329 deletion completed in 6.104996573s

• [SLOW TEST:7.189 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:10:13.117: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-fbedf58e-65af-11e9-b8ea-e2349624188d
STEP: Creating secret with name secret-projected-all-test-volume-fbedf57b-65af-11e9-b8ea-e2349624188d
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 23 10:10:13.211: INFO: Waiting up to 5m0s for pod "projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d" in namespace "projected-1700" to be "success or failure"
Apr 23 10:10:13.224: INFO: Pod "projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.998453ms
Apr 23 10:10:15.227: INFO: Pod "projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015788435s
Apr 23 10:10:17.231: INFO: Pod "projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019787894s
STEP: Saw pod success
Apr 23 10:10:17.231: INFO: Pod "projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:10:17.234: INFO: Trying to get logs from node net1a83gn1-worker-1 pod projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 23 10:10:17.256: INFO: Waiting for pod projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d to disappear
Apr 23 10:10:17.259: INFO: Pod projected-volume-fbedf546-65af-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:10:17.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1700" for this suite.
Apr 23 10:10:23.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:10:23.357: INFO: namespace projected-1700 deletion completed in 6.094117037s

• [SLOW TEST:10.240 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:10:23.358: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:10:27.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4556" for this suite.
Apr 23 10:10:33.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:10:33.581: INFO: namespace emptydir-wrapper-4556 deletion completed in 6.1119166s

• [SLOW TEST:10.223 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:10:33.581: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 23 10:10:33.706: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19825,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 23 10:10:33.706: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19826,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 23 10:10:33.706: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19827,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 23 10:10:43.745: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19846,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 23 10:10:43.745: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19847,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 23 10:10:43.745: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2814,SelfLink:/api/v1/namespaces/watch-2814/configmaps/e2e-watch-test-label-changed,UID:0824c826-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:19848,Generation:0,CreationTimestamp:2019-04-23 10:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:10:43.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2814" for this suite.
Apr 23 10:10:49.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:10:49.861: INFO: namespace watch-2814 deletion completed in 6.112066927s

• [SLOW TEST:16.280 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:10:49.862: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-11cf9e08-65b0-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:10:49.943: INFO: Waiting up to 5m0s for pod "pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d" in namespace "secrets-2926" to be "success or failure"
Apr 23 10:10:49.949: INFO: Pod "pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496418ms
Apr 23 10:10:51.952: INFO: Pod "pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009433229s
Apr 23 10:10:53.957: INFO: Pod "pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013602199s
STEP: Saw pod success
Apr 23 10:10:53.957: INFO: Pod "pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:10:53.959: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:10:53.980: INFO: Waiting for pod pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d to disappear
Apr 23 10:10:53.983: INFO: Pod pod-secrets-11d50d0e-65b0-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:10:53.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2926" for this suite.
Apr 23 10:11:00.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:11:00.093: INFO: namespace secrets-2926 deletion completed in 6.105060084s
STEP: Destroying namespace "secret-namespace-4720" for this suite.
Apr 23 10:11:06.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:11:06.202: INFO: namespace secret-namespace-4720 deletion completed in 6.108825293s

• [SLOW TEST:16.340 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:11:06.202: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9121
Apr 23 10:11:10.256: INFO: Started pod liveness-http in namespace container-probe-9121
STEP: checking the pod's current state and verifying that restartCount is present
Apr 23 10:11:10.259: INFO: Initial restart count of pod liveness-http is 0
Apr 23 10:11:32.305: INFO: Restart count of pod container-probe-9121/liveness-http is now 1 (22.046548758s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:11:32.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9121" for this suite.
Apr 23 10:11:38.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:11:38.438: INFO: namespace container-probe-9121 deletion completed in 6.104898833s

• [SLOW TEST:32.236 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:11:38.439: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 23 10:11:43.021: INFO: Successfully updated pod "labelsupdate2ec3f8be-65b0-11e9-b8ea-e2349624188d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:11:45.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-155" for this suite.
Apr 23 10:12:07.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:12:07.149: INFO: namespace downward-api-155 deletion completed in 22.102575972s

• [SLOW TEST:28.710 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:12:07.149: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 23 10:12:15.235: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 23 10:12:15.239: INFO: Pod pod-with-poststart-http-hook still exists
Apr 23 10:12:17.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 23 10:12:17.243: INFO: Pod pod-with-poststart-http-hook still exists
Apr 23 10:12:19.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 23 10:12:19.243: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:12:19.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1170" for this suite.
Apr 23 10:12:41.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:12:41.345: INFO: namespace container-lifecycle-hook-1170 deletion completed in 22.098418948s

• [SLOW TEST:34.197 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:12:41.346: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 23 10:12:41.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-7952'
Apr 23 10:12:41.479: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 23 10:12:41.479: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 23 10:12:43.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7952'
Apr 23 10:12:43.586: INFO: stderr: ""
Apr 23 10:12:43.586: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:12:43.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7952" for this suite.
Apr 23 10:13:05.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:13:05.691: INFO: namespace kubectl-7952 deletion completed in 22.101399396s

• [SLOW TEST:24.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:13:05.691: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-62c63148-65b0-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:13:05.746: INFO: Waiting up to 5m0s for pod "pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d" in namespace "secrets-5839" to be "success or failure"
Apr 23 10:13:05.749: INFO: Pod "pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129937ms
Apr 23 10:13:07.752: INFO: Pod "pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006550502s
Apr 23 10:13:09.756: INFO: Pod "pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009931348s
STEP: Saw pod success
Apr 23 10:13:09.756: INFO: Pod "pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:13:09.759: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d container secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:13:09.784: INFO: Waiting for pod pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d to disappear
Apr 23 10:13:09.786: INFO: Pod pod-secrets-62c71916-65b0-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:13:09.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5839" for this suite.
Apr 23 10:13:15.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:13:15.889: INFO: namespace secrets-5839 deletion completed in 6.099663735s

• [SLOW TEST:10.198 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:13:15.890: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-68d983e6-65b0-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:13:15.935: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d" in namespace "projected-9279" to be "success or failure"
Apr 23 10:13:15.939: INFO: Pod "pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.396927ms
Apr 23 10:13:17.943: INFO: Pod "pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008018642s
Apr 23 10:13:19.947: INFO: Pod "pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011672311s
STEP: Saw pod success
Apr 23 10:13:19.947: INFO: Pod "pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:13:19.949: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:13:19.972: INFO: Waiting for pod pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d to disappear
Apr 23 10:13:19.976: INFO: Pod pod-projected-secrets-68da2d73-65b0-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:13:19.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9279" for this suite.
Apr 23 10:13:25.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:13:26.080: INFO: namespace projected-9279 deletion completed in 6.100119363s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:13:26.080: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2536
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 23 10:13:26.137: INFO: Found 0 stateful pods, waiting for 3
Apr 23 10:13:36.141: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:13:36.141: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:13:36.141: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 23 10:13:36.169: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 23 10:13:46.205: INFO: Updating stateful set ss2
Apr 23 10:13:46.210: INFO: Waiting for Pod statefulset-2536/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 23 10:13:56.286: INFO: Found 2 stateful pods, waiting for 3
Apr 23 10:14:06.291: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:14:06.291: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:14:06.291: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 23 10:14:06.316: INFO: Updating stateful set ss2
Apr 23 10:14:06.327: INFO: Waiting for Pod statefulset-2536/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 10:14:16.353: INFO: Updating stateful set ss2
Apr 23 10:14:16.361: INFO: Waiting for StatefulSet statefulset-2536/ss2 to complete update
Apr 23 10:14:16.361: INFO: Waiting for Pod statefulset-2536/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 23 10:14:26.368: INFO: Waiting for StatefulSet statefulset-2536/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 23 10:14:36.369: INFO: Deleting all statefulset in ns statefulset-2536
Apr 23 10:14:36.371: INFO: Scaling statefulset ss2 to 0
Apr 23 10:14:56.387: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 10:14:56.390: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:14:56.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2536" for this suite.
Apr 23 10:15:02.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:15:02.508: INFO: namespace statefulset-2536 deletion completed in 6.099920143s

• [SLOW TEST:96.428 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:15:02.508: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:15:02.545: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 23 10:15:02.551: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 23 10:15:07.555: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 23 10:15:07.556: INFO: Creating deployment "test-rolling-update-deployment"
Apr 23 10:15:07.562: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 23 10:15:07.575: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 23 10:15:09.582: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 23 10:15:09.585: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691611307, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691611307, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691611307, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691611307, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 10:15:11.589: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 23 10:15:11.599: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4625,SelfLink:/apis/apps/v1/namespaces/deployment-4625/deployments/test-rolling-update-deployment,UID:ab634432-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:20843,Generation:1,CreationTimestamp:2019-04-23 10:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-23 10:15:07 +0000 UTC 2019-04-23 10:15:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-23 10:15:09 +0000 UTC 2019-04-23 10:15:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 10:15:11.602: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-4625,SelfLink:/apis/apps/v1/namespaces/deployment-4625/replicasets/test-rolling-update-deployment-67599b4d9,UID:ab65f20e-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:20832,Generation:1,CreationTimestamp:2019-04-23 10:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ab634432-65b0-11e9-be4b-42010a8a0fda 0xc0011445d0 0xc0011445d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 23 10:15:11.602: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 23 10:15:11.602: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4625,SelfLink:/apis/apps/v1/namespaces/deployment-4625/replicasets/test-rolling-update-controller,UID:a866a3ba-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:20842,Generation:2,CreationTimestamp:2019-04-23 10:15:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ab634432-65b0-11e9-be4b-42010a8a0fda 0xc0011444f7 0xc0011444f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 23 10:15:11.605: INFO: Pod "test-rolling-update-deployment-67599b4d9-hlcw8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-hlcw8,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-4625,SelfLink:/api/v1/namespaces/deployment-4625/pods/test-rolling-update-deployment-67599b4d9-hlcw8,UID:ab67037b-65b0-11e9-be4b-42010a8a0fda,ResourceVersion:20831,Generation:0,CreationTimestamp:2019-04-23 10:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.2.125/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 ab65f20e-65b0-11e9-be4b-42010a8a0fda 0xc001145760 0xc001145761}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2pq8q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2pq8q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2pq8q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:net1a83gn1-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011458c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011458e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 10:15:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 10:15:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 10:15:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-23 10:15:07 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.221,PodIP:10.2.2.125,StartTime:2019-04-23 10:15:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-23 10:15:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://806e4f2ba39f665c509f7d8d8feb765360c7df6cc4181ded066d119c22aaecb0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:15:11.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4625" for this suite.
Apr 23 10:15:17.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:15:17.706: INFO: namespace deployment-4625 deletion completed in 6.096334815s

• [SLOW TEST:15.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:15:17.706: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:15:17.740: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:15:21.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9230" for this suite.
Apr 23 10:16:03.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:16:04.078: INFO: namespace pods-9230 deletion completed in 42.097080897s

• [SLOW TEST:46.372 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:16:04.079: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 23 10:16:08.132: INFO: Pod pod-hostip-cd191f73-65b0-11e9-b8ea-e2349624188d has hostIP: 10.138.15.221
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:16:08.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4374" for this suite.
Apr 23 10:16:30.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:16:30.235: INFO: namespace pods-4374 deletion completed in 22.097091338s

• [SLOW TEST:26.156 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:16:30.235: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-dcb0685e-65b0-11e9-b8ea-e2349624188d
STEP: Creating secret with name s-test-opt-upd-dcb068a1-65b0-11e9-b8ea-e2349624188d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dcb0685e-65b0-11e9-b8ea-e2349624188d
STEP: Updating secret s-test-opt-upd-dcb068a1-65b0-11e9-b8ea-e2349624188d
STEP: Creating secret with name s-test-opt-create-dcb068b4-65b0-11e9-b8ea-e2349624188d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:16:38.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3080" for this suite.
Apr 23 10:17:00.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:17:00.503: INFO: namespace projected-3080 deletion completed in 22.108209254s

• [SLOW TEST:30.268 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:17:00.503: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-mtz4
STEP: Creating a pod to test atomic-volume-subpath
Apr 23 10:17:00.575: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mtz4" in namespace "subpath-9430" to be "success or failure"
Apr 23 10:17:00.580: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.611997ms
Apr 23 10:17:02.584: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008303955s
Apr 23 10:17:04.588: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 4.012408679s
Apr 23 10:17:06.592: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 6.016393515s
Apr 23 10:17:08.596: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 8.020195634s
Apr 23 10:17:10.599: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 10.024179845s
Apr 23 10:17:12.603: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 12.028003943s
Apr 23 10:17:14.608: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 14.03226089s
Apr 23 10:17:16.612: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 16.036419331s
Apr 23 10:17:18.615: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 18.040159999s
Apr 23 10:17:20.620: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 20.044392932s
Apr 23 10:17:22.624: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Running", Reason="", readiness=true. Elapsed: 22.048760222s
Apr 23 10:17:24.628: INFO: Pod "pod-subpath-test-secret-mtz4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052912383s
STEP: Saw pod success
Apr 23 10:17:24.628: INFO: Pod "pod-subpath-test-secret-mtz4" satisfied condition "success or failure"
Apr 23 10:17:24.631: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-subpath-test-secret-mtz4 container test-container-subpath-secret-mtz4: <nil>
STEP: delete the pod
Apr 23 10:17:24.657: INFO: Waiting for pod pod-subpath-test-secret-mtz4 to disappear
Apr 23 10:17:24.659: INFO: Pod pod-subpath-test-secret-mtz4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-mtz4
Apr 23 10:17:24.659: INFO: Deleting pod "pod-subpath-test-secret-mtz4" in namespace "subpath-9430"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:17:24.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9430" for this suite.
Apr 23 10:17:30.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:17:30.763: INFO: namespace subpath-9430 deletion completed in 6.098022829s

• [SLOW TEST:30.260 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:17:30.764: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 23 10:17:30.809: INFO: Waiting up to 5m0s for pod "var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d" in namespace "var-expansion-7526" to be "success or failure"
Apr 23 10:17:30.812: INFO: Pod "var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.952603ms
Apr 23 10:17:32.816: INFO: Pod "var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006605904s
Apr 23 10:17:34.820: INFO: Pod "var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010363719s
STEP: Saw pod success
Apr 23 10:17:34.820: INFO: Pod "var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:17:34.822: INFO: Trying to get logs from node net1a83gn1-worker-1 pod var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d container dapi-container: <nil>
STEP: delete the pod
Apr 23 10:17:34.850: INFO: Waiting for pod var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d to disappear
Apr 23 10:17:34.853: INFO: Pod var-expansion-00c4eed1-65b1-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:17:34.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7526" for this suite.
Apr 23 10:17:40.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:17:40.960: INFO: namespace var-expansion-7526 deletion completed in 6.102936473s

• [SLOW TEST:10.196 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:17:40.960: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4593
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4593
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4593
Apr 23 10:17:41.012: INFO: Found 0 stateful pods, waiting for 1
Apr 23 10:17:51.016: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 23 10:17:51.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 10:17:51.281: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 10:17:51.281: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 10:17:51.281: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 10:17:51.285: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 23 10:18:01.289: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 10:18:01.289: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 10:18:01.302: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999717s
Apr 23 10:18:02.306: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997070473s
Apr 23 10:18:03.310: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993155702s
Apr 23 10:18:04.314: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988807586s
Apr 23 10:18:05.318: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98469261s
Apr 23 10:18:06.322: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.980868279s
Apr 23 10:18:07.326: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977161926s
Apr 23 10:18:08.330: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97306004s
Apr 23 10:18:09.334: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96901331s
Apr 23 10:18:10.338: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.780173ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4593
Apr 23 10:18:11.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 10:18:11.614: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 10:18:11.614: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 10:18:11.614: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 10:18:11.618: INFO: Found 1 stateful pods, waiting for 3
Apr 23 10:18:21.622: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:18:21.622: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 10:18:21.622: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 23 10:18:21.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 10:18:21.904: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 10:18:21.904: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 10:18:21.904: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 10:18:21.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 10:18:22.195: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 10:18:22.195: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 10:18:22.195: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 10:18:22.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 23 10:18:22.493: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 23 10:18:22.493: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 23 10:18:22.493: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 23 10:18:22.493: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 10:18:22.496: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 23 10:18:32.503: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 10:18:32.503: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 10:18:32.503: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 10:18:32.513: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999622s
Apr 23 10:18:33.518: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996973528s
Apr 23 10:18:34.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992263012s
Apr 23 10:18:35.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988026179s
Apr 23 10:18:36.531: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98369721s
Apr 23 10:18:37.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979519032s
Apr 23 10:18:38.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974810401s
Apr 23 10:18:39.543: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970789222s
Apr 23 10:18:40.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967385958s
Apr 23 10:18:41.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.715067ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4593
Apr 23 10:18:42.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 10:18:42.839: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 10:18:42.839: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 10:18:42.839: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 10:18:42.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 10:18:43.122: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 10:18:43.122: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 10:18:43.122: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 10:18:43.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 exec --namespace=statefulset-4593 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 23 10:18:43.386: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 23 10:18:43.386: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 23 10:18:43.386: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 23 10:18:43.386: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 23 10:19:23.400: INFO: Deleting all statefulset in ns statefulset-4593
Apr 23 10:19:23.403: INFO: Scaling statefulset ss to 0
Apr 23 10:19:23.411: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 10:19:23.413: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:19:23.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4593" for this suite.
Apr 23 10:19:29.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:19:29.539: INFO: namespace statefulset-4593 deletion completed in 6.103261129s

• [SLOW TEST:108.579 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:19:29.539: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-4790f1e7-65b1-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:19:29.593: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d" in namespace "projected-2769" to be "success or failure"
Apr 23 10:19:29.598: INFO: Pod "pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.805746ms
Apr 23 10:19:31.602: INFO: Pod "pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009807698s
Apr 23 10:19:33.606: INFO: Pod "pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013753883s
STEP: Saw pod success
Apr 23 10:19:33.606: INFO: Pod "pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:19:33.609: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:19:33.630: INFO: Waiting for pod pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d to disappear
Apr 23 10:19:33.634: INFO: Pod pod-projected-secrets-47919063-65b1-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:19:33.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2769" for this suite.
Apr 23 10:19:39.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:19:39.741: INFO: namespace projected-2769 deletion completed in 6.102045319s

• [SLOW TEST:10.202 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:19:39.741: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4da4838f-65b1-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume configMaps
Apr 23 10:19:39.788: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d" in namespace "projected-7232" to be "success or failure"
Apr 23 10:19:39.793: INFO: Pod "pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316748ms
Apr 23 10:19:41.797: INFO: Pod "pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009210671s
Apr 23 10:19:43.801: INFO: Pod "pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013132647s
STEP: Saw pod success
Apr 23 10:19:43.801: INFO: Pod "pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:19:43.803: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 23 10:19:43.828: INFO: Waiting for pod pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d to disappear
Apr 23 10:19:43.831: INFO: Pod pod-projected-configmaps-4da53eea-65b1-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:19:43.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7232" for this suite.
Apr 23 10:19:49.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:19:49.938: INFO: namespace projected-7232 deletion completed in 6.102690212s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:19:49.938: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:19:49.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 version --client'
Apr 23 10:19:50.035: INFO: stderr: ""
Apr 23 10:19:50.035: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 23 10:19:50.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-6527'
Apr 23 10:19:50.562: INFO: stderr: ""
Apr 23 10:19:50.562: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 23 10:19:50.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 create -f - --namespace=kubectl-6527'
Apr 23 10:19:50.747: INFO: stderr: ""
Apr 23 10:19:50.747: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 23 10:19:51.751: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 10:19:51.751: INFO: Found 0 / 1
Apr 23 10:19:52.751: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 10:19:52.751: INFO: Found 0 / 1
Apr 23 10:19:53.752: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 10:19:53.752: INFO: Found 1 / 1
Apr 23 10:19:53.752: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 23 10:19:53.755: INFO: Selector matched 1 pods for map[app:redis]
Apr 23 10:19:53.755: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 10:19:53.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 describe pod redis-master-mm79n --namespace=kubectl-6527'
Apr 23 10:19:53.844: INFO: stderr: ""
Apr 23 10:19:53.844: INFO: stdout: "Name:               redis-master-mm79n\nNamespace:          kubectl-6527\nPriority:           0\nPriorityClassName:  <none>\nNode:               net1a83gn1-worker-1/10.138.15.219\nStart Time:         Tue, 23 Apr 2019 10:19:50 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.2.1.171/32\nStatus:             Running\nIP:                 10.2.1.171\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1179bd7439e57733cc6b569f8c9de4c0dbe9ac6651829c8420da4718eb4a4d2d\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 23 Apr 2019 10:19:53 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4zrgz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-4zrgz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4zrgz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                          Message\n  ----    ------     ----  ----                          -------\n  Normal  Scheduled  3s    default-scheduler             Successfully assigned kubectl-6527/redis-master-mm79n to net1a83gn1-worker-1\n  Normal  Pulled     1s    kubelet, net1a83gn1-worker-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, net1a83gn1-worker-1  Created container redis-master\n  Normal  Started    0s    kubelet, net1a83gn1-worker-1  Started container redis-master\n"
Apr 23 10:19:53.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 describe rc redis-master --namespace=kubectl-6527'
Apr 23 10:19:53.944: INFO: stderr: ""
Apr 23 10:19:53.944: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6527\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-mm79n\n"
Apr 23 10:19:53.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 describe service redis-master --namespace=kubectl-6527'
Apr 23 10:19:54.029: INFO: stderr: ""
Apr 23 10:19:54.029: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6527\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.0.13\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.1.171:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 23 10:19:54.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 describe node net1a83gn1-master-1'
Apr 23 10:19:54.140: INFO: stderr: ""
Apr 23 10:19:54.140: INFO: stdout: "Name:               net1a83gn1-master-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west1\n                    failure-domain.beta.kubernetes.io/zone=us-west1-a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=net1a83gn1-master-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    stackpoint.io/cluster_id=6374\n                    stackpoint.io/instance_id=net1a83gn1-master-1\n                    stackpoint.io/node_group=\n                    stackpoint.io/node_id=20282\n                    stackpoint.io/node_pool=\n                    stackpoint.io/private_ip=10.138.15.218\n                    stackpoint.io/role=master\n                    stackpoint.io/size=n1-standard-2\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.138.15.218/32\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 23 Apr 2019 08:44:26 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 23 Apr 2019 10:19:23 +0000   Tue, 23 Apr 2019 10:19:23 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 23 Apr 2019 10:19:03 +0000   Tue, 23 Apr 2019 08:44:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 23 Apr 2019 10:19:03 +0000   Tue, 23 Apr 2019 08:44:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 23 Apr 2019 10:19:03 +0000   Tue, 23 Apr 2019 08:44:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 23 Apr 2019 10:19:03 +0000   Tue, 23 Apr 2019 08:45:16 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.138.15.218\n  ExternalIP:   35.233.213.233\n  InternalDNS:  net1a83gn1-master-1.c.hello-reykjavik.internal\n  Hostname:     net1a83gn1-master-1\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        2\n ephemeral-storage:          50758760Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7473Mi\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        2\n ephemeral-storage:          46779273139\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7373Mi\n pods:                       110\nSystem Info:\n Machine ID:                 4919c6a25217da9536af184cede121bf\n System UUID:                4919C6A2-5217-DA95-36AF-184CEDE121BF\n Boot ID:                    15dfb84c-b2cb-4eac-ba95-2250f1a121f6\n Kernel Version:             4.15.0-1029-gcp\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.4\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     10.2.0.0/24\nProviderID:                  gce://hello-reykjavik/us-west1-a/net1a83gn1-master-1\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8336f57400ec47e0-x6hpj    0 (0%)        0 (0%)      0 (0%)           0 (0%)         88m\n  kube-system                calico-node-7j4kp                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                coredns-fb8b8dccf-6hg6g                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     95m\n  kube-system                coredns-fb8b8dccf-9bxzl                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     95m\n  kube-system                dashboard-proxy-55f955c8b4-dps5f                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                kube-apiserver-net1a83gn1-master-1                         250m (12%)    0 (0%)      0 (0%)           0 (0%)         94m\n  kube-system                kube-controller-manager-net1a83gn1-master-1                200m (10%)    0 (0%)      0 (0%)           0 (0%)         94m\n  kube-system                kube-proxy-gdp7k                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                kube-scheduler-net1a83gn1-master-1                         100m (5%)     0 (0%)      0 (0%)           0 (0%)         94m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        1 (50%)     0 (0%)\n  memory                     140Mi (1%)  340Mi (4%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
Apr 23 10:19:54.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994727835 describe namespace kubectl-6527'
Apr 23 10:19:54.227: INFO: stderr: ""
Apr 23 10:19:54.227: INFO: stdout: "Name:         kubectl-6527\nLabels:       e2e-framework=kubectl\n              e2e-run=0e303eb1-65a5-11e9-b8ea-e2349624188d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:19:54.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6527" for this suite.
Apr 23 10:20:16.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:20:16.340: INFO: namespace kubectl-6527 deletion completed in 22.109468418s

• [SLOW TEST:26.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:20:16.340: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-637d31f0-65b1-11e9-b8ea-e2349624188d
STEP: Creating a pod to test consume secrets
Apr 23 10:20:16.438: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d" in namespace "projected-6925" to be "success or failure"
Apr 23 10:20:16.446: INFO: Pod "pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.860184ms
Apr 23 10:20:18.450: INFO: Pod "pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011727697s
Apr 23 10:20:20.454: INFO: Pod "pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015652828s
STEP: Saw pod success
Apr 23 10:20:20.454: INFO: Pod "pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:20:20.457: INFO: Trying to get logs from node net1a83gn1-worker-3 pod pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 23 10:20:20.479: INFO: Waiting for pod pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d to disappear
Apr 23 10:20:20.481: INFO: Pod pod-projected-secrets-637dc636-65b1-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:20:20.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6925" for this suite.
Apr 23 10:20:26.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:20:26.588: INFO: namespace projected-6925 deletion completed in 6.102694697s

• [SLOW TEST:10.248 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:20:26.589: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 23 10:20:26.632: INFO: Waiting up to 5m0s for pod "pod-69915334-65b1-11e9-b8ea-e2349624188d" in namespace "emptydir-2983" to be "success or failure"
Apr 23 10:20:26.634: INFO: Pod "pod-69915334-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.398978ms
Apr 23 10:20:28.639: INFO: Pod "pod-69915334-65b1-11e9-b8ea-e2349624188d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006959931s
Apr 23 10:20:30.643: INFO: Pod "pod-69915334-65b1-11e9-b8ea-e2349624188d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010973176s
STEP: Saw pod success
Apr 23 10:20:30.643: INFO: Pod "pod-69915334-65b1-11e9-b8ea-e2349624188d" satisfied condition "success or failure"
Apr 23 10:20:30.646: INFO: Trying to get logs from node net1a83gn1-worker-1 pod pod-69915334-65b1-11e9-b8ea-e2349624188d container test-container: <nil>
STEP: delete the pod
Apr 23 10:20:30.668: INFO: Waiting for pod pod-69915334-65b1-11e9-b8ea-e2349624188d to disappear
Apr 23 10:20:30.670: INFO: Pod pod-69915334-65b1-11e9-b8ea-e2349624188d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:20:30.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2983" for this suite.
Apr 23 10:20:36.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:20:36.774: INFO: namespace emptydir-2983 deletion completed in 6.099245416s

• [SLOW TEST:10.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:20:36.774: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2331.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2331.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2331.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2331.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 254.0.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.0.254_udp@PTR;check="$$(dig +tcp +noall +answer +search 254.0.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.0.254_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2331.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2331.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2331.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2331.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2331.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2331.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 254.0.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.0.254_udp@PTR;check="$$(dig +tcp +noall +answer +search 254.0.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.0.254_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 23 10:20:40.867: INFO: Unable to read wheezy_udp@dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.870: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.872: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.875: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.896: INFO: Unable to read jessie_udp@dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.898: INFO: Unable to read jessie_tcp@dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.901: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.903: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local from pod dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d: the server could not find the requested resource (get pods dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d)
Apr 23 10:20:40.919: INFO: Lookups using dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d failed for: [wheezy_udp@dns-test-service.dns-2331.svc.cluster.local wheezy_tcp@dns-test-service.dns-2331.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local jessie_udp@dns-test-service.dns-2331.svc.cluster.local jessie_tcp@dns-test-service.dns-2331.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2331.svc.cluster.local]

Apr 23 10:20:45.979: INFO: DNS probes using dns-2331/dns-test-6fa75e0b-65b1-11e9-b8ea-e2349624188d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:20:46.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2331" for this suite.
Apr 23 10:20:52.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:20:52.205: INFO: namespace dns-2331 deletion completed in 6.098136048s

• [SLOW TEST:15.432 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:20:52.205: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 23 10:20:52.271: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 23 10:20:52.282: INFO: Number of nodes with available pods: 0
Apr 23 10:20:52.282: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 23 10:20:52.310: INFO: Number of nodes with available pods: 0
Apr 23 10:20:52.310: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:53.314: INFO: Number of nodes with available pods: 0
Apr 23 10:20:53.314: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:54.315: INFO: Number of nodes with available pods: 0
Apr 23 10:20:54.315: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:55.314: INFO: Number of nodes with available pods: 1
Apr 23 10:20:55.314: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 23 10:20:55.338: INFO: Number of nodes with available pods: 1
Apr 23 10:20:55.338: INFO: Number of running nodes: 0, number of available pods: 1
Apr 23 10:20:56.342: INFO: Number of nodes with available pods: 0
Apr 23 10:20:56.342: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 23 10:20:56.352: INFO: Number of nodes with available pods: 0
Apr 23 10:20:56.352: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:57.356: INFO: Number of nodes with available pods: 0
Apr 23 10:20:57.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:58.356: INFO: Number of nodes with available pods: 0
Apr 23 10:20:58.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:20:59.356: INFO: Number of nodes with available pods: 0
Apr 23 10:20:59.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:00.356: INFO: Number of nodes with available pods: 0
Apr 23 10:21:00.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:01.356: INFO: Number of nodes with available pods: 0
Apr 23 10:21:01.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:02.356: INFO: Number of nodes with available pods: 0
Apr 23 10:21:02.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:03.359: INFO: Number of nodes with available pods: 0
Apr 23 10:21:03.359: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:04.356: INFO: Number of nodes with available pods: 0
Apr 23 10:21:04.357: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:05.356: INFO: Number of nodes with available pods: 0
Apr 23 10:21:05.356: INFO: Node net1a83gn1-worker-1 is running more than one daemon pod
Apr 23 10:21:06.356: INFO: Number of nodes with available pods: 1
Apr 23 10:21:06.356: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2758, will wait for the garbage collector to delete the pods
Apr 23 10:21:06.426: INFO: Deleting DaemonSet.extensions daemon-set took: 9.395689ms
Apr 23 10:21:06.726: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.451181ms
Apr 23 10:21:09.630: INFO: Number of nodes with available pods: 0
Apr 23 10:21:09.630: INFO: Number of running nodes: 0, number of available pods: 0
Apr 23 10:21:09.634: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2758/daemonsets","resourceVersion":"22090"},"items":null}

Apr 23 10:21:09.636: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2758/pods","resourceVersion":"22090"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:21:09.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2758" for this suite.
Apr 23 10:21:15.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:21:15.796: INFO: namespace daemonsets-2758 deletion completed in 6.114878214s

• [SLOW TEST:23.591 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:21:15.796: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 23 10:21:15.834: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:21:19.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3144" for this suite.
Apr 23 10:21:25.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:21:26.091: INFO: namespace init-container-3144 deletion completed in 6.125327387s

• [SLOW TEST:10.294 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 23 10:21:26.091: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8426
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 23 10:21:26.131: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 23 10:21:48.240: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.3.46 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 10:21:48.240: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 10:21:49.442: INFO: Found all expected endpoints: [netserver-0]
Apr 23 10:21:49.445: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.2.131 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 10:21:49.445: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 10:21:50.703: INFO: Found all expected endpoints: [netserver-1]
Apr 23 10:21:50.706: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.1.177 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 23 10:21:50.706: INFO: >>> kubeConfig: /tmp/kubeconfig-994727835
Apr 23 10:21:51.961: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 23 10:21:51.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8426" for this suite.
Apr 23 10:22:13.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 23 10:22:14.080: INFO: namespace pod-network-test-8426 deletion completed in 22.114428223s

• [SLOW TEST:47.989 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSApr 23 10:22:14.080: INFO: Running AfterSuite actions on all nodes
Apr 23 10:22:14.080: INFO: Running AfterSuite actions on node 1
Apr 23 10:22:14.080: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5412.962 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h30m14.8688156s
Test Suite Passed
