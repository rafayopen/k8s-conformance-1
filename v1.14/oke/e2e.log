I1002 21:07:54.598792      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-715202161
I1002 21:07:54.598928      17 e2e.go:240] Starting e2e run "b2e9ea31-e558-11e9-bbfa-0a580af40203" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1570050473 - Will randomize all specs
Will run 204 of 3586 specs

Oct  2 21:07:54.774: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:07:54.780: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct  2 21:07:54.817: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct  2 21:07:54.878: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct  2 21:07:54.878: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Oct  2 21:07:54.878: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct  2 21:07:54.893: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Oct  2 21:07:54.893: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct  2 21:07:54.893: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct  2 21:07:54.893: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin-1-8' (0 seconds elapsed)
Oct  2 21:07:54.893: INFO: e2e test version: v1.14.6
Oct  2 21:07:54.907: INFO: kube-apiserver version: v1.14.6-2+1f1885f7817668
SSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:07:54.907: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
Oct  2 21:07:54.971: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b3e84d7a-e558-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:07:55.069: INFO: Waiting up to 5m0s for pod "pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203" in namespace "secrets-2621" to be "success or failure"
Oct  2 21:07:55.076: INFO: Pod "pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.260833ms
Oct  2 21:07:57.097: INFO: Pod "pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02858619s
Oct  2 21:07:59.105: INFO: Pod "pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035853921s
STEP: Saw pod success
Oct  2 21:07:59.105: INFO: Pod "pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:07:59.111: INFO: Trying to get logs from node 10.0.10.4 pod pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:07:59.247: INFO: Waiting for pod pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:07:59.253: INFO: Pod pod-secrets-b3f4b6e9-e558-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:07:59.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2621" for this suite.
Oct  2 21:08:05.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:08:05.583: INFO: namespace secrets-2621 deletion completed in 6.324112518s
STEP: Destroying namespace "secret-namespace-2371" for this suite.
Oct  2 21:08:11.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:08:11.838: INFO: namespace secret-namespace-2371 deletion completed in 6.254287387s

• [SLOW TEST:16.931 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:08:11.838: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 21:08:11.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6886'
Oct  2 21:08:12.185: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  2 21:08:12.185: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct  2 21:08:12.212: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-vwfjc]
Oct  2 21:08:12.212: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-vwfjc" in namespace "kubectl-6886" to be "running and ready"
Oct  2 21:08:12.219: INFO: Pod "e2e-test-nginx-rc-vwfjc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.653819ms
Oct  2 21:08:14.226: INFO: Pod "e2e-test-nginx-rc-vwfjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014548277s
Oct  2 21:08:16.234: INFO: Pod "e2e-test-nginx-rc-vwfjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022171324s
Oct  2 21:08:18.241: INFO: Pod "e2e-test-nginx-rc-vwfjc": Phase="Running", Reason="", readiness=true. Elapsed: 6.02981614s
Oct  2 21:08:18.242: INFO: Pod "e2e-test-nginx-rc-vwfjc" satisfied condition "running and ready"
Oct  2 21:08:18.242: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-vwfjc]
Oct  2 21:08:18.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 logs rc/e2e-test-nginx-rc --namespace=kubectl-6886'
Oct  2 21:08:18.510: INFO: stderr: ""
Oct  2 21:08:18.510: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Oct  2 21:08:18.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete rc e2e-test-nginx-rc --namespace=kubectl-6886'
Oct  2 21:08:18.615: INFO: stderr: ""
Oct  2 21:08:18.616: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:08:18.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6886" for this suite.
Oct  2 21:08:24.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:08:24.898: INFO: namespace kubectl-6886 deletion completed in 6.275391078s

• [SLOW TEST:13.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:08:24.899: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct  2 21:08:32.042: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:08:33.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3861" for this suite.
Oct  2 21:08:57.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:08:57.336: INFO: namespace replicaset-3861 deletion completed in 24.253206524s

• [SLOW TEST:32.438 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:08:57.337: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 21:08:57.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9603'
Oct  2 21:08:57.511: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  2 21:08:57.511: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct  2 21:08:57.523: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct  2 21:08:57.523: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct  2 21:08:57.532: INFO: scanned /root for discovery docs: <nil>
Oct  2 21:08:57.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9603'
Oct  2 21:09:13.413: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  2 21:09:13.413: INFO: stdout: "Created e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281\nScaling up e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct  2 21:09:13.413: INFO: stdout: "Created e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281\nScaling up e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct  2 21:09:13.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9603'
Oct  2 21:09:13.527: INFO: stderr: ""
Oct  2 21:09:13.527: INFO: stdout: "e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281-s78wv "
Oct  2 21:09:13.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281-s78wv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9603'
Oct  2 21:09:13.648: INFO: stderr: ""
Oct  2 21:09:13.648: INFO: stdout: "true"
Oct  2 21:09:13.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281-s78wv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9603'
Oct  2 21:09:13.778: INFO: stderr: ""
Oct  2 21:09:13.778: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct  2 21:09:13.779: INFO: e2e-test-nginx-rc-176b6a9558ce4f5bca27d2a5ae9c6281-s78wv is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Oct  2 21:09:13.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete rc e2e-test-nginx-rc --namespace=kubectl-9603'
Oct  2 21:09:13.894: INFO: stderr: ""
Oct  2 21:09:13.894: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:09:13.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9603" for this suite.
Oct  2 21:09:37.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:09:38.153: INFO: namespace kubectl-9603 deletion completed in 24.245989481s

• [SLOW TEST:40.817 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:09:38.153: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6583/configmap-test-f1716678-e558-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:09:38.239: INFO: Waiting up to 5m0s for pod "pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203" in namespace "configmap-6583" to be "success or failure"
Oct  2 21:09:38.246: INFO: Pod "pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.528689ms
Oct  2 21:09:40.254: INFO: Pod "pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014717954s
STEP: Saw pod success
Oct  2 21:09:40.254: INFO: Pod "pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:09:40.261: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203 container env-test: <nil>
STEP: delete the pod
Oct  2 21:09:40.340: INFO: Waiting for pod pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:09:40.347: INFO: Pod pod-configmaps-f1734ac8-e558-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:09:40.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6583" for this suite.
Oct  2 21:09:46.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:09:46.601: INFO: namespace configmap-6583 deletion completed in 6.246936434s

• [SLOW TEST:8.447 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:09:46.602: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 21:09:46.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1462'
Oct  2 21:09:46.781: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  2 21:09:46.781: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Oct  2 21:09:48.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1462'
Oct  2 21:09:48.953: INFO: stderr: ""
Oct  2 21:09:48.953: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:09:48.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1462" for this suite.
Oct  2 21:10:10.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:10:11.226: INFO: namespace kubectl-1462 deletion completed in 22.265403278s

• [SLOW TEST:24.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:10:11.226: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-05280638-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:10:11.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203" in namespace "configmap-536" to be "success or failure"
Oct  2 21:10:11.321: INFO: Pod "pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.094335ms
Oct  2 21:10:13.328: INFO: Pod "pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014454367s
Oct  2 21:10:15.334: INFO: Pod "pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0208316s
STEP: Saw pod success
Oct  2 21:10:15.334: INFO: Pod "pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:10:15.340: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:10:15.427: INFO: Waiting for pod pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:10:15.433: INFO: Pod pod-configmaps-052a01bc-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:10:15.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-536" for this suite.
Oct  2 21:10:21.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:10:21.695: INFO: namespace configmap-536 deletion completed in 6.256405044s

• [SLOW TEST:10.469 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:10:21.696: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  2 21:10:29.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  2 21:10:29.843: INFO: Pod pod-with-prestop-http-hook still exists
Oct  2 21:10:31.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  2 21:10:31.850: INFO: Pod pod-with-prestop-http-hook still exists
Oct  2 21:10:33.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  2 21:10:33.849: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:10:34.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9553" for this suite.
Oct  2 21:10:58.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:10:58.320: INFO: namespace container-lifecycle-hook-9553 deletion completed in 24.312825696s

• [SLOW TEST:36.624 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:10:58.321: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-2139ce3e-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:10:58.406: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203" in namespace "projected-5123" to be "success or failure"
Oct  2 21:10:58.416: INFO: Pod "pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143354ms
Oct  2 21:11:00.424: INFO: Pod "pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018052618s
Oct  2 21:11:02.432: INFO: Pod "pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025573471s
STEP: Saw pod success
Oct  2 21:11:02.432: INFO: Pod "pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:11:02.438: INFO: Trying to get logs from node 10.0.10.3 pod pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:11:02.509: INFO: Waiting for pod pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:11:02.515: INFO: Pod pod-projected-configmaps-213bd65d-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:11:02.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5123" for this suite.
Oct  2 21:11:08.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:11:08.832: INFO: namespace projected-5123 deletion completed in 6.310858905s

• [SLOW TEST:10.511 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:11:08.832: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Oct  2 21:11:09.406: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct  2 21:11:11.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:11:13.513: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:11:15.513: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705647469, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:11:20.341: INFO: Waited 2.818081254s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:11:20.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5359" for this suite.
Oct  2 21:11:26.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:11:27.071: INFO: namespace aggregator-5359 deletion completed in 6.26721794s

• [SLOW TEST:18.239 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:11:27.072: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Oct  2 21:11:27.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-6307'
Oct  2 21:11:27.510: INFO: stderr: ""
Oct  2 21:11:27.510: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:11:27.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6307'
Oct  2 21:11:27.673: INFO: stderr: ""
Oct  2 21:11:27.673: INFO: stdout: "update-demo-nautilus-8pbj5 update-demo-nautilus-wmdxn "
Oct  2 21:11:27.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-8pbj5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:11:27.821: INFO: stderr: ""
Oct  2 21:11:27.821: INFO: stdout: ""
Oct  2 21:11:27.821: INFO: update-demo-nautilus-8pbj5 is created but not running
Oct  2 21:11:32.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6307'
Oct  2 21:11:32.926: INFO: stderr: ""
Oct  2 21:11:32.926: INFO: stdout: "update-demo-nautilus-8pbj5 update-demo-nautilus-wmdxn "
Oct  2 21:11:32.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-8pbj5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:11:33.042: INFO: stderr: ""
Oct  2 21:11:33.042: INFO: stdout: "true"
Oct  2 21:11:33.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-8pbj5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:11:33.146: INFO: stderr: ""
Oct  2 21:11:33.146: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:11:33.146: INFO: validating pod update-demo-nautilus-8pbj5
Oct  2 21:11:33.289: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:11:33.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:11:33.289: INFO: update-demo-nautilus-8pbj5 is verified up and running
Oct  2 21:11:33.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-wmdxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:11:33.427: INFO: stderr: ""
Oct  2 21:11:33.427: INFO: stdout: "true"
Oct  2 21:11:33.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-wmdxn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:11:33.566: INFO: stderr: ""
Oct  2 21:11:33.566: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:11:33.566: INFO: validating pod update-demo-nautilus-wmdxn
Oct  2 21:11:33.722: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:11:33.722: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:11:33.723: INFO: update-demo-nautilus-wmdxn is verified up and running
STEP: rolling-update to new replication controller
Oct  2 21:11:33.724: INFO: scanned /root for discovery docs: <nil>
Oct  2 21:11:33.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6307'
Oct  2 21:11:56.404: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  2 21:11:56.405: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:11:56.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6307'
Oct  2 21:11:56.520: INFO: stderr: ""
Oct  2 21:11:56.520: INFO: stdout: "update-demo-kitten-cd4k6 update-demo-kitten-wvrlk update-demo-nautilus-wmdxn "
STEP: Replicas for name=update-demo: expected=2 actual=3
Oct  2 21:12:01.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6307'
Oct  2 21:12:01.636: INFO: stderr: ""
Oct  2 21:12:01.636: INFO: stdout: "update-demo-kitten-cd4k6 update-demo-kitten-wvrlk "
Oct  2 21:12:01.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-kitten-cd4k6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:12:01.770: INFO: stderr: ""
Oct  2 21:12:01.770: INFO: stdout: "true"
Oct  2 21:12:01.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-kitten-cd4k6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:12:01.884: INFO: stderr: ""
Oct  2 21:12:01.884: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  2 21:12:01.884: INFO: validating pod update-demo-kitten-cd4k6
Oct  2 21:12:01.991: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  2 21:12:01.991: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  2 21:12:01.992: INFO: update-demo-kitten-cd4k6 is verified up and running
Oct  2 21:12:01.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-kitten-wvrlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:12:02.107: INFO: stderr: ""
Oct  2 21:12:02.107: INFO: stdout: "true"
Oct  2 21:12:02.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-kitten-wvrlk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6307'
Oct  2 21:12:02.231: INFO: stderr: ""
Oct  2 21:12:02.231: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  2 21:12:02.231: INFO: validating pod update-demo-kitten-wvrlk
Oct  2 21:12:02.410: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  2 21:12:02.410: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  2 21:12:02.410: INFO: update-demo-kitten-wvrlk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:12:02.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6307" for this suite.
Oct  2 21:12:26.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:12:26.702: INFO: namespace kubectl-6307 deletion completed in 24.281443082s

• [SLOW TEST:59.630 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:12:26.703: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-55ea7414-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:12:26.812: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203" in namespace "projected-3444" to be "success or failure"
Oct  2 21:12:26.818: INFO: Pod "pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.208679ms
Oct  2 21:12:28.825: INFO: Pod "pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013089178s
Oct  2 21:12:30.832: INFO: Pod "pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019779518s
STEP: Saw pod success
Oct  2 21:12:30.832: INFO: Pod "pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:12:30.837: INFO: Trying to get logs from node 10.0.10.3 pod pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:12:30.876: INFO: Waiting for pod pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:12:30.889: INFO: Pod pod-projected-configmaps-55ed2137-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:12:30.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3444" for this suite.
Oct  2 21:12:36.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:12:37.178: INFO: namespace projected-3444 deletion completed in 6.282271639s

• [SLOW TEST:10.475 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:12:37.178: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:12:39.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9189" for this suite.
Oct  2 21:13:19.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:13:19.728: INFO: namespace kubelet-test-9189 deletion completed in 40.397736375s

• [SLOW TEST:42.550 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:13:19.728: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-75828af7-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:13:19.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203" in namespace "configmap-5996" to be "success or failure"
Oct  2 21:13:19.820: INFO: Pod "pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.517747ms
Oct  2 21:13:21.827: INFO: Pod "pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015631507s
STEP: Saw pod success
Oct  2 21:13:21.827: INFO: Pod "pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:13:21.833: INFO: Trying to get logs from node 10.0.10.3 pod pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:13:21.889: INFO: Waiting for pod pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:13:21.896: INFO: Pod pod-configmaps-758468a8-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:13:21.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5996" for this suite.
Oct  2 21:13:27.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:13:28.133: INFO: namespace configmap-5996 deletion completed in 6.230293568s

• [SLOW TEST:8.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:13:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:13:28.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203" in namespace "projected-6282" to be "success or failure"
Oct  2 21:13:28.246: INFO: Pod "downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 19.532015ms
Oct  2 21:13:30.254: INFO: Pod "downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027398057s
STEP: Saw pod success
Oct  2 21:13:30.254: INFO: Pod "downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:13:30.260: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:13:30.301: INFO: Waiting for pod downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:13:30.308: INFO: Pod downwardapi-volume-7a8830ad-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:13:30.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6282" for this suite.
Oct  2 21:13:36.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:13:36.557: INFO: namespace projected-6282 deletion completed in 6.242836238s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:13:36.558: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  2 21:13:36.646: INFO: Waiting up to 5m0s for pod "pod-7f8cc786-e559-11e9-bbfa-0a580af40203" in namespace "emptydir-3045" to be "success or failure"
Oct  2 21:13:36.653: INFO: Pod "pod-7f8cc786-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.810577ms
Oct  2 21:13:38.659: INFO: Pod "pod-7f8cc786-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013218694s
STEP: Saw pod success
Oct  2 21:13:38.660: INFO: Pod "pod-7f8cc786-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:13:38.665: INFO: Trying to get logs from node 10.0.10.3 pod pod-7f8cc786-e559-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:13:38.811: INFO: Waiting for pod pod-7f8cc786-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:13:38.817: INFO: Pod pod-7f8cc786-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:13:38.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3045" for this suite.
Oct  2 21:13:44.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:13:45.071: INFO: namespace emptydir-3045 deletion completed in 6.247854994s

• [SLOW TEST:8.513 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:13:45.071: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-849fa31b-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:13:45.166: INFO: Waiting up to 5m0s for pod "pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203" in namespace "configmap-3956" to be "success or failure"
Oct  2 21:13:45.173: INFO: Pod "pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.28502ms
Oct  2 21:13:47.180: INFO: Pod "pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014806555s
STEP: Saw pod success
Oct  2 21:13:47.180: INFO: Pod "pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:13:47.190: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:13:47.232: INFO: Waiting for pod pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:13:47.238: INFO: Pod pod-configmaps-84a16f61-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:13:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3956" for this suite.
Oct  2 21:13:53.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:13:53.498: INFO: namespace configmap-3956 deletion completed in 6.253485977s

• [SLOW TEST:8.427 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:13:53.499: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct  2 21:13:53.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-3456'
Oct  2 21:13:53.875: INFO: stderr: ""
Oct  2 21:13:53.875: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:13:53.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3456'
Oct  2 21:13:54.003: INFO: stderr: ""
Oct  2 21:13:54.003: INFO: stdout: "update-demo-nautilus-mp4v2 update-demo-nautilus-xtqjw "
Oct  2 21:13:54.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-mp4v2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3456'
Oct  2 21:13:54.135: INFO: stderr: ""
Oct  2 21:13:54.135: INFO: stdout: ""
Oct  2 21:13:54.135: INFO: update-demo-nautilus-mp4v2 is created but not running
Oct  2 21:13:59.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3456'
Oct  2 21:13:59.292: INFO: stderr: ""
Oct  2 21:13:59.292: INFO: stdout: "update-demo-nautilus-mp4v2 update-demo-nautilus-xtqjw "
Oct  2 21:13:59.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-mp4v2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3456'
Oct  2 21:13:59.430: INFO: stderr: ""
Oct  2 21:13:59.430: INFO: stdout: "true"
Oct  2 21:13:59.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-mp4v2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3456'
Oct  2 21:13:59.546: INFO: stderr: ""
Oct  2 21:13:59.546: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:13:59.546: INFO: validating pod update-demo-nautilus-mp4v2
Oct  2 21:13:59.711: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:13:59.711: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:13:59.711: INFO: update-demo-nautilus-mp4v2 is verified up and running
Oct  2 21:13:59.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-xtqjw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3456'
Oct  2 21:13:59.825: INFO: stderr: ""
Oct  2 21:13:59.825: INFO: stdout: "true"
Oct  2 21:13:59.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-xtqjw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3456'
Oct  2 21:13:59.942: INFO: stderr: ""
Oct  2 21:13:59.942: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:13:59.942: INFO: validating pod update-demo-nautilus-xtqjw
Oct  2 21:14:00.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:14:00.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:14:00.109: INFO: update-demo-nautilus-xtqjw is verified up and running
STEP: using delete to clean up resources
Oct  2 21:14:00.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-3456'
Oct  2 21:14:00.228: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:14:00.228: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  2 21:14:00.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3456'
Oct  2 21:14:00.371: INFO: stderr: "No resources found.\n"
Oct  2 21:14:00.371: INFO: stdout: ""
Oct  2 21:14:00.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -l name=update-demo --namespace=kubectl-3456 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  2 21:14:00.499: INFO: stderr: ""
Oct  2 21:14:00.499: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:14:00.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3456" for this suite.
Oct  2 21:14:24.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:14:24.738: INFO: namespace kubectl-3456 deletion completed in 24.232059834s

• [SLOW TEST:31.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:14:24.738: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9c4527d6-e559-11e9-bbfa-0a580af40203
STEP: Creating configMap with name cm-test-opt-upd-9c452818-e559-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9c4527d6-e559-11e9-bbfa-0a580af40203
STEP: Updating configmap cm-test-opt-upd-9c452818-e559-11e9-bbfa-0a580af40203
STEP: Creating configMap with name cm-test-opt-create-9c452842-e559-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:14:29.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5836" for this suite.
Oct  2 21:14:53.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:14:53.410: INFO: namespace configmap-5836 deletion completed in 24.278279371s

• [SLOW TEST:28.672 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:14:53.412: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 21:14:53.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6519'
Oct  2 21:14:53.600: INFO: stderr: ""
Oct  2 21:14:53.600: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct  2 21:14:58.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pod e2e-test-nginx-pod --namespace=kubectl-6519 -o json'
Oct  2 21:14:58.757: INFO: stderr: ""
Oct  2 21:14:58.757: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-10-02T21:14:53Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6519\",\n        \"resourceVersion\": \"5403\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6519/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ad69c58f-e559-11e9-884c-0a580aed1ab9\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gs8d2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.10.4\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gs8d2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gs8d2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-02T21:14:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-02T21:14:54Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-02T21:14:54Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-02T21:14:53Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://47fe15c75aa59bdfe95f835e6fcb21f3dd503ccc3299f532742b0d1741d99ad0\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-02T21:14:54Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.10.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.16\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-02T21:14:53Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct  2 21:14:58.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 replace -f - --namespace=kubectl-6519'
Oct  2 21:14:59.109: INFO: stderr: ""
Oct  2 21:14:59.109: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct  2 21:14:59.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete pods e2e-test-nginx-pod --namespace=kubectl-6519'
Oct  2 21:15:00.999: INFO: stderr: ""
Oct  2 21:15:00.999: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:15:00.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6519" for this suite.
Oct  2 21:15:07.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:15:07.257: INFO: namespace kubectl-6519 deletion completed in 6.250368155s

• [SLOW TEST:13.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:15:07.257: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  2 21:15:07.358: INFO: Waiting up to 5m0s for pod "pod-b59d0f25-e559-11e9-bbfa-0a580af40203" in namespace "emptydir-2077" to be "success or failure"
Oct  2 21:15:07.365: INFO: Pod "pod-b59d0f25-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.700883ms
Oct  2 21:15:09.373: INFO: Pod "pod-b59d0f25-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015444092s
STEP: Saw pod success
Oct  2 21:15:09.373: INFO: Pod "pod-b59d0f25-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:15:09.378: INFO: Trying to get logs from node 10.0.10.3 pod pod-b59d0f25-e559-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:15:09.510: INFO: Waiting for pod pod-b59d0f25-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:15:09.517: INFO: Pod pod-b59d0f25-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:15:09.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2077" for this suite.
Oct  2 21:15:15.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:15:15.827: INFO: namespace emptydir-2077 deletion completed in 6.303458247s

• [SLOW TEST:8.570 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:15:15.827: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  2 21:15:15.894: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:15:19.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-110" for this suite.
Oct  2 21:15:25.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:15:25.456: INFO: namespace init-container-110 deletion completed in 6.261644617s

• [SLOW TEST:9.629 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:15:25.456: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Oct  2 21:15:27.549: INFO: Pod pod-hostip-c072661c-e559-11e9-bbfa-0a580af40203 has hostIP: 10.0.10.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:15:27.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7918" for this suite.
Oct  2 21:15:51.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:15:51.804: INFO: namespace pods-7918 deletion completed in 24.249351139s

• [SLOW TEST:26.348 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:15:51.804: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Oct  2 21:15:51.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 api-versions'
Oct  2 21:15:51.999: INFO: stderr: ""
Oct  2 21:15:51.999: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:15:51.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9207" for this suite.
Oct  2 21:15:58.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:15:58.289: INFO: namespace kubectl-9207 deletion completed in 6.282745488s

• [SLOW TEST:6.485 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:15:58.289: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-8798/secret-test-d405af4a-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:15:58.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203" in namespace "secrets-8798" to be "success or failure"
Oct  2 21:15:58.398: INFO: Pod "pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.368458ms
Oct  2 21:16:00.408: INFO: Pod "pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020274688s
STEP: Saw pod success
Oct  2 21:16:00.408: INFO: Pod "pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:16:00.413: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203 container env-test: <nil>
STEP: delete the pod
Oct  2 21:16:00.528: INFO: Waiting for pod pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:16:00.534: INFO: Pod pod-configmaps-d4084af6-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:16:00.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8798" for this suite.
Oct  2 21:16:06.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:16:06.844: INFO: namespace secrets-8798 deletion completed in 6.303001809s

• [SLOW TEST:8.555 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:16:06.845: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  2 21:16:06.943: INFO: Waiting up to 5m0s for pod "pod-d921aba4-e559-11e9-bbfa-0a580af40203" in namespace "emptydir-3205" to be "success or failure"
Oct  2 21:16:06.954: INFO: Pod "pod-d921aba4-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.382264ms
Oct  2 21:16:08.965: INFO: Pod "pod-d921aba4-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021293488s
Oct  2 21:16:10.972: INFO: Pod "pod-d921aba4-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02837791s
STEP: Saw pod success
Oct  2 21:16:10.972: INFO: Pod "pod-d921aba4-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:16:10.978: INFO: Trying to get logs from node 10.0.10.3 pod pod-d921aba4-e559-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:16:11.013: INFO: Waiting for pod pod-d921aba4-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:16:11.019: INFO: Pod pod-d921aba4-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:16:11.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3205" for this suite.
Oct  2 21:16:17.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:16:17.323: INFO: namespace emptydir-3205 deletion completed in 6.297664116s

• [SLOW TEST:10.478 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:16:17.323: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-df62e63d-e559-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:16:17.440: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203" in namespace "projected-1249" to be "success or failure"
Oct  2 21:16:17.463: INFO: Pod "pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 22.937904ms
Oct  2 21:16:19.470: INFO: Pod "pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029922058s
STEP: Saw pod success
Oct  2 21:16:19.470: INFO: Pod "pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:16:19.476: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:16:19.511: INFO: Waiting for pod pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:16:19.517: INFO: Pod pod-projected-configmaps-df64bfc1-e559-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:16:19.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1249" for this suite.
Oct  2 21:16:25.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:16:25.785: INFO: namespace projected-1249 deletion completed in 6.26122477s

• [SLOW TEST:8.462 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:16:25.786: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Oct  2 21:16:25.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 --namespace=kubectl-3928 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct  2 21:16:28.464: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct  2 21:16:28.464: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:16:30.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3928" for this suite.
Oct  2 21:16:36.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:16:36.738: INFO: namespace kubectl-3928 deletion completed in 6.257857727s

• [SLOW TEST:10.952 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:16:36.738: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:17:02.851: INFO: Container started at 2019-10-02 21:16:38 +0000 UTC, pod became ready at 2019-10-02 21:17:01 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:17:02.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7495" for this suite.
Oct  2 21:17:26.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:17:27.129: INFO: namespace container-probe-7495 deletion completed in 24.272107728s

• [SLOW TEST:50.391 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:17:27.130: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-4270
Oct  2 21:17:29.217: INFO: Started pod liveness-exec in namespace container-probe-4270
STEP: checking the pod's current state and verifying that restartCount is present
Oct  2 21:17:29.222: INFO: Initial restart count of pod liveness-exec is 0
Oct  2 21:18:15.406: INFO: Restart count of pod container-probe-4270/liveness-exec is now 1 (46.184087198s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:18:15.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4270" for this suite.
Oct  2 21:18:21.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:18:21.673: INFO: namespace container-probe-4270 deletion completed in 6.237918822s

• [SLOW TEST:54.543 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:18:21.674: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Oct  2 21:18:21.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 cluster-info'
Oct  2 21:18:21.975: INFO: stderr: ""
Oct  2 21:18:21.975: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:18:21.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6244" for this suite.
Oct  2 21:18:28.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:18:28.223: INFO: namespace kubectl-6244 deletion completed in 6.240506325s

• [SLOW TEST:6.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:18:28.224: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4517
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  2 21:18:28.278: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  2 21:18:54.472: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.7:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4517 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:18:54.472: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:18:54.798: INFO: Found all expected endpoints: [netserver-0]
Oct  2 21:18:54.805: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.20:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4517 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:18:54.805: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:18:55.081: INFO: Found all expected endpoints: [netserver-1]
Oct  2 21:18:55.089: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.23:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4517 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:18:55.089: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:18:55.410: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:18:55.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4517" for this suite.
Oct  2 21:19:19.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:19:19.652: INFO: namespace pod-network-test-4517 deletion completed in 24.235122644s

• [SLOW TEST:51.429 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:19:19.654: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4c0b6286-e55a-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:19:19.738: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203" in namespace "configmap-831" to be "success or failure"
Oct  2 21:19:19.744: INFO: Pod "pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.43729ms
Oct  2 21:19:21.757: INFO: Pod "pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018986888s
Oct  2 21:19:23.763: INFO: Pod "pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025325794s
STEP: Saw pod success
Oct  2 21:19:23.763: INFO: Pod "pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:19:23.768: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:19:23.839: INFO: Waiting for pod pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:19:23.844: INFO: Pod pod-configmaps-4c0d3131-e55a-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:19:23.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-831" for this suite.
Oct  2 21:19:29.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:19:30.107: INFO: namespace configmap-831 deletion completed in 6.256786137s

• [SLOW TEST:10.453 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:19:30.108: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Oct  2 21:19:30.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-4217'
Oct  2 21:19:30.512: INFO: stderr: ""
Oct  2 21:19:30.512: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Oct  2 21:19:31.520: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:19:31.520: INFO: Found 0 / 1
Oct  2 21:19:32.519: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:19:32.519: INFO: Found 0 / 1
Oct  2 21:19:33.519: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:19:33.519: INFO: Found 1 / 1
Oct  2 21:19:33.519: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  2 21:19:33.525: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:19:33.525: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct  2 21:19:33.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 logs redis-master-ks58v redis-master --namespace=kubectl-4217'
Oct  2 21:19:33.664: INFO: stderr: ""
Oct  2 21:19:33.664: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Oct 21:19:32.413 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Oct 21:19:32.413 # Server started, Redis version 3.2.12\n1:M 02 Oct 21:19:32.413 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Oct 21:19:32.413 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct  2 21:19:33.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 log redis-master-ks58v redis-master --namespace=kubectl-4217 --tail=1'
Oct  2 21:19:33.789: INFO: stderr: ""
Oct  2 21:19:33.789: INFO: stdout: "1:M 02 Oct 21:19:32.413 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct  2 21:19:33.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 log redis-master-ks58v redis-master --namespace=kubectl-4217 --limit-bytes=1'
Oct  2 21:19:33.937: INFO: stderr: ""
Oct  2 21:19:33.937: INFO: stdout: " "
STEP: exposing timestamps
Oct  2 21:19:33.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 log redis-master-ks58v redis-master --namespace=kubectl-4217 --tail=1 --timestamps'
Oct  2 21:19:34.198: INFO: stderr: ""
Oct  2 21:19:34.198: INFO: stdout: "2019-10-02T21:19:32.413689397Z 1:M 02 Oct 21:19:32.413 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct  2 21:19:36.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 log redis-master-ks58v redis-master --namespace=kubectl-4217 --since=1s'
Oct  2 21:19:36.809: INFO: stderr: ""
Oct  2 21:19:36.809: INFO: stdout: ""
Oct  2 21:19:36.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 log redis-master-ks58v redis-master --namespace=kubectl-4217 --since=24h'
Oct  2 21:19:36.944: INFO: stderr: ""
Oct  2 21:19:36.944: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Oct 21:19:32.413 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Oct 21:19:32.413 # Server started, Redis version 3.2.12\n1:M 02 Oct 21:19:32.413 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Oct 21:19:32.413 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Oct  2 21:19:36.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-4217'
Oct  2 21:19:37.053: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:19:37.053: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct  2 21:19:37.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4217'
Oct  2 21:19:37.188: INFO: stderr: "No resources found.\n"
Oct  2 21:19:37.188: INFO: stdout: ""
Oct  2 21:19:37.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -l name=nginx --namespace=kubectl-4217 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  2 21:19:37.295: INFO: stderr: ""
Oct  2 21:19:37.295: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:19:37.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4217" for this suite.
Oct  2 21:19:43.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:19:43.576: INFO: namespace kubectl-4217 deletion completed in 6.269715159s

• [SLOW TEST:13.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:19:43.576: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5a4ddfca-e55a-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5a4ddfca-e55a-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:19:47.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-646" for this suite.
Oct  2 21:20:11.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:20:12.081: INFO: namespace projected-646 deletion completed in 24.24975911s

• [SLOW TEST:28.505 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:20:12.082: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-6b4bdb27-e55a-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:20:12.169: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203" in namespace "configmap-4529" to be "success or failure"
Oct  2 21:20:12.177: INFO: Pod "pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.198083ms
Oct  2 21:20:14.183: INFO: Pod "pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013923317s
STEP: Saw pod success
Oct  2 21:20:14.184: INFO: Pod "pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:20:14.189: INFO: Trying to get logs from node 10.0.10.3 pod pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:20:14.247: INFO: Waiting for pod pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:20:14.254: INFO: Pod pod-configmaps-6b4da3fe-e55a-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:20:14.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4529" for this suite.
Oct  2 21:20:20.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:20:20.529: INFO: namespace configmap-4529 deletion completed in 6.268038962s

• [SLOW TEST:8.448 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:20:20.529: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  2 21:20:23.166: INFO: Successfully updated pod "labelsupdate7053cbfa-e55a-11e9-bbfa-0a580af40203"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:20:25.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7469" for this suite.
Oct  2 21:20:49.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:20:49.474: INFO: namespace projected-7469 deletion completed in 24.265555964s

• [SLOW TEST:28.944 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:20:49.474: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct  2 21:20:53.592: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-819441d5-e55a-11e9-bbfa-0a580af40203,GenerateName:,Namespace:events-7608,SelfLink:/api/v1/namespaces/events-7608/pods/send-events-819441d5-e55a-11e9-bbfa-0a580af40203,UID:8195534b-e55a-11e9-884c-0a580aed1ab9,ResourceVersion:6721,Generation:0,CreationTimestamp:2019-10-02 21:20:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 530523095,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qsq6q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qsq6q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-qsq6q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007098a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000709940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:20:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:20:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:20:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:20:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.26,StartTime:2019-10-02 21:20:49 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-02 21:20:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://db7494f94de4f28ce0a4fc59afe988fde8153cfb946f6de84566f517fdd8de65}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct  2 21:20:55.604: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct  2 21:20:57.613: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:20:57.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7608" for this suite.
Oct  2 21:21:37.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:21:37.895: INFO: namespace events-7608 deletion completed in 40.2614465s

• [SLOW TEST:48.421 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:21:37.896: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:21:37.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203" in namespace "projected-6526" to be "success or failure"
Oct  2 21:21:38.007: INFO: Pod "downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.542455ms
Oct  2 21:21:40.014: INFO: Pod "downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015704621s
STEP: Saw pod success
Oct  2 21:21:40.014: INFO: Pod "downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:21:40.026: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:21:40.083: INFO: Waiting for pod downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:21:40.102: INFO: Pod downwardapi-volume-9e7519f1-e55a-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:21:40.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6526" for this suite.
Oct  2 21:21:46.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:21:46.397: INFO: namespace projected-6526 deletion completed in 6.289198466s

• [SLOW TEST:8.502 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:21:46.398: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1002 21:22:17.078809      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 21:22:17.078: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:22:17.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-645" for this suite.
Oct  2 21:22:23.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:22:23.362: INFO: namespace gc-645 deletion completed in 6.277835106s

• [SLOW TEST:36.964 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:22:23.362: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct  2 21:22:25.997: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5715 pod-service-account-b9de0f5b-e55a-11e9-bbfa-0a580af40203 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct  2 21:22:26.417: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5715 pod-service-account-b9de0f5b-e55a-11e9-bbfa-0a580af40203 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct  2 21:22:26.920: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5715 pod-service-account-b9de0f5b-e55a-11e9-bbfa-0a580af40203 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:22:27.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5715" for this suite.
Oct  2 21:22:33.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:22:33.633: INFO: namespace svcaccounts-5715 deletion completed in 6.303697426s

• [SLOW TEST:10.270 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:22:33.633: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Oct  2 21:22:33.715: INFO: Waiting up to 5m0s for pod "var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203" in namespace "var-expansion-7460" to be "success or failure"
Oct  2 21:22:33.721: INFO: Pod "var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 5.870366ms
Oct  2 21:22:35.728: INFO: Pod "var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01317755s
Oct  2 21:22:37.735: INFO: Pod "var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020109311s
STEP: Saw pod success
Oct  2 21:22:37.735: INFO: Pod "var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:22:37.741: INFO: Trying to get logs from node 10.0.10.4 pod var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 21:22:37.778: INFO: Waiting for pod var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:22:37.787: INFO: Pod var-expansion-bfab11b9-e55a-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:22:37.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7460" for this suite.
Oct  2 21:22:43.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:22:44.058: INFO: namespace var-expansion-7460 deletion completed in 6.263697821s

• [SLOW TEST:10.425 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:22:44.058: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct  2 21:22:44.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-8000'
Oct  2 21:22:44.458: INFO: stderr: ""
Oct  2 21:22:44.458: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:22:44.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:22:44.587: INFO: stderr: ""
Oct  2 21:22:44.587: INFO: stdout: "update-demo-nautilus-7rgfm update-demo-nautilus-spgls "
Oct  2 21:22:44.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:22:44.720: INFO: stderr: ""
Oct  2 21:22:44.720: INFO: stdout: ""
Oct  2 21:22:44.720: INFO: update-demo-nautilus-7rgfm is created but not running
Oct  2 21:22:49.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:22:49.828: INFO: stderr: ""
Oct  2 21:22:49.828: INFO: stdout: "update-demo-nautilus-7rgfm update-demo-nautilus-spgls "
Oct  2 21:22:49.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:22:49.940: INFO: stderr: ""
Oct  2 21:22:49.940: INFO: stdout: "true"
Oct  2 21:22:49.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:22:50.037: INFO: stderr: ""
Oct  2 21:22:50.037: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:22:50.037: INFO: validating pod update-demo-nautilus-7rgfm
Oct  2 21:22:50.137: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:22:50.137: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:22:50.137: INFO: update-demo-nautilus-7rgfm is verified up and running
Oct  2 21:22:50.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-spgls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:22:50.242: INFO: stderr: ""
Oct  2 21:22:50.242: INFO: stdout: "true"
Oct  2 21:22:50.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-spgls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:22:50.338: INFO: stderr: ""
Oct  2 21:22:50.338: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:22:50.338: INFO: validating pod update-demo-nautilus-spgls
Oct  2 21:22:50.436: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:22:50.436: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:22:50.436: INFO: update-demo-nautilus-spgls is verified up and running
STEP: scaling down the replication controller
Oct  2 21:22:50.439: INFO: scanned /root for discovery docs: <nil>
Oct  2 21:22:50.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8000'
Oct  2 21:22:51.623: INFO: stderr: ""
Oct  2 21:22:51.623: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:22:51.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:22:51.739: INFO: stderr: ""
Oct  2 21:22:51.739: INFO: stdout: "update-demo-nautilus-7rgfm update-demo-nautilus-spgls "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  2 21:22:56.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:22:56.864: INFO: stderr: ""
Oct  2 21:22:56.864: INFO: stdout: "update-demo-nautilus-7rgfm update-demo-nautilus-spgls "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  2 21:23:01.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:23:01.973: INFO: stderr: ""
Oct  2 21:23:01.973: INFO: stdout: "update-demo-nautilus-7rgfm "
Oct  2 21:23:01.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:02.077: INFO: stderr: ""
Oct  2 21:23:02.077: INFO: stdout: "true"
Oct  2 21:23:02.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:02.184: INFO: stderr: ""
Oct  2 21:23:02.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:23:02.184: INFO: validating pod update-demo-nautilus-7rgfm
Oct  2 21:23:02.194: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:23:02.194: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:23:02.194: INFO: update-demo-nautilus-7rgfm is verified up and running
STEP: scaling up the replication controller
Oct  2 21:23:02.196: INFO: scanned /root for discovery docs: <nil>
Oct  2 21:23:02.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8000'
Oct  2 21:23:03.364: INFO: stderr: ""
Oct  2 21:23:03.364: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  2 21:23:03.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8000'
Oct  2 21:23:03.649: INFO: stderr: ""
Oct  2 21:23:03.649: INFO: stdout: "update-demo-nautilus-7rgfm update-demo-nautilus-x8gkj "
Oct  2 21:23:03.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:03.826: INFO: stderr: ""
Oct  2 21:23:03.826: INFO: stdout: "true"
Oct  2 21:23:03.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-7rgfm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:03.922: INFO: stderr: ""
Oct  2 21:23:03.922: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:23:03.922: INFO: validating pod update-demo-nautilus-7rgfm
Oct  2 21:23:03.933: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:23:03.933: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:23:03.933: INFO: update-demo-nautilus-7rgfm is verified up and running
Oct  2 21:23:03.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-x8gkj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:04.062: INFO: stderr: ""
Oct  2 21:23:04.062: INFO: stdout: "true"
Oct  2 21:23:04.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods update-demo-nautilus-x8gkj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8000'
Oct  2 21:23:04.178: INFO: stderr: ""
Oct  2 21:23:04.178: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  2 21:23:04.178: INFO: validating pod update-demo-nautilus-x8gkj
Oct  2 21:23:04.268: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  2 21:23:04.269: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  2 21:23:04.269: INFO: update-demo-nautilus-x8gkj is verified up and running
STEP: using delete to clean up resources
Oct  2 21:23:04.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-8000'
Oct  2 21:23:04.395: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:23:04.395: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  2 21:23:04.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8000'
Oct  2 21:23:04.510: INFO: stderr: "No resources found.\n"
Oct  2 21:23:04.510: INFO: stdout: ""
Oct  2 21:23:04.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -l name=update-demo --namespace=kubectl-8000 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  2 21:23:04.629: INFO: stderr: ""
Oct  2 21:23:04.629: INFO: stdout: "update-demo-nautilus-7rgfm\nupdate-demo-nautilus-x8gkj\n"
Oct  2 21:23:05.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8000'
Oct  2 21:23:05.256: INFO: stderr: "No resources found.\n"
Oct  2 21:23:05.256: INFO: stdout: ""
Oct  2 21:23:05.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -l name=update-demo --namespace=kubectl-8000 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  2 21:23:05.396: INFO: stderr: ""
Oct  2 21:23:05.396: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:23:05.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8000" for this suite.
Oct  2 21:23:29.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:23:29.668: INFO: namespace kubectl-8000 deletion completed in 24.265470622s

• [SLOW TEST:45.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:23:29.669: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:23:33.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3757" for this suite.
Oct  2 21:24:13.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:24:14.081: INFO: namespace kubelet-test-3757 deletion completed in 40.26171806s

• [SLOW TEST:44.412 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:24:14.082: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  2 21:24:16.711: INFO: Successfully updated pod "pod-update-fb896df4-e55a-11e9-bbfa-0a580af40203"
STEP: verifying the updated pod is in kubernetes
Oct  2 21:24:16.722: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:24:16.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6216" for this suite.
Oct  2 21:24:40.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:24:40.985: INFO: namespace pods-6216 deletion completed in 24.257192285s

• [SLOW TEST:26.903 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:24:40.985: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-0b91dd88-e55b-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:24:41.064: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203" in namespace "configmap-9758" to be "success or failure"
Oct  2 21:24:41.084: INFO: Pod "pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 19.722962ms
Oct  2 21:24:43.091: INFO: Pod "pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027121988s
STEP: Saw pod success
Oct  2 21:24:43.091: INFO: Pod "pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:24:43.097: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:24:43.235: INFO: Waiting for pod pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:24:43.242: INFO: Pod pod-configmaps-0b939237-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:24:43.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9758" for this suite.
Oct  2 21:24:49.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:24:49.606: INFO: namespace configmap-9758 deletion completed in 6.358492085s

• [SLOW TEST:8.621 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:24:49.607: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  2 21:24:55.935: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:24:55.941: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:24:57.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:24:57.947: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:24:59.942: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:24:59.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:01.942: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:01.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:03.942: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:03.949: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:05.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:05.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:07.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:07.947: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:09.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:09.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:11.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:11.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:13.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:13.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:15.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:15.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:17.942: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:17.948: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  2 21:25:19.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  2 21:25:19.949: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:25:19.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3828" for this suite.
Oct  2 21:25:43.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:25:44.194: INFO: namespace container-lifecycle-hook-3828 deletion completed in 24.237376819s

• [SLOW TEST:54.587 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:25:44.194: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:25:44.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9680" for this suite.
Oct  2 21:25:50.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:25:50.516: INFO: namespace services-9680 deletion completed in 6.236566177s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.323 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:25:50.517: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j9qf9 in namespace proxy-2376
I1002 21:25:50.601869      17 runners.go:184] Created replication controller with name: proxy-service-j9qf9, namespace: proxy-2376, replica count: 1
I1002 21:25:51.652272      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1002 21:25:52.652543      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1002 21:25:53.652839      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:54.653058      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:55.653282      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:56.653674      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:57.653969      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:58.654192      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:25:59.654461      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1002 21:26:00.654680      17 runners.go:184] proxy-service-j9qf9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  2 21:26:00.662: INFO: setup took 10.090672284s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct  2 21:26:00.987: INFO: (0) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 324.819632ms)
Oct  2 21:26:01.015: INFO: (0) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 352.603132ms)
Oct  2 21:26:01.037: INFO: (0) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 374.632692ms)
Oct  2 21:26:01.037: INFO: (0) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 375.000241ms)
Oct  2 21:26:01.037: INFO: (0) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 374.518532ms)
Oct  2 21:26:01.041: INFO: (0) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 378.917069ms)
Oct  2 21:26:01.042: INFO: (0) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 378.920333ms)
Oct  2 21:26:01.043: INFO: (0) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 380.540796ms)
Oct  2 21:26:01.044: INFO: (0) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 380.867497ms)
Oct  2 21:26:01.050: INFO: (0) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 387.150439ms)
Oct  2 21:26:01.051: INFO: (0) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 388.730955ms)
Oct  2 21:26:01.057: INFO: (0) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 394.386428ms)
Oct  2 21:26:01.069: INFO: (0) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 406.262103ms)
Oct  2 21:26:01.069: INFO: (0) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 406.425175ms)
Oct  2 21:26:01.074: INFO: (0) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 412.569537ms)
Oct  2 21:26:01.130: INFO: (0) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 467.690815ms)
Oct  2 21:26:01.141: INFO: (1) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 9.802953ms)
Oct  2 21:26:01.141: INFO: (1) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 9.945964ms)
Oct  2 21:26:01.143: INFO: (1) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 12.802206ms)
Oct  2 21:26:01.144: INFO: (1) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 12.309658ms)
Oct  2 21:26:01.145: INFO: (1) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 13.97594ms)
Oct  2 21:26:01.146: INFO: (1) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 14.46091ms)
Oct  2 21:26:01.146: INFO: (1) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 14.689253ms)
Oct  2 21:26:01.146: INFO: (1) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 15.402869ms)
Oct  2 21:26:01.147: INFO: (1) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 15.430112ms)
Oct  2 21:26:01.147: INFO: (1) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 15.546312ms)
Oct  2 21:26:01.148: INFO: (1) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 15.755649ms)
Oct  2 21:26:01.148: INFO: (1) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 16.85275ms)
Oct  2 21:26:01.148: INFO: (1) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 18.08327ms)
Oct  2 21:26:01.150: INFO: (1) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 18.921092ms)
Oct  2 21:26:01.152: INFO: (1) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 20.664063ms)
Oct  2 21:26:01.161: INFO: (1) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 30.889226ms)
Oct  2 21:26:01.172: INFO: (2) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 11.182922ms)
Oct  2 21:26:01.174: INFO: (2) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 12.76709ms)
Oct  2 21:26:01.182: INFO: (2) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 20.528005ms)
Oct  2 21:26:01.184: INFO: (2) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 22.485584ms)
Oct  2 21:26:01.184: INFO: (2) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 22.830709ms)
Oct  2 21:26:01.184: INFO: (2) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 22.702648ms)
Oct  2 21:26:01.185: INFO: (2) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 22.817569ms)
Oct  2 21:26:01.185: INFO: (2) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 23.076285ms)
Oct  2 21:26:01.186: INFO: (2) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 24.538497ms)
Oct  2 21:26:01.188: INFO: (2) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 26.148572ms)
Oct  2 21:26:01.189: INFO: (2) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 27.517591ms)
Oct  2 21:26:01.190: INFO: (2) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 28.038825ms)
Oct  2 21:26:01.192: INFO: (2) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 30.069167ms)
Oct  2 21:26:01.199: INFO: (2) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 36.969546ms)
Oct  2 21:26:01.199: INFO: (2) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 37.473874ms)
Oct  2 21:26:01.201: INFO: (2) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 38.827037ms)
Oct  2 21:26:01.212: INFO: (3) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 10.913938ms)
Oct  2 21:26:01.221: INFO: (3) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 19.6873ms)
Oct  2 21:26:01.221: INFO: (3) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 20.227152ms)
Oct  2 21:26:01.223: INFO: (3) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 21.745277ms)
Oct  2 21:26:01.258: INFO: (3) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 55.593375ms)
Oct  2 21:26:01.258: INFO: (3) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 57.105215ms)
Oct  2 21:26:01.258: INFO: (3) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 56.777011ms)
Oct  2 21:26:01.259: INFO: (3) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 56.248496ms)
Oct  2 21:26:01.260: INFO: (3) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 58.28376ms)
Oct  2 21:26:01.262: INFO: (3) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 59.634612ms)
Oct  2 21:26:01.262: INFO: (3) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 59.542527ms)
Oct  2 21:26:01.262: INFO: (3) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 59.815546ms)
Oct  2 21:26:01.262: INFO: (3) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 59.57435ms)
Oct  2 21:26:01.262: INFO: (3) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 60.141249ms)
Oct  2 21:26:01.268: INFO: (3) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 66.260096ms)
Oct  2 21:26:01.268: INFO: (3) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 67.131307ms)
Oct  2 21:26:01.320: INFO: (4) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 51.214563ms)
Oct  2 21:26:01.322: INFO: (4) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 52.895239ms)
Oct  2 21:26:01.327: INFO: (4) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 58.704797ms)
Oct  2 21:26:01.328: INFO: (4) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 58.793932ms)
Oct  2 21:26:01.337: INFO: (4) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 67.972034ms)
Oct  2 21:26:01.338: INFO: (4) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 68.950755ms)
Oct  2 21:26:01.338: INFO: (4) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 69.855556ms)
Oct  2 21:26:01.339: INFO: (4) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 70.240283ms)
Oct  2 21:26:01.339: INFO: (4) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 69.902253ms)
Oct  2 21:26:01.340: INFO: (4) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 70.543614ms)
Oct  2 21:26:01.343: INFO: (4) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 74.659064ms)
Oct  2 21:26:01.344: INFO: (4) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 75.791831ms)
Oct  2 21:26:01.347: INFO: (4) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 78.361998ms)
Oct  2 21:26:01.362: INFO: (4) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 92.993837ms)
Oct  2 21:26:01.365: INFO: (4) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 96.085164ms)
Oct  2 21:26:01.392: INFO: (4) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 123.424249ms)
Oct  2 21:26:01.432: INFO: (5) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 39.236079ms)
Oct  2 21:26:01.433: INFO: (5) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 40.219368ms)
Oct  2 21:26:01.433: INFO: (5) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 39.562768ms)
Oct  2 21:26:01.434: INFO: (5) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 39.821574ms)
Oct  2 21:26:01.435: INFO: (5) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 41.349756ms)
Oct  2 21:26:01.436: INFO: (5) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 41.773369ms)
Oct  2 21:26:01.438: INFO: (5) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 43.601741ms)
Oct  2 21:26:01.438: INFO: (5) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 43.813324ms)
Oct  2 21:26:01.520: INFO: (5) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 127.297569ms)
Oct  2 21:26:01.521: INFO: (5) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 127.488862ms)
Oct  2 21:26:01.522: INFO: (5) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 128.100726ms)
Oct  2 21:26:01.522: INFO: (5) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 129.532232ms)
Oct  2 21:26:01.523: INFO: (5) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 128.741173ms)
Oct  2 21:26:01.551: INFO: (5) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 157.78345ms)
Oct  2 21:26:01.556: INFO: (5) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 162.399478ms)
Oct  2 21:26:01.566: INFO: (5) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 172.782173ms)
Oct  2 21:26:01.605: INFO: (6) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 38.454602ms)
Oct  2 21:26:01.607: INFO: (6) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 40.524673ms)
Oct  2 21:26:01.608: INFO: (6) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 41.124041ms)
Oct  2 21:26:01.609: INFO: (6) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 42.160578ms)
Oct  2 21:26:01.609: INFO: (6) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 42.873878ms)
Oct  2 21:26:01.642: INFO: (6) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 75.498177ms)
Oct  2 21:26:01.651: INFO: (6) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 84.264295ms)
Oct  2 21:26:01.701: INFO: (6) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 135.127463ms)
Oct  2 21:26:01.702: INFO: (6) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 135.343491ms)
Oct  2 21:26:01.702: INFO: (6) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 136.222466ms)
Oct  2 21:26:01.703: INFO: (6) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 135.763498ms)
Oct  2 21:26:01.703: INFO: (6) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 136.667957ms)
Oct  2 21:26:01.712: INFO: (6) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 145.792799ms)
Oct  2 21:26:01.736: INFO: (6) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 169.506166ms)
Oct  2 21:26:01.749: INFO: (6) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 182.260547ms)
Oct  2 21:26:01.749: INFO: (6) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 182.852122ms)
Oct  2 21:26:01.769: INFO: (7) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 18.454155ms)
Oct  2 21:26:01.780: INFO: (7) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 29.50774ms)
Oct  2 21:26:01.781: INFO: (7) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 30.932079ms)
Oct  2 21:26:01.782: INFO: (7) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 32.140325ms)
Oct  2 21:26:01.783: INFO: (7) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 32.667772ms)
Oct  2 21:26:01.783: INFO: (7) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 32.923223ms)
Oct  2 21:26:01.783: INFO: (7) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 32.403713ms)
Oct  2 21:26:01.784: INFO: (7) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 34.130723ms)
Oct  2 21:26:01.808: INFO: (7) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 57.960423ms)
Oct  2 21:26:01.809: INFO: (7) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 57.924792ms)
Oct  2 21:26:01.812: INFO: (7) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 62.842487ms)
Oct  2 21:26:01.813: INFO: (7) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 62.217576ms)
Oct  2 21:26:01.839: INFO: (7) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 89.698594ms)
Oct  2 21:26:01.842: INFO: (7) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 92.449452ms)
Oct  2 21:26:01.843: INFO: (7) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 92.064708ms)
Oct  2 21:26:01.843: INFO: (7) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 93.709409ms)
Oct  2 21:26:01.870: INFO: (8) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 26.394924ms)
Oct  2 21:26:01.879: INFO: (8) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 34.275903ms)
Oct  2 21:26:01.879: INFO: (8) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 35.666356ms)
Oct  2 21:26:01.879: INFO: (8) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 35.133645ms)
Oct  2 21:26:01.879: INFO: (8) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 35.426063ms)
Oct  2 21:26:01.879: INFO: (8) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 35.359251ms)
Oct  2 21:26:01.880: INFO: (8) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 34.566921ms)
Oct  2 21:26:01.880: INFO: (8) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 34.820143ms)
Oct  2 21:26:01.885: INFO: (8) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 40.623896ms)
Oct  2 21:26:01.886: INFO: (8) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 42.17604ms)
Oct  2 21:26:01.886: INFO: (8) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 42.058753ms)
Oct  2 21:26:01.887: INFO: (8) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 42.250707ms)
Oct  2 21:26:01.887: INFO: (8) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 42.432664ms)
Oct  2 21:26:01.887: INFO: (8) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 43.718915ms)
Oct  2 21:26:01.889: INFO: (8) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 44.942099ms)
Oct  2 21:26:01.903: INFO: (8) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 58.965106ms)
Oct  2 21:26:01.945: INFO: (9) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 40.806814ms)
Oct  2 21:26:01.949: INFO: (9) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 45.475834ms)
Oct  2 21:26:01.950: INFO: (9) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 46.58444ms)
Oct  2 21:26:01.952: INFO: (9) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 47.260089ms)
Oct  2 21:26:01.952: INFO: (9) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 47.690015ms)
Oct  2 21:26:01.954: INFO: (9) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 48.792467ms)
Oct  2 21:26:01.960: INFO: (9) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 55.863613ms)
Oct  2 21:26:01.961: INFO: (9) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 56.599165ms)
Oct  2 21:26:01.966: INFO: (9) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 61.552013ms)
Oct  2 21:26:01.969: INFO: (9) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 63.872108ms)
Oct  2 21:26:01.976: INFO: (9) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 71.158956ms)
Oct  2 21:26:01.976: INFO: (9) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 71.97827ms)
Oct  2 21:26:01.976: INFO: (9) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 72.364093ms)
Oct  2 21:26:01.977: INFO: (9) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 73.432134ms)
Oct  2 21:26:01.994: INFO: (9) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 90.269652ms)
Oct  2 21:26:01.999: INFO: (9) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 94.262358ms)
Oct  2 21:26:02.049: INFO: (10) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 49.02835ms)
Oct  2 21:26:02.056: INFO: (10) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 55.736445ms)
Oct  2 21:26:02.056: INFO: (10) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 56.232347ms)
Oct  2 21:26:02.056: INFO: (10) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 56.396119ms)
Oct  2 21:26:02.056: INFO: (10) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 56.882925ms)
Oct  2 21:26:02.057: INFO: (10) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 57.279546ms)
Oct  2 21:26:02.057: INFO: (10) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 57.170112ms)
Oct  2 21:26:02.057: INFO: (10) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 57.005964ms)
Oct  2 21:26:02.059: INFO: (10) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 59.92792ms)
Oct  2 21:26:02.060: INFO: (10) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 59.624727ms)
Oct  2 21:26:02.072: INFO: (10) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 73.185086ms)
Oct  2 21:26:02.073: INFO: (10) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 72.798859ms)
Oct  2 21:26:02.074: INFO: (10) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 75.026611ms)
Oct  2 21:26:02.092: INFO: (10) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 92.444705ms)
Oct  2 21:26:02.093: INFO: (10) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 92.851705ms)
Oct  2 21:26:02.095: INFO: (10) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 95.620088ms)
Oct  2 21:26:02.125: INFO: (11) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 29.56196ms)
Oct  2 21:26:02.140: INFO: (11) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 44.259976ms)
Oct  2 21:26:02.141: INFO: (11) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 45.808492ms)
Oct  2 21:26:02.164: INFO: (11) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 68.402183ms)
Oct  2 21:26:02.169: INFO: (11) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 73.651588ms)
Oct  2 21:26:02.170: INFO: (11) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 75.382684ms)
Oct  2 21:26:02.172: INFO: (11) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 76.728754ms)
Oct  2 21:26:02.172: INFO: (11) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 76.303346ms)
Oct  2 21:26:02.171: INFO: (11) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 74.302645ms)
Oct  2 21:26:02.173: INFO: (11) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 77.635976ms)
Oct  2 21:26:02.173: INFO: (11) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 77.398066ms)
Oct  2 21:26:02.191: INFO: (11) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 95.695862ms)
Oct  2 21:26:02.222: INFO: (11) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 126.668778ms)
Oct  2 21:26:02.222: INFO: (11) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 126.379581ms)
Oct  2 21:26:02.223: INFO: (11) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 126.496492ms)
Oct  2 21:26:02.226: INFO: (11) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 131.441182ms)
Oct  2 21:26:02.248: INFO: (12) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 21.68944ms)
Oct  2 21:26:02.248: INFO: (12) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 21.09448ms)
Oct  2 21:26:02.252: INFO: (12) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 24.432845ms)
Oct  2 21:26:02.253: INFO: (12) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 26.544019ms)
Oct  2 21:26:02.253: INFO: (12) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 26.635148ms)
Oct  2 21:26:02.254: INFO: (12) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 25.699855ms)
Oct  2 21:26:02.258: INFO: (12) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 30.325269ms)
Oct  2 21:26:02.259: INFO: (12) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 32.25304ms)
Oct  2 21:26:02.260: INFO: (12) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 32.477075ms)
Oct  2 21:26:02.260: INFO: (12) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 33.524642ms)
Oct  2 21:26:02.261: INFO: (12) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 33.596743ms)
Oct  2 21:26:02.261: INFO: (12) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 33.571929ms)
Oct  2 21:26:02.275: INFO: (12) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 47.120085ms)
Oct  2 21:26:02.289: INFO: (12) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 62.799253ms)
Oct  2 21:26:02.293: INFO: (12) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 65.986364ms)
Oct  2 21:26:02.353: INFO: (12) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 126.119375ms)
Oct  2 21:26:02.390: INFO: (13) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 36.048193ms)
Oct  2 21:26:02.390: INFO: (13) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 35.896974ms)
Oct  2 21:26:02.390: INFO: (13) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 34.907941ms)
Oct  2 21:26:02.390: INFO: (13) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 35.522518ms)
Oct  2 21:26:02.391: INFO: (13) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 35.811759ms)
Oct  2 21:26:02.417: INFO: (13) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 62.322797ms)
Oct  2 21:26:02.417: INFO: (13) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 62.650694ms)
Oct  2 21:26:02.424: INFO: (13) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 70.125782ms)
Oct  2 21:26:02.424: INFO: (13) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 68.685695ms)
Oct  2 21:26:02.424: INFO: (13) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 70.004587ms)
Oct  2 21:26:02.428: INFO: (13) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 72.820271ms)
Oct  2 21:26:02.429: INFO: (13) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 74.49439ms)
Oct  2 21:26:02.434: INFO: (13) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 79.648301ms)
Oct  2 21:26:02.435: INFO: (13) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 80.717575ms)
Oct  2 21:26:02.435: INFO: (13) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 80.898073ms)
Oct  2 21:26:02.445: INFO: (13) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 90.190464ms)
Oct  2 21:26:02.465: INFO: (14) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 19.199587ms)
Oct  2 21:26:02.472: INFO: (14) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 24.573373ms)
Oct  2 21:26:02.473: INFO: (14) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 26.839725ms)
Oct  2 21:26:02.478: INFO: (14) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 32.205172ms)
Oct  2 21:26:02.478: INFO: (14) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 31.197217ms)
Oct  2 21:26:02.480: INFO: (14) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 34.151285ms)
Oct  2 21:26:02.480: INFO: (14) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 33.243825ms)
Oct  2 21:26:02.482: INFO: (14) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 35.544199ms)
Oct  2 21:26:02.482: INFO: (14) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 34.879161ms)
Oct  2 21:26:02.482: INFO: (14) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 36.662559ms)
Oct  2 21:26:02.495: INFO: (14) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 49.312579ms)
Oct  2 21:26:02.496: INFO: (14) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 49.502586ms)
Oct  2 21:26:02.496: INFO: (14) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 49.721864ms)
Oct  2 21:26:02.516: INFO: (14) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 69.016134ms)
Oct  2 21:26:02.523: INFO: (14) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 75.927377ms)
Oct  2 21:26:02.533: INFO: (14) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 86.374208ms)
Oct  2 21:26:02.601: INFO: (15) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 67.178896ms)
Oct  2 21:26:02.605: INFO: (15) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 72.379907ms)
Oct  2 21:26:02.606: INFO: (15) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 72.325692ms)
Oct  2 21:26:02.606: INFO: (15) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 72.582299ms)
Oct  2 21:26:02.606: INFO: (15) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 72.855867ms)
Oct  2 21:26:02.606: INFO: (15) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 72.644037ms)
Oct  2 21:26:02.615: INFO: (15) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 82.430872ms)
Oct  2 21:26:02.625: INFO: (15) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 91.533568ms)
Oct  2 21:26:02.626: INFO: (15) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 92.487107ms)
Oct  2 21:26:02.626: INFO: (15) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 92.691578ms)
Oct  2 21:26:02.627: INFO: (15) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 93.264388ms)
Oct  2 21:26:02.628: INFO: (15) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 93.942668ms)
Oct  2 21:26:02.636: INFO: (15) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 102.231861ms)
Oct  2 21:26:02.644: INFO: (15) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 111.288275ms)
Oct  2 21:26:02.645: INFO: (15) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 111.769298ms)
Oct  2 21:26:02.645: INFO: (15) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 112.438853ms)
Oct  2 21:26:02.705: INFO: (16) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 57.855332ms)
Oct  2 21:26:02.706: INFO: (16) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 60.191317ms)
Oct  2 21:26:02.707: INFO: (16) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 59.25863ms)
Oct  2 21:26:02.709: INFO: (16) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 62.92319ms)
Oct  2 21:26:02.710: INFO: (16) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 63.32911ms)
Oct  2 21:26:02.710: INFO: (16) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 63.07608ms)
Oct  2 21:26:02.710: INFO: (16) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 64.043918ms)
Oct  2 21:26:02.711: INFO: (16) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 64.907751ms)
Oct  2 21:26:02.711: INFO: (16) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 63.713691ms)
Oct  2 21:26:02.711: INFO: (16) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 65.920518ms)
Oct  2 21:26:02.711: INFO: (16) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 65.188706ms)
Oct  2 21:26:02.734: INFO: (16) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 87.830831ms)
Oct  2 21:26:02.734: INFO: (16) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 88.069151ms)
Oct  2 21:26:02.764: INFO: (16) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 117.483374ms)
Oct  2 21:26:02.765: INFO: (16) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 118.086292ms)
Oct  2 21:26:02.765: INFO: (16) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 118.212174ms)
Oct  2 21:26:02.801: INFO: (17) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 36.030281ms)
Oct  2 21:26:02.807: INFO: (17) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 41.299452ms)
Oct  2 21:26:02.809: INFO: (17) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 43.917037ms)
Oct  2 21:26:02.812: INFO: (17) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 45.534295ms)
Oct  2 21:26:02.812: INFO: (17) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 46.180832ms)
Oct  2 21:26:02.813: INFO: (17) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 46.621453ms)
Oct  2 21:26:02.813: INFO: (17) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 46.618954ms)
Oct  2 21:26:02.813: INFO: (17) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 48.096678ms)
Oct  2 21:26:02.814: INFO: (17) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 47.20666ms)
Oct  2 21:26:02.814: INFO: (17) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 48.819423ms)
Oct  2 21:26:02.816: INFO: (17) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 49.843254ms)
Oct  2 21:26:02.829: INFO: (17) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 62.377476ms)
Oct  2 21:26:02.829: INFO: (17) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 62.674943ms)
Oct  2 21:26:02.830: INFO: (17) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 63.458152ms)
Oct  2 21:26:02.837: INFO: (17) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 71.56517ms)
Oct  2 21:26:02.854: INFO: (17) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 87.548966ms)
Oct  2 21:26:02.881: INFO: (18) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 26.532942ms)
Oct  2 21:26:02.888: INFO: (18) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 33.678026ms)
Oct  2 21:26:02.899: INFO: (18) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 44.246181ms)
Oct  2 21:26:02.899: INFO: (18) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 43.99992ms)
Oct  2 21:26:02.899: INFO: (18) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 44.396455ms)
Oct  2 21:26:02.899: INFO: (18) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 44.162553ms)
Oct  2 21:26:02.925: INFO: (18) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 69.714599ms)
Oct  2 21:26:02.926: INFO: (18) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 71.331899ms)
Oct  2 21:26:02.926: INFO: (18) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 70.77223ms)
Oct  2 21:26:02.927: INFO: (18) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 72.003904ms)
Oct  2 21:26:02.942: INFO: (18) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 87.047692ms)
Oct  2 21:26:02.943: INFO: (18) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 87.906511ms)
Oct  2 21:26:02.943: INFO: (18) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 88.430195ms)
Oct  2 21:26:02.944: INFO: (18) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 89.565436ms)
Oct  2 21:26:02.955: INFO: (18) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 100.088231ms)
Oct  2 21:26:03.043: INFO: (18) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 188.579001ms)
Oct  2 21:26:03.108: INFO: (19) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 62.975353ms)
Oct  2 21:26:03.120: INFO: (19) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2/proxy/rewriteme">test</a> (200; 75.667151ms)
Oct  2 21:26:03.121: INFO: (19) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">... (200; 76.149558ms)
Oct  2 21:26:03.122: INFO: (19) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:462/proxy/: tls qux (200; 78.565219ms)
Oct  2 21:26:03.122: INFO: (19) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname2/proxy/: tls qux (200; 78.701674ms)
Oct  2 21:26:03.123: INFO: (19) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname2/proxy/: bar (200; 78.856536ms)
Oct  2 21:26:03.124: INFO: (19) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 80.449121ms)
Oct  2 21:26:03.124: INFO: (19) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:443/proxy/tlsrewritem... (200; 80.263242ms)
Oct  2 21:26:03.137: INFO: (19) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:160/proxy/: foo (200; 93.178947ms)
Oct  2 21:26:03.137: INFO: (19) /api/v1/namespaces/proxy-2376/services/http:proxy-service-j9qf9:portname1/proxy/: foo (200; 93.963773ms)
Oct  2 21:26:03.137: INFO: (19) /api/v1/namespaces/proxy-2376/services/https:proxy-service-j9qf9:tlsportname1/proxy/: tls baz (200; 93.881987ms)
Oct  2 21:26:03.138: INFO: (19) /api/v1/namespaces/proxy-2376/pods/https:proxy-service-j9qf9-h5br2:460/proxy/: tls baz (200; 94.398318ms)
Oct  2 21:26:03.150: INFO: (19) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname1/proxy/: foo (200; 105.020993ms)
Oct  2 21:26:03.154: INFO: (19) /api/v1/namespaces/proxy-2376/services/proxy-service-j9qf9:portname2/proxy/: bar (200; 109.184285ms)
Oct  2 21:26:03.154: INFO: (19) /api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/: <a href="/api/v1/namespaces/proxy-2376/pods/proxy-service-j9qf9-h5br2:1080/proxy/rewriteme">test<... (200; 109.175602ms)
Oct  2 21:26:03.155: INFO: (19) /api/v1/namespaces/proxy-2376/pods/http:proxy-service-j9qf9-h5br2:162/proxy/: bar (200; 110.644525ms)
STEP: deleting ReplicationController proxy-service-j9qf9 in namespace proxy-2376, will wait for the garbage collector to delete the pods
Oct  2 21:26:03.242: INFO: Deleting ReplicationController proxy-service-j9qf9 took: 29.174708ms
Oct  2 21:26:03.543: INFO: Terminating ReplicationController proxy-service-j9qf9 pods took: 300.521252ms
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:26:05.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2376" for this suite.
Oct  2 21:26:11.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:26:11.926: INFO: namespace proxy-2376 deletion completed in 6.275804018s

• [SLOW TEST:21.409 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:26:11.927: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Oct  2 21:26:11.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-8697'
Oct  2 21:26:12.391: INFO: stderr: ""
Oct  2 21:26:12.391: INFO: stdout: "pod/pause created\n"
Oct  2 21:26:12.391: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct  2 21:26:12.391: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8697" to be "running and ready"
Oct  2 21:26:12.401: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.097709ms
Oct  2 21:26:14.408: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.016357251s
Oct  2 21:26:14.408: INFO: Pod "pause" satisfied condition "running and ready"
Oct  2 21:26:14.408: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Oct  2 21:26:14.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 label pods pause testing-label=testing-label-value --namespace=kubectl-8697'
Oct  2 21:26:14.545: INFO: stderr: ""
Oct  2 21:26:14.545: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct  2 21:26:14.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pod pause -L testing-label --namespace=kubectl-8697'
Oct  2 21:26:14.690: INFO: stderr: ""
Oct  2 21:26:14.690: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct  2 21:26:14.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 label pods pause testing-label- --namespace=kubectl-8697'
Oct  2 21:26:14.923: INFO: stderr: ""
Oct  2 21:26:14.923: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct  2 21:26:14.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pod pause -L testing-label --namespace=kubectl-8697'
Oct  2 21:26:15.028: INFO: stderr: ""
Oct  2 21:26:15.028: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Oct  2 21:26:15.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-8697'
Oct  2 21:26:15.159: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:26:15.159: INFO: stdout: "pod \"pause\" force deleted\n"
Oct  2 21:26:15.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get rc,svc -l name=pause --no-headers --namespace=kubectl-8697'
Oct  2 21:26:15.297: INFO: stderr: "No resources found.\n"
Oct  2 21:26:15.297: INFO: stdout: ""
Oct  2 21:26:15.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 get pods -l name=pause --namespace=kubectl-8697 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  2 21:26:15.417: INFO: stderr: ""
Oct  2 21:26:15.417: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:26:15.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8697" for this suite.
Oct  2 21:26:21.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:26:21.690: INFO: namespace kubectl-8697 deletion completed in 6.267214864s

• [SLOW TEST:9.764 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:26:21.691: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  2 21:26:21.779: INFO: Waiting up to 5m0s for pod "downward-api-479a7896-e55b-11e9-bbfa-0a580af40203" in namespace "downward-api-9072" to be "success or failure"
Oct  2 21:26:21.786: INFO: Pod "downward-api-479a7896-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.037516ms
Oct  2 21:26:23.794: INFO: Pod "downward-api-479a7896-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015341893s
Oct  2 21:26:25.805: INFO: Pod "downward-api-479a7896-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025573436s
STEP: Saw pod success
Oct  2 21:26:25.805: INFO: Pod "downward-api-479a7896-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:26:25.812: INFO: Trying to get logs from node 10.0.10.3 pod downward-api-479a7896-e55b-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 21:26:25.915: INFO: Waiting for pod downward-api-479a7896-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:26:25.923: INFO: Pod downward-api-479a7896-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:26:25.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9072" for this suite.
Oct  2 21:26:31.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:26:32.248: INFO: namespace downward-api-9072 deletion completed in 6.318136707s

• [SLOW TEST:10.557 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:26:32.248: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1416
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct  2 21:26:32.360: INFO: Found 0 stateful pods, waiting for 3
Oct  2 21:26:42.368: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:26:42.368: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:26:42.368: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:26:42.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-1416 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:26:42.789: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:26:42.789: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:26:42.789: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct  2 21:26:52.842: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct  2 21:27:02.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-1416 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:27:03.319: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:27:03.319: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:27:03.319: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:27:03.349: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:27:03.349: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:03.349: INFO: Waiting for Pod statefulset-1416/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:03.349: INFO: Waiting for Pod statefulset-1416/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:13.366: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:27:13.366: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:13.366: INFO: Waiting for Pod statefulset-1416/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:23.363: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:27:23.363: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:27:23.363: INFO: Waiting for Pod statefulset-1416/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Oct  2 21:27:33.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-1416 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:27:33.810: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:27:33.810: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:27:33.810: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:27:43.860: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct  2 21:27:53.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-1416 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:27:54.307: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:27:54.307: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:27:54.307: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:28:04.347: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:28:04.347: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  2 21:28:04.347: INFO: Waiting for Pod statefulset-1416/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  2 21:28:04.347: INFO: Waiting for Pod statefulset-1416/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  2 21:28:14.360: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:28:14.360: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  2 21:28:24.363: INFO: Waiting for StatefulSet statefulset-1416/ss2 to complete update
Oct  2 21:28:24.363: INFO: Waiting for Pod statefulset-1416/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  2 21:28:34.359: INFO: Deleting all statefulset in ns statefulset-1416
Oct  2 21:28:34.366: INFO: Scaling statefulset ss2 to 0
Oct  2 21:28:54.391: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:28:54.398: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:28:54.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1416" for this suite.
Oct  2 21:29:02.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:29:02.673: INFO: namespace statefulset-1416 deletion completed in 8.240756435s

• [SLOW TEST:150.424 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:29:02.673: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:29:02.751: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203" in namespace "projected-9429" to be "success or failure"
Oct  2 21:29:02.758: INFO: Pod "downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.148812ms
Oct  2 21:29:04.766: INFO: Pod "downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014890654s
Oct  2 21:29:06.773: INFO: Pod "downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022229356s
STEP: Saw pod success
Oct  2 21:29:06.774: INFO: Pod "downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:29:06.779: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:29:06.910: INFO: Waiting for pod downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:29:06.916: INFO: Pod downwardapi-volume-a78cd9ca-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:29:06.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9429" for this suite.
Oct  2 21:29:12.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:29:13.185: INFO: namespace projected-9429 deletion completed in 6.2626937s

• [SLOW TEST:10.512 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:29:13.186: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-3228/configmap-test-add1f3c1-e55b-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:29:13.276: INFO: Waiting up to 5m0s for pod "pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203" in namespace "configmap-3228" to be "success or failure"
Oct  2 21:29:13.283: INFO: Pod "pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.495117ms
Oct  2 21:29:15.291: INFO: Pod "pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014902982s
STEP: Saw pod success
Oct  2 21:29:15.291: INFO: Pod "pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:29:15.296: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203 container env-test: <nil>
STEP: delete the pod
Oct  2 21:29:15.427: INFO: Waiting for pod pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:29:15.433: INFO: Pod pod-configmaps-add3d13c-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:29:15.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3228" for this suite.
Oct  2 21:29:21.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:29:21.703: INFO: namespace configmap-3228 deletion completed in 6.261666572s

• [SLOW TEST:8.517 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:29:21.703: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:29:21.792: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203" in namespace "downward-api-618" to be "success or failure"
Oct  2 21:29:21.799: INFO: Pod "downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.964399ms
Oct  2 21:29:23.811: INFO: Pod "downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019829212s
STEP: Saw pod success
Oct  2 21:29:23.811: INFO: Pod "downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:29:23.821: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:29:23.857: INFO: Waiting for pod downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:29:23.862: INFO: Pod downwardapi-volume-b2e637cb-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:29:23.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-618" for this suite.
Oct  2 21:29:29.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:29:30.119: INFO: namespace downward-api-618 deletion completed in 6.25083762s

• [SLOW TEST:8.416 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:29:30.119: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b7e8e540-e55b-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:29:30.206: INFO: Waiting up to 5m0s for pod "pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203" in namespace "secrets-3510" to be "success or failure"
Oct  2 21:29:30.213: INFO: Pod "pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.662597ms
Oct  2 21:29:32.220: INFO: Pod "pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013478704s
STEP: Saw pod success
Oct  2 21:29:32.220: INFO: Pod "pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:29:32.226: INFO: Trying to get logs from node 10.0.10.4 pod pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:29:32.259: INFO: Waiting for pod pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:29:32.268: INFO: Pod pod-secrets-b7eb137f-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:29:32.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3510" for this suite.
Oct  2 21:29:38.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:29:38.530: INFO: namespace secrets-3510 deletion completed in 6.255539541s

• [SLOW TEST:8.411 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:29:38.530: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct  2 21:29:38.609: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8761,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  2 21:29:38.610: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8761,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct  2 21:29:48.629: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8784,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  2 21:29:48.629: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8784,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct  2 21:29:58.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8807,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  2 21:29:58.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8807,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct  2 21:30:08.659: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8829,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  2 21:30:08.659: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-a,UID:bcedd0a9-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8829,Generation:0,CreationTimestamp:2019-10-02 21:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct  2 21:30:18.673: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-b,UID:d4cecb8d-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8851,Generation:0,CreationTimestamp:2019-10-02 21:30:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  2 21:30:18.673: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-b,UID:d4cecb8d-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8851,Generation:0,CreationTimestamp:2019-10-02 21:30:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct  2 21:30:28.688: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-b,UID:d4cecb8d-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8874,Generation:0,CreationTimestamp:2019-10-02 21:30:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  2 21:30:28.688: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-66,SelfLink:/api/v1/namespaces/watch-66/configmaps/e2e-watch-test-configmap-b,UID:d4cecb8d-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:8874,Generation:0,CreationTimestamp:2019-10-02 21:30:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:30:38.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-66" for this suite.
Oct  2 21:30:44.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:30:44.981: INFO: namespace watch-66 deletion completed in 6.284921789s

• [SLOW TEST:66.451 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:30:44.981: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct  2 21:30:45.049: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:30:58.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1167" for this suite.
Oct  2 21:31:04.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:31:04.822: INFO: namespace pods-1167 deletion completed in 6.285216049s

• [SLOW TEST:19.841 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:31:04.822: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f0622100-e55b-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 21:31:04.968: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203" in namespace "projected-8460" to be "success or failure"
Oct  2 21:31:04.976: INFO: Pod "pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.46137ms
Oct  2 21:31:06.985: INFO: Pod "pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016796474s
STEP: Saw pod success
Oct  2 21:31:06.985: INFO: Pod "pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:31:06.995: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 21:31:07.030: INFO: Waiting for pod pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:31:07.036: INFO: Pod pod-projected-configmaps-f0654dfc-e55b-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:31:07.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8460" for this suite.
Oct  2 21:31:13.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:31:13.392: INFO: namespace projected-8460 deletion completed in 6.346506621s

• [SLOW TEST:8.570 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:31:13.392: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:31:13.480: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct  2 21:31:18.490: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  2 21:31:18.490: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct  2 21:31:20.498: INFO: Creating deployment "test-rollover-deployment"
Oct  2 21:31:20.514: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct  2 21:31:22.525: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct  2 21:31:22.537: INFO: Ensure that both replica sets have 1 created replica
Oct  2 21:31:22.548: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct  2 21:31:22.579: INFO: Updating deployment test-rollover-deployment
Oct  2 21:31:22.579: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct  2 21:31:24.592: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct  2 21:31:24.604: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct  2 21:31:24.631: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:24.632: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648682, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:26.644: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:26.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648684, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:28.646: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:28.646: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648684, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:30.645: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:30.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648684, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:32.644: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:32.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648684, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:34.648: INFO: all replica sets need to contain the pod-template-hash label
Oct  2 21:31:34.648: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648684, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705648680, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  2 21:31:36.645: INFO: 
Oct  2 21:31:36.645: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  2 21:31:36.664: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3697,SelfLink:/apis/apps/v1/namespaces/deployment-3697/deployments/test-rollover-deployment,UID:f9aa95e3-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:9151,Generation:2,CreationTimestamp:2019-10-02 21:31:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-02 21:31:20 +0000 UTC 2019-10-02 21:31:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-02 21:31:34 +0000 UTC 2019-10-02 21:31:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct  2 21:31:36.670: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-3697,SelfLink:/apis/apps/v1/namespaces/deployment-3697/replicasets/test-rollover-deployment-659c699649,UID:fae83b0d-e55b-11e9-a07f-0a580aed12b5,ResourceVersion:9140,Generation:2,CreationTimestamp:2019-10-02 21:31:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f9aa95e3-e55b-11e9-884c-0a580aed1ab9 0xc0018a9927 0xc0018a9928}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  2 21:31:36.670: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct  2 21:31:36.670: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3697,SelfLink:/apis/apps/v1/namespaces/deployment-3697/replicasets/test-rollover-controller,UID:f5787ee4-e55b-11e9-884c-0a580aed1ab9,ResourceVersion:9150,Generation:2,CreationTimestamp:2019-10-02 21:31:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f9aa95e3-e55b-11e9-884c-0a580aed1ab9 0xc0018a984f 0xc0018a9860}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 21:31:36.670: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-3697,SelfLink:/apis/apps/v1/namespaces/deployment-3697/replicasets/test-rollover-deployment-7b45b6464,UID:f9aeb447-e55b-11e9-a07f-0a580aed12b5,ResourceVersion:9101,Generation:2,CreationTimestamp:2019-10-02 21:31:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f9aa95e3-e55b-11e9-884c-0a580aed1ab9 0xc0018a99e0 0xc0018a99e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 21:31:36.676: INFO: Pod "test-rollover-deployment-659c699649-2gkz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-2gkz9,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-3697,SelfLink:/api/v1/namespaces/deployment-3697/pods/test-rollover-deployment-659c699649-2gkz9,UID:faefd610-e55b-11e9-a07f-0a580aed12b5,ResourceVersion:9116,Generation:0,CreationTimestamp:2019-10-02 21:31:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 fae83b0d-e55b-11e9-a07f-0a580aed12b5 0xc001f78597 0xc001f78598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r5b7r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r5b7r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-r5b7r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f78610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f78630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:31:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:31:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:31:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:31:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.1.42,StartTime:2019-10-02 21:31:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-02 21:31:24 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://241d118ff8b41e4bb4b80bca43f8919a72e4314212ef29fd9a60896eb43a4d41}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:31:36.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3697" for this suite.
Oct  2 21:31:44.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:31:44.950: INFO: namespace deployment-3697 deletion completed in 8.26836623s

• [SLOW TEST:31.558 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:31:44.951: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-084da380-e55c-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:31:45.089: INFO: Waiting up to 5m0s for pod "pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203" in namespace "secrets-3969" to be "success or failure"
Oct  2 21:31:45.098: INFO: Pod "pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.874976ms
Oct  2 21:31:47.104: INFO: Pod "pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015027917s
STEP: Saw pod success
Oct  2 21:31:47.104: INFO: Pod "pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:31:47.125: INFO: Trying to get logs from node 10.0.10.4 pod pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:31:47.161: INFO: Waiting for pod pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:31:47.166: INFO: Pod pod-secrets-0850a514-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:31:47.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3969" for this suite.
Oct  2 21:31:53.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:31:53.477: INFO: namespace secrets-3969 deletion completed in 6.303880653s

• [SLOW TEST:8.526 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:31:53.478: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1694
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  2 21:31:53.552: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  2 21:32:13.720: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.13:8080/dial?request=hostName&protocol=http&host=10.244.0.12&port=8080&tries=1'] Namespace:pod-network-test-1694 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:32:13.720: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:32:14.034: INFO: Waiting for endpoints: map[]
Oct  2 21:32:14.041: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.13:8080/dial?request=hostName&protocol=http&host=10.244.1.44&port=8080&tries=1'] Namespace:pod-network-test-1694 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:32:14.041: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:32:14.294: INFO: Waiting for endpoints: map[]
Oct  2 21:32:14.301: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.13:8080/dial?request=hostName&protocol=http&host=10.244.2.40&port=8080&tries=1'] Namespace:pod-network-test-1694 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:32:14.301: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:32:14.615: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:32:14.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1694" for this suite.
Oct  2 21:32:38.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:32:38.889: INFO: namespace pod-network-test-1694 deletion completed in 24.266466572s

• [SLOW TEST:45.411 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:32:38.889: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct  2 21:32:39.007: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9949,SelfLink:/api/v1/namespaces/watch-9949/configmaps/e2e-watch-test-resource-version,UID:286ca5e7-e55c-11e9-884c-0a580aed1ab9,ResourceVersion:9443,Generation:0,CreationTimestamp:2019-10-02 21:32:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  2 21:32:39.008: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9949,SelfLink:/api/v1/namespaces/watch-9949/configmaps/e2e-watch-test-resource-version,UID:286ca5e7-e55c-11e9-884c-0a580aed1ab9,ResourceVersion:9444,Generation:0,CreationTimestamp:2019-10-02 21:32:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:32:39.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9949" for this suite.
Oct  2 21:32:45.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:32:45.264: INFO: namespace watch-9949 deletion completed in 6.249656044s

• [SLOW TEST:6.375 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:32:45.264: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-2c38f86b-e55c-11e9-bbfa-0a580af40203
STEP: Creating secret with name secret-projected-all-test-volume-2c38f846-e55c-11e9-bbfa-0a580af40203
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct  2 21:32:45.362: INFO: Waiting up to 5m0s for pod "projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203" in namespace "projected-1783" to be "success or failure"
Oct  2 21:32:45.370: INFO: Pod "projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.534583ms
Oct  2 21:32:47.379: INFO: Pod "projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017487842s
STEP: Saw pod success
Oct  2 21:32:47.379: INFO: Pod "projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:32:47.385: INFO: Trying to get logs from node 10.0.10.3 pod projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct  2 21:32:47.431: INFO: Waiting for pod projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:32:47.437: INFO: Pod projected-volume-2c38f7ff-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:32:47.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1783" for this suite.
Oct  2 21:32:53.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:32:53.703: INFO: namespace projected-1783 deletion completed in 6.25945049s

• [SLOW TEST:8.439 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:32:53.704: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-31426617-e55c-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:32:53.797: INFO: Waiting up to 5m0s for pod "pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203" in namespace "secrets-7626" to be "success or failure"
Oct  2 21:32:53.804: INFO: Pod "pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.120011ms
Oct  2 21:32:55.812: INFO: Pod "pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014430833s
STEP: Saw pod success
Oct  2 21:32:55.812: INFO: Pod "pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:32:55.817: INFO: Trying to get logs from node 10.0.10.4 pod pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:32:55.860: INFO: Waiting for pod pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:32:55.866: INFO: Pod pod-secrets-31448acc-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:32:55.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7626" for this suite.
Oct  2 21:33:01.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:33:02.157: INFO: namespace secrets-7626 deletion completed in 6.283709689s

• [SLOW TEST:8.453 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:33:02.158: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 21:33:02.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7958'
Oct  2 21:33:02.476: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  2 21:33:02.476: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Oct  2 21:33:02.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete jobs e2e-test-nginx-job --namespace=kubectl-7958'
Oct  2 21:33:02.685: INFO: stderr: ""
Oct  2 21:33:02.686: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:33:02.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7958" for this suite.
Oct  2 21:33:08.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:33:08.926: INFO: namespace kubectl-7958 deletion completed in 6.234946481s

• [SLOW TEST:6.769 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:33:08.927: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  2 21:33:09.014: INFO: Waiting up to 5m0s for pod "pod-3a55c87f-e55c-11e9-bbfa-0a580af40203" in namespace "emptydir-9768" to be "success or failure"
Oct  2 21:33:09.022: INFO: Pod "pod-3a55c87f-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.400311ms
Oct  2 21:33:11.028: INFO: Pod "pod-3a55c87f-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01369797s
Oct  2 21:33:13.036: INFO: Pod "pod-3a55c87f-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022072851s
STEP: Saw pod success
Oct  2 21:33:13.036: INFO: Pod "pod-3a55c87f-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:33:13.041: INFO: Trying to get logs from node 10.0.10.4 pod pod-3a55c87f-e55c-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:33:13.079: INFO: Waiting for pod pod-3a55c87f-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:33:13.086: INFO: Pod pod-3a55c87f-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:33:13.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9768" for this suite.
Oct  2 21:33:19.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:33:19.356: INFO: namespace emptydir-9768 deletion completed in 6.263117496s

• [SLOW TEST:10.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:33:19.357: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:33:19.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203" in namespace "downward-api-838" to be "success or failure"
Oct  2 21:33:19.440: INFO: Pod "downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.631544ms
Oct  2 21:33:21.446: INFO: Pod "downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016126815s
STEP: Saw pod success
Oct  2 21:33:21.446: INFO: Pod "downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:33:21.451: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:33:21.485: INFO: Waiting for pod downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:33:21.503: INFO: Pod downwardapi-volume-408b5ba7-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:33:21.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-838" for this suite.
Oct  2 21:33:27.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:33:27.739: INFO: namespace downward-api-838 deletion completed in 6.230120504s

• [SLOW TEST:8.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:33:27.741: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9335
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9335
STEP: Creating statefulset with conflicting port in namespace statefulset-9335
STEP: Waiting until pod test-pod will start running in namespace statefulset-9335
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9335
Oct  2 21:33:29.886: INFO: Observed stateful pod in namespace: statefulset-9335, name: ss-0, uid: 45ab5e45-e55c-11e9-a07f-0a580aed12b5, status phase: Pending. Waiting for statefulset controller to delete.
Oct  2 21:33:37.779: INFO: Observed stateful pod in namespace: statefulset-9335, name: ss-0, uid: 45ab5e45-e55c-11e9-a07f-0a580aed12b5, status phase: Failed. Waiting for statefulset controller to delete.
Oct  2 21:33:37.791: INFO: Observed stateful pod in namespace: statefulset-9335, name: ss-0, uid: 45ab5e45-e55c-11e9-a07f-0a580aed12b5, status phase: Failed. Waiting for statefulset controller to delete.
Oct  2 21:33:37.801: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9335
STEP: Removing pod with conflicting port in namespace statefulset-9335
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9335 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  2 21:33:41.844: INFO: Deleting all statefulset in ns statefulset-9335
Oct  2 21:33:41.850: INFO: Scaling statefulset ss to 0
Oct  2 21:33:51.877: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:33:51.882: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:33:51.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9335" for this suite.
Oct  2 21:33:57.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:33:58.156: INFO: namespace statefulset-9335 deletion completed in 6.244027488s

• [SLOW TEST:30.416 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:33:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-57ae90fa-e55c-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-57ae90fa-e55c-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:34:02.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3945" for this suite.
Oct  2 21:34:26.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:34:26.732: INFO: namespace configmap-3945 deletion completed in 24.318062714s

• [SLOW TEST:28.576 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:34:26.733: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:34:26.829: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct  2 21:34:31.836: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  2 21:34:31.836: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  2 21:34:31.873: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7454,SelfLink:/apis/apps/v1/namespaces/deployment-7454/deployments/test-cleanup-deployment,UID:6bb7fd62-e55c-11e9-884c-0a580aed1ab9,ResourceVersion:9960,Generation:1,CreationTimestamp:2019-10-02 21:34:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct  2 21:34:31.878: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct  2 21:34:31.878: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct  2 21:34:31.879: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-7454,SelfLink:/apis/apps/v1/namespaces/deployment-7454/replicasets/test-cleanup-controller,UID:68b71b6f-e55c-11e9-884c-0a580aed1ab9,ResourceVersion:9961,Generation:1,CreationTimestamp:2019-10-02 21:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6bb7fd62-e55c-11e9-884c-0a580aed1ab9 0xc001a3f63f 0xc001a3f650}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  2 21:34:31.884: INFO: Pod "test-cleanup-controller-rfz9p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-rfz9p,GenerateName:test-cleanup-controller-,Namespace:deployment-7454,SelfLink:/api/v1/namespaces/deployment-7454/pods/test-cleanup-controller-rfz9p,UID:68ba25e1-e55c-11e9-a07f-0a580aed12b5,ResourceVersion:9952,Generation:0,CreationTimestamp:2019-10-02 21:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 68b71b6f-e55c-11e9-884c-0a580aed1ab9 0xc001a3fb9f 0xc001a3fbb0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6qxbw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6qxbw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6qxbw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3fc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3fc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:34:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:34:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:34:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:34:26 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.44,StartTime:2019-10-02 21:34:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:34:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8f20d7b90893ef199a9b3c821efc8385988914afc6f509ed25036b6f5e09c115}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:34:31.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7454" for this suite.
Oct  2 21:34:37.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:34:38.156: INFO: namespace deployment-7454 deletion completed in 6.265790194s

• [SLOW TEST:11.423 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:34:38.156: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3106
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  2 21:34:38.227: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  2 21:34:56.385: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.45 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3106 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:34:56.385: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:34:57.700: INFO: Found all expected endpoints: [netserver-0]
Oct  2 21:34:57.707: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.48 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3106 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:34:57.707: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:34:58.967: INFO: Found all expected endpoints: [netserver-1]
Oct  2 21:34:58.981: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.16 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3106 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:34:58.981: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:35:00.289: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:35:00.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3106" for this suite.
Oct  2 21:35:24.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:35:24.550: INFO: namespace pod-network-test-3106 deletion completed in 24.253104355s

• [SLOW TEST:46.394 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:35:24.550: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  2 21:35:29.222: INFO: Successfully updated pod "annotationupdate8b29f590-e55c-11e9-bbfa-0a580af40203"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:35:31.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7326" for this suite.
Oct  2 21:35:55.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:35:55.592: INFO: namespace downward-api-7326 deletion completed in 24.276339895s

• [SLOW TEST:31.042 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:35:55.593: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8694
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct  2 21:35:55.699: INFO: Found 0 stateful pods, waiting for 3
Oct  2 21:36:05.710: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:36:05.710: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:36:05.710: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct  2 21:36:05.756: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct  2 21:36:15.805: INFO: Updating stateful set ss2
Oct  2 21:36:15.817: INFO: Waiting for Pod statefulset-8694/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:36:25.830: INFO: Waiting for Pod statefulset-8694/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct  2 21:36:35.877: INFO: Found 2 stateful pods, waiting for 3
Oct  2 21:36:45.887: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:36:45.887: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:36:45.887: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct  2 21:36:45.934: INFO: Updating stateful set ss2
Oct  2 21:36:45.945: INFO: Waiting for Pod statefulset-8694/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:36:55.959: INFO: Waiting for Pod statefulset-8694/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  2 21:37:05.984: INFO: Updating stateful set ss2
Oct  2 21:37:06.002: INFO: Waiting for StatefulSet statefulset-8694/ss2 to complete update
Oct  2 21:37:06.002: INFO: Waiting for Pod statefulset-8694/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  2 21:37:16.016: INFO: Deleting all statefulset in ns statefulset-8694
Oct  2 21:37:16.023: INFO: Scaling statefulset ss2 to 0
Oct  2 21:37:36.050: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:37:36.056: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:37:36.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8694" for this suite.
Oct  2 21:37:44.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:37:44.360: INFO: namespace statefulset-8694 deletion completed in 8.266846285s

• [SLOW TEST:108.767 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:37:44.360: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Oct  2 21:37:44.444: INFO: Waiting up to 5m0s for pod "client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203" in namespace "containers-5143" to be "success or failure"
Oct  2 21:37:44.455: INFO: Pod "client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.278845ms
Oct  2 21:37:46.461: INFO: Pod "client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016744958s
Oct  2 21:37:48.475: INFO: Pod "client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030877931s
STEP: Saw pod success
Oct  2 21:37:48.475: INFO: Pod "client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:37:48.481: INFO: Trying to get logs from node 10.0.10.3 pod client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:37:48.526: INFO: Waiting for pod client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:37:48.537: INFO: Pod client-containers-de809aa5-e55c-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:37:48.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5143" for this suite.
Oct  2 21:37:54.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:37:54.788: INFO: namespace containers-5143 deletion completed in 6.243942848s

• [SLOW TEST:10.428 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:37:54.789: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:37:54.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3451" for this suite.
Oct  2 21:38:18.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:38:19.148: INFO: namespace pods-3451 deletion completed in 24.263553363s

• [SLOW TEST:24.360 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:38:19.149: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Oct  2 21:38:19.225: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct  2 21:38:19.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:19.654: INFO: stderr: ""
Oct  2 21:38:19.654: INFO: stdout: "service/redis-slave created\n"
Oct  2 21:38:19.654: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct  2 21:38:19.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:20.044: INFO: stderr: ""
Oct  2 21:38:20.044: INFO: stdout: "service/redis-master created\n"
Oct  2 21:38:20.045: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct  2 21:38:20.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:20.421: INFO: stderr: ""
Oct  2 21:38:20.421: INFO: stdout: "service/frontend created\n"
Oct  2 21:38:20.422: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct  2 21:38:20.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:20.816: INFO: stderr: ""
Oct  2 21:38:20.816: INFO: stdout: "deployment.apps/frontend created\n"
Oct  2 21:38:20.817: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  2 21:38:20.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:21.145: INFO: stderr: ""
Oct  2 21:38:21.145: INFO: stdout: "deployment.apps/redis-master created\n"
Oct  2 21:38:21.145: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct  2 21:38:21.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-2113'
Oct  2 21:38:21.595: INFO: stderr: ""
Oct  2 21:38:21.595: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct  2 21:38:21.595: INFO: Waiting for all frontend pods to be Running.
Oct  2 21:38:51.646: INFO: Waiting for frontend to serve content.
Oct  2 21:38:51.743: INFO: Trying to add a new entry to the guestbook.
Oct  2 21:38:51.890: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct  2 21:38:51.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.177: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.177: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct  2 21:38:52.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.345: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.345: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  2 21:38:52.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.529: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  2 21:38:52.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.671: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.671: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  2 21:38:52.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.791: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.791: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  2 21:38:52.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete --grace-period=0 --force -f - --namespace=kubectl-2113'
Oct  2 21:38:52.955: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  2 21:38:52.955: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:38:52.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2113" for this suite.
Oct  2 21:39:33.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:39:33.309: INFO: namespace kubectl-2113 deletion completed in 40.327660105s

• [SLOW TEST:74.160 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:39:33.310: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Oct  2 21:39:33.379: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-715202161 proxy --unix-socket=/tmp/kubectl-proxy-unix046173712/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:39:33.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7522" for this suite.
Oct  2 21:39:39.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:39:39.685: INFO: namespace kubectl-7522 deletion completed in 6.240597413s

• [SLOW TEST:6.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:39:39.685: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:39:39.759: INFO: Waiting up to 5m0s for pod "downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203" in namespace "projected-4782" to be "success or failure"
Oct  2 21:39:39.769: INFO: Pod "downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.748247ms
Oct  2 21:39:41.776: INFO: Pod "downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017004166s
STEP: Saw pod success
Oct  2 21:39:41.776: INFO: Pod "downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:39:41.782: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:39:41.820: INFO: Waiting for pod downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:39:41.825: INFO: Pod downwardapi-volume-233cc2e4-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:39:41.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4782" for this suite.
Oct  2 21:39:47.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:39:48.083: INFO: namespace projected-4782 deletion completed in 6.251422369s

• [SLOW TEST:8.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:39:48.084: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:39:48.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-4719'
Oct  2 21:39:48.378: INFO: stderr: ""
Oct  2 21:39:48.378: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct  2 21:39:48.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-4719'
Oct  2 21:39:48.707: INFO: stderr: ""
Oct  2 21:39:48.708: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  2 21:39:49.715: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:39:49.715: INFO: Found 1 / 1
Oct  2 21:39:49.716: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  2 21:39:49.721: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 21:39:49.721: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  2 21:39:49.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 describe pod redis-master-hfb55 --namespace=kubectl-4719'
Oct  2 21:39:49.874: INFO: stderr: ""
Oct  2 21:39:49.874: INFO: stdout: "Name:               redis-master-hfb55\nNamespace:          kubectl-4719\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.0.10.4/10.0.10.4\nStart Time:         Wed, 02 Oct 2019 21:39:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.56\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://41f4f77784360c243ef106bb8434f76e9d0e1357bbd3b6bda3d25b3edf95f950\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 02 Oct 2019 21:39:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pmbvq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pmbvq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pmbvq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  1s    default-scheduler   Successfully assigned kubectl-4719/redis-master-hfb55 to 10.0.10.4\n  Normal  Pulled     0s    kubelet, 10.0.10.4  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, 10.0.10.4  Created container redis-master\n  Normal  Started    0s    kubelet, 10.0.10.4  Started container redis-master\n"
Oct  2 21:39:49.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 describe rc redis-master --namespace=kubectl-4719'
Oct  2 21:39:50.023: INFO: stderr: ""
Oct  2 21:39:50.023: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4719\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-hfb55\n"
Oct  2 21:39:50.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 describe service redis-master --namespace=kubectl-4719'
Oct  2 21:39:50.154: INFO: stderr: ""
Oct  2 21:39:50.154: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4719\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.198.211\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.56:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct  2 21:39:50.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 describe node 10.0.10.2'
Oct  2 21:39:50.327: INFO: stderr: ""
Oct  2 21:39:50.327: INFO: stdout: "Name:               10.0.10.2\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=VM.Standard1.1\n                    beta.kubernetes.io/os=linux\n                    displayName=fk-czdgyzugbqw-nygenbymezw-s5xdityhsda-0\n                    failure-domain.beta.kubernetes.io/region=iad\n                    failure-domain.beta.kubernetes.io/zone=US-ASHBURN-AD-3\n                    hostname=fk-czdgyzugbqw-nygenbymezw-s5xdityhsda-0\n                    internal_addr=10.0.10.2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.0.10.2\n                    kubernetes.io/os=linux\n                    name=pool1\n                    node-role.kubernetes.io/node=\n                    node.info/compartment.id_prefix=\n                    node.info/compartment.id_suffix=\n                    node.info/compartment.name=IaaSInternal.fred.kuo\n                    node.info/kubeletVersion=v1.14\n                    oke.oraclecloud.com/node.info.private_subnet=true\n                    oke.oraclecloud.com/node.info.private_worker=true\n                    oke.oraclecloud.com/tenant_agent.version=1.9.2-0cfe77961\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.0.10.2\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"5a:08:07:f0:38:4f\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.10.2\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 02 Oct 2019 20:51:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 02 Oct 2019 21:38:51 +0000   Wed, 02 Oct 2019 20:51:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 02 Oct 2019 21:38:51 +0000   Wed, 02 Oct 2019 20:51:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 02 Oct 2019 21:38:51 +0000   Wed, 02 Oct 2019 20:51:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 02 Oct 2019 21:38:51 +0000   Wed, 02 Oct 2019 20:52:08 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.10.2\nCapacity:\n cpu:                2\n ephemeral-storage:  40223552Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6858548Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37070025462\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6756148Ki\n pods:               110\nSystem Info:\n Machine ID:                 f55882225d9147c598d6cfcca167e226\n System UUID:                D7477E1A-D6D1-4A7E-ADEA-98332C10326F\n Boot ID:                    f144b89c-f978-4e57-92d7-05cff82b6443\n Kernel Version:             4.14.35-1902.2.0.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.6\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.14.6\n Kube-Proxy Version:         v1.14.6\nPodCIDR:                     10.244.0.0/24\nProviderID:                  ocid1.instance.oc1.iad.abuwcljr7hvdo6uigdhdwlinlrnn2hqtajojhin6g4br33e3bgqxx7a7ut7a\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-hngt6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                coredns-56969c94-q4m8c                                     100m (5%)     0 (0%)      70Mi (1%)        170Mi (2%)     53m\n  kube-system                kube-dns-autoscaler-5987f4cd86-snh94                       20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         53m\n  kube-system                kube-flannel-ds-bgwzj                                      100m (5%)     1 (50%)     50Mi (0%)        500Mi (7%)     48m\n  kube-system                kube-proxy-8j7cc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kubernetes-dashboard-5c75764dd6-5fg46                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  kube-system                proxymux-client-10.0.10.2                                  50m (2%)      500m (25%)  64Mi (0%)        256Mi (3%)     48m\n  kube-system                tiller-deploy-785fd4d8b5-lmpfd                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                270m (13%)  1500m (75%)\n  memory             194Mi (2%)  926Mi (14%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age   From                   Message\n  ----    ------                   ----  ----                   -------\n  Normal  Starting                 48m   kubelet, 10.0.10.2     Starting kubelet.\n  Normal  Starting                 48m   kubelet, 10.0.10.2     Starting kubelet.\n  Normal  Starting                 48m   kubelet, 10.0.10.2     Starting kubelet.\n  Normal  NodeHasSufficientMemory  48m   kubelet, 10.0.10.2     Node 10.0.10.2 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    48m   kubelet, 10.0.10.2     Node 10.0.10.2 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     48m   kubelet, 10.0.10.2     Node 10.0.10.2 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  48m   kubelet, 10.0.10.2     Updated Node Allocatable limit across pods\n  Normal  Starting                 47m   kube-proxy, 10.0.10.2  Starting kube-proxy.\n  Normal  NodeReady                47m   kubelet, 10.0.10.2     Node 10.0.10.2 status is now: NodeReady\n"
Oct  2 21:39:50.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 describe namespace kubectl-4719'
Oct  2 21:39:50.447: INFO: stderr: ""
Oct  2 21:39:50.447: INFO: stdout: "Name:         kubectl-4719\nLabels:       e2e-framework=kubectl\n              e2e-run=b2e9ea31-e558-11e9-bbfa-0a580af40203\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:39:50.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4719" for this suite.
Oct  2 21:40:14.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:40:14.714: INFO: namespace kubectl-4719 deletion completed in 24.259222179s

• [SLOW TEST:26.631 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:40:14.715: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-38205d08-e55d-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:40:14.812: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203" in namespace "projected-3950" to be "success or failure"
Oct  2 21:40:14.819: INFO: Pod "pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.728902ms
Oct  2 21:40:16.830: INFO: Pod "pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017808535s
STEP: Saw pod success
Oct  2 21:40:16.830: INFO: Pod "pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:40:16.836: INFO: Trying to get logs from node 10.0.10.3 pod pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:40:16.870: INFO: Waiting for pod pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:40:16.877: INFO: Pod pod-projected-secrets-382265ae-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:40:16.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3950" for this suite.
Oct  2 21:40:22.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:40:23.166: INFO: namespace projected-3950 deletion completed in 6.273924189s

• [SLOW TEST:8.451 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:40:23.166: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:40:23.230: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:40:25.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-230" for this suite.
Oct  2 21:41:09.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:09.820: INFO: namespace pods-230 deletion completed in 44.296065733s

• [SLOW TEST:46.654 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:09.820: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Oct  2 21:41:09.932: INFO: Waiting up to 5m0s for pod "client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203" in namespace "containers-8409" to be "success or failure"
Oct  2 21:41:09.939: INFO: Pod "client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.559487ms
Oct  2 21:41:11.947: INFO: Pod "client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015465682s
STEP: Saw pod success
Oct  2 21:41:11.947: INFO: Pod "client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:41:11.953: INFO: Trying to get logs from node 10.0.10.3 pod client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:41:11.993: INFO: Waiting for pod client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:41:11.999: INFO: Pod client-containers-58f9045d-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:41:11.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8409" for this suite.
Oct  2 21:41:18.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:18.258: INFO: namespace containers-8409 deletion completed in 6.252839793s

• [SLOW TEST:8.438 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:18.258: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:41:18.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203" in namespace "downward-api-1577" to be "success or failure"
Oct  2 21:41:18.339: INFO: Pod "downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.498338ms
Oct  2 21:41:20.346: INFO: Pod "downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013538687s
STEP: Saw pod success
Oct  2 21:41:20.346: INFO: Pod "downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:41:20.353: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:41:20.412: INFO: Waiting for pod downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:41:20.418: INFO: Pod downwardapi-volume-5dfdaa0b-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:41:20.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1577" for this suite.
Oct  2 21:41:26.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:26.665: INFO: namespace downward-api-1577 deletion completed in 6.240706003s

• [SLOW TEST:8.407 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:26.665: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:41:26.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203" in namespace "downward-api-7490" to be "success or failure"
Oct  2 21:41:26.759: INFO: Pod "downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.6287ms
Oct  2 21:41:28.767: INFO: Pod "downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01997215s
STEP: Saw pod success
Oct  2 21:41:28.767: INFO: Pod "downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:41:28.773: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:41:28.810: INFO: Waiting for pod downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:41:28.816: INFO: Pod downwardapi-volume-6301d5d1-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:41:28.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7490" for this suite.
Oct  2 21:41:34.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:35.116: INFO: namespace downward-api-7490 deletion completed in 6.293274077s

• [SLOW TEST:8.451 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:35.116: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1002 21:41:41.275466      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 21:41:41.275: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:41:41.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3295" for this suite.
Oct  2 21:41:49.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:49.537: INFO: namespace gc-3295 deletion completed in 8.255019479s

• [SLOW TEST:14.421 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:49.538: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-70a532e9-e55d-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:41:49.721: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203" in namespace "projected-9116" to be "success or failure"
Oct  2 21:41:49.730: INFO: Pod "pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.48443ms
Oct  2 21:41:51.739: INFO: Pod "pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017516996s
STEP: Saw pod success
Oct  2 21:41:51.739: INFO: Pod "pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:41:51.745: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:41:51.786: INFO: Waiting for pod pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:41:51.792: INFO: Pod pod-projected-secrets-70b1aab6-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:41:51.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9116" for this suite.
Oct  2 21:41:57.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:41:58.060: INFO: namespace projected-9116 deletion completed in 6.2588827s

• [SLOW TEST:8.522 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:41:58.060: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:42:00.201: INFO: Waiting up to 5m0s for pod "client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203" in namespace "pods-1926" to be "success or failure"
Oct  2 21:42:00.215: INFO: Pod "client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 13.980525ms
Oct  2 21:42:02.222: INFO: Pod "client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020841073s
STEP: Saw pod success
Oct  2 21:42:02.222: INFO: Pod "client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:42:02.228: INFO: Trying to get logs from node 10.0.10.4 pod client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203 container env3cont: <nil>
STEP: delete the pod
Oct  2 21:42:02.348: INFO: Waiting for pod client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:42:02.356: INFO: Pod client-envvars-76f42351-e55d-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:42:02.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1926" for this suite.
Oct  2 21:42:44.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:42:44.692: INFO: namespace pods-1926 deletion completed in 42.328217788s

• [SLOW TEST:46.632 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:42:44.693: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7437
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7437
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7437
Oct  2 21:42:44.795: INFO: Found 0 stateful pods, waiting for 1
Oct  2 21:42:54.812: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct  2 21:42:54.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:42:55.340: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:42:55.340: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:42:55.340: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:42:55.347: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  2 21:43:05.355: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:43:05.355: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:43:05.396: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999748s
Oct  2 21:43:06.404: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990479199s
Oct  2 21:43:07.411: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98266811s
Oct  2 21:43:08.417: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975668104s
Oct  2 21:43:09.423: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.969520038s
Oct  2 21:43:10.438: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.963387224s
Oct  2 21:43:11.445: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.947963169s
Oct  2 21:43:12.453: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.940910423s
Oct  2 21:43:13.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.933651963s
Oct  2 21:43:14.467: INFO: Verifying statefulset ss doesn't scale past 1 for another 925.668396ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7437
Oct  2 21:43:15.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:43:15.892: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:43:15.892: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:43:15.892: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:43:15.904: INFO: Found 1 stateful pods, waiting for 3
Oct  2 21:43:25.911: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:43:25.911: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:43:25.911: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct  2 21:43:25.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:43:26.325: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:43:26.325: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:43:26.325: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:43:26.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:43:26.809: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:43:26.809: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:43:26.810: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:43:26.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:43:27.237: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:43:27.237: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:43:27.237: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:43:27.237: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:43:27.244: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  2 21:43:37.257: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:43:37.257: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:43:37.257: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:43:37.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999758s
Oct  2 21:43:38.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993622469s
Oct  2 21:43:39.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985275498s
Oct  2 21:43:40.300: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977593247s
Oct  2 21:43:41.317: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969685783s
Oct  2 21:43:42.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.953459013s
Oct  2 21:43:43.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.946009992s
Oct  2 21:43:44.340: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.938929032s
Oct  2 21:43:45.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.929882695s
Oct  2 21:43:46.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 922.889673ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7437
Oct  2 21:43:47.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:43:47.712: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:43:47.712: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:43:47.712: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:43:47.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:43:48.226: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:43:48.226: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:43:48.226: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:43:48.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:43:48.551: INFO: rc: 1
Oct  2 21:43:48.551: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc0024734d0 exit status 1 <nil> <nil> true [0xc002406a50 0xc002406a68 0xc002406a80] [0xc002406a50 0xc002406a68 0xc002406a80] [0xc002406a60 0xc002406a78] [0x9c0ae0 0x9c0ae0] 0xc0024f3f80 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1

Oct  2 21:43:58.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:43:58.727: INFO: rc: 1
Oct  2 21:43:58.727: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00172d9b0 exit status 1 <nil> <nil> true [0xc002d6b4e8 0xc002d6b500 0xc002d6b518] [0xc002d6b4e8 0xc002d6b500 0xc002d6b518] [0xc002d6b4f8 0xc002d6b510] [0x9c0ae0 0x9c0ae0] 0xc0020c6ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:08.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:08.836: INFO: rc: 1
Oct  2 21:44:08.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002473980 exit status 1 <nil> <nil> true [0xc002406a88 0xc002406aa0 0xc002406ab8] [0xc002406a88 0xc002406aa0 0xc002406ab8] [0xc002406a98 0xc002406ab0] [0x9c0ae0 0x9c0ae0] 0xc00311ca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:18.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:18.959: INFO: rc: 1
Oct  2 21:44:18.960: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a300 exit status 1 <nil> <nil> true [0xc002406008 0xc002406020 0xc002406038] [0xc002406008 0xc002406020 0xc002406038] [0xc002406018 0xc002406030] [0x9c0ae0 0x9c0ae0] 0xc0024f2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:28.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:29.063: INFO: rc: 1
Oct  2 21:44:29.063: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dba3c0 exit status 1 <nil> <nil> true [0xc002d6a000 0xc002d6a018 0xc002d6a050] [0xc002d6a000 0xc002d6a018 0xc002d6a050] [0xc002d6a010 0xc002d6a030] [0x9c0ae0 0x9c0ae0] 0xc001ab8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:39.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:39.162: INFO: rc: 1
Oct  2 21:44:39.162: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dba750 exit status 1 <nil> <nil> true [0xc002d6a068 0xc002d6a0c0 0xc002d6a118] [0xc002d6a068 0xc002d6a0c0 0xc002d6a118] [0xc002d6a0a0 0xc002d6a100] [0x9c0ae0 0x9c0ae0] 0xc001ab8ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:49.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:49.261: INFO: rc: 1
Oct  2 21:44:49.261: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbaab0 exit status 1 <nil> <nil> true [0xc002d6a120 0xc002d6a148 0xc002d6a170] [0xc002d6a120 0xc002d6a148 0xc002d6a170] [0xc002d6a130 0xc002d6a168] [0x9c0ae0 0x9c0ae0] 0xc001ab9080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:44:59.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:44:59.368: INFO: rc: 1
Oct  2 21:44:59.368: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbaea0 exit status 1 <nil> <nil> true [0xc002d6a178 0xc002d6a1b8 0xc002d6a1d8] [0xc002d6a178 0xc002d6a1b8 0xc002d6a1d8] [0xc002d6a1b0 0xc002d6a1c8] [0x9c0ae0 0x9c0ae0] 0xc001ab9440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:09.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:45:09.474: INFO: rc: 1
Oct  2 21:45:09.475: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a7b0 exit status 1 <nil> <nil> true [0xc002406040 0xc002406058 0xc002406070] [0xc002406040 0xc002406058 0xc002406070] [0xc002406050 0xc002406068] [0x9c0ae0 0x9c0ae0] 0xc0024f2b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:19.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:45:19.577: INFO: rc: 1
Oct  2 21:45:19.577: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbb2c0 exit status 1 <nil> <nil> true [0xc002d6a1f8 0xc002d6a258 0xc002d6a2a8] [0xc002d6a1f8 0xc002d6a258 0xc002d6a2a8] [0xc002d6a230 0xc002d6a288] [0x9c0ae0 0x9c0ae0] 0xc001ab9800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:29.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:45:29.692: INFO: rc: 1
Oct  2 21:45:29.692: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbb650 exit status 1 <nil> <nil> true [0xc002d6a2c0 0xc002d6a2d8 0xc002d6a300] [0xc002d6a2c0 0xc002d6a2d8 0xc002d6a300] [0xc002d6a2d0 0xc002d6a2e8] [0x9c0ae0 0x9c0ae0] 0xc001ab9b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:39.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:45:39.803: INFO: rc: 1
Oct  2 21:45:39.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280ab70 exit status 1 <nil> <nil> true [0xc002406078 0xc0024060a8 0xc0024060c0] [0xc002406078 0xc0024060a8 0xc0024060c0] [0xc002406098 0xc0024060b8] [0x9c0ae0 0x9c0ae0] 0xc0024f30e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:49.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:45:49.898: INFO: rc: 1
Oct  2 21:45:49.898: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280af30 exit status 1 <nil> <nil> true [0xc0024060c8 0xc0024060e0 0xc002406100] [0xc0024060c8 0xc0024060e0 0xc002406100] [0xc0024060d8 0xc0024060f8] [0x9c0ae0 0x9c0ae0] 0xc0024f3440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:45:59.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:00.014: INFO: rc: 1
Oct  2 21:46:00.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280b290 exit status 1 <nil> <nil> true [0xc002406108 0xc002406120 0xc002406138] [0xc002406108 0xc002406120 0xc002406138] [0xc002406118 0xc002406130] [0x9c0ae0 0x9c0ae0] 0xc0024f37a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:46:10.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:10.122: INFO: rc: 1
Oct  2 21:46:10.123: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbba10 exit status 1 <nil> <nil> true [0xc002d6a318 0xc002d6a370 0xc002d6a3c0] [0xc002d6a318 0xc002d6a370 0xc002d6a3c0] [0xc002d6a350 0xc002d6a3a8] [0x9c0ae0 0x9c0ae0] 0xc001ab9f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:46:20.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:20.217: INFO: rc: 1
Oct  2 21:46:20.217: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a360 exit status 1 <nil> <nil> true [0xc002406008 0xc002406020 0xc002406038] [0xc002406008 0xc002406020 0xc002406038] [0xc002406018 0xc002406030] [0x9c0ae0 0x9c0ae0] 0xc001ab8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:46:30.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:30.318: INFO: rc: 1
Oct  2 21:46:30.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a840 exit status 1 <nil> <nil> true [0xc002406040 0xc002406058 0xc002406070] [0xc002406040 0xc002406058 0xc002406070] [0xc002406050 0xc002406068] [0x9c0ae0 0x9c0ae0] 0xc001ab8ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:46:40.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:40.420: INFO: rc: 1
Oct  2 21:46:40.420: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280ac30 exit status 1 <nil> <nil> true [0xc002406078 0xc0024060a8 0xc0024060c0] [0xc002406078 0xc0024060a8 0xc0024060c0] [0xc002406098 0xc0024060b8] [0x9c0ae0 0x9c0ae0] 0xc001ab9080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:46:50.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:46:50.519: INFO: rc: 1
Oct  2 21:46:50.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280aff0 exit status 1 <nil> <nil> true [0xc0024060c8 0xc0024060e0 0xc002406100] [0xc0024060c8 0xc0024060e0 0xc002406100] [0xc0024060d8 0xc0024060f8] [0x9c0ae0 0x9c0ae0] 0xc001ab9440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:00.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:00.612: INFO: rc: 1
Oct  2 21:47:00.612: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dba390 exit status 1 <nil> <nil> true [0xc002d6a000 0xc002d6a018 0xc002d6a050] [0xc002d6a000 0xc002d6a018 0xc002d6a050] [0xc002d6a010 0xc002d6a030] [0x9c0ae0 0x9c0ae0] 0xc0024f2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:10.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:10.702: INFO: rc: 1
Oct  2 21:47:10.702: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dba720 exit status 1 <nil> <nil> true [0xc002d6a068 0xc002d6a0c0 0xc002d6a118] [0xc002d6a068 0xc002d6a0c0 0xc002d6a118] [0xc002d6a0a0 0xc002d6a100] [0x9c0ae0 0x9c0ae0] 0xc0024f2b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:20.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:20.813: INFO: rc: 1
Oct  2 21:47:20.813: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbaae0 exit status 1 <nil> <nil> true [0xc002d6a120 0xc002d6a148 0xc002d6a170] [0xc002d6a120 0xc002d6a148 0xc002d6a170] [0xc002d6a130 0xc002d6a168] [0x9c0ae0 0x9c0ae0] 0xc0024f30e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:30.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:30.923: INFO: rc: 1
Oct  2 21:47:30.923: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280b590 exit status 1 <nil> <nil> true [0xc002406108 0xc002406120 0xc002406138] [0xc002406108 0xc002406120 0xc002406138] [0xc002406118 0xc002406130] [0x9c0ae0 0x9c0ae0] 0xc001ab9800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:40.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:41.026: INFO: rc: 1
Oct  2 21:47:41.027: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbaed0 exit status 1 <nil> <nil> true [0xc002d6a178 0xc002d6a1b8 0xc002d6a1d8] [0xc002d6a178 0xc002d6a1b8 0xc002d6a1d8] [0xc002d6a1b0 0xc002d6a1c8] [0x9c0ae0 0x9c0ae0] 0xc0024f3440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:47:51.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:47:51.139: INFO: rc: 1
Oct  2 21:47:51.139: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbb320 exit status 1 <nil> <nil> true [0xc002d6a1f8 0xc002d6a258 0xc002d6a2a8] [0xc002d6a1f8 0xc002d6a258 0xc002d6a2a8] [0xc002d6a230 0xc002d6a288] [0x9c0ae0 0x9c0ae0] 0xc0024f37a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:01.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:01.235: INFO: rc: 1
Oct  2 21:48:01.235: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280b8f0 exit status 1 <nil> <nil> true [0xc002406140 0xc002406158 0xc002406170] [0xc002406140 0xc002406158 0xc002406170] [0xc002406150 0xc002406168] [0x9c0ae0 0x9c0ae0] 0xc001ab9b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:11.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:11.355: INFO: rc: 1
Oct  2 21:48:11.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dbb6b0 exit status 1 <nil> <nil> true [0xc002d6a2c0 0xc002d6a2d8 0xc002d6a300] [0xc002d6a2c0 0xc002d6a2d8 0xc002d6a300] [0xc002d6a2d0 0xc002d6a2e8] [0x9c0ae0 0x9c0ae0] 0xc0024f3b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:21.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:21.456: INFO: rc: 1
Oct  2 21:48:21.456: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002dba2d0 exit status 1 <nil> <nil> true [0xc002d6a008 0xc002d6a020 0xc002d6a068] [0xc002d6a008 0xc002d6a020 0xc002d6a068] [0xc002d6a018 0xc002d6a050] [0x9c0ae0 0x9c0ae0] 0xc0024f2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:31.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:31.567: INFO: rc: 1
Oct  2 21:48:31.568: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a420 exit status 1 <nil> <nil> true [0xc002406000 0xc002406018 0xc002406030] [0xc002406000 0xc002406018 0xc002406030] [0xc002406010 0xc002406028] [0x9c0ae0 0x9c0ae0] 0xc001ab8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:41.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:41.666: INFO: rc: 1
Oct  2 21:48:41.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00280a900 exit status 1 <nil> <nil> true [0xc002406038 0xc002406050 0xc002406068] [0xc002406038 0xc002406050 0xc002406068] [0xc002406048 0xc002406060] [0x9c0ae0 0x9c0ae0] 0xc001ab8ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:48:51.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-7437 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:48:51.779: INFO: rc: 1
Oct  2 21:48:51.779: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Oct  2 21:48:51.779: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  2 21:48:51.804: INFO: Deleting all statefulset in ns statefulset-7437
Oct  2 21:48:51.810: INFO: Scaling statefulset ss to 0
Oct  2 21:48:51.827: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:48:51.832: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:48:51.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7437" for this suite.
Oct  2 21:48:57.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:48:58.131: INFO: namespace statefulset-7437 deletion completed in 6.264452848s

• [SLOW TEST:373.438 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:48:58.131: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:48:58.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203" in namespace "projected-6065" to be "success or failure"
Oct  2 21:48:58.216: INFO: Pod "downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.139183ms
Oct  2 21:49:00.228: INFO: Pod "downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018098859s
Oct  2 21:49:02.237: INFO: Pod "downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026719963s
STEP: Saw pod success
Oct  2 21:49:02.237: INFO: Pod "downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:49:02.242: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:49:02.330: INFO: Waiting for pod downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:49:02.336: INFO: Pod downwardapi-volume-701953dc-e55e-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:49:02.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6065" for this suite.
Oct  2 21:49:08.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:49:08.572: INFO: namespace projected-6065 deletion completed in 6.229482372s

• [SLOW TEST:10.441 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:49:08.572: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct  2 21:49:12.734: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:12.734: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:13.019: INFO: Exec stderr: ""
Oct  2 21:49:13.019: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:13.019: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:13.418: INFO: Exec stderr: ""
Oct  2 21:49:13.418: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:13.418: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:13.679: INFO: Exec stderr: ""
Oct  2 21:49:13.679: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:13.679: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:13.914: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct  2 21:49:13.914: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:13.914: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:14.220: INFO: Exec stderr: ""
Oct  2 21:49:14.220: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:14.220: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:14.536: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct  2 21:49:14.536: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:14.536: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:14.803: INFO: Exec stderr: ""
Oct  2 21:49:14.803: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:14.803: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:15.082: INFO: Exec stderr: ""
Oct  2 21:49:15.082: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:15.082: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:15.413: INFO: Exec stderr: ""
Oct  2 21:49:15.413: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 21:49:15.413: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 21:49:15.713: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:49:15.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5915" for this suite.
Oct  2 21:49:55.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:49:55.974: INFO: namespace e2e-kubelet-etc-hosts-5915 deletion completed in 40.253642652s

• [SLOW TEST:47.402 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:49:55.974: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203
Oct  2 21:49:56.071: INFO: Pod name my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203: Found 0 pods out of 1
Oct  2 21:50:01.090: INFO: Pod name my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203: Found 1 pods out of 1
Oct  2 21:50:01.090: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203" are running
Oct  2 21:50:01.098: INFO: Pod "my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203-m969w" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 21:49:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 21:49:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 21:49:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 21:49:56 +0000 UTC Reason: Message:}])
Oct  2 21:50:01.098: INFO: Trying to dial the pod
Oct  2 21:50:06.210: INFO: Controller my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203: Got expected result from replica 1 [my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203-m969w]: "my-hostname-basic-9293ac55-e55e-11e9-bbfa-0a580af40203-m969w", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:50:06.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1967" for this suite.
Oct  2 21:50:12.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:50:12.441: INFO: namespace replication-controller-1967 deletion completed in 6.223398878s

• [SLOW TEST:16.467 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:50:12.441: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1002 21:50:13.590504      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 21:50:13.590: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:50:13.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3929" for this suite.
Oct  2 21:50:19.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:50:19.844: INFO: namespace gc-3929 deletion completed in 6.246951694s

• [SLOW TEST:7.403 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:50:19.845: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:50:26.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2337" for this suite.
Oct  2 21:50:32.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:50:32.331: INFO: namespace namespaces-2337 deletion completed in 6.239412876s
STEP: Destroying namespace "nsdeletetest-1657" for this suite.
Oct  2 21:50:32.337: INFO: Namespace nsdeletetest-1657 was already deleted
STEP: Destroying namespace "nsdeletetest-2948" for this suite.
Oct  2 21:50:38.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:50:38.598: INFO: namespace nsdeletetest-2948 deletion completed in 6.260112868s

• [SLOW TEST:18.753 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:50:38.598: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Oct  2 21:50:38.720: INFO: Waiting up to 5m0s for pod "client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203" in namespace "containers-8636" to be "success or failure"
Oct  2 21:50:38.728: INFO: Pod "client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.371553ms
Oct  2 21:50:40.734: INFO: Pod "client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014079857s
Oct  2 21:50:42.741: INFO: Pod "client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02083967s
STEP: Saw pod success
Oct  2 21:50:42.741: INFO: Pod "client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:50:42.747: INFO: Trying to get logs from node 10.0.10.4 pod client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:50:42.830: INFO: Waiting for pod client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:50:42.838: INFO: Pod client-containers-ac028a3b-e55e-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:50:42.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8636" for this suite.
Oct  2 21:50:48.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:50:49.168: INFO: namespace containers-8636 deletion completed in 6.323038041s

• [SLOW TEST:10.570 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:50:49.170: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-bxld
STEP: Creating a pod to test atomic-volume-subpath
Oct  2 21:50:49.292: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-bxld" in namespace "subpath-7109" to be "success or failure"
Oct  2 21:50:49.299: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Pending", Reason="", readiness=false. Elapsed: 6.879176ms
Oct  2 21:50:51.307: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01427379s
Oct  2 21:50:53.314: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 4.021468413s
Oct  2 21:50:55.321: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 6.028739957s
Oct  2 21:50:57.338: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 8.045807587s
Oct  2 21:50:59.344: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 10.051847183s
Oct  2 21:51:01.359: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 12.066543441s
Oct  2 21:51:03.376: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 14.083291816s
Oct  2 21:51:05.383: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 16.090847789s
Oct  2 21:51:07.390: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 18.097622882s
Oct  2 21:51:09.397: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 20.104548156s
Oct  2 21:51:11.405: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Running", Reason="", readiness=true. Elapsed: 22.112575728s
Oct  2 21:51:13.413: INFO: Pod "pod-subpath-test-secret-bxld": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.120817479s
STEP: Saw pod success
Oct  2 21:51:13.413: INFO: Pod "pod-subpath-test-secret-bxld" satisfied condition "success or failure"
Oct  2 21:51:13.419: INFO: Trying to get logs from node 10.0.10.3 pod pod-subpath-test-secret-bxld container test-container-subpath-secret-bxld: <nil>
STEP: delete the pod
Oct  2 21:51:13.512: INFO: Waiting for pod pod-subpath-test-secret-bxld to disappear
Oct  2 21:51:13.520: INFO: Pod pod-subpath-test-secret-bxld no longer exists
STEP: Deleting pod pod-subpath-test-secret-bxld
Oct  2 21:51:13.520: INFO: Deleting pod "pod-subpath-test-secret-bxld" in namespace "subpath-7109"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:51:13.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7109" for this suite.
Oct  2 21:51:19.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:51:19.810: INFO: namespace subpath-7109 deletion completed in 6.277864938s

• [SLOW TEST:30.641 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:51:19.810: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Oct  2 21:51:19.902: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4319" to be "success or failure"
Oct  2 21:51:19.910: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.237587ms
Oct  2 21:51:21.929: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027196591s
Oct  2 21:51:23.936: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034037683s
STEP: Saw pod success
Oct  2 21:51:23.936: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct  2 21:51:23.941: INFO: Trying to get logs from node 10.0.10.4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct  2 21:51:24.026: INFO: Waiting for pod pod-host-path-test to disappear
Oct  2 21:51:24.032: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:51:24.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4319" for this suite.
Oct  2 21:51:30.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:51:30.349: INFO: namespace hostpath-4319 deletion completed in 6.310989815s

• [SLOW TEST:10.539 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:51:30.350: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:51:30.434: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203" in namespace "projected-4775" to be "success or failure"
Oct  2 21:51:30.450: INFO: Pod "downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 16.630121ms
Oct  2 21:51:32.458: INFO: Pod "downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024486476s
STEP: Saw pod success
Oct  2 21:51:32.458: INFO: Pod "downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:51:32.486: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:51:32.522: INFO: Waiting for pod downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:51:32.532: INFO: Pod downwardapi-volume-cad43e7e-e55e-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:51:32.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4775" for this suite.
Oct  2 21:51:38.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:51:38.860: INFO: namespace projected-4775 deletion completed in 6.321110421s

• [SLOW TEST:8.511 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:51:38.861: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-cfeea6fb-e55e-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:51:43.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4123" for this suite.
Oct  2 21:52:05.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:52:05.613: INFO: namespace configmap-4123 deletion completed in 22.3442031s

• [SLOW TEST:26.753 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:52:05.613: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 21:52:05.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203" in namespace "projected-9702" to be "success or failure"
Oct  2 21:52:05.719: INFO: Pod "downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.601093ms
Oct  2 21:52:07.727: INFO: Pod "downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015343854s
STEP: Saw pod success
Oct  2 21:52:07.727: INFO: Pod "downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:52:07.733: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 21:52:07.772: INFO: Waiting for pod downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:52:07.780: INFO: Pod downwardapi-volume-dfdc3f3e-e55e-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:52:07.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9702" for this suite.
Oct  2 21:52:13.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:52:14.110: INFO: namespace projected-9702 deletion completed in 6.32386598s

• [SLOW TEST:8.497 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:52:14.110: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-872
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-872
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-872
Oct  2 21:52:14.219: INFO: Found 0 stateful pods, waiting for 1
Oct  2 21:52:24.227: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct  2 21:52:24.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:52:24.626: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:52:24.626: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:52:24.626: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:52:24.633: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  2 21:52:34.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:52:34.641: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:52:34.673: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:52:34.673: INFO: ss-0  10.0.10.4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  }]
Oct  2 21:52:34.674: INFO: 
Oct  2 21:52:34.674: INFO: StatefulSet ss has not reached scale 3, at 1
Oct  2 21:52:35.681: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993946248s
Oct  2 21:52:36.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986958384s
Oct  2 21:52:37.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979948883s
Oct  2 21:52:38.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972073731s
Oct  2 21:52:39.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964822828s
Oct  2 21:52:40.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.957818221s
Oct  2 21:52:41.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.950548793s
Oct  2 21:52:42.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943502141s
Oct  2 21:52:43.739: INFO: Verifying statefulset ss doesn't scale past 3 for another 935.917506ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-872
Oct  2 21:52:44.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:52:45.218: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  2 21:52:45.218: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:52:45.218: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:52:45.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:52:45.601: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  2 21:52:45.601: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:52:45.601: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:52:45.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:52:46.066: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  2 21:52:46.066: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  2 21:52:46.066: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  2 21:52:46.073: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:52:46.073: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  2 21:52:46.073: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct  2 21:52:46.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:52:46.519: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:52:46.519: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:52:46.519: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:52:46.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:52:46.929: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:52:46.929: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:52:46.929: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:52:46.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  2 21:52:47.314: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  2 21:52:47.314: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  2 21:52:47.314: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  2 21:52:47.314: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:52:47.322: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  2 21:52:57.335: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:52:57.335: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:52:57.335: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  2 21:52:57.374: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:52:57.375: INFO: ss-0  10.0.10.4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  }]
Oct  2 21:52:57.376: INFO: ss-1  10.0.10.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:57.376: INFO: ss-2  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:57.376: INFO: 
Oct  2 21:52:57.376: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  2 21:52:58.384: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:52:58.384: INFO: ss-0  10.0.10.4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:14 +0000 UTC  }]
Oct  2 21:52:58.384: INFO: ss-1  10.0.10.3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:58.384: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:58.384: INFO: 
Oct  2 21:52:58.384: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  2 21:52:59.392: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:52:59.392: INFO: ss-1  10.0.10.3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:59.392: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:52:59.392: INFO: 
Oct  2 21:52:59.392: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  2 21:53:00.399: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:00.399: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:00.399: INFO: 
Oct  2 21:53:00.399: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:01.406: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:01.406: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:01.406: INFO: 
Oct  2 21:53:01.406: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:02.414: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:02.414: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:02.414: INFO: 
Oct  2 21:53:02.414: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:03.422: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:03.422: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:03.422: INFO: 
Oct  2 21:53:03.422: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:04.430: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:04.430: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:04.430: INFO: 
Oct  2 21:53:04.430: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:05.439: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:05.439: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:05.439: INFO: 
Oct  2 21:53:05.439: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  2 21:53:06.453: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Oct  2 21:53:06.453: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:52:34 +0000 UTC  }]
Oct  2 21:53:06.453: INFO: 
Oct  2 21:53:06.453: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-872
Oct  2 21:53:07.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:07.748: INFO: rc: 1
Oct  2 21:53:07.748: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0021de1b0 exit status 1 <nil> <nil> true [0xc0028e43f8 0xc0028e4410 0xc0028e4430] [0xc0028e43f8 0xc0028e4410 0xc0028e4430] [0xc0028e4408 0xc0028e4428] [0x9c0ae0 0x9c0ae0] 0xc002a00ea0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Oct  2 21:53:17.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:17.869: INFO: rc: 1
Oct  2 21:53:17.869: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021de510 exit status 1 <nil> <nil> true [0xc0028e4438 0xc0028e4450 0xc0028e4468] [0xc0028e4438 0xc0028e4450 0xc0028e4468] [0xc0028e4448 0xc0028e4460] [0x9c0ae0 0x9c0ae0] 0xc002a01200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:53:27.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:27.990: INFO: rc: 1
Oct  2 21:53:27.991: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028918f0 exit status 1 <nil> <nil> true [0xc0024c2820 0xc0024c2858 0xc0024c2870] [0xc0024c2820 0xc0024c2858 0xc0024c2870] [0xc0024c2848 0xc0024c2868] [0x9c0ae0 0x9c0ae0] 0xc002e060c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:53:37.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:38.089: INFO: rc: 1
Oct  2 21:53:38.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002891c50 exit status 1 <nil> <nil> true [0xc0024c2878 0xc0024c2890 0xc0024c28a8] [0xc0024c2878 0xc0024c2890 0xc0024c28a8] [0xc0024c2888 0xc0024c28a0] [0x9c0ae0 0x9c0ae0] 0xc002e065a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:53:48.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:48.186: INFO: rc: 1
Oct  2 21:53:48.186: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021de8a0 exit status 1 <nil> <nil> true [0xc0028e4470 0xc0028e4488 0xc0028e44a0] [0xc0028e4470 0xc0028e4488 0xc0028e44a0] [0xc0028e4480 0xc0028e4498] [0x9c0ae0 0x9c0ae0] 0xc002a01560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:53:58.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:53:58.279: INFO: rc: 1
Oct  2 21:53:58.279: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021dec00 exit status 1 <nil> <nil> true [0xc0028e44a8 0xc0028e44c0 0xc0028e44d8] [0xc0028e44a8 0xc0028e44c0 0xc0028e44d8] [0xc0028e44b8 0xc0028e44d0] [0x9c0ae0 0x9c0ae0] 0xc002a018c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:08.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:08.396: INFO: rc: 1
Oct  2 21:54:08.396: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021def60 exit status 1 <nil> <nil> true [0xc0028e44e0 0xc0028e44f8 0xc0028e4510] [0xc0028e44e0 0xc0028e44f8 0xc0028e4510] [0xc0028e44f0 0xc0028e4508] [0x9c0ae0 0x9c0ae0] 0xc002a01c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:18.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:18.500: INFO: rc: 1
Oct  2 21:54:18.500: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021df320 exit status 1 <nil> <nil> true [0xc0028e4518 0xc0028e4530 0xc0028e4548] [0xc0028e4518 0xc0028e4530 0xc0028e4548] [0xc0028e4528 0xc0028e4540] [0x9c0ae0 0x9c0ae0] 0xc002a01f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:28.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:28.590: INFO: rc: 1
Oct  2 21:54:28.591: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6330 exit status 1 <nil> <nil> true [0xc0024c2018 0xc0024c20b0 0xc0024c20d8] [0xc0024c2018 0xc0024c20b0 0xc0024c20d8] [0xc0024c2050 0xc0024c20c8] [0x9c0ae0 0x9c0ae0] 0xc002a002a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:38.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:38.708: INFO: rc: 1
Oct  2 21:54:38.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6690 exit status 1 <nil> <nil> true [0xc0024c20e8 0xc0024c2118 0xc0024c2150] [0xc0024c20e8 0xc0024c2118 0xc0024c2150] [0xc0024c2108 0xc0024c2140] [0x9c0ae0 0x9c0ae0] 0xc002a00600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:48.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:48.817: INFO: rc: 1
Oct  2 21:54:48.817: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6a80 exit status 1 <nil> <nil> true [0xc0024c2158 0xc0024c2188 0xc0024c21c0] [0xc0024c2158 0xc0024c2188 0xc0024c21c0] [0xc0024c2168 0xc0024c21b0] [0x9c0ae0 0x9c0ae0] 0xc002a00a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:54:58.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:54:58.911: INFO: rc: 1
Oct  2 21:54:58.912: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6ed0 exit status 1 <nil> <nil> true [0xc0024c21d0 0xc0024c2208 0xc0024c2238] [0xc0024c21d0 0xc0024c2208 0xc0024c2238] [0xc0024c21f0 0xc0024c2230] [0x9c0ae0 0x9c0ae0] 0xc002a00de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:08.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:09.005: INFO: rc: 1
Oct  2 21:55:09.005: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0390 exit status 1 <nil> <nil> true [0xc0028e4000 0xc0028e4018 0xc0028e4030] [0xc0028e4000 0xc0028e4018 0xc0028e4030] [0xc0028e4010 0xc0028e4028] [0x9c0ae0 0x9c0ae0] 0xc001c84420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:19.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:19.104: INFO: rc: 1
Oct  2 21:55:19.104: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0750 exit status 1 <nil> <nil> true [0xc0028e4038 0xc0028e4050 0xc0028e4068] [0xc0028e4038 0xc0028e4050 0xc0028e4068] [0xc0028e4048 0xc0028e4060] [0x9c0ae0 0x9c0ae0] 0xc001c847e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:29.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:29.208: INFO: rc: 1
Oct  2 21:55:29.208: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed7230 exit status 1 <nil> <nil> true [0xc0024c2240 0xc0024c2288 0xc0024c22b8] [0xc0024c2240 0xc0024c2288 0xc0024c22b8] [0xc0024c2278 0xc0024c22a8] [0x9c0ae0 0x9c0ae0] 0xc002a01140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:39.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:39.321: INFO: rc: 1
Oct  2 21:55:39.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0ab0 exit status 1 <nil> <nil> true [0xc0028e4070 0xc0028e4088 0xc0028e40a0] [0xc0028e4070 0xc0028e4088 0xc0028e40a0] [0xc0028e4080 0xc0028e4098] [0x9c0ae0 0x9c0ae0] 0xc001c84ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:49.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:49.420: INFO: rc: 1
Oct  2 21:55:49.420: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0e10 exit status 1 <nil> <nil> true [0xc0028e40a8 0xc0028e40c0 0xc0028e40d8] [0xc0028e40a8 0xc0028e40c0 0xc0028e40d8] [0xc0028e40b8 0xc0028e40d0] [0x9c0ae0 0x9c0ae0] 0xc001c84f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:55:59.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:55:59.521: INFO: rc: 1
Oct  2 21:55:59.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed75c0 exit status 1 <nil> <nil> true [0xc0024c22c8 0xc0024c2308 0xc0024c2338] [0xc0024c22c8 0xc0024c2308 0xc0024c2338] [0xc0024c2300 0xc0024c2318] [0x9c0ae0 0x9c0ae0] 0xc002a014a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:56:09.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:56:09.624: INFO: rc: 1
Oct  2 21:56:09.624: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc1350 exit status 1 <nil> <nil> true [0xc0028e40e0 0xc0028e40f8 0xc0028e4110] [0xc0028e40e0 0xc0028e40f8 0xc0028e4110] [0xc0028e40f0 0xc0028e4108] [0x9c0ae0 0x9c0ae0] 0xc001c852c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:56:19.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:56:19.730: INFO: rc: 1
Oct  2 21:56:19.730: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc16b0 exit status 1 <nil> <nil> true [0xc0028e4118 0xc0028e4130 0xc0028e4148] [0xc0028e4118 0xc0028e4130 0xc0028e4148] [0xc0028e4128 0xc0028e4140] [0x9c0ae0 0x9c0ae0] 0xc001c85740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:56:29.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:56:29.829: INFO: rc: 1
Oct  2 21:56:29.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0330 exit status 1 <nil> <nil> true [0xc0028e4008 0xc0028e4020 0xc0028e4038] [0xc0028e4008 0xc0028e4020 0xc0028e4038] [0xc0028e4018 0xc0028e4030] [0x9c0ae0 0x9c0ae0] 0xc001c84420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:56:39.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:56:39.923: INFO: rc: 1
Oct  2 21:56:39.924: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc06f0 exit status 1 <nil> <nil> true [0xc0028e4040 0xc0028e4058 0xc0028e4070] [0xc0028e4040 0xc0028e4058 0xc0028e4070] [0xc0028e4050 0xc0028e4068] [0x9c0ae0 0x9c0ae0] 0xc001c847e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:56:49.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:56:50.031: INFO: rc: 1
Oct  2 21:56:50.031: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0a80 exit status 1 <nil> <nil> true [0xc0028e4078 0xc0028e4090 0xc0028e40a8] [0xc0028e4078 0xc0028e4090 0xc0028e40a8] [0xc0028e4088 0xc0028e40a0] [0x9c0ae0 0x9c0ae0] 0xc001c84ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:00.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:00.135: INFO: rc: 1
Oct  2 21:57:00.136: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc0de0 exit status 1 <nil> <nil> true [0xc0028e40b0 0xc0028e40c8 0xc0028e40e0] [0xc0028e40b0 0xc0028e40c8 0xc0028e40e0] [0xc0028e40c0 0xc0028e40d8] [0x9c0ae0 0x9c0ae0] 0xc001c84f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:10.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:10.239: INFO: rc: 1
Oct  2 21:57:10.239: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed63f0 exit status 1 <nil> <nil> true [0xc0024c2000 0xc0024c2050 0xc0024c20c8] [0xc0024c2000 0xc0024c2050 0xc0024c20c8] [0xc0024c2038 0xc0024c20b8] [0x9c0ae0 0x9c0ae0] 0xc002a002a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:20.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:20.335: INFO: rc: 1
Oct  2 21:57:20.336: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc1380 exit status 1 <nil> <nil> true [0xc0028e40e8 0xc0028e4100 0xc0028e4118] [0xc0028e40e8 0xc0028e4100 0xc0028e4118] [0xc0028e40f8 0xc0028e4110] [0x9c0ae0 0x9c0ae0] 0xc001c852c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:30.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:30.451: INFO: rc: 1
Oct  2 21:57:30.451: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc1710 exit status 1 <nil> <nil> true [0xc0028e4120 0xc0028e4138 0xc0028e4150] [0xc0028e4120 0xc0028e4138 0xc0028e4150] [0xc0028e4130 0xc0028e4148] [0x9c0ae0 0x9c0ae0] 0xc001c85740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:40.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:40.570: INFO: rc: 1
Oct  2 21:57:40.571: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dc1a70 exit status 1 <nil> <nil> true [0xc0028e4158 0xc0028e4170 0xc0028e4190] [0xc0028e4158 0xc0028e4170 0xc0028e4190] [0xc0028e4168 0xc0028e4188] [0x9c0ae0 0x9c0ae0] 0xc001c85b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:57:50.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:57:50.679: INFO: rc: 1
Oct  2 21:57:50.679: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6750 exit status 1 <nil> <nil> true [0xc0024c20d8 0xc0024c2108 0xc0024c2140] [0xc0024c20d8 0xc0024c2108 0xc0024c2140] [0xc0024c20f8 0xc0024c2130] [0x9c0ae0 0x9c0ae0] 0xc002a00600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:58:00.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:58:00.798: INFO: rc: 1
Oct  2 21:58:00.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ed6c30 exit status 1 <nil> <nil> true [0xc0024c2150 0xc0024c2168 0xc0024c21b0] [0xc0024c2150 0xc0024c2168 0xc0024c21b0] [0xc0024c2160 0xc0024c21a0] [0x9c0ae0 0x9c0ae0] 0xc002a00a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct  2 21:58:10.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 exec --namespace=statefulset-872 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  2 21:58:10.904: INFO: rc: 1
Oct  2 21:58:10.904: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Oct  2 21:58:10.904: INFO: Scaling statefulset ss to 0
Oct  2 21:58:10.956: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  2 21:58:10.962: INFO: Deleting all statefulset in ns statefulset-872
Oct  2 21:58:10.972: INFO: Scaling statefulset ss to 0
Oct  2 21:58:10.998: INFO: Waiting for statefulset status.replicas updated to 0
Oct  2 21:58:11.004: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:58:11.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-872" for this suite.
Oct  2 21:58:17.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:58:17.322: INFO: namespace statefulset-872 deletion completed in 6.278218415s

• [SLOW TEST:363.212 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:58:17.322: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:58:17.391: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct  2 21:58:17.411: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  2 21:58:22.419: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  2 21:58:22.419: INFO: Creating deployment "test-rolling-update-deployment"
Oct  2 21:58:22.428: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct  2 21:58:22.459: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct  2 21:58:24.473: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct  2 21:58:24.478: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  2 21:58:24.501: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7559,SelfLink:/apis/apps/v1/namespaces/deployment-7559/deployments/test-rolling-update-deployment,UID:c0684492-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:14946,Generation:1,CreationTimestamp:2019-10-02 21:58:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-02 21:58:22 +0000 UTC 2019-10-02 21:58:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-02 21:58:24 +0000 UTC 2019-10-02 21:58:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct  2 21:58:24.508: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-7559,SelfLink:/apis/apps/v1/namespaces/deployment-7559/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:c06e72ab-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:14935,Generation:1,CreationTimestamp:2019-10-02 21:58:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c0684492-e55f-11e9-a07f-0a580aed12b5 0xc0025fd237 0xc0025fd238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  2 21:58:24.508: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct  2 21:58:24.508: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7559,SelfLink:/apis/apps/v1/namespaces/deployment-7559/replicasets/test-rolling-update-controller,UID:bd691ee5-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:14944,Generation:2,CreationTimestamp:2019-10-02 21:58:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c0684492-e55f-11e9-a07f-0a580aed12b5 0xc0025fd167 0xc0025fd168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 21:58:24.518: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-w84fw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-w84fw,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-7559,SelfLink:/api/v1/namespaces/deployment-7559/pods/test-rolling-update-deployment-57b6b5bb54-w84fw,UID:c070067a-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:14934,Generation:0,CreationTimestamp:2019-10-02 21:58:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 c06e72ab-e55f-11e9-a07f-0a580aed12b5 0xc0025fdaf7 0xc0025fdaf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t7g8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t7g8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-t7g8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025fdb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025fdb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.1.71,StartTime:2019-10-02 21:58:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c624c1f6c77b30c5adc6fb11b382afc307e5caa8c4d23e68198f773324bfa91c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:58:24.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7559" for this suite.
Oct  2 21:58:30.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:58:30.829: INFO: namespace deployment-7559 deletion completed in 6.304205408s

• [SLOW TEST:13.506 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:58:30.829: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-c5732930-e55f-11e9-bbfa-0a580af40203
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:58:30.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7735" for this suite.
Oct  2 21:58:36.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:58:37.171: INFO: namespace configmap-7735 deletion completed in 6.278177942s

• [SLOW TEST:6.342 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:58:37.171: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 21:58:37.237: INFO: Creating deployment "nginx-deployment"
Oct  2 21:58:37.245: INFO: Waiting for observed generation 1
Oct  2 21:58:39.258: INFO: Waiting for all required pods to come up
Oct  2 21:58:39.267: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct  2 21:58:41.290: INFO: Waiting for deployment "nginx-deployment" to complete
Oct  2 21:58:41.303: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct  2 21:58:41.318: INFO: Updating deployment nginx-deployment
Oct  2 21:58:41.318: INFO: Waiting for observed generation 2
Oct  2 21:58:43.331: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct  2 21:58:43.338: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct  2 21:58:43.346: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct  2 21:58:43.365: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct  2 21:58:43.365: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct  2 21:58:43.376: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct  2 21:58:43.389: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct  2 21:58:43.389: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct  2 21:58:43.401: INFO: Updating deployment nginx-deployment
Oct  2 21:58:43.401: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct  2 21:58:43.420: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct  2 21:58:43.431: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  2 21:58:43.458: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9050,SelfLink:/apis/apps/v1/namespaces/deployment-9050/deployments/nginx-deployment,UID:c93d43ec-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15236,Generation:3,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-10-02 21:58:41 +0000 UTC 2019-10-02 21:58:37 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2019-10-02 21:58:43 +0000 UTC 2019-10-02 21:58:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct  2 21:58:43.486: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-9050,SelfLink:/apis/apps/v1/namespaces/deployment-9050/replicasets/nginx-deployment-b79c9d74d,UID:cbabbd3d-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15224,Generation:3,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c93d43ec-e55f-11e9-a07f-0a580aed12b5 0xc001f79237 0xc001f79238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 21:58:43.486: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct  2 21:58:43.486: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-9050,SelfLink:/apis/apps/v1/namespaces/deployment-9050/replicasets/nginx-deployment-85db8c99c5,UID:c93e6b03-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15222,Generation:3,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c93d43ec-e55f-11e9-a07f-0a580aed12b5 0xc001f79167 0xc001f79168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct  2 21:58:43.515: INFO: Pod "nginx-deployment-85db8c99c5-2dfcx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2dfcx,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-2dfcx,UID:ccec5b06-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15263,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc001f79b87 0xc001f79b88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f79c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f79c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2019-10-02 21:58:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.515: INFO: Pod "nginx-deployment-85db8c99c5-2ncx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2ncx5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-2ncx5,UID:ccf0cd75-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15269,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc001f79cf0 0xc001f79cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f79d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f79d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.515: INFO: Pod "nginx-deployment-85db8c99c5-478pv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-478pv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-478pv,UID:ccf124fc-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15270,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc001f79e00 0xc001f79e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f79e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f79e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.515: INFO: Pod "nginx-deployment-85db8c99c5-5lgbs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5lgbs,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-5lgbs,UID:c9480b2f-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15097,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc001f79f20 0xc001f79f21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f79f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f79fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.70,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://aca9d12d071c1d69931d049caa12e802a1ac5733fc802706a82cae6dde6a8d9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.515: INFO: Pod "nginx-deployment-85db8c99c5-6f8jd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6f8jd,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-6f8jd,UID:ccec6442-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15234,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a80c0 0xc0018a80c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.516: INFO: Pod "nginx-deployment-85db8c99c5-7tznq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7tznq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-7tznq,UID:ccead9b7-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15262,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8250 0xc0018a8251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a82d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a82f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2019-10-02 21:58:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.516: INFO: Pod "nginx-deployment-85db8c99c5-br94l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-br94l,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-br94l,UID:c944916c-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15113,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a83b0 0xc0018a83b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.31,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c87f9de38f248830d616ae768017eb4d38aa5f430ca849157545440200b673d7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.516: INFO: Pod "nginx-deployment-85db8c99c5-ccmkx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ccmkx,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-ccmkx,UID:c942feea-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15124,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8530 0xc0018a8531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a85a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a85c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.1.72,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9eb6a30710b965fcb890f5d94108fde03061d4ea4d92948e885caf14b75d622a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.516: INFO: Pod "nginx-deployment-85db8c99c5-cdjc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-cdjc9,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-cdjc9,UID:ccf0b749-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15267,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8690 0xc0018a8691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.516: INFO: Pod "nginx-deployment-85db8c99c5-g2k26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-g2k26,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-g2k26,UID:ccee09bf-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15247,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a87a0 0xc0018a87a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.517: INFO: Pod "nginx-deployment-85db8c99c5-gp9zt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gp9zt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-gp9zt,UID:ccede2dd-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15245,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a88b0 0xc0018a88b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.517: INFO: Pod "nginx-deployment-85db8c99c5-h44rc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-h44rc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-h44rc,UID:c9449a40-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15120,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a89c0 0xc0018a89c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.69,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://255d87d2108f7432565c32103606a3b4e545c18b9703a2f34cd4971ac759e584}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.517: INFO: Pod "nginx-deployment-85db8c99c5-mz7v6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-mz7v6,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-mz7v6,UID:c94492d2-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15127,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8b20 0xc0018a8b21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.1.75,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:39 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://95143517f118a2b5bea1a741b72fd2562477cdd090e12eda796e2cdea4327f57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.517: INFO: Pod "nginx-deployment-85db8c99c5-qtq6l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qtq6l,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-qtq6l,UID:c941b08b-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15095,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8c80 0xc0018a8c81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.68,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://763fa385e93a9d0f12a7f46c0d34d0b4709711bd23dfd6790d4cd43eaa85c104}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.517: INFO: Pod "nginx-deployment-85db8c99c5-rb7ss" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rb7ss,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-rb7ss,UID:c9430e91-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15111,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8de0 0xc0018a8de1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.29,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7f841c908130365e190030268c88c43e88d07896437cb93b616336a155952295}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.518: INFO: Pod "nginx-deployment-85db8c99c5-sfk2t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-sfk2t,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-sfk2t,UID:ccee08b0-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15246,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a8f40 0xc0018a8f41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a8fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a8fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.518: INFO: Pod "nginx-deployment-85db8c99c5-vq5f6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vq5f6,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-vq5f6,UID:ccf07ebc-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15255,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a9050 0xc0018a9051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a90c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a90e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.518: INFO: Pod "nginx-deployment-85db8c99c5-w5xcq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-w5xcq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-w5xcq,UID:c9481da2-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15116,Generation:0,CreationTimestamp:2019-10-02 21:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a9160 0xc0018a9161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a91d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a91f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.30,StartTime:2019-10-02 21:58:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-02 21:58:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://194c6a44344a84e0d707ee80cc719377ae19a0b3302c11d95bb1fa4e7eed856c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.518: INFO: Pod "nginx-deployment-85db8c99c5-x2pbx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x2pbx,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-x2pbx,UID:ccf0b651-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15266,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a92c0 0xc0018a92c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.518: INFO: Pod "nginx-deployment-85db8c99c5-x7q27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x7q27,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-85db8c99c5-x7q27,UID:ccee353a-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15251,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 c93e6b03-e55f-11e9-a07f-0a580aed12b5 0xc0018a93d0 0xc0018a93d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.519: INFO: Pod "nginx-deployment-b79c9d74d-2bh7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-2bh7x,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-2bh7x,UID:ccf115f4-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15271,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9500 0xc0018a9501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a95b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.519: INFO: Pod "nginx-deployment-b79c9d74d-4sn2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-4sn2x,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-4sn2x,UID:cbae7861-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15162,Generation:0,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9630 0xc0018a9631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a96b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a96d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2019-10-02 21:58:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.519: INFO: Pod "nginx-deployment-b79c9d74d-5cbtf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-5cbtf,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-5cbtf,UID:ccf13268-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15274,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a97b0 0xc0018a97b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.519: INFO: Pod "nginx-deployment-b79c9d74d-8ph2k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-8ph2k,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-8ph2k,UID:cbb59992-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15189,Generation:0,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9920 0xc0018a9921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a99a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a99d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2019-10-02 21:58:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.519: INFO: Pod "nginx-deployment-b79c9d74d-dr8nn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dr8nn,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-dr8nn,UID:ccecba94-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15256,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9b00 0xc0018a9b01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-10-02 21:58:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.520: INFO: Pod "nginx-deployment-b79c9d74d-gd9b4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gd9b4,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-gd9b4,UID:cbb77f85-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15220,Generation:0,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9cd0 0xc0018a9cd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.72,StartTime:2019-10-02 21:58:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.520: INFO: Pod "nginx-deployment-b79c9d74d-lx724" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-lx724,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-lx724,UID:ccf6e447-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15276,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9e60 0xc0018a9e61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018a9ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018a9ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.520: INFO: Pod "nginx-deployment-b79c9d74d-pwp2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-pwp2w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-pwp2w,UID:ccee71ca-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15248,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0018a9f77 0xc0018a9f78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001764000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001764030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.520: INFO: Pod "nginx-deployment-b79c9d74d-rqwll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-rqwll,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-rqwll,UID:cbae9422-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15217,Generation:0,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0017640e0 0xc0017640e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017641a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017641e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.71,StartTime:2019-10-02 21:58:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.520: INFO: Pod "nginx-deployment-b79c9d74d-s8g7v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-s8g7v,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-s8g7v,UID:cbad11e5-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15202,Generation:0,CreationTimestamp:2019-10-02 21:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0017642e0 0xc0017642e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001764360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001764380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.32,StartTime:2019-10-02 21:58:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.521: INFO: Pod "nginx-deployment-b79c9d74d-sbv57" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-sbv57,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-sbv57,UID:ccee7834-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15254,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc001764470 0xc001764471}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017644f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001764510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.521: INFO: Pod "nginx-deployment-b79c9d74d-vmsvd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vmsvd,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-vmsvd,UID:ccf13142-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15273,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc001764590 0xc001764591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001764610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001764630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  2 21:58:43.521: INFO: Pod "nginx-deployment-b79c9d74d-xm99f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xm99f,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9050,SelfLink:/api/v1/namespaces/deployment-9050/pods/nginx-deployment-b79c9d74d-xm99f,UID:ccf19f56-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15275,Generation:0,CreationTimestamp:2019-10-02 21:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d cbabbd3d-e55f-11e9-a07f-0a580aed12b5 0xc0017646b0 0xc0017646b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pwmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001764730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001764750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 21:58:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:58:43.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9050" for this suite.
Oct  2 21:58:51.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:58:51.826: INFO: namespace deployment-9050 deletion completed in 8.29848967s

• [SLOW TEST:14.656 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:58:51.828: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  2 21:58:51.926: INFO: Waiting up to 5m0s for pod "pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203" in namespace "emptydir-8990" to be "success or failure"
Oct  2 21:58:51.936: INFO: Pod "pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.030801ms
Oct  2 21:58:53.948: INFO: Pod "pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021290597s
Oct  2 21:58:55.961: INFO: Pod "pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03513799s
STEP: Saw pod success
Oct  2 21:58:55.961: INFO: Pod "pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:58:55.971: INFO: Trying to get logs from node 10.0.10.4 pod pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 21:58:56.033: INFO: Waiting for pod pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:58:56.040: INFO: Pod pod-d1fbca4c-e55f-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:58:56.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8990" for this suite.
Oct  2 21:59:02.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:59:02.348: INFO: namespace emptydir-8990 deletion completed in 6.300838816s

• [SLOW TEST:10.520 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:59:02.348: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  2 21:59:02.410: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:59:05.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8263" for this suite.
Oct  2 21:59:11.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:59:11.980: INFO: namespace init-container-8263 deletion completed in 6.270144803s

• [SLOW TEST:9.632 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:59:11.980: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-ddfc6b69-e55f-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 21:59:12.073: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203" in namespace "projected-7814" to be "success or failure"
Oct  2 21:59:12.083: INFO: Pod "pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.873663ms
Oct  2 21:59:14.091: INFO: Pod "pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018507851s
STEP: Saw pod success
Oct  2 21:59:14.091: INFO: Pod "pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 21:59:14.099: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  2 21:59:14.148: INFO: Waiting for pod pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203 to disappear
Oct  2 21:59:14.157: INFO: Pod pod-projected-secrets-ddfd7dad-e55f-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:59:14.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7814" for this suite.
Oct  2 21:59:20.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:59:20.488: INFO: namespace projected-7814 deletion completed in 6.324203263s

• [SLOW TEST:8.508 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:59:20.488: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct  2 21:59:20.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15719,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  2 21:59:20.590: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15720,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  2 21:59:20.590: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15721,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct  2 21:59:30.661: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15745,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  2 21:59:30.661: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15746,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct  2 21:59:30.661: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7446,SelfLink:/api/v1/namespaces/watch-7446/configmaps/e2e-watch-test-label-changed,UID:e30e7f11-e55f-11e9-a07f-0a580aed12b5,ResourceVersion:15747,Generation:0,CreationTimestamp:2019-10-02 21:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 21:59:30.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7446" for this suite.
Oct  2 21:59:36.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 21:59:36.959: INFO: namespace watch-7446 deletion completed in 6.291499028s

• [SLOW TEST:16.470 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 21:59:36.959: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:00:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2495" for this suite.
Oct  2 22:01:01.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:01:01.388: INFO: namespace container-probe-2495 deletion completed in 24.312559533s

• [SLOW TEST:84.429 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:01:01.389: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 22:01:01.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6144'
Oct  2 22:01:01.690: INFO: stderr: ""
Oct  2 22:01:01.690: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Oct  2 22:01:01.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete pods e2e-test-nginx-pod --namespace=kubectl-6144'
Oct  2 22:01:18.503: INFO: stderr: ""
Oct  2 22:01:18.503: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:01:18.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6144" for this suite.
Oct  2 22:01:24.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:01:24.869: INFO: namespace kubectl-6144 deletion completed in 6.357645317s

• [SLOW TEST:23.481 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:01:24.870: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:01:27.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3756" for this suite.
Oct  2 22:01:33.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:01:33.478: INFO: namespace emptydir-wrapper-3756 deletion completed in 6.382276858s

• [SLOW TEST:8.608 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:01:33.478: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:01:33.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 version'
Oct  2 22:01:33.657: INFO: stderr: ""
Oct  2 22:01:33.657: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:49Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14+\", GitVersion:\"v1.14.6-2+1f1885f7817668\", GitCommit:\"1f1885f7817668afc903d08ca81c4a1d05d80f68\", GitTreeState:\"clean\", BuildDate:\"2019-09-10T20:19:19Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:01:33.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3492" for this suite.
Oct  2 22:01:39.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:01:39.991: INFO: namespace kubectl-3492 deletion completed in 6.326869085s

• [SLOW TEST:6.512 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:01:39.991: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5979
Oct  2 22:01:44.128: INFO: Started pod liveness-http in namespace container-probe-5979
STEP: checking the pod's current state and verifying that restartCount is present
Oct  2 22:01:44.134: INFO: Initial restart count of pod liveness-http is 0
Oct  2 22:02:00.293: INFO: Restart count of pod container-probe-5979/liveness-http is now 1 (16.158814647s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:02:00.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5979" for this suite.
Oct  2 22:02:06.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:02:06.641: INFO: namespace container-probe-5979 deletion completed in 6.315141921s

• [SLOW TEST:26.650 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:02:06.642: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  2 22:02:10.818: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:10.825: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:12.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:12.843: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:14.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:14.839: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:16.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:16.847: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:18.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:18.839: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:20.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:20.856: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:22.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:22.835: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:24.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:24.834: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:26.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:26.837: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:28.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:28.833: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:30.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:30.835: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:32.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:32.833: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:34.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:34.833: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:36.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:36.834: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  2 22:02:38.825: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  2 22:02:38.834: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:02:38.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8924" for this suite.
Oct  2 22:03:03.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:03:03.279: INFO: namespace container-lifecycle-hook-8924 deletion completed in 24.274049287s

• [SLOW TEST:56.637 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:03:03.279: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1038.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1038.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  2 22:03:19.556: INFO: DNS probes using dns-1038/dns-test-67d8ff26-e560-11e9-bbfa-0a580af40203 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:03:19.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1038" for this suite.
Oct  2 22:03:25.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:03:25.894: INFO: namespace dns-1038 deletion completed in 6.28960501s

• [SLOW TEST:22.615 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:03:25.895: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:03:25.959: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:03:27.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2731" for this suite.
Oct  2 22:03:33.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:03:33.392: INFO: namespace custom-resource-definition-2731 deletion completed in 6.308285201s

• [SLOW TEST:7.498 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:03:33.393: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  2 22:03:33.479: INFO: PodSpec: initContainers in spec.initContainers
Oct  2 22:04:18.363: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-79cfd2f5-e560-11e9-bbfa-0a580af40203", GenerateName:"", Namespace:"init-container-4459", SelfLink:"/api/v1/namespaces/init-container-4459/pods/pod-init-79cfd2f5-e560-11e9-bbfa-0a580af40203", UID:"79d0e2b3-e560-11e9-a07f-0a580aed12b5", ResourceVersion:"16638", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705650613, loc:(*time.Location)(0x8825120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"479505641"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mxfkb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002fffc00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mxfkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mxfkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mxfkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003100d98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.10.4", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b2e900), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003100e30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003100e50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003100e58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003100e5c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705650613, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705650613, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705650613, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705650613, loc:(*time.Location)(0x8825120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.10.4", PodIP:"10.244.1.96", StartTime:(*v1.Time)(0xc001b4e8e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002350380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002350460)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://edcba90b41cb24225b12ca2b7f389ec9e8933380f9c10416277ffd705a954944"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b4e920), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b4e900), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:04:18.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4459" for this suite.
Oct  2 22:04:42.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:04:42.666: INFO: namespace init-container-4459 deletion completed in 24.295577672s

• [SLOW TEST:69.274 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:04:42.667: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Oct  2 22:04:42.751: INFO: Waiting up to 5m0s for pod "var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203" in namespace "var-expansion-9921" to be "success or failure"
Oct  2 22:04:42.780: INFO: Pod "var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 28.316364ms
Oct  2 22:04:44.793: INFO: Pod "var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041545306s
STEP: Saw pod success
Oct  2 22:04:44.793: INFO: Pod "var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:04:44.801: INFO: Trying to get logs from node 10.0.10.3 pod var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:04:44.852: INFO: Waiting for pod var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:04:44.859: INFO: Pod var-expansion-a317c5da-e560-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:04:44.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9921" for this suite.
Oct  2 22:04:50.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:04:51.129: INFO: namespace var-expansion-9921 deletion completed in 6.264082554s

• [SLOW TEST:8.462 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:04:51.129: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-t87v
STEP: Creating a pod to test atomic-volume-subpath
Oct  2 22:04:51.224: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-t87v" in namespace "subpath-4529" to be "success or failure"
Oct  2 22:04:51.234: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Pending", Reason="", readiness=false. Elapsed: 10.137562ms
Oct  2 22:04:53.256: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 2.031253521s
Oct  2 22:04:55.264: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 4.040154321s
Oct  2 22:04:57.273: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 6.048538103s
Oct  2 22:04:59.281: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 8.056572413s
Oct  2 22:05:01.289: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 10.065164837s
Oct  2 22:05:03.297: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 12.073197863s
Oct  2 22:05:05.306: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 14.081375012s
Oct  2 22:05:07.314: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 16.089670991s
Oct  2 22:05:09.322: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 18.097907957s
Oct  2 22:05:11.330: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Running", Reason="", readiness=true. Elapsed: 20.106212632s
Oct  2 22:05:13.339: INFO: Pod "pod-subpath-test-projected-t87v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.114425357s
STEP: Saw pod success
Oct  2 22:05:13.339: INFO: Pod "pod-subpath-test-projected-t87v" satisfied condition "success or failure"
Oct  2 22:05:13.345: INFO: Trying to get logs from node 10.0.10.4 pod pod-subpath-test-projected-t87v container test-container-subpath-projected-t87v: <nil>
STEP: delete the pod
Oct  2 22:05:13.431: INFO: Waiting for pod pod-subpath-test-projected-t87v to disappear
Oct  2 22:05:13.439: INFO: Pod pod-subpath-test-projected-t87v no longer exists
STEP: Deleting pod pod-subpath-test-projected-t87v
Oct  2 22:05:13.439: INFO: Deleting pod "pod-subpath-test-projected-t87v" in namespace "subpath-4529"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:05:13.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4529" for this suite.
Oct  2 22:05:19.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:05:19.757: INFO: namespace subpath-4529 deletion completed in 6.304577946s

• [SLOW TEST:28.628 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:05:19.758: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  2 22:05:22.509: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203"
Oct  2 22:05:22.509: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203" in namespace "pods-6071" to be "terminated due to deadline exceeded"
Oct  2 22:05:22.515: INFO: Pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203": Phase="Running", Reason="", readiness=true. Elapsed: 6.470787ms
Oct  2 22:05:24.523: INFO: Pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203": Phase="Running", Reason="", readiness=true. Elapsed: 2.014240857s
Oct  2 22:05:26.533: INFO: Pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.024490327s
Oct  2 22:05:26.533: INFO: Pod "pod-update-activedeadlineseconds-b943dc8f-e560-11e9-bbfa-0a580af40203" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:05:26.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6071" for this suite.
Oct  2 22:05:32.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:05:32.830: INFO: namespace pods-6071 deletion completed in 6.291080601s

• [SLOW TEST:13.072 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:05:32.831: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:05:32.946: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203" in namespace "downward-api-8174" to be "success or failure"
Oct  2 22:05:32.957: INFO: Pod "downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.451953ms
Oct  2 22:05:34.965: INFO: Pod "downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01904237s
STEP: Saw pod success
Oct  2 22:05:34.965: INFO: Pod "downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:05:34.972: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:05:35.014: INFO: Waiting for pod downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:05:35.030: INFO: Pod downwardapi-volume-c10222da-e560-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:05:35.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8174" for this suite.
Oct  2 22:05:41.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:05:41.338: INFO: namespace downward-api-8174 deletion completed in 6.299520066s

• [SLOW TEST:8.507 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:05:41.338: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9022
Oct  2 22:05:45.433: INFO: Started pod liveness-http in namespace container-probe-9022
STEP: checking the pod's current state and verifying that restartCount is present
Oct  2 22:05:45.440: INFO: Initial restart count of pod liveness-http is 0
Oct  2 22:06:03.537: INFO: Restart count of pod container-probe-9022/liveness-http is now 1 (18.097449602s elapsed)
Oct  2 22:06:23.658: INFO: Restart count of pod container-probe-9022/liveness-http is now 2 (38.218909731s elapsed)
Oct  2 22:06:45.757: INFO: Restart count of pod container-probe-9022/liveness-http is now 3 (1m0.31787212s elapsed)
Oct  2 22:07:05.892: INFO: Restart count of pod container-probe-9022/liveness-http is now 4 (1m20.452441629s elapsed)
Oct  2 22:08:14.216: INFO: Restart count of pod container-probe-9022/liveness-http is now 5 (2m28.776891138s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:08:14.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9022" for this suite.
Oct  2 22:08:20.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:08:20.583: INFO: namespace container-probe-9022 deletion completed in 6.306503699s

• [SLOW TEST:159.245 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:08:20.583: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Oct  2 22:08:20.668: INFO: Waiting up to 5m0s for pod "pod-24fb20c6-e561-11e9-bbfa-0a580af40203" in namespace "emptydir-6985" to be "success or failure"
Oct  2 22:08:20.680: INFO: Pod "pod-24fb20c6-e561-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.191799ms
Oct  2 22:08:22.689: INFO: Pod "pod-24fb20c6-e561-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021019771s
STEP: Saw pod success
Oct  2 22:08:22.690: INFO: Pod "pod-24fb20c6-e561-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:08:22.697: INFO: Trying to get logs from node 10.0.10.4 pod pod-24fb20c6-e561-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:08:22.992: INFO: Waiting for pod pod-24fb20c6-e561-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:08:23.000: INFO: Pod pod-24fb20c6-e561-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:08:23.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6985" for this suite.
Oct  2 22:08:29.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:08:29.269: INFO: namespace emptydir-6985 deletion completed in 6.26149296s

• [SLOW TEST:8.686 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:08:29.270: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8770
Oct  2 22:08:31.368: INFO: Started pod liveness-exec in namespace container-probe-8770
STEP: checking the pod's current state and verifying that restartCount is present
Oct  2 22:08:31.374: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:12:32.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8770" for this suite.
Oct  2 22:12:38.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:12:38.883: INFO: namespace container-probe-8770 deletion completed in 6.286249611s

• [SLOW TEST:249.613 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:12:38.883: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:12:38.953: INFO: Waiting up to 5m0s for pod "downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203" in namespace "downward-api-78" to be "success or failure"
Oct  2 22:12:38.962: INFO: Pod "downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.432967ms
Oct  2 22:12:40.969: INFO: Pod "downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01589248s
STEP: Saw pod success
Oct  2 22:12:40.969: INFO: Pod "downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:12:40.976: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:12:41.029: INFO: Waiting for pod downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:12:41.039: INFO: Pod downwardapi-volume-beee7f68-e561-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:12:41.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-78" for this suite.
Oct  2 22:12:47.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:12:47.333: INFO: namespace downward-api-78 deletion completed in 6.287462564s

• [SLOW TEST:8.450 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:12:47.333: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  2 22:12:47.410: INFO: Waiting up to 5m0s for pod "downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203" in namespace "downward-api-4640" to be "success or failure"
Oct  2 22:12:47.426: INFO: Pod "downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 16.069118ms
Oct  2 22:12:49.434: INFO: Pod "downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023989189s
STEP: Saw pod success
Oct  2 22:12:49.434: INFO: Pod "downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:12:49.441: INFO: Trying to get logs from node 10.0.10.3 pod downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:12:49.481: INFO: Waiting for pod downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:12:49.489: INFO: Pod downward-api-c3f7ac90-e561-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:12:49.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4640" for this suite.
Oct  2 22:12:55.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:12:55.771: INFO: namespace downward-api-4640 deletion completed in 6.27534409s

• [SLOW TEST:8.438 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:12:55.772: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct  2 22:12:55.864: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9581,SelfLink:/api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-watch-closed,UID:c9019f76-e561-11e9-a07f-0a580aed12b5,ResourceVersion:18068,Generation:0,CreationTimestamp:2019-10-02 22:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  2 22:12:55.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9581,SelfLink:/api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-watch-closed,UID:c9019f76-e561-11e9-a07f-0a580aed12b5,ResourceVersion:18069,Generation:0,CreationTimestamp:2019-10-02 22:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct  2 22:12:55.901: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9581,SelfLink:/api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-watch-closed,UID:c9019f76-e561-11e9-a07f-0a580aed12b5,ResourceVersion:18070,Generation:0,CreationTimestamp:2019-10-02 22:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  2 22:12:55.901: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9581,SelfLink:/api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-watch-closed,UID:c9019f76-e561-11e9-a07f-0a580aed12b5,ResourceVersion:18071,Generation:0,CreationTimestamp:2019-10-02 22:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:12:55.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9581" for this suite.
Oct  2 22:13:01.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:13:02.204: INFO: namespace watch-9581 deletion completed in 6.296772796s

• [SLOW TEST:6.432 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:13:02.204: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  2 22:13:02.283: INFO: Waiting up to 5m0s for pod "downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203" in namespace "downward-api-856" to be "success or failure"
Oct  2 22:13:02.291: INFO: Pod "downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.594636ms
Oct  2 22:13:04.300: INFO: Pod "downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017268044s
STEP: Saw pod success
Oct  2 22:13:04.300: INFO: Pod "downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:13:04.307: INFO: Trying to get logs from node 10.0.10.3 pod downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:13:04.359: INFO: Waiting for pod downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:13:04.367: INFO: Pod downward-api-ccd65c31-e561-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:13:04.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-856" for this suite.
Oct  2 22:13:10.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:13:10.651: INFO: namespace downward-api-856 deletion completed in 6.277691019s

• [SLOW TEST:8.447 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:13:10.652: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8744.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8744.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8744.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8744.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 168.28.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.28.168_udp@PTR;check="$$(dig +tcp +noall +answer +search 168.28.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.28.168_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8744.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8744.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8744.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8744.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8744.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8744.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 168.28.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.28.168_udp@PTR;check="$$(dig +tcp +noall +answer +search 168.28.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.28.168_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  2 22:13:12.907: INFO: Unable to read wheezy_udp@dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:12.918: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:12.940: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:12.950: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:13.024: INFO: Unable to read jessie_udp@dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:13.035: INFO: Unable to read jessie_tcp@dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:13.045: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:13.055: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local from pod dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203: the server could not find the requested resource (get pods dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203)
Oct  2 22:13:13.139: INFO: Lookups using dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203 failed for: [wheezy_udp@dns-test-service.dns-8744.svc.cluster.local wheezy_tcp@dns-test-service.dns-8744.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local jessie_udp@dns-test-service.dns-8744.svc.cluster.local jessie_tcp@dns-test-service.dns-8744.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8744.svc.cluster.local]

Oct  2 22:13:18.413: INFO: DNS probes using dns-8744/dns-test-d1e300a3-e561-11e9-bbfa-0a580af40203 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:13:18.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8744" for this suite.
Oct  2 22:13:24.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:13:24.805: INFO: namespace dns-8744 deletion completed in 6.275600766s

• [SLOW TEST:14.153 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:13:24.805: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  2 22:13:24.894: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  2 22:13:24.908: INFO: Waiting for terminating namespaces to be deleted...
Oct  2 22:13:24.914: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Oct  2 22:13:25.048: INFO: kube-flannel-ds-bgwzj from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:13:25.048: INFO: kube-dns-autoscaler-5987f4cd86-snh94 from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container autoscaler ready: true, restart count 0
Oct  2 22:13:25.048: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:13:25.048: INFO: kubernetes-dashboard-5c75764dd6-5fg46 from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  2 22:13:25.048: INFO: coredns-56969c94-q4m8c from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:13:25.048: INFO: tiller-deploy-785fd4d8b5-lmpfd from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container tiller ready: true, restart count 0
Oct  2 22:13:25.048: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-hngt6 from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:13:25.048: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:13:25.048: INFO: kube-proxy-8j7cc from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.048: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:13:25.048: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Oct  2 22:13:25.059: INFO: proxymux-client-10.0.10.3 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:13:25.059: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-p2l7g from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:13:25.059: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:13:25.059: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:13:25.059: INFO: kube-flannel-ds-6w9tm from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.059: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:13:25.059: INFO: kube-proxy-sbsqs from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.059: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:13:25.059: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-02 21:07:04 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.059: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  2 22:13:25.060: INFO: sonobuoy-e2e-job-7762dab4d6fa43aa from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:13:25.060: INFO: 	Container e2e ready: true, restart count 0
Oct  2 22:13:25.060: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  2 22:13:25.060: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Oct  2 22:13:25.075: INFO: kube-proxy-tmrht from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.075: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:13:25.075: INFO: coredns-56969c94-zsr6t from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.075: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:13:25.075: INFO: coredns-56969c94-f2czw from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.075: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:13:25.075: INFO: proxymux-client-10.0.10.4 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:13:25.075: INFO: kube-flannel-ds-jpfsd from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:13:25.075: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:13:25.075: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-6d8qm from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:13:25.075: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:13:25.075: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c9f429b757c32a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:13:26.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8545" for this suite.
Oct  2 22:13:32.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:13:32.394: INFO: namespace sched-pred-8545 deletion completed in 6.256734042s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.589 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:13:32.397: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:13:32.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203" in namespace "projected-1887" to be "success or failure"
Oct  2 22:13:32.476: INFO: Pod "downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.471559ms
Oct  2 22:13:34.484: INFO: Pod "downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203": Phase="Running", Reason="", readiness=true. Elapsed: 2.01629494s
Oct  2 22:13:36.492: INFO: Pod "downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024707057s
STEP: Saw pod success
Oct  2 22:13:36.493: INFO: Pod "downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:13:36.500: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:13:36.538: INFO: Waiting for pod downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:13:36.545: INFO: Pod downwardapi-volume-ded40a89-e561-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:13:36.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1887" for this suite.
Oct  2 22:13:42.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:13:42.812: INFO: namespace projected-1887 deletion completed in 6.260776481s

• [SLOW TEST:10.416 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:13:42.813: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  2 22:13:42.880: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:13:46.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6786" for this suite.
Oct  2 22:14:10.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:14:11.099: INFO: namespace init-container-6786 deletion completed in 24.286640655s

• [SLOW TEST:28.287 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:14:11.100: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  2 22:14:11.160: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  2 22:14:11.172: INFO: Waiting for terminating namespaces to be deleted...
Oct  2 22:14:11.178: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Oct  2 22:14:11.188: INFO: kube-proxy-8j7cc from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.188: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:14:11.188: INFO: kube-flannel-ds-bgwzj from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.188: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:14:11.188: INFO: kube-dns-autoscaler-5987f4cd86-snh94 from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.188: INFO: 	Container autoscaler ready: true, restart count 0
Oct  2 22:14:11.188: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:14:11.188: INFO: kubernetes-dashboard-5c75764dd6-5fg46 from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.188: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  2 22:14:11.188: INFO: coredns-56969c94-q4m8c from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.188: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:14:11.188: INFO: tiller-deploy-785fd4d8b5-lmpfd from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.189: INFO: 	Container tiller ready: true, restart count 0
Oct  2 22:14:11.189: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-hngt6 from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:14:11.189: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:14:11.189: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:14:11.189: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Oct  2 22:14:11.198: INFO: kube-proxy-sbsqs from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.198: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:14:11.198: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-02 21:07:04 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.198: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  2 22:14:11.198: INFO: sonobuoy-e2e-job-7762dab4d6fa43aa from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:14:11.198: INFO: 	Container e2e ready: true, restart count 0
Oct  2 22:14:11.198: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  2 22:14:11.198: INFO: proxymux-client-10.0.10.3 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:14:11.198: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-p2l7g from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:14:11.198: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:14:11.198: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:14:11.198: INFO: kube-flannel-ds-6w9tm from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.198: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:14:11.198: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Oct  2 22:14:11.209: INFO: kube-flannel-ds-jpfsd from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.209: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:14:11.209: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-6d8qm from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:14:11.209: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:14:11.209: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:14:11.209: INFO: proxymux-client-10.0.10.4 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:14:11.209: INFO: coredns-56969c94-zsr6t from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.209: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:14:11.209: INFO: kube-proxy-tmrht from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.209: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:14:11.209: INFO: coredns-56969c94-f2czw from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:14:11.209: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f738db70-e561-11e9-bbfa-0a580af40203 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f738db70-e561-11e9-bbfa-0a580af40203 off the node 10.0.10.4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f738db70-e561-11e9-bbfa-0a580af40203
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:14:15.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6145" for this suite.
Oct  2 22:14:31.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:14:31.750: INFO: namespace sched-pred-6145 deletion completed in 16.267824994s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:20.650 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:14:31.752: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0234ddc9-e562-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:14:31.832: INFO: Waiting up to 5m0s for pod "pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203" in namespace "secrets-4775" to be "success or failure"
Oct  2 22:14:31.842: INFO: Pod "pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.948739ms
Oct  2 22:14:33.850: INFO: Pod "pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018613651s
STEP: Saw pod success
Oct  2 22:14:33.850: INFO: Pod "pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:14:33.857: INFO: Trying to get logs from node 10.0.10.3 pod pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:14:33.906: INFO: Waiting for pod pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:14:33.915: INFO: Pod pod-secrets-02365b43-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:14:33.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4775" for this suite.
Oct  2 22:14:39.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:14:40.204: INFO: namespace secrets-4775 deletion completed in 6.282210987s

• [SLOW TEST:8.452 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:14:40.204: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-073e2d0e-e562-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 22:14:40.282: INFO: Waiting up to 5m0s for pod "pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203" in namespace "configmap-9623" to be "success or failure"
Oct  2 22:14:40.291: INFO: Pod "pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.458795ms
Oct  2 22:14:42.300: INFO: Pod "pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018258354s
STEP: Saw pod success
Oct  2 22:14:42.301: INFO: Pod "pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:14:42.309: INFO: Trying to get logs from node 10.0.10.4 pod pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 22:14:42.368: INFO: Waiting for pod pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:14:42.377: INFO: Pod pod-configmaps-073fb967-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:14:42.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9623" for this suite.
Oct  2 22:14:48.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:14:48.689: INFO: namespace configmap-9623 deletion completed in 6.304885985s

• [SLOW TEST:8.485 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:14:48.691: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-f42d
STEP: Creating a pod to test atomic-volume-subpath
Oct  2 22:14:48.798: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f42d" in namespace "subpath-6841" to be "success or failure"
Oct  2 22:14:48.807: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.020412ms
Oct  2 22:14:50.815: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 2.017228334s
Oct  2 22:14:52.823: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 4.025731641s
Oct  2 22:14:54.831: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 6.033429219s
Oct  2 22:14:56.838: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 8.040756163s
Oct  2 22:14:58.849: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 10.05091439s
Oct  2 22:15:00.860: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 12.062426456s
Oct  2 22:15:02.868: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 14.070826849s
Oct  2 22:15:04.876: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 16.078840428s
Oct  2 22:15:06.885: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 18.087519218s
Oct  2 22:15:08.901: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Running", Reason="", readiness=true. Elapsed: 20.103361158s
Oct  2 22:15:10.914: INFO: Pod "pod-subpath-test-downwardapi-f42d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.116200002s
STEP: Saw pod success
Oct  2 22:15:10.914: INFO: Pod "pod-subpath-test-downwardapi-f42d" satisfied condition "success or failure"
Oct  2 22:15:10.920: INFO: Trying to get logs from node 10.0.10.3 pod pod-subpath-test-downwardapi-f42d container test-container-subpath-downwardapi-f42d: <nil>
STEP: delete the pod
Oct  2 22:15:11.012: INFO: Waiting for pod pod-subpath-test-downwardapi-f42d to disappear
Oct  2 22:15:11.028: INFO: Pod pod-subpath-test-downwardapi-f42d no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-f42d
Oct  2 22:15:11.028: INFO: Deleting pod "pod-subpath-test-downwardapi-f42d" in namespace "subpath-6841"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:15:11.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6841" for this suite.
Oct  2 22:15:17.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:15:17.337: INFO: namespace subpath-6841 deletion completed in 6.293821787s

• [SLOW TEST:28.646 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:15:17.338: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-dnlv
STEP: Creating a pod to test atomic-volume-subpath
Oct  2 22:15:17.428: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dnlv" in namespace "subpath-3621" to be "success or failure"
Oct  2 22:15:17.438: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Pending", Reason="", readiness=false. Elapsed: 9.764181ms
Oct  2 22:15:19.454: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 2.026078957s
Oct  2 22:15:21.462: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 4.03384507s
Oct  2 22:15:23.471: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 6.043032702s
Oct  2 22:15:25.481: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 8.053232978s
Oct  2 22:15:27.490: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 10.062278815s
Oct  2 22:15:29.499: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 12.070860937s
Oct  2 22:15:31.513: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 14.08511122s
Oct  2 22:15:33.532: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 16.103840752s
Oct  2 22:15:35.539: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 18.111619819s
Oct  2 22:15:37.548: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Running", Reason="", readiness=true. Elapsed: 20.120187073s
Oct  2 22:15:39.557: INFO: Pod "pod-subpath-test-configmap-dnlv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.128723264s
STEP: Saw pod success
Oct  2 22:15:39.557: INFO: Pod "pod-subpath-test-configmap-dnlv" satisfied condition "success or failure"
Oct  2 22:15:39.566: INFO: Trying to get logs from node 10.0.10.4 pod pod-subpath-test-configmap-dnlv container test-container-subpath-configmap-dnlv: <nil>
STEP: delete the pod
Oct  2 22:15:39.631: INFO: Waiting for pod pod-subpath-test-configmap-dnlv to disappear
Oct  2 22:15:39.639: INFO: Pod pod-subpath-test-configmap-dnlv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dnlv
Oct  2 22:15:39.639: INFO: Deleting pod "pod-subpath-test-configmap-dnlv" in namespace "subpath-3621"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:15:39.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3621" for this suite.
Oct  2 22:15:45.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:15:45.908: INFO: namespace subpath-3621 deletion completed in 6.256116288s

• [SLOW TEST:28.571 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:15:45.909: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  2 22:15:46.003: INFO: Waiting up to 5m0s for pod "pod-2e690203-e562-11e9-bbfa-0a580af40203" in namespace "emptydir-7942" to be "success or failure"
Oct  2 22:15:46.034: INFO: Pod "pod-2e690203-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 31.052511ms
Oct  2 22:15:48.042: INFO: Pod "pod-2e690203-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038796146s
STEP: Saw pod success
Oct  2 22:15:48.042: INFO: Pod "pod-2e690203-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:15:48.048: INFO: Trying to get logs from node 10.0.10.3 pod pod-2e690203-e562-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:15:48.113: INFO: Waiting for pod pod-2e690203-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:15:48.120: INFO: Pod pod-2e690203-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:15:48.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7942" for this suite.
Oct  2 22:15:54.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:15:54.432: INFO: namespace emptydir-7942 deletion completed in 6.305154579s

• [SLOW TEST:8.524 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:15:54.433: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1002 22:16:34.576518      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 22:16:34.576: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:16:34.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1274" for this suite.
Oct  2 22:16:42.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:16:42.905: INFO: namespace gc-1274 deletion completed in 8.322952608s

• [SLOW TEST:48.472 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:16:42.906: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  2 22:16:43.046: INFO: Number of nodes with available pods: 0
Oct  2 22:16:43.046: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:16:44.071: INFO: Number of nodes with available pods: 0
Oct  2 22:16:44.071: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:16:45.069: INFO: Number of nodes with available pods: 3
Oct  2 22:16:45.069: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct  2 22:16:45.108: INFO: Number of nodes with available pods: 2
Oct  2 22:16:45.108: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:16:46.135: INFO: Number of nodes with available pods: 2
Oct  2 22:16:46.135: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:16:47.122: INFO: Number of nodes with available pods: 3
Oct  2 22:16:47.122: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3544, will wait for the garbage collector to delete the pods
Oct  2 22:16:47.209: INFO: Deleting DaemonSet.extensions daemon-set took: 15.010161ms
Oct  2 22:16:47.510: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.339831ms
Oct  2 22:16:58.620: INFO: Number of nodes with available pods: 0
Oct  2 22:16:58.620: INFO: Number of running nodes: 0, number of available pods: 0
Oct  2 22:16:58.628: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3544/daemonsets","resourceVersion":"19216"},"items":null}

Oct  2 22:16:58.637: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3544/pods","resourceVersion":"19216"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:16:58.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3544" for this suite.
Oct  2 22:17:06.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:17:07.001: INFO: namespace daemonsets-3544 deletion completed in 8.316589311s

• [SLOW TEST:24.095 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:17:07.001: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct  2 22:17:07.110: INFO: Waiting up to 5m0s for pod "pod-5ec2aacb-e562-11e9-bbfa-0a580af40203" in namespace "emptydir-7034" to be "success or failure"
Oct  2 22:17:07.122: INFO: Pod "pod-5ec2aacb-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.40809ms
Oct  2 22:17:09.131: INFO: Pod "pod-5ec2aacb-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020290381s
Oct  2 22:17:11.139: INFO: Pod "pod-5ec2aacb-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028420386s
STEP: Saw pod success
Oct  2 22:17:11.139: INFO: Pod "pod-5ec2aacb-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:17:11.146: INFO: Trying to get logs from node 10.0.10.4 pod pod-5ec2aacb-e562-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:17:11.196: INFO: Waiting for pod pod-5ec2aacb-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:17:11.209: INFO: Pod pod-5ec2aacb-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:17:11.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7034" for this suite.
Oct  2 22:17:17.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:17:17.522: INFO: namespace emptydir-7034 deletion completed in 6.30620849s

• [SLOW TEST:10.521 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:17:17.523: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1002 22:17:27.733206      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 22:17:27.733: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:17:27.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1774" for this suite.
Oct  2 22:17:35.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:17:36.059: INFO: namespace gc-1774 deletion completed in 8.319922498s

• [SLOW TEST:18.536 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:17:36.059: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  2 22:17:38.718: INFO: Successfully updated pod "labelsupdate70106740-e562-11e9-bbfa-0a580af40203"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:17:42.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-465" for this suite.
Oct  2 22:18:06.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:18:07.140: INFO: namespace downward-api-465 deletion completed in 24.281467721s

• [SLOW TEST:31.081 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:18:07.141: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-8297ed4a-e562-11e9-bbfa-0a580af40203
STEP: Creating secret with name s-test-opt-upd-8297ed97-e562-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8297ed4a-e562-11e9-bbfa-0a580af40203
STEP: Updating secret s-test-opt-upd-8297ed97-e562-11e9-bbfa-0a580af40203
STEP: Creating secret with name s-test-opt-create-8297eda9-e562-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:18:11.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2347" for this suite.
Oct  2 22:18:35.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:18:35.812: INFO: namespace secrets-2347 deletion completed in 24.283137179s

• [SLOW TEST:28.671 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:18:35.812: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:18:35.885: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203" in namespace "downward-api-9808" to be "success or failure"
Oct  2 22:18:35.896: INFO: Pod "downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.170792ms
Oct  2 22:18:37.907: INFO: Pod "downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022226177s
STEP: Saw pod success
Oct  2 22:18:37.907: INFO: Pod "downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:18:37.914: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:18:37.952: INFO: Waiting for pod downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:18:37.959: INFO: Pod downwardapi-volume-93adef55-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:18:37.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9808" for this suite.
Oct  2 22:18:43.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:18:44.237: INFO: namespace downward-api-9808 deletion completed in 6.271472148s

• [SLOW TEST:8.426 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:18:44.238: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9994.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9994.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9994.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9994.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9994.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9994.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  2 22:18:48.558: INFO: DNS probes using dns-9994/dns-test-98b3dec2-e562-11e9-bbfa-0a580af40203 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:18:48.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9994" for this suite.
Oct  2 22:18:54.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:18:54.877: INFO: namespace dns-9994 deletion completed in 6.274429681s

• [SLOW TEST:10.639 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:18:54.878: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-9f0e7824-e562-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:18:54.989: INFO: Waiting up to 5m0s for pod "pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203" in namespace "secrets-4096" to be "success or failure"
Oct  2 22:18:55.002: INFO: Pod "pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123452ms
Oct  2 22:18:57.013: INFO: Pod "pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024222496s
STEP: Saw pod success
Oct  2 22:18:57.013: INFO: Pod "pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:18:57.020: INFO: Trying to get logs from node 10.0.10.3 pod pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:18:57.123: INFO: Waiting for pod pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:18:57.132: INFO: Pod pod-secrets-9f10ad58-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:18:57.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4096" for this suite.
Oct  2 22:19:03.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:19:03.417: INFO: namespace secrets-4096 deletion completed in 6.278728889s

• [SLOW TEST:8.539 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:19:03.417: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-scvc
STEP: Creating a pod to test atomic-volume-subpath
Oct  2 22:19:03.534: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-scvc" in namespace "subpath-6126" to be "success or failure"
Oct  2 22:19:03.543: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.066608ms
Oct  2 22:19:05.551: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016433723s
Oct  2 22:19:07.574: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 4.039872718s
Oct  2 22:19:09.594: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 6.060156915s
Oct  2 22:19:11.603: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 8.069250534s
Oct  2 22:19:13.611: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 10.07661686s
Oct  2 22:19:15.620: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 12.085362579s
Oct  2 22:19:17.627: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 14.092947394s
Oct  2 22:19:19.636: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 16.10131189s
Oct  2 22:19:21.644: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 18.109729008s
Oct  2 22:19:23.657: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 20.122807482s
Oct  2 22:19:25.665: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Running", Reason="", readiness=true. Elapsed: 22.131260551s
Oct  2 22:19:27.686: INFO: Pod "pod-subpath-test-configmap-scvc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.151691418s
STEP: Saw pod success
Oct  2 22:19:27.686: INFO: Pod "pod-subpath-test-configmap-scvc" satisfied condition "success or failure"
Oct  2 22:19:27.693: INFO: Trying to get logs from node 10.0.10.4 pod pod-subpath-test-configmap-scvc container test-container-subpath-configmap-scvc: <nil>
STEP: delete the pod
Oct  2 22:19:27.834: INFO: Waiting for pod pod-subpath-test-configmap-scvc to disappear
Oct  2 22:19:27.841: INFO: Pod pod-subpath-test-configmap-scvc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-scvc
Oct  2 22:19:27.841: INFO: Deleting pod "pod-subpath-test-configmap-scvc" in namespace "subpath-6126"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:19:27.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6126" for this suite.
Oct  2 22:19:33.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:19:34.206: INFO: namespace subpath-6126 deletion completed in 6.346392213s

• [SLOW TEST:30.788 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:19:34.206: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:19:39.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8428" for this suite.
Oct  2 22:20:03.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:20:03.622: INFO: namespace replication-controller-8428 deletion completed in 24.278005308s

• [SLOW TEST:29.416 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:20:03.622: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  2 22:20:03.699: INFO: Waiting up to 5m0s for pod "pod-c8052a5d-e562-11e9-bbfa-0a580af40203" in namespace "emptydir-8867" to be "success or failure"
Oct  2 22:20:03.707: INFO: Pod "pod-c8052a5d-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.424981ms
Oct  2 22:20:05.715: INFO: Pod "pod-c8052a5d-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016351252s
STEP: Saw pod success
Oct  2 22:20:05.715: INFO: Pod "pod-c8052a5d-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:20:05.722: INFO: Trying to get logs from node 10.0.10.4 pod pod-c8052a5d-e562-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:20:05.843: INFO: Waiting for pod pod-c8052a5d-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:20:05.850: INFO: Pod pod-c8052a5d-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:20:05.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8867" for this suite.
Oct  2 22:20:11.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:20:12.150: INFO: namespace emptydir-8867 deletion completed in 6.293416055s

• [SLOW TEST:8.528 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:20:12.150: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:20:33.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-93" for this suite.
Oct  2 22:20:39.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:20:39.947: INFO: namespace container-runtime-93 deletion completed in 6.272010975s

• [SLOW TEST:27.797 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:20:39.947: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-ddab1812-e562-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 22:20:40.040: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203" in namespace "projected-8448" to be "success or failure"
Oct  2 22:20:40.051: INFO: Pod "pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.293603ms
Oct  2 22:20:42.072: INFO: Pod "pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032650686s
STEP: Saw pod success
Oct  2 22:20:42.072: INFO: Pod "pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:20:42.086: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 22:20:42.128: INFO: Waiting for pod pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:20:42.136: INFO: Pod pod-projected-configmaps-ddad7ec4-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:20:42.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8448" for this suite.
Oct  2 22:20:48.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:20:48.420: INFO: namespace projected-8448 deletion completed in 6.277920107s

• [SLOW TEST:8.473 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:20:48.420: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  2 22:20:48.489: INFO: Waiting up to 5m0s for pod "pod-e2b7a527-e562-11e9-bbfa-0a580af40203" in namespace "emptydir-6664" to be "success or failure"
Oct  2 22:20:48.504: INFO: Pod "pod-e2b7a527-e562-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 15.066784ms
Oct  2 22:20:50.512: INFO: Pod "pod-e2b7a527-e562-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023187358s
STEP: Saw pod success
Oct  2 22:20:50.512: INFO: Pod "pod-e2b7a527-e562-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:20:50.519: INFO: Trying to get logs from node 10.0.10.3 pod pod-e2b7a527-e562-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:20:50.568: INFO: Waiting for pod pod-e2b7a527-e562-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:20:50.578: INFO: Pod pod-e2b7a527-e562-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:20:50.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6664" for this suite.
Oct  2 22:20:56.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:20:56.899: INFO: namespace emptydir-6664 deletion completed in 6.313901238s

• [SLOW TEST:8.479 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:20:56.899: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:20:56.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9513" for this suite.
Oct  2 22:21:21.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:21:21.360: INFO: namespace kubelet-test-9513 deletion completed in 24.355557114s

• [SLOW TEST:24.461 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:21:21.360: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-f65bcc75-e562-11e9-bbfa-0a580af40203
STEP: Creating secret with name s-test-opt-upd-f65bcccf-e562-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f65bcc75-e562-11e9-bbfa-0a580af40203
STEP: Updating secret s-test-opt-upd-f65bcccf-e562-11e9-bbfa-0a580af40203
STEP: Creating secret with name s-test-opt-create-f65bcd07-e562-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:21:27.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5228" for this suite.
Oct  2 22:21:51.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:21:52.069: INFO: namespace projected-5228 deletion completed in 24.315235334s

• [SLOW TEST:30.710 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:21:52.070: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:21:52.201: INFO: (0) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.772752ms)
Oct  2 22:21:52.209: INFO: (1) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.529651ms)
Oct  2 22:21:52.219: INFO: (2) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.489527ms)
Oct  2 22:21:52.229: INFO: (3) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.612082ms)
Oct  2 22:21:52.237: INFO: (4) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.887007ms)
Oct  2 22:21:52.253: INFO: (5) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 15.952436ms)
Oct  2 22:21:52.332: INFO: (6) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 79.225174ms)
Oct  2 22:21:52.341: INFO: (7) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.171765ms)
Oct  2 22:21:52.363: INFO: (8) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 21.728179ms)
Oct  2 22:21:52.375: INFO: (9) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.130507ms)
Oct  2 22:21:52.387: INFO: (10) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.083569ms)
Oct  2 22:21:52.405: INFO: (11) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.489777ms)
Oct  2 22:21:52.413: INFO: (12) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.593776ms)
Oct  2 22:21:52.422: INFO: (13) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.001492ms)
Oct  2 22:21:52.430: INFO: (14) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.672526ms)
Oct  2 22:21:52.441: INFO: (15) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.554052ms)
Oct  2 22:21:52.450: INFO: (16) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.640801ms)
Oct  2 22:21:52.459: INFO: (17) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.836913ms)
Oct  2 22:21:52.468: INFO: (18) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.776509ms)
Oct  2 22:21:52.479: INFO: (19) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 11.127873ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:21:52.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-336" for this suite.
Oct  2 22:21:58.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:21:58.767: INFO: namespace proxy-336 deletion completed in 6.280601916s

• [SLOW TEST:6.697 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:21:58.767: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct  2 22:21:58.897: INFO: Pod name pod-release: Found 0 pods out of 1
Oct  2 22:22:03.920: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:22:04.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1701" for this suite.
Oct  2 22:22:10.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:22:11.270: INFO: namespace replication-controller-1701 deletion completed in 6.309752442s

• [SLOW TEST:12.503 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:22:11.270: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Oct  2 22:22:11.329: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-715202161 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:22:11.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-661" for this suite.
Oct  2 22:22:17.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:22:17.810: INFO: namespace kubectl-661 deletion completed in 6.373635313s

• [SLOW TEST:6.540 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:22:17.811: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:22:17.901: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203" in namespace "downward-api-5058" to be "success or failure"
Oct  2 22:22:17.908: INFO: Pod "downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.806738ms
Oct  2 22:22:19.917: INFO: Pod "downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016011097s
STEP: Saw pod success
Oct  2 22:22:19.917: INFO: Pod "downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:22:19.930: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:22:20.033: INFO: Waiting for pod downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:22:20.045: INFO: Pod downwardapi-volume-18026b10-e563-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:22:20.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5058" for this suite.
Oct  2 22:22:26.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:22:26.420: INFO: namespace downward-api-5058 deletion completed in 6.323836858s

• [SLOW TEST:8.609 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:22:26.421: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  2 22:22:26.586: INFO: Number of nodes with available pods: 0
Oct  2 22:22:26.586: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:22:27.604: INFO: Number of nodes with available pods: 0
Oct  2 22:22:27.604: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:22:28.611: INFO: Number of nodes with available pods: 3
Oct  2 22:22:28.611: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct  2 22:22:28.662: INFO: Number of nodes with available pods: 2
Oct  2 22:22:28.662: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:29.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:29.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:30.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:30.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:31.676: INFO: Number of nodes with available pods: 2
Oct  2 22:22:31.676: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:32.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:32.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:33.683: INFO: Number of nodes with available pods: 2
Oct  2 22:22:33.683: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:34.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:34.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:35.676: INFO: Number of nodes with available pods: 2
Oct  2 22:22:35.676: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:36.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:36.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:37.683: INFO: Number of nodes with available pods: 2
Oct  2 22:22:37.683: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:38.677: INFO: Number of nodes with available pods: 2
Oct  2 22:22:38.677: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:39.688: INFO: Number of nodes with available pods: 2
Oct  2 22:22:39.688: INFO: Node 10.0.10.4 is running more than one daemon pod
Oct  2 22:22:40.677: INFO: Number of nodes with available pods: 3
Oct  2 22:22:40.677: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4266, will wait for the garbage collector to delete the pods
Oct  2 22:22:40.767: INFO: Deleting DaemonSet.extensions daemon-set took: 26.970205ms
Oct  2 22:22:41.067: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.267481ms
Oct  2 22:22:53.374: INFO: Number of nodes with available pods: 0
Oct  2 22:22:53.374: INFO: Number of running nodes: 0, number of available pods: 0
Oct  2 22:22:53.381: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4266/daemonsets","resourceVersion":"20845"},"items":null}

Oct  2 22:22:53.392: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4266/pods","resourceVersion":"20845"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:22:53.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4266" for this suite.
Oct  2 22:23:01.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:23:01.788: INFO: namespace daemonsets-4266 deletion completed in 8.345470214s

• [SLOW TEST:35.367 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:23:01.788: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-701
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-701
STEP: Deleting pre-stop pod
Oct  2 22:23:13.036: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:23:13.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-701" for this suite.
Oct  2 22:23:53.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:23:53.375: INFO: namespace prestop-701 deletion completed in 40.316455737s

• [SLOW TEST:51.587 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:23:53.375: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:23:53.456: INFO: Creating ReplicaSet my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203
Oct  2 22:23:53.486: INFO: Pod name my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203: Found 0 pods out of 1
Oct  2 22:23:58.495: INFO: Pod name my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203: Found 1 pods out of 1
Oct  2 22:23:58.495: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203" is running
Oct  2 22:23:58.504: INFO: Pod "my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203-wr4tw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 22:23:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 22:23:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 22:23:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-02 22:23:53 +0000 UTC Reason: Message:}])
Oct  2 22:23:58.505: INFO: Trying to dial the pod
Oct  2 22:24:03.619: INFO: Controller my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203: Got expected result from replica 1 [my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203-wr4tw]: "my-hostname-basic-50f98689-e563-11e9-bbfa-0a580af40203-wr4tw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:24:03.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8289" for this suite.
Oct  2 22:24:09.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:24:09.895: INFO: namespace replicaset-8289 deletion completed in 6.267670061s

• [SLOW TEST:16.520 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:24:09.895: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1002 22:24:20.021817      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  2 22:24:20.021: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:24:20.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2442" for this suite.
Oct  2 22:24:26.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:24:26.340: INFO: namespace gc-2442 deletion completed in 6.312349s

• [SLOW TEST:16.445 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:24:26.340: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:24:26.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203" in namespace "projected-1961" to be "success or failure"
Oct  2 22:24:26.444: INFO: Pod "downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.635998ms
Oct  2 22:24:28.454: INFO: Pod "downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020792597s
STEP: Saw pod success
Oct  2 22:24:28.454: INFO: Pod "downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:24:28.461: INFO: Trying to get logs from node 10.0.10.3 pod downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:24:28.520: INFO: Waiting for pod downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:24:28.528: INFO: Pod downwardapi-volume-649ca6a8-e563-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:24:28.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1961" for this suite.
Oct  2 22:24:34.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:24:34.811: INFO: namespace projected-1961 deletion completed in 6.276860957s

• [SLOW TEST:8.471 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:24:34.812: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2487
I1002 22:24:34.879311      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2487, replica count: 1
I1002 22:24:35.929903      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1002 22:24:36.930110      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  2 22:24:37.052: INFO: Created: latency-svc-hqxd9
Oct  2 22:24:37.065: INFO: Got endpoints: latency-svc-hqxd9 [35.019039ms]
Oct  2 22:24:37.084: INFO: Created: latency-svc-5mqm4
Oct  2 22:24:37.090: INFO: Created: latency-svc-9vk2v
Oct  2 22:24:37.095: INFO: Got endpoints: latency-svc-5mqm4 [29.359309ms]
Oct  2 22:24:37.099: INFO: Got endpoints: latency-svc-9vk2v [33.258566ms]
Oct  2 22:24:37.103: INFO: Created: latency-svc-gxz9k
Oct  2 22:24:37.110: INFO: Created: latency-svc-kw8t9
Oct  2 22:24:37.111: INFO: Got endpoints: latency-svc-gxz9k [44.69747ms]
Oct  2 22:24:37.116: INFO: Created: latency-svc-6hdkn
Oct  2 22:24:37.121: INFO: Created: latency-svc-wczc9
Oct  2 22:24:37.122: INFO: Got endpoints: latency-svc-kw8t9 [55.20201ms]
Oct  2 22:24:37.129: INFO: Got endpoints: latency-svc-6hdkn [62.063573ms]
Oct  2 22:24:37.130: INFO: Got endpoints: latency-svc-wczc9 [63.570629ms]
Oct  2 22:24:37.137: INFO: Created: latency-svc-lpktl
Oct  2 22:24:37.141: INFO: Created: latency-svc-87t64
Oct  2 22:24:37.148: INFO: Got endpoints: latency-svc-lpktl [80.789258ms]
Oct  2 22:24:37.149: INFO: Created: latency-svc-dpp4l
Oct  2 22:24:37.150: INFO: Got endpoints: latency-svc-87t64 [82.276783ms]
Oct  2 22:24:37.156: INFO: Created: latency-svc-g5jpn
Oct  2 22:24:37.157: INFO: Got endpoints: latency-svc-dpp4l [89.733581ms]
Oct  2 22:24:37.162: INFO: Created: latency-svc-lhzhr
Oct  2 22:24:37.165: INFO: Got endpoints: latency-svc-g5jpn [97.81068ms]
Oct  2 22:24:37.170: INFO: Got endpoints: latency-svc-lhzhr [102.239904ms]
Oct  2 22:24:37.173: INFO: Created: latency-svc-m7bbv
Oct  2 22:24:37.182: INFO: Created: latency-svc-mb7bz
Oct  2 22:24:37.182: INFO: Got endpoints: latency-svc-m7bbv [114.360405ms]
Oct  2 22:24:37.194: INFO: Created: latency-svc-smz4h
Oct  2 22:24:37.199: INFO: Got endpoints: latency-svc-mb7bz [130.848933ms]
Oct  2 22:24:37.201: INFO: Got endpoints: latency-svc-smz4h [133.67025ms]
Oct  2 22:24:37.212: INFO: Created: latency-svc-zr2vc
Oct  2 22:24:37.218: INFO: Created: latency-svc-f4j7t
Oct  2 22:24:37.226: INFO: Got endpoints: latency-svc-zr2vc [159.424991ms]
Oct  2 22:24:37.237: INFO: Got endpoints: latency-svc-f4j7t [141.935085ms]
Oct  2 22:24:37.240: INFO: Created: latency-svc-8qtq4
Oct  2 22:24:37.251: INFO: Created: latency-svc-lhz5l
Oct  2 22:24:37.256: INFO: Got endpoints: latency-svc-8qtq4 [156.988698ms]
Oct  2 22:24:37.260: INFO: Got endpoints: latency-svc-lhz5l [149.384228ms]
Oct  2 22:24:37.263: INFO: Created: latency-svc-dmmxp
Oct  2 22:24:37.272: INFO: Got endpoints: latency-svc-dmmxp [150.164055ms]
Oct  2 22:24:37.273: INFO: Created: latency-svc-2dbzx
Oct  2 22:24:37.279: INFO: Created: latency-svc-zf57f
Oct  2 22:24:37.282: INFO: Got endpoints: latency-svc-2dbzx [152.941277ms]
Oct  2 22:24:37.288: INFO: Got endpoints: latency-svc-zf57f [27.684768ms]
Oct  2 22:24:37.290: INFO: Created: latency-svc-cn4lp
Oct  2 22:24:37.308: INFO: Got endpoints: latency-svc-cn4lp [177.76837ms]
Oct  2 22:24:37.308: INFO: Created: latency-svc-9tgdz
Oct  2 22:24:37.320: INFO: Created: latency-svc-479zj
Oct  2 22:24:37.322: INFO: Got endpoints: latency-svc-9tgdz [173.978562ms]
Oct  2 22:24:37.323: INFO: Created: latency-svc-8kjf7
Oct  2 22:24:37.333: INFO: Created: latency-svc-psrl5
Oct  2 22:24:37.335: INFO: Got endpoints: latency-svc-8kjf7 [177.309946ms]
Oct  2 22:24:37.336: INFO: Got endpoints: latency-svc-479zj [186.023652ms]
Oct  2 22:24:37.344: INFO: Created: latency-svc-hbwbs
Oct  2 22:24:37.356: INFO: Got endpoints: latency-svc-psrl5 [190.62415ms]
Oct  2 22:24:37.361: INFO: Created: latency-svc-4s75b
Oct  2 22:24:37.372: INFO: Got endpoints: latency-svc-4s75b [189.585211ms]
Oct  2 22:24:37.372: INFO: Got endpoints: latency-svc-hbwbs [202.689914ms]
Oct  2 22:24:37.375: INFO: Created: latency-svc-f2zlh
Oct  2 22:24:37.377: INFO: Created: latency-svc-t7w7b
Oct  2 22:24:37.384: INFO: Got endpoints: latency-svc-f2zlh [185.06983ms]
Oct  2 22:24:37.385: INFO: Got endpoints: latency-svc-t7w7b [183.67147ms]
Oct  2 22:24:37.389: INFO: Created: latency-svc-pcg54
Oct  2 22:24:37.398: INFO: Created: latency-svc-q9nml
Oct  2 22:24:37.403: INFO: Got endpoints: latency-svc-pcg54 [176.529638ms]
Oct  2 22:24:37.409: INFO: Created: latency-svc-44nmf
Oct  2 22:24:37.418: INFO: Created: latency-svc-gdv75
Oct  2 22:24:37.420: INFO: Got endpoints: latency-svc-q9nml [182.734971ms]
Oct  2 22:24:37.420: INFO: Got endpoints: latency-svc-44nmf [163.35222ms]
Oct  2 22:24:37.432: INFO: Created: latency-svc-c5rls
Oct  2 22:24:37.433: INFO: Got endpoints: latency-svc-gdv75 [160.553884ms]
Oct  2 22:24:37.448: INFO: Created: latency-svc-2kbq7
Oct  2 22:24:37.454: INFO: Got endpoints: latency-svc-c5rls [172.006932ms]
Oct  2 22:24:37.456: INFO: Created: latency-svc-5v49k
Oct  2 22:24:37.457: INFO: Created: latency-svc-788qc
Oct  2 22:24:37.458: INFO: Created: latency-svc-kc6rd
Oct  2 22:24:37.458: INFO: Got endpoints: latency-svc-2kbq7 [169.850309ms]
Oct  2 22:24:37.468: INFO: Got endpoints: latency-svc-5v49k [159.66418ms]
Oct  2 22:24:37.469: INFO: Created: latency-svc-9w92n
Oct  2 22:24:37.473: INFO: Created: latency-svc-c6lmh
Oct  2 22:24:37.482: INFO: Created: latency-svc-th5pq
Oct  2 22:24:37.492: INFO: Created: latency-svc-v5qmm
Oct  2 22:24:37.497: INFO: Created: latency-svc-htt7j
Oct  2 22:24:37.502: INFO: Created: latency-svc-7664v
Oct  2 22:24:37.511: INFO: Created: latency-svc-h79gl
Oct  2 22:24:37.515: INFO: Got endpoints: latency-svc-788qc [192.485172ms]
Oct  2 22:24:37.524: INFO: Created: latency-svc-jmh7v
Oct  2 22:24:37.539: INFO: Created: latency-svc-lx486
Oct  2 22:24:37.546: INFO: Created: latency-svc-fpmtk
Oct  2 22:24:37.558: INFO: Created: latency-svc-rwxcx
Oct  2 22:24:37.570: INFO: Created: latency-svc-sftm9
Oct  2 22:24:37.571: INFO: Got endpoints: latency-svc-kc6rd [235.46199ms]
Oct  2 22:24:37.580: INFO: Created: latency-svc-fhz8f
Oct  2 22:24:37.589: INFO: Created: latency-svc-jbk75
Oct  2 22:24:37.596: INFO: Created: latency-svc-78qgp
Oct  2 22:24:37.612: INFO: Got endpoints: latency-svc-9w92n [275.514641ms]
Oct  2 22:24:37.629: INFO: Created: latency-svc-qkt6q
Oct  2 22:24:37.663: INFO: Got endpoints: latency-svc-c6lmh [306.968781ms]
Oct  2 22:24:37.686: INFO: Created: latency-svc-qszgl
Oct  2 22:24:37.715: INFO: Got endpoints: latency-svc-th5pq [343.072193ms]
Oct  2 22:24:37.733: INFO: Created: latency-svc-xx9zv
Oct  2 22:24:37.763: INFO: Got endpoints: latency-svc-v5qmm [390.327682ms]
Oct  2 22:24:37.778: INFO: Created: latency-svc-g48jw
Oct  2 22:24:37.819: INFO: Got endpoints: latency-svc-htt7j [434.360949ms]
Oct  2 22:24:37.834: INFO: Created: latency-svc-hdqvv
Oct  2 22:24:37.864: INFO: Got endpoints: latency-svc-7664v [475.745577ms]
Oct  2 22:24:37.882: INFO: Created: latency-svc-r27j5
Oct  2 22:24:37.912: INFO: Got endpoints: latency-svc-h79gl [509.288214ms]
Oct  2 22:24:37.932: INFO: Created: latency-svc-vrn45
Oct  2 22:24:37.964: INFO: Got endpoints: latency-svc-jmh7v [541.542988ms]
Oct  2 22:24:37.979: INFO: Created: latency-svc-h5485
Oct  2 22:24:38.015: INFO: Got endpoints: latency-svc-lx486 [592.782899ms]
Oct  2 22:24:38.035: INFO: Created: latency-svc-jpvmn
Oct  2 22:24:38.066: INFO: Got endpoints: latency-svc-fpmtk [633.610371ms]
Oct  2 22:24:38.085: INFO: Created: latency-svc-krntv
Oct  2 22:24:38.114: INFO: Got endpoints: latency-svc-rwxcx [659.246651ms]
Oct  2 22:24:38.129: INFO: Created: latency-svc-6qc76
Oct  2 22:24:38.166: INFO: Got endpoints: latency-svc-sftm9 [707.486464ms]
Oct  2 22:24:38.183: INFO: Created: latency-svc-gx62p
Oct  2 22:24:38.213: INFO: Got endpoints: latency-svc-fhz8f [745.437765ms]
Oct  2 22:24:38.234: INFO: Created: latency-svc-w2x7p
Oct  2 22:24:38.263: INFO: Got endpoints: latency-svc-jbk75 [748.328835ms]
Oct  2 22:24:38.285: INFO: Created: latency-svc-qwq7x
Oct  2 22:24:38.315: INFO: Got endpoints: latency-svc-78qgp [743.71852ms]
Oct  2 22:24:38.344: INFO: Created: latency-svc-gxjp8
Oct  2 22:24:38.369: INFO: Got endpoints: latency-svc-qkt6q [756.978764ms]
Oct  2 22:24:38.398: INFO: Created: latency-svc-xvw55
Oct  2 22:24:38.413: INFO: Got endpoints: latency-svc-qszgl [749.364147ms]
Oct  2 22:24:38.432: INFO: Created: latency-svc-lzmzq
Oct  2 22:24:38.465: INFO: Got endpoints: latency-svc-xx9zv [749.959536ms]
Oct  2 22:24:38.484: INFO: Created: latency-svc-5jxpv
Oct  2 22:24:38.515: INFO: Got endpoints: latency-svc-g48jw [752.043218ms]
Oct  2 22:24:38.531: INFO: Created: latency-svc-qhbsx
Oct  2 22:24:38.563: INFO: Got endpoints: latency-svc-hdqvv [744.282306ms]
Oct  2 22:24:38.580: INFO: Created: latency-svc-6zxh2
Oct  2 22:24:38.614: INFO: Got endpoints: latency-svc-r27j5 [749.67482ms]
Oct  2 22:24:38.630: INFO: Created: latency-svc-mmfm7
Oct  2 22:24:38.665: INFO: Got endpoints: latency-svc-vrn45 [752.020884ms]
Oct  2 22:24:38.680: INFO: Created: latency-svc-slvht
Oct  2 22:24:38.713: INFO: Got endpoints: latency-svc-h5485 [749.713746ms]
Oct  2 22:24:38.730: INFO: Created: latency-svc-grqvq
Oct  2 22:24:38.764: INFO: Got endpoints: latency-svc-jpvmn [748.042729ms]
Oct  2 22:24:38.782: INFO: Created: latency-svc-2plkh
Oct  2 22:24:38.815: INFO: Got endpoints: latency-svc-krntv [748.132368ms]
Oct  2 22:24:38.834: INFO: Created: latency-svc-rvhd2
Oct  2 22:24:38.866: INFO: Got endpoints: latency-svc-6qc76 [752.193722ms]
Oct  2 22:24:38.894: INFO: Created: latency-svc-nxcrq
Oct  2 22:24:38.913: INFO: Got endpoints: latency-svc-gx62p [746.789165ms]
Oct  2 22:24:38.937: INFO: Created: latency-svc-9v5sc
Oct  2 22:24:38.963: INFO: Got endpoints: latency-svc-w2x7p [749.727213ms]
Oct  2 22:24:38.979: INFO: Created: latency-svc-7788g
Oct  2 22:24:39.014: INFO: Got endpoints: latency-svc-qwq7x [750.457043ms]
Oct  2 22:24:39.031: INFO: Created: latency-svc-jc2wn
Oct  2 22:24:39.063: INFO: Got endpoints: latency-svc-gxjp8 [748.75318ms]
Oct  2 22:24:39.081: INFO: Created: latency-svc-r4zlv
Oct  2 22:24:39.113: INFO: Got endpoints: latency-svc-xvw55 [743.425413ms]
Oct  2 22:24:39.128: INFO: Created: latency-svc-z9526
Oct  2 22:24:39.166: INFO: Got endpoints: latency-svc-lzmzq [752.579465ms]
Oct  2 22:24:39.183: INFO: Created: latency-svc-zwnqv
Oct  2 22:24:39.213: INFO: Got endpoints: latency-svc-5jxpv [747.373184ms]
Oct  2 22:24:39.229: INFO: Created: latency-svc-p82wc
Oct  2 22:24:39.263: INFO: Got endpoints: latency-svc-qhbsx [747.332652ms]
Oct  2 22:24:39.280: INFO: Created: latency-svc-w2tvz
Oct  2 22:24:39.318: INFO: Got endpoints: latency-svc-6zxh2 [754.65328ms]
Oct  2 22:24:39.334: INFO: Created: latency-svc-mlmkh
Oct  2 22:24:39.364: INFO: Got endpoints: latency-svc-mmfm7 [749.643753ms]
Oct  2 22:24:39.382: INFO: Created: latency-svc-7kf9x
Oct  2 22:24:39.414: INFO: Got endpoints: latency-svc-slvht [748.664156ms]
Oct  2 22:24:39.450: INFO: Created: latency-svc-hl7zl
Oct  2 22:24:39.463: INFO: Got endpoints: latency-svc-grqvq [749.305712ms]
Oct  2 22:24:39.478: INFO: Created: latency-svc-vsh2c
Oct  2 22:24:39.513: INFO: Got endpoints: latency-svc-2plkh [749.781409ms]
Oct  2 22:24:39.529: INFO: Created: latency-svc-9bstf
Oct  2 22:24:39.573: INFO: Got endpoints: latency-svc-rvhd2 [758.677355ms]
Oct  2 22:24:39.613: INFO: Created: latency-svc-4c6t9
Oct  2 22:24:39.614: INFO: Got endpoints: latency-svc-nxcrq [748.121444ms]
Oct  2 22:24:39.633: INFO: Created: latency-svc-hswd2
Oct  2 22:24:39.663: INFO: Got endpoints: latency-svc-9v5sc [749.92852ms]
Oct  2 22:24:39.680: INFO: Created: latency-svc-tpgsd
Oct  2 22:24:39.714: INFO: Got endpoints: latency-svc-7788g [751.031243ms]
Oct  2 22:24:39.732: INFO: Created: latency-svc-b7ggh
Oct  2 22:24:39.765: INFO: Got endpoints: latency-svc-jc2wn [751.636843ms]
Oct  2 22:24:39.783: INFO: Created: latency-svc-w8qpn
Oct  2 22:24:39.812: INFO: Got endpoints: latency-svc-r4zlv [749.065205ms]
Oct  2 22:24:39.828: INFO: Created: latency-svc-w9brt
Oct  2 22:24:39.870: INFO: Got endpoints: latency-svc-z9526 [756.500556ms]
Oct  2 22:24:39.888: INFO: Created: latency-svc-lcg24
Oct  2 22:24:39.914: INFO: Got endpoints: latency-svc-zwnqv [747.924693ms]
Oct  2 22:24:39.929: INFO: Created: latency-svc-zz75v
Oct  2 22:24:39.978: INFO: Got endpoints: latency-svc-p82wc [764.134995ms]
Oct  2 22:24:39.995: INFO: Created: latency-svc-f8k6q
Oct  2 22:24:40.021: INFO: Got endpoints: latency-svc-w2tvz [758.644426ms]
Oct  2 22:24:40.039: INFO: Created: latency-svc-dx9dc
Oct  2 22:24:40.064: INFO: Got endpoints: latency-svc-mlmkh [745.6232ms]
Oct  2 22:24:40.085: INFO: Created: latency-svc-wvdth
Oct  2 22:24:40.113: INFO: Got endpoints: latency-svc-7kf9x [748.436457ms]
Oct  2 22:24:40.128: INFO: Created: latency-svc-f2mff
Oct  2 22:24:40.163: INFO: Got endpoints: latency-svc-hl7zl [749.098256ms]
Oct  2 22:24:40.179: INFO: Created: latency-svc-2f7pl
Oct  2 22:24:40.213: INFO: Got endpoints: latency-svc-vsh2c [749.895991ms]
Oct  2 22:24:40.227: INFO: Created: latency-svc-fv6cb
Oct  2 22:24:40.263: INFO: Got endpoints: latency-svc-9bstf [749.070773ms]
Oct  2 22:24:40.278: INFO: Created: latency-svc-6mmzk
Oct  2 22:24:40.312: INFO: Got endpoints: latency-svc-4c6t9 [738.981795ms]
Oct  2 22:24:40.328: INFO: Created: latency-svc-6kfzm
Oct  2 22:24:40.363: INFO: Got endpoints: latency-svc-hswd2 [748.349829ms]
Oct  2 22:24:40.379: INFO: Created: latency-svc-t9j69
Oct  2 22:24:40.416: INFO: Got endpoints: latency-svc-tpgsd [752.816389ms]
Oct  2 22:24:40.435: INFO: Created: latency-svc-w2z6z
Oct  2 22:24:40.463: INFO: Got endpoints: latency-svc-b7ggh [748.753512ms]
Oct  2 22:24:40.482: INFO: Created: latency-svc-flfpg
Oct  2 22:24:40.513: INFO: Got endpoints: latency-svc-w8qpn [747.639061ms]
Oct  2 22:24:40.528: INFO: Created: latency-svc-977m9
Oct  2 22:24:40.567: INFO: Got endpoints: latency-svc-w9brt [754.508785ms]
Oct  2 22:24:40.593: INFO: Created: latency-svc-lpdhh
Oct  2 22:24:40.613: INFO: Got endpoints: latency-svc-lcg24 [742.877353ms]
Oct  2 22:24:40.630: INFO: Created: latency-svc-fckpm
Oct  2 22:24:40.663: INFO: Got endpoints: latency-svc-zz75v [749.453909ms]
Oct  2 22:24:40.687: INFO: Created: latency-svc-q7q4r
Oct  2 22:24:40.713: INFO: Got endpoints: latency-svc-f8k6q [734.479749ms]
Oct  2 22:24:40.734: INFO: Created: latency-svc-94ffn
Oct  2 22:24:40.763: INFO: Got endpoints: latency-svc-dx9dc [741.899697ms]
Oct  2 22:24:40.781: INFO: Created: latency-svc-kgn4p
Oct  2 22:24:40.813: INFO: Got endpoints: latency-svc-wvdth [749.036931ms]
Oct  2 22:24:40.830: INFO: Created: latency-svc-q8rwt
Oct  2 22:24:40.870: INFO: Got endpoints: latency-svc-f2mff [757.402111ms]
Oct  2 22:24:40.887: INFO: Created: latency-svc-tr2gw
Oct  2 22:24:40.919: INFO: Got endpoints: latency-svc-2f7pl [755.716606ms]
Oct  2 22:24:40.941: INFO: Created: latency-svc-frwrc
Oct  2 22:24:40.962: INFO: Got endpoints: latency-svc-fv6cb [749.265279ms]
Oct  2 22:24:40.985: INFO: Created: latency-svc-zt6tx
Oct  2 22:24:41.014: INFO: Got endpoints: latency-svc-6mmzk [751.157796ms]
Oct  2 22:24:41.032: INFO: Created: latency-svc-w65fs
Oct  2 22:24:41.066: INFO: Got endpoints: latency-svc-6kfzm [752.862808ms]
Oct  2 22:24:41.082: INFO: Created: latency-svc-ps98h
Oct  2 22:24:41.125: INFO: Got endpoints: latency-svc-t9j69 [761.280767ms]
Oct  2 22:24:41.143: INFO: Created: latency-svc-tkrhx
Oct  2 22:24:41.165: INFO: Got endpoints: latency-svc-w2z6z [748.448056ms]
Oct  2 22:24:41.180: INFO: Created: latency-svc-kv9k5
Oct  2 22:24:41.216: INFO: Got endpoints: latency-svc-flfpg [753.417561ms]
Oct  2 22:24:41.232: INFO: Created: latency-svc-jlsgk
Oct  2 22:24:41.264: INFO: Got endpoints: latency-svc-977m9 [751.015905ms]
Oct  2 22:24:41.280: INFO: Created: latency-svc-rnbtl
Oct  2 22:24:41.334: INFO: Got endpoints: latency-svc-lpdhh [766.889596ms]
Oct  2 22:24:41.363: INFO: Got endpoints: latency-svc-fckpm [749.630971ms]
Oct  2 22:24:41.363: INFO: Created: latency-svc-474gv
Oct  2 22:24:41.379: INFO: Created: latency-svc-6bh42
Oct  2 22:24:41.414: INFO: Got endpoints: latency-svc-q7q4r [750.481067ms]
Oct  2 22:24:41.436: INFO: Created: latency-svc-tptvp
Oct  2 22:24:41.462: INFO: Got endpoints: latency-svc-94ffn [749.104721ms]
Oct  2 22:24:41.478: INFO: Created: latency-svc-gjpcv
Oct  2 22:24:41.521: INFO: Got endpoints: latency-svc-kgn4p [757.397542ms]
Oct  2 22:24:41.540: INFO: Created: latency-svc-lsvsc
Oct  2 22:24:41.573: INFO: Got endpoints: latency-svc-q8rwt [759.559676ms]
Oct  2 22:24:41.591: INFO: Created: latency-svc-qw7jq
Oct  2 22:24:41.614: INFO: Got endpoints: latency-svc-tr2gw [744.20012ms]
Oct  2 22:24:41.632: INFO: Created: latency-svc-jqz4n
Oct  2 22:24:41.668: INFO: Got endpoints: latency-svc-frwrc [749.059803ms]
Oct  2 22:24:41.697: INFO: Created: latency-svc-xbsng
Oct  2 22:24:41.714: INFO: Got endpoints: latency-svc-zt6tx [752.072896ms]
Oct  2 22:24:41.731: INFO: Created: latency-svc-6jzjf
Oct  2 22:24:41.766: INFO: Got endpoints: latency-svc-w65fs [751.398475ms]
Oct  2 22:24:41.789: INFO: Created: latency-svc-6jtsb
Oct  2 22:24:41.814: INFO: Got endpoints: latency-svc-ps98h [748.080461ms]
Oct  2 22:24:41.852: INFO: Created: latency-svc-rndr5
Oct  2 22:24:41.862: INFO: Got endpoints: latency-svc-tkrhx [737.4301ms]
Oct  2 22:24:41.880: INFO: Created: latency-svc-44tck
Oct  2 22:24:41.913: INFO: Got endpoints: latency-svc-kv9k5 [748.049275ms]
Oct  2 22:24:41.929: INFO: Created: latency-svc-c6m8q
Oct  2 22:24:41.983: INFO: Got endpoints: latency-svc-jlsgk [766.684802ms]
Oct  2 22:24:42.001: INFO: Created: latency-svc-qsxx7
Oct  2 22:24:42.028: INFO: Got endpoints: latency-svc-rnbtl [763.72817ms]
Oct  2 22:24:42.044: INFO: Created: latency-svc-2fsxh
Oct  2 22:24:42.073: INFO: Got endpoints: latency-svc-474gv [739.466319ms]
Oct  2 22:24:42.090: INFO: Created: latency-svc-9q42z
Oct  2 22:24:42.113: INFO: Got endpoints: latency-svc-6bh42 [749.419301ms]
Oct  2 22:24:42.130: INFO: Created: latency-svc-r24b8
Oct  2 22:24:42.163: INFO: Got endpoints: latency-svc-tptvp [748.563419ms]
Oct  2 22:24:42.257: INFO: Created: latency-svc-9p4wb
Oct  2 22:24:42.263: INFO: Got endpoints: latency-svc-gjpcv [800.221396ms]
Oct  2 22:24:42.263: INFO: Got endpoints: latency-svc-lsvsc [742.47201ms]
Oct  2 22:24:42.280: INFO: Created: latency-svc-tj64k
Oct  2 22:24:42.302: INFO: Created: latency-svc-xll8b
Oct  2 22:24:42.316: INFO: Got endpoints: latency-svc-qw7jq [743.074503ms]
Oct  2 22:24:42.341: INFO: Created: latency-svc-dz4k6
Oct  2 22:24:42.363: INFO: Got endpoints: latency-svc-jqz4n [748.223522ms]
Oct  2 22:24:42.380: INFO: Created: latency-svc-fllzv
Oct  2 22:24:42.422: INFO: Got endpoints: latency-svc-xbsng [753.515301ms]
Oct  2 22:24:42.437: INFO: Created: latency-svc-zgd47
Oct  2 22:24:42.463: INFO: Got endpoints: latency-svc-6jzjf [747.947992ms]
Oct  2 22:24:42.479: INFO: Created: latency-svc-qjhzt
Oct  2 22:24:42.513: INFO: Got endpoints: latency-svc-6jtsb [746.655609ms]
Oct  2 22:24:42.533: INFO: Created: latency-svc-ltzr9
Oct  2 22:24:42.564: INFO: Got endpoints: latency-svc-rndr5 [750.222337ms]
Oct  2 22:24:42.582: INFO: Created: latency-svc-96598
Oct  2 22:24:42.613: INFO: Got endpoints: latency-svc-44tck [750.197ms]
Oct  2 22:24:42.631: INFO: Created: latency-svc-ddplv
Oct  2 22:24:42.665: INFO: Got endpoints: latency-svc-c6m8q [752.462683ms]
Oct  2 22:24:42.685: INFO: Created: latency-svc-6lwnx
Oct  2 22:24:42.714: INFO: Got endpoints: latency-svc-qsxx7 [730.781823ms]
Oct  2 22:24:42.735: INFO: Created: latency-svc-84ldm
Oct  2 22:24:42.764: INFO: Got endpoints: latency-svc-2fsxh [735.862574ms]
Oct  2 22:24:42.782: INFO: Created: latency-svc-rhdbp
Oct  2 22:24:42.817: INFO: Got endpoints: latency-svc-9q42z [743.821056ms]
Oct  2 22:24:42.839: INFO: Created: latency-svc-lgbrr
Oct  2 22:24:42.865: INFO: Got endpoints: latency-svc-r24b8 [751.883345ms]
Oct  2 22:24:42.881: INFO: Created: latency-svc-cc8bt
Oct  2 22:24:42.913: INFO: Got endpoints: latency-svc-9p4wb [750.335398ms]
Oct  2 22:24:42.935: INFO: Created: latency-svc-ksnpn
Oct  2 22:24:42.970: INFO: Got endpoints: latency-svc-tj64k [707.384423ms]
Oct  2 22:24:42.987: INFO: Created: latency-svc-lnmqq
Oct  2 22:24:43.015: INFO: Got endpoints: latency-svc-xll8b [751.159178ms]
Oct  2 22:24:43.035: INFO: Created: latency-svc-jnhcs
Oct  2 22:24:43.063: INFO: Got endpoints: latency-svc-dz4k6 [746.466531ms]
Oct  2 22:24:43.079: INFO: Created: latency-svc-n56vx
Oct  2 22:24:43.113: INFO: Got endpoints: latency-svc-fllzv [749.842042ms]
Oct  2 22:24:43.130: INFO: Created: latency-svc-vzvqh
Oct  2 22:24:43.164: INFO: Got endpoints: latency-svc-zgd47 [741.758ms]
Oct  2 22:24:43.198: INFO: Created: latency-svc-kvgm8
Oct  2 22:24:43.214: INFO: Got endpoints: latency-svc-qjhzt [750.725922ms]
Oct  2 22:24:43.233: INFO: Created: latency-svc-p8klh
Oct  2 22:24:43.263: INFO: Got endpoints: latency-svc-ltzr9 [750.189651ms]
Oct  2 22:24:43.279: INFO: Created: latency-svc-7c6kh
Oct  2 22:24:43.315: INFO: Got endpoints: latency-svc-96598 [750.58006ms]
Oct  2 22:24:43.344: INFO: Created: latency-svc-2hpwl
Oct  2 22:24:43.364: INFO: Got endpoints: latency-svc-ddplv [750.664568ms]
Oct  2 22:24:43.413: INFO: Got endpoints: latency-svc-6lwnx [747.915564ms]
Oct  2 22:24:43.463: INFO: Got endpoints: latency-svc-84ldm [748.220611ms]
Oct  2 22:24:43.521: INFO: Got endpoints: latency-svc-rhdbp [756.992535ms]
Oct  2 22:24:43.527: INFO: Created: latency-svc-ndg8w
Oct  2 22:24:43.527: INFO: Created: latency-svc-4jf8f
Oct  2 22:24:43.527: INFO: Created: latency-svc-k8czf
Oct  2 22:24:43.538: INFO: Created: latency-svc-7vtp8
Oct  2 22:24:43.563: INFO: Got endpoints: latency-svc-lgbrr [745.662531ms]
Oct  2 22:24:43.580: INFO: Created: latency-svc-8ks6d
Oct  2 22:24:43.613: INFO: Got endpoints: latency-svc-cc8bt [747.853513ms]
Oct  2 22:24:43.628: INFO: Created: latency-svc-x2nfg
Oct  2 22:24:43.664: INFO: Got endpoints: latency-svc-ksnpn [751.159381ms]
Oct  2 22:24:43.684: INFO: Created: latency-svc-jcwwn
Oct  2 22:24:43.712: INFO: Got endpoints: latency-svc-lnmqq [742.163798ms]
Oct  2 22:24:43.729: INFO: Created: latency-svc-cvpfl
Oct  2 22:24:43.765: INFO: Got endpoints: latency-svc-jnhcs [749.682053ms]
Oct  2 22:24:43.784: INFO: Created: latency-svc-mzcvm
Oct  2 22:24:43.814: INFO: Got endpoints: latency-svc-n56vx [750.639329ms]
Oct  2 22:24:43.829: INFO: Created: latency-svc-6ckzn
Oct  2 22:24:43.863: INFO: Got endpoints: latency-svc-vzvqh [750.265283ms]
Oct  2 22:24:43.878: INFO: Created: latency-svc-dhsql
Oct  2 22:24:43.914: INFO: Got endpoints: latency-svc-kvgm8 [749.732455ms]
Oct  2 22:24:43.930: INFO: Created: latency-svc-bdl42
Oct  2 22:24:43.966: INFO: Got endpoints: latency-svc-p8klh [752.487674ms]
Oct  2 22:24:43.983: INFO: Created: latency-svc-l44sm
Oct  2 22:24:44.013: INFO: Got endpoints: latency-svc-7c6kh [749.74959ms]
Oct  2 22:24:44.043: INFO: Created: latency-svc-zp2fx
Oct  2 22:24:44.063: INFO: Got endpoints: latency-svc-2hpwl [747.811285ms]
Oct  2 22:24:44.080: INFO: Created: latency-svc-65qs5
Oct  2 22:24:44.113: INFO: Got endpoints: latency-svc-ndg8w [749.561455ms]
Oct  2 22:24:44.130: INFO: Created: latency-svc-4l2r8
Oct  2 22:24:44.163: INFO: Got endpoints: latency-svc-4jf8f [749.175341ms]
Oct  2 22:24:44.194: INFO: Created: latency-svc-n4n9q
Oct  2 22:24:44.213: INFO: Got endpoints: latency-svc-k8czf [750.23218ms]
Oct  2 22:24:44.243: INFO: Created: latency-svc-w2tvl
Oct  2 22:24:44.262: INFO: Got endpoints: latency-svc-7vtp8 [741.160876ms]
Oct  2 22:24:44.281: INFO: Created: latency-svc-npvsj
Oct  2 22:24:44.319: INFO: Got endpoints: latency-svc-8ks6d [755.669526ms]
Oct  2 22:24:44.347: INFO: Created: latency-svc-msr66
Oct  2 22:24:44.362: INFO: Got endpoints: latency-svc-x2nfg [749.555711ms]
Oct  2 22:24:44.379: INFO: Created: latency-svc-lkvx5
Oct  2 22:24:44.413: INFO: Got endpoints: latency-svc-jcwwn [748.36358ms]
Oct  2 22:24:44.429: INFO: Created: latency-svc-5jdgt
Oct  2 22:24:44.463: INFO: Got endpoints: latency-svc-cvpfl [750.565981ms]
Oct  2 22:24:44.478: INFO: Created: latency-svc-hf48f
Oct  2 22:24:44.513: INFO: Got endpoints: latency-svc-mzcvm [747.847882ms]
Oct  2 22:24:44.531: INFO: Created: latency-svc-rrlsl
Oct  2 22:24:44.563: INFO: Got endpoints: latency-svc-6ckzn [749.039708ms]
Oct  2 22:24:44.578: INFO: Created: latency-svc-snqn6
Oct  2 22:24:44.617: INFO: Got endpoints: latency-svc-dhsql [753.732339ms]
Oct  2 22:24:44.635: INFO: Created: latency-svc-8px47
Oct  2 22:24:44.678: INFO: Got endpoints: latency-svc-bdl42 [763.653063ms]
Oct  2 22:24:44.709: INFO: Created: latency-svc-q4m9c
Oct  2 22:24:44.712: INFO: Got endpoints: latency-svc-l44sm [746.148759ms]
Oct  2 22:24:44.760: INFO: Created: latency-svc-czmp2
Oct  2 22:24:44.767: INFO: Got endpoints: latency-svc-zp2fx [753.558343ms]
Oct  2 22:24:44.785: INFO: Created: latency-svc-rhd5g
Oct  2 22:24:44.825: INFO: Got endpoints: latency-svc-65qs5 [761.577123ms]
Oct  2 22:24:44.841: INFO: Created: latency-svc-nz9fk
Oct  2 22:24:44.862: INFO: Got endpoints: latency-svc-4l2r8 [748.357329ms]
Oct  2 22:24:44.883: INFO: Created: latency-svc-t7d77
Oct  2 22:24:44.933: INFO: Got endpoints: latency-svc-n4n9q [769.556589ms]
Oct  2 22:24:44.963: INFO: Got endpoints: latency-svc-w2tvl [749.922381ms]
Oct  2 22:24:45.014: INFO: Got endpoints: latency-svc-npvsj [751.765925ms]
Oct  2 22:24:45.063: INFO: Got endpoints: latency-svc-msr66 [744.341902ms]
Oct  2 22:24:45.113: INFO: Got endpoints: latency-svc-lkvx5 [750.595065ms]
Oct  2 22:24:45.165: INFO: Got endpoints: latency-svc-5jdgt [751.903172ms]
Oct  2 22:24:45.216: INFO: Got endpoints: latency-svc-hf48f [753.017124ms]
Oct  2 22:24:45.270: INFO: Got endpoints: latency-svc-rrlsl [757.580426ms]
Oct  2 22:24:45.313: INFO: Got endpoints: latency-svc-snqn6 [750.329356ms]
Oct  2 22:24:45.373: INFO: Got endpoints: latency-svc-8px47 [755.590966ms]
Oct  2 22:24:45.413: INFO: Got endpoints: latency-svc-q4m9c [735.622766ms]
Oct  2 22:24:45.576: INFO: Got endpoints: latency-svc-nz9fk [751.41585ms]
Oct  2 22:24:45.577: INFO: Got endpoints: latency-svc-czmp2 [864.360029ms]
Oct  2 22:24:45.577: INFO: Got endpoints: latency-svc-rhd5g [809.803957ms]
Oct  2 22:24:45.613: INFO: Got endpoints: latency-svc-t7d77 [751.14857ms]
Oct  2 22:24:45.614: INFO: Latencies: [27.684768ms 29.359309ms 33.258566ms 44.69747ms 55.20201ms 62.063573ms 63.570629ms 80.789258ms 82.276783ms 89.733581ms 97.81068ms 102.239904ms 114.360405ms 130.848933ms 133.67025ms 141.935085ms 149.384228ms 150.164055ms 152.941277ms 156.988698ms 159.424991ms 159.66418ms 160.553884ms 163.35222ms 169.850309ms 172.006932ms 173.978562ms 176.529638ms 177.309946ms 177.76837ms 182.734971ms 183.67147ms 185.06983ms 186.023652ms 189.585211ms 190.62415ms 192.485172ms 202.689914ms 235.46199ms 275.514641ms 306.968781ms 343.072193ms 390.327682ms 434.360949ms 475.745577ms 509.288214ms 541.542988ms 592.782899ms 633.610371ms 659.246651ms 707.384423ms 707.486464ms 730.781823ms 734.479749ms 735.622766ms 735.862574ms 737.4301ms 738.981795ms 739.466319ms 741.160876ms 741.758ms 741.899697ms 742.163798ms 742.47201ms 742.877353ms 743.074503ms 743.425413ms 743.71852ms 743.821056ms 744.20012ms 744.282306ms 744.341902ms 745.437765ms 745.6232ms 745.662531ms 746.148759ms 746.466531ms 746.655609ms 746.789165ms 747.332652ms 747.373184ms 747.639061ms 747.811285ms 747.847882ms 747.853513ms 747.915564ms 747.924693ms 747.947992ms 748.042729ms 748.049275ms 748.080461ms 748.121444ms 748.132368ms 748.220611ms 748.223522ms 748.328835ms 748.349829ms 748.357329ms 748.36358ms 748.436457ms 748.448056ms 748.563419ms 748.664156ms 748.75318ms 748.753512ms 749.036931ms 749.039708ms 749.059803ms 749.065205ms 749.070773ms 749.098256ms 749.104721ms 749.175341ms 749.265279ms 749.305712ms 749.364147ms 749.419301ms 749.453909ms 749.555711ms 749.561455ms 749.630971ms 749.643753ms 749.67482ms 749.682053ms 749.713746ms 749.727213ms 749.732455ms 749.74959ms 749.781409ms 749.842042ms 749.895991ms 749.922381ms 749.92852ms 749.959536ms 750.189651ms 750.197ms 750.222337ms 750.23218ms 750.265283ms 750.329356ms 750.335398ms 750.457043ms 750.481067ms 750.565981ms 750.58006ms 750.595065ms 750.639329ms 750.664568ms 750.725922ms 751.015905ms 751.031243ms 751.14857ms 751.157796ms 751.159178ms 751.159381ms 751.398475ms 751.41585ms 751.636843ms 751.765925ms 751.883345ms 751.903172ms 752.020884ms 752.043218ms 752.072896ms 752.193722ms 752.462683ms 752.487674ms 752.579465ms 752.816389ms 752.862808ms 753.017124ms 753.417561ms 753.515301ms 753.558343ms 753.732339ms 754.508785ms 754.65328ms 755.590966ms 755.669526ms 755.716606ms 756.500556ms 756.978764ms 756.992535ms 757.397542ms 757.402111ms 757.580426ms 758.644426ms 758.677355ms 759.559676ms 761.280767ms 761.577123ms 763.653063ms 763.72817ms 764.134995ms 766.684802ms 766.889596ms 769.556589ms 800.221396ms 809.803957ms 864.360029ms]
Oct  2 22:24:45.614: INFO: 50 %ile: 748.448056ms
Oct  2 22:24:45.615: INFO: 90 %ile: 756.500556ms
Oct  2 22:24:45.615: INFO: 99 %ile: 809.803957ms
Oct  2 22:24:45.615: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:24:45.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2487" for this suite.
Oct  2 22:25:03.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:25:03.987: INFO: namespace svc-latency-2487 deletion completed in 18.363521452s

• [SLOW TEST:29.175 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:25:03.987: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-3297
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3297 to expose endpoints map[]
Oct  2 22:25:04.079: INFO: Get endpoints failed (15.971235ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  2 22:25:05.087: INFO: Get endpoints failed (1.023299439s elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  2 22:25:06.099: INFO: Get endpoints failed (2.035461696s elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  2 22:25:07.110: INFO: successfully validated that service endpoint-test2 in namespace services-3297 exposes endpoints map[] (3.047086525s elapsed)
STEP: Creating pod pod1 in namespace services-3297
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3297 to expose endpoints map[pod1:[80]]
Oct  2 22:25:10.194: INFO: successfully validated that service endpoint-test2 in namespace services-3297 exposes endpoints map[pod1:[80]] (3.068092775s elapsed)
STEP: Creating pod pod2 in namespace services-3297
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3297 to expose endpoints map[pod1:[80] pod2:[80]]
Oct  2 22:25:12.300: INFO: successfully validated that service endpoint-test2 in namespace services-3297 exposes endpoints map[pod1:[80] pod2:[80]] (2.095991607s elapsed)
STEP: Deleting pod pod1 in namespace services-3297
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3297 to expose endpoints map[pod2:[80]]
Oct  2 22:25:13.372: INFO: successfully validated that service endpoint-test2 in namespace services-3297 exposes endpoints map[pod2:[80]] (1.042172419s elapsed)
STEP: Deleting pod pod2 in namespace services-3297
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3297 to expose endpoints map[]
Oct  2 22:25:14.404: INFO: successfully validated that service endpoint-test2 in namespace services-3297 exposes endpoints map[] (1.016222012s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:25:14.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3297" for this suite.
Oct  2 22:25:20.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:25:20.838: INFO: namespace services-3297 deletion completed in 6.37535838s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:16.851 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:25:20.839: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  2 22:25:20.932: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  2 22:25:20.945: INFO: Waiting for terminating namespaces to be deleted...
Oct  2 22:25:20.951: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Oct  2 22:25:20.977: INFO: kube-flannel-ds-bgwzj from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:25:20.978: INFO: kube-dns-autoscaler-5987f4cd86-snh94 from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container autoscaler ready: true, restart count 0
Oct  2 22:25:20.978: INFO: coredns-56969c94-q4m8c from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:25:20.978: INFO: tiller-deploy-785fd4d8b5-lmpfd from kube-system started at 2019-10-02 20:52:10 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container tiller ready: true, restart count 0
Oct  2 22:25:20.978: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-hngt6 from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:25:20.978: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:25:20.978: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:25:20.978: INFO: kubernetes-dashboard-5c75764dd6-5fg46 from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  2 22:25:20.978: INFO: kube-proxy-8j7cc from kube-system started at 2019-10-02 20:51:49 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.978: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:25:20.978: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Oct  2 22:25:20.992: INFO: kube-flannel-ds-6w9tm from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.992: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:25:20.992: INFO: kube-proxy-sbsqs from kube-system started at 2019-10-02 20:52:24 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.992: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:25:20.992: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-02 21:07:04 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:20.992: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  2 22:25:20.992: INFO: sonobuoy-e2e-job-7762dab4d6fa43aa from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:25:20.992: INFO: 	Container e2e ready: true, restart count 0
Oct  2 22:25:20.992: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  2 22:25:20.992: INFO: proxymux-client-10.0.10.3 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:25:20.992: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-p2l7g from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:25:20.992: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:25:20.992: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:25:20.992: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Oct  2 22:25:21.007: INFO: coredns-56969c94-f2czw from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:21.007: INFO: 	Container coredns ready: true, restart count 0
Oct  2 22:25:21.007: INFO: proxymux-client-10.0.10.4 from kube-system started at <nil> (0 container statuses recorded)
Oct  2 22:25:21.007: INFO: kube-flannel-ds-jpfsd from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:21.007: INFO: 	Container kube-flannel ready: true, restart count 1
Oct  2 22:25:21.007: INFO: sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-6d8qm from heptio-sonobuoy started at 2019-10-02 21:07:11 +0000 UTC (2 container statuses recorded)
Oct  2 22:25:21.007: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  2 22:25:21.007: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  2 22:25:21.007: INFO: kube-proxy-tmrht from kube-system started at 2019-10-02 20:52:08 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:21.007: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  2 22:25:21.007: INFO: coredns-56969c94-zsr6t from kube-system started at 2019-10-02 20:52:41 +0000 UTC (1 container statuses recorded)
Oct  2 22:25:21.007: INFO: 	Container coredns ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.0.10.2
STEP: verifying the node has the label node 10.0.10.3
STEP: verifying the node has the label node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod sonobuoy-e2e-job-7762dab4d6fa43aa requesting resource cpu=0m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-6d8qm requesting resource cpu=0m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-hngt6 requesting resource cpu=0m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod sonobuoy-systemd-logs-daemon-set-760c54af792d42ce-p2l7g requesting resource cpu=0m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod coredns-56969c94-f2czw requesting resource cpu=100m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod coredns-56969c94-q4m8c requesting resource cpu=100m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod coredns-56969c94-zsr6t requesting resource cpu=100m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod kube-dns-autoscaler-5987f4cd86-snh94 requesting resource cpu=20m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod kube-flannel-ds-6w9tm requesting resource cpu=100m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod kube-flannel-ds-bgwzj requesting resource cpu=100m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod kube-flannel-ds-jpfsd requesting resource cpu=100m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod kube-proxy-8j7cc requesting resource cpu=0m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod kube-proxy-sbsqs requesting resource cpu=0m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod kube-proxy-tmrht requesting resource cpu=0m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod kubernetes-dashboard-5c75764dd6-5fg46 requesting resource cpu=0m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod proxymux-client-10.0.10.2 requesting resource cpu=50m on Node 10.0.10.2
Oct  2 22:25:21.176: INFO: Pod proxymux-client-10.0.10.3 requesting resource cpu=50m on Node 10.0.10.3
Oct  2 22:25:21.176: INFO: Pod proxymux-client-10.0.10.4 requesting resource cpu=50m on Node 10.0.10.4
Oct  2 22:25:21.176: INFO: Pod tiller-deploy-785fd4d8b5-lmpfd requesting resource cpu=0m on Node 10.0.10.2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-854281cc-e563-11e9-bbfa-0a580af40203.15c9f4d07178c278], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1251/filler-pod-854281cc-e563-11e9-bbfa-0a580af40203 to 10.0.10.3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-854281cc-e563-11e9-bbfa-0a580af40203.15c9f4d09ec3d39f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-854281cc-e563-11e9-bbfa-0a580af40203.15c9f4d0a105786a], Reason = [Created], Message = [Created container filler-pod-854281cc-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-854281cc-e563-11e9-bbfa-0a580af40203.15c9f4d0a9ffe643], Reason = [Started], Message = [Started container filler-pod-854281cc-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203.15c9f4d072329b95], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1251/filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203 to 10.0.10.4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203.15c9f4d0afd2b520], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203.15c9f4d0b1e95837], Reason = [Created], Message = [Created container filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203.15c9f4d0be408e93], Reason = [Started], Message = [Started container filler-pod-8546abc1-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8548983f-e563-11e9-bbfa-0a580af40203.15c9f4d0739f5853], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1251/filler-pod-8548983f-e563-11e9-bbfa-0a580af40203 to 10.0.10.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8548983f-e563-11e9-bbfa-0a580af40203.15c9f4d09ec742e7], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8548983f-e563-11e9-bbfa-0a580af40203.15c9f4d0c6ea0256], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8548983f-e563-11e9-bbfa-0a580af40203.15c9f4d0c91b2831], Reason = [Created], Message = [Created container filler-pod-8548983f-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8548983f-e563-11e9-bbfa-0a580af40203.15c9f4d0d0790f2d], Reason = [Started], Message = [Started container filler-pod-8548983f-e563-11e9-bbfa-0a580af40203]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c9f4d0efa599dc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.0.10.2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.10.3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.10.4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:25:24.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1251" for this suite.
Oct  2 22:25:30.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:25:30.756: INFO: namespace sched-pred-1251 deletion completed in 6.330623073s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.917 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:25:30.756: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:25:30.890: INFO: (0) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 25.556704ms)
Oct  2 22:25:30.900: INFO: (1) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.687194ms)
Oct  2 22:25:30.908: INFO: (2) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.632699ms)
Oct  2 22:25:30.916: INFO: (3) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.117813ms)
Oct  2 22:25:30.924: INFO: (4) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.755264ms)
Oct  2 22:25:30.931: INFO: (5) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.625209ms)
Oct  2 22:25:30.939: INFO: (6) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.653994ms)
Oct  2 22:25:30.985: INFO: (7) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 45.795102ms)
Oct  2 22:25:31.000: INFO: (8) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 15.157896ms)
Oct  2 22:25:31.022: INFO: (9) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 21.765675ms)
Oct  2 22:25:31.031: INFO: (10) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.286259ms)
Oct  2 22:25:31.040: INFO: (11) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.252911ms)
Oct  2 22:25:31.062: INFO: (12) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 22.648958ms)
Oct  2 22:25:31.081: INFO: (13) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.473988ms)
Oct  2 22:25:31.094: INFO: (14) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.86199ms)
Oct  2 22:25:31.104: INFO: (15) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.035297ms)
Oct  2 22:25:31.112: INFO: (16) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.37896ms)
Oct  2 22:25:31.120: INFO: (17) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.831488ms)
Oct  2 22:25:31.128: INFO: (18) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.972502ms)
Oct  2 22:25:31.136: INFO: (19) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.984517ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:25:31.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6939" for this suite.
Oct  2 22:25:37.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:25:37.497: INFO: namespace proxy-6939 deletion completed in 6.352750922s

• [SLOW TEST:6.740 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:25:37.497: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  2 22:25:37.590: INFO: Waiting up to 5m0s for pod "pod-8f082927-e563-11e9-bbfa-0a580af40203" in namespace "emptydir-6044" to be "success or failure"
Oct  2 22:25:37.614: INFO: Pod "pod-8f082927-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 23.90013ms
Oct  2 22:25:39.622: INFO: Pod "pod-8f082927-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031730865s
Oct  2 22:25:41.631: INFO: Pod "pod-8f082927-e563-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041147746s
STEP: Saw pod success
Oct  2 22:25:41.631: INFO: Pod "pod-8f082927-e563-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:25:41.638: INFO: Trying to get logs from node 10.0.10.4 pod pod-8f082927-e563-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:25:41.702: INFO: Waiting for pod pod-8f082927-e563-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:25:41.724: INFO: Pod pod-8f082927-e563-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:25:41.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6044" for this suite.
Oct  2 22:25:47.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:25:48.086: INFO: namespace emptydir-6044 deletion completed in 6.35527491s

• [SLOW TEST:10.589 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:25:48.087: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-789
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  2 22:25:48.142: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  2 22:26:06.400: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.134:8080/dial?request=hostName&protocol=udp&host=10.244.0.50&port=8081&tries=1'] Namespace:pod-network-test-789 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 22:26:06.400: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 22:26:06.747: INFO: Waiting for endpoints: map[]
Oct  2 22:26:06.763: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.134:8080/dial?request=hostName&protocol=udp&host=10.244.1.133&port=8081&tries=1'] Namespace:pod-network-test-789 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 22:26:06.763: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 22:26:07.121: INFO: Waiting for endpoints: map[]
Oct  2 22:26:07.128: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.134:8080/dial?request=hostName&protocol=udp&host=10.244.2.117&port=8081&tries=1'] Namespace:pod-network-test-789 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  2 22:26:07.129: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
Oct  2 22:26:07.506: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:26:07.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-789" for this suite.
Oct  2 22:26:31.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:26:31.797: INFO: namespace pod-network-test-789 deletion completed in 24.282449696s

• [SLOW TEST:43.710 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:26:31.798: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-af64aa6c-e563-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:26:31.888: INFO: Waiting up to 5m0s for pod "pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203" in namespace "secrets-4550" to be "success or failure"
Oct  2 22:26:31.898: INFO: Pod "pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.20116ms
Oct  2 22:26:33.906: INFO: Pod "pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01829574s
STEP: Saw pod success
Oct  2 22:26:33.906: INFO: Pod "pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:26:33.913: INFO: Trying to get logs from node 10.0.10.3 pod pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:26:34.015: INFO: Waiting for pod pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:26:34.022: INFO: Pod pod-secrets-af660a18-e563-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:26:34.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4550" for this suite.
Oct  2 22:26:40.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:26:40.321: INFO: namespace secrets-4550 deletion completed in 6.292881934s

• [SLOW TEST:8.523 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:26:40.321: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-b478a6af-e563-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:26:40.414: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203" in namespace "projected-5182" to be "success or failure"
Oct  2 22:26:40.424: INFO: Pod "pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.356472ms
Oct  2 22:26:42.434: INFO: Pod "pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020111384s
STEP: Saw pod success
Oct  2 22:26:42.434: INFO: Pod "pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:26:42.441: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203 container secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:26:42.508: INFO: Waiting for pod pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:26:42.515: INFO: Pod pod-projected-secrets-b479ca9e-e563-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:26:42.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5182" for this suite.
Oct  2 22:26:48.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:26:48.799: INFO: namespace projected-5182 deletion completed in 6.277397747s

• [SLOW TEST:8.478 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:26:48.800: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:26:48.894: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct  2 22:26:48.930: INFO: Number of nodes with available pods: 0
Oct  2 22:26:48.930: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:26:49.946: INFO: Number of nodes with available pods: 0
Oct  2 22:26:49.946: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:26:50.945: INFO: Number of nodes with available pods: 3
Oct  2 22:26:50.945: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct  2 22:26:51.014: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:51.014: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:51.014: INFO: Wrong image for pod: daemon-set-rktt5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:52.042: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:52.042: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:52.042: INFO: Wrong image for pod: daemon-set-rktt5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:53.030: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:53.030: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:53.030: INFO: Wrong image for pod: daemon-set-rktt5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:54.030: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:54.030: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:54.030: INFO: Wrong image for pod: daemon-set-rktt5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:54.030: INFO: Pod daemon-set-rktt5 is not available
Oct  2 22:26:55.039: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:55.039: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:55.039: INFO: Pod daemon-set-vnqw7 is not available
Oct  2 22:26:56.030: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:56.030: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:56.030: INFO: Pod daemon-set-vnqw7 is not available
Oct  2 22:26:57.031: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:57.031: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:57.031: INFO: Pod daemon-set-vnqw7 is not available
Oct  2 22:26:58.029: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:58.030: INFO: Wrong image for pod: daemon-set-99l6l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:58.030: INFO: Pod daemon-set-99l6l is not available
Oct  2 22:26:59.052: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:26:59.052: INFO: Pod daemon-set-m5m7k is not available
Oct  2 22:27:00.037: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:27:00.037: INFO: Pod daemon-set-m5m7k is not available
Oct  2 22:27:01.031: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:27:02.030: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:27:03.030: INFO: Wrong image for pod: daemon-set-7xjz6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  2 22:27:03.030: INFO: Pod daemon-set-7xjz6 is not available
Oct  2 22:27:04.030: INFO: Pod daemon-set-fkxgm is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct  2 22:27:04.051: INFO: Number of nodes with available pods: 2
Oct  2 22:27:04.051: INFO: Node 10.0.10.3 is running more than one daemon pod
Oct  2 22:27:05.067: INFO: Number of nodes with available pods: 3
Oct  2 22:27:05.067: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6863, will wait for the garbage collector to delete the pods
Oct  2 22:27:05.165: INFO: Deleting DaemonSet.extensions daemon-set took: 13.73372ms
Oct  2 22:27:05.465: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.193382ms
Oct  2 22:27:17.873: INFO: Number of nodes with available pods: 0
Oct  2 22:27:17.873: INFO: Number of running nodes: 0, number of available pods: 0
Oct  2 22:27:17.878: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6863/daemonsets","resourceVersion":"23490"},"items":null}

Oct  2 22:27:17.886: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6863/pods","resourceVersion":"23490"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:27:17.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6863" for this suite.
Oct  2 22:27:25.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:27:26.223: INFO: namespace daemonsets-6863 deletion completed in 8.301202232s

• [SLOW TEST:37.424 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:27:26.224: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1357
Oct  2 22:27:28.344: INFO: Started pod liveness-http in namespace container-probe-1357
STEP: checking the pod's current state and verifying that restartCount is present
Oct  2 22:27:28.351: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:31:29.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1357" for this suite.
Oct  2 22:31:35.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:31:35.908: INFO: namespace container-probe-1357 deletion completed in 6.292422127s

• [SLOW TEST:249.684 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:31:35.908: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-64a9c290-e564-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 22:31:36.007: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203" in namespace "projected-6955" to be "success or failure"
Oct  2 22:31:36.020: INFO: Pod "pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 12.92342ms
Oct  2 22:31:38.029: INFO: Pod "pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022005816s
Oct  2 22:31:40.041: INFO: Pod "pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033350078s
STEP: Saw pod success
Oct  2 22:31:40.041: INFO: Pod "pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:31:40.048: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 22:31:40.101: INFO: Waiting for pod pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:31:40.109: INFO: Pod pod-projected-configmaps-64ab1083-e564-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:31:40.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6955" for this suite.
Oct  2 22:31:46.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:31:46.437: INFO: namespace projected-6955 deletion completed in 6.322359101s

• [SLOW TEST:10.529 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:31:46.438: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:31:46.555: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct  2 22:31:46.582: INFO: Number of nodes with available pods: 0
Oct  2 22:31:46.582: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct  2 22:31:46.624: INFO: Number of nodes with available pods: 0
Oct  2 22:31:46.624: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:47.641: INFO: Number of nodes with available pods: 0
Oct  2 22:31:47.641: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:48.632: INFO: Number of nodes with available pods: 1
Oct  2 22:31:48.632: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct  2 22:31:48.669: INFO: Number of nodes with available pods: 1
Oct  2 22:31:48.669: INFO: Number of running nodes: 0, number of available pods: 1
Oct  2 22:31:49.678: INFO: Number of nodes with available pods: 0
Oct  2 22:31:49.678: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct  2 22:31:49.695: INFO: Number of nodes with available pods: 0
Oct  2 22:31:49.695: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:50.704: INFO: Number of nodes with available pods: 0
Oct  2 22:31:50.704: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:51.704: INFO: Number of nodes with available pods: 0
Oct  2 22:31:51.704: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:52.711: INFO: Number of nodes with available pods: 0
Oct  2 22:31:52.711: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:53.712: INFO: Number of nodes with available pods: 0
Oct  2 22:31:53.712: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:31:54.708: INFO: Number of nodes with available pods: 1
Oct  2 22:31:54.708: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4628, will wait for the garbage collector to delete the pods
Oct  2 22:31:54.799: INFO: Deleting DaemonSet.extensions daemon-set took: 16.03844ms
Oct  2 22:31:55.099: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.259318ms
Oct  2 22:31:58.507: INFO: Number of nodes with available pods: 0
Oct  2 22:31:58.507: INFO: Number of running nodes: 0, number of available pods: 0
Oct  2 22:31:58.512: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4628/daemonsets","resourceVersion":"24241"},"items":null}

Oct  2 22:31:58.518: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4628/pods","resourceVersion":"24241"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:31:58.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4628" for this suite.
Oct  2 22:32:04.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:32:04.864: INFO: namespace daemonsets-4628 deletion completed in 6.307076098s

• [SLOW TEST:18.427 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:32:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct  2 22:32:04.925: INFO: namespace kubectl-8423
Oct  2 22:32:04.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-8423'
Oct  2 22:32:05.386: INFO: stderr: ""
Oct  2 22:32:05.386: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  2 22:32:06.397: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:32:06.397: INFO: Found 0 / 1
Oct  2 22:32:07.396: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:32:07.396: INFO: Found 1 / 1
Oct  2 22:32:07.396: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  2 22:32:07.426: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:32:07.426: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  2 22:32:07.426: INFO: wait on redis-master startup in kubectl-8423 
Oct  2 22:32:07.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 logs redis-master-xk2cd redis-master --namespace=kubectl-8423'
Oct  2 22:32:07.703: INFO: stderr: ""
Oct  2 22:32:07.703: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Oct 22:32:06.301 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Oct 22:32:06.302 # Server started, Redis version 3.2.12\n1:M 02 Oct 22:32:06.302 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Oct 22:32:06.302 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct  2 22:32:07.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8423'
Oct  2 22:32:07.860: INFO: stderr: ""
Oct  2 22:32:07.860: INFO: stdout: "service/rm2 exposed\n"
Oct  2 22:32:07.888: INFO: Service rm2 in namespace kubectl-8423 found.
STEP: exposing service
Oct  2 22:32:09.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8423'
Oct  2 22:32:10.034: INFO: stderr: ""
Oct  2 22:32:10.034: INFO: stdout: "service/rm3 exposed\n"
Oct  2 22:32:10.041: INFO: Service rm3 in namespace kubectl-8423 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:32:12.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8423" for this suite.
Oct  2 22:32:36.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:32:36.344: INFO: namespace kubectl-8423 deletion completed in 24.281268326s

• [SLOW TEST:31.480 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:32:36.345: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  2 22:32:36.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203" in namespace "downward-api-1522" to be "success or failure"
Oct  2 22:32:36.442: INFO: Pod "downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 25.51126ms
Oct  2 22:32:38.450: INFO: Pod "downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203": Phase="Running", Reason="", readiness=true. Elapsed: 2.033732159s
Oct  2 22:32:40.471: INFO: Pod "downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054244283s
STEP: Saw pod success
Oct  2 22:32:40.471: INFO: Pod "downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:32:40.486: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203 container client-container: <nil>
STEP: delete the pod
Oct  2 22:32:40.530: INFO: Waiting for pod downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:32:40.538: INFO: Pod downwardapi-volume-88ad06af-e564-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:32:40.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1522" for this suite.
Oct  2 22:32:46.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:32:46.852: INFO: namespace downward-api-1522 deletion completed in 6.307943781s

• [SLOW TEST:10.507 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:32:46.852: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-8ef6da80-e564-11e9-bbfa-0a580af40203
STEP: Creating configMap with name cm-test-opt-upd-8ef6daea-e564-11e9-bbfa-0a580af40203
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8ef6da80-e564-11e9-bbfa-0a580af40203
STEP: Updating configmap cm-test-opt-upd-8ef6daea-e564-11e9-bbfa-0a580af40203
STEP: Creating configMap with name cm-test-opt-create-8ef6db0f-e564-11e9-bbfa-0a580af40203
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:32:51.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4991" for this suite.
Oct  2 22:33:15.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:33:15.540: INFO: namespace projected-4991 deletion completed in 24.295817618s

• [SLOW TEST:28.688 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:33:15.540: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:33:15.762: INFO: Create a RollingUpdate DaemonSet
Oct  2 22:33:15.771: INFO: Check that daemon pods launch on every node of the cluster
Oct  2 22:33:15.787: INFO: Number of nodes with available pods: 0
Oct  2 22:33:15.787: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:33:16.806: INFO: Number of nodes with available pods: 0
Oct  2 22:33:16.806: INFO: Node 10.0.10.2 is running more than one daemon pod
Oct  2 22:33:17.802: INFO: Number of nodes with available pods: 3
Oct  2 22:33:17.802: INFO: Number of running nodes: 3, number of available pods: 3
Oct  2 22:33:17.802: INFO: Update the DaemonSet to trigger a rollout
Oct  2 22:33:17.834: INFO: Updating DaemonSet daemon-set
Oct  2 22:33:27.864: INFO: Roll back the DaemonSet before rollout is complete
Oct  2 22:33:27.879: INFO: Updating DaemonSet daemon-set
Oct  2 22:33:27.879: INFO: Make sure DaemonSet rollback is complete
Oct  2 22:33:27.895: INFO: Wrong image for pod: daemon-set-55rlr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  2 22:33:27.895: INFO: Pod daemon-set-55rlr is not available
Oct  2 22:33:28.910: INFO: Wrong image for pod: daemon-set-55rlr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  2 22:33:28.910: INFO: Pod daemon-set-55rlr is not available
Oct  2 22:33:29.910: INFO: Wrong image for pod: daemon-set-55rlr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  2 22:33:29.910: INFO: Pod daemon-set-55rlr is not available
Oct  2 22:33:30.911: INFO: Wrong image for pod: daemon-set-55rlr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  2 22:33:30.911: INFO: Pod daemon-set-55rlr is not available
Oct  2 22:33:31.912: INFO: Wrong image for pod: daemon-set-55rlr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  2 22:33:31.912: INFO: Pod daemon-set-55rlr is not available
Oct  2 22:33:32.910: INFO: Pod daemon-set-9w7zl is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1481, will wait for the garbage collector to delete the pods
Oct  2 22:33:33.009: INFO: Deleting DaemonSet.extensions daemon-set took: 13.605105ms
Oct  2 22:33:33.309: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.291266ms
Oct  2 22:33:43.418: INFO: Number of nodes with available pods: 0
Oct  2 22:33:43.418: INFO: Number of running nodes: 0, number of available pods: 0
Oct  2 22:33:43.424: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1481/daemonsets","resourceVersion":"24689"},"items":null}

Oct  2 22:33:43.430: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1481/pods","resourceVersion":"24689"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:33:43.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1481" for this suite.
Oct  2 22:33:49.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:33:49.845: INFO: namespace daemonsets-1481 deletion completed in 6.383634745s

• [SLOW TEST:34.305 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:33:49.845: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  2 22:33:49.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-8874'
Oct  2 22:33:50.028: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  2 22:33:50.028: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Oct  2 22:33:54.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8874'
Oct  2 22:33:54.212: INFO: stderr: ""
Oct  2 22:33:54.212: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:33:54.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8874" for this suite.
Oct  2 22:34:00.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:34:00.497: INFO: namespace kubectl-8874 deletion completed in 6.277496666s

• [SLOW TEST:10.652 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:34:00.497: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Oct  2 22:34:00.584: INFO: Waiting up to 5m0s for pod "client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203" in namespace "containers-7128" to be "success or failure"
Oct  2 22:34:00.594: INFO: Pod "client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.35834ms
Oct  2 22:34:02.602: INFO: Pod "client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017373334s
STEP: Saw pod success
Oct  2 22:34:02.602: INFO: Pod "client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:34:02.608: INFO: Trying to get logs from node 10.0.10.3 pod client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:34:02.651: INFO: Waiting for pod client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:34:02.662: INFO: Pod client-containers-bad7ea3e-e564-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:34:02.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7128" for this suite.
Oct  2 22:34:08.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:34:08.964: INFO: namespace containers-7128 deletion completed in 6.29546119s

• [SLOW TEST:8.467 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:34:08.965: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  2 22:34:09.050: INFO: Waiting up to 5m0s for pod "pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203" in namespace "emptydir-7315" to be "success or failure"
Oct  2 22:34:09.061: INFO: Pod "pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.094197ms
Oct  2 22:34:11.069: INFO: Pod "pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018695624s
STEP: Saw pod success
Oct  2 22:34:11.069: INFO: Pod "pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:34:11.077: INFO: Trying to get logs from node 10.0.10.4 pod pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:34:11.130: INFO: Waiting for pod pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:34:11.139: INFO: Pod pod-bfe3aa3a-e564-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:34:11.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7315" for this suite.
Oct  2 22:34:17.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:34:17.442: INFO: namespace emptydir-7315 deletion completed in 6.297062107s

• [SLOW TEST:8.478 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:34:17.443: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:34:17.503: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:34:19.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-755" for this suite.
Oct  2 22:35:05.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:35:06.126: INFO: namespace pods-755 deletion completed in 46.304518342s

• [SLOW TEST:48.683 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:35:06.126: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Oct  2 22:35:06.752: INFO: created pod pod-service-account-defaultsa
Oct  2 22:35:06.752: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct  2 22:35:06.762: INFO: created pod pod-service-account-mountsa
Oct  2 22:35:06.762: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct  2 22:35:06.773: INFO: created pod pod-service-account-nomountsa
Oct  2 22:35:06.773: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct  2 22:35:06.783: INFO: created pod pod-service-account-defaultsa-mountspec
Oct  2 22:35:06.783: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct  2 22:35:06.795: INFO: created pod pod-service-account-mountsa-mountspec
Oct  2 22:35:06.795: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct  2 22:35:06.809: INFO: created pod pod-service-account-nomountsa-mountspec
Oct  2 22:35:06.809: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct  2 22:35:06.823: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct  2 22:35:06.823: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct  2 22:35:06.833: INFO: created pod pod-service-account-mountsa-nomountspec
Oct  2 22:35:06.833: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct  2 22:35:06.845: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct  2 22:35:06.845: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:35:06.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1777" for this suite.
Oct  2 22:35:12.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:35:13.187: INFO: namespace svcaccounts-1777 deletion completed in 6.333491373s

• [SLOW TEST:7.061 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:35:13.187: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e629ac4c-e564-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:35:13.290: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203" in namespace "projected-662" to be "success or failure"
Oct  2 22:35:13.301: INFO: Pod "pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.575299ms
Oct  2 22:35:15.309: INFO: Pod "pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018894349s
STEP: Saw pod success
Oct  2 22:35:15.309: INFO: Pod "pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:35:15.315: INFO: Trying to get logs from node 10.0.10.3 pod pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:35:15.360: INFO: Waiting for pod pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:35:15.367: INFO: Pod pod-projected-secrets-e62d5e2b-e564-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:35:15.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-662" for this suite.
Oct  2 22:35:21.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:35:21.643: INFO: namespace projected-662 deletion completed in 6.269104792s

• [SLOW TEST:8.456 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:35:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-8745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8745 to expose endpoints map[]
Oct  2 22:35:21.732: INFO: Get endpoints failed (9.303503ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct  2 22:35:22.740: INFO: successfully validated that service multi-endpoint-test in namespace services-8745 exposes endpoints map[] (1.017786031s elapsed)
STEP: Creating pod pod1 in namespace services-8745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8745 to expose endpoints map[pod1:[100]]
Oct  2 22:35:24.820: INFO: successfully validated that service multi-endpoint-test in namespace services-8745 exposes endpoints map[pod1:[100]] (2.066123113s elapsed)
STEP: Creating pod pod2 in namespace services-8745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8745 to expose endpoints map[pod1:[100] pod2:[101]]
Oct  2 22:35:26.912: INFO: successfully validated that service multi-endpoint-test in namespace services-8745 exposes endpoints map[pod1:[100] pod2:[101]] (2.079611152s elapsed)
STEP: Deleting pod pod1 in namespace services-8745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8745 to expose endpoints map[pod2:[101]]
Oct  2 22:35:26.952: INFO: successfully validated that service multi-endpoint-test in namespace services-8745 exposes endpoints map[pod2:[101]] (26.032393ms elapsed)
STEP: Deleting pod pod2 in namespace services-8745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8745 to expose endpoints map[]
Oct  2 22:35:27.003: INFO: successfully validated that service multi-endpoint-test in namespace services-8745 exposes endpoints map[] (16.847374ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:35:27.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8745" for this suite.
Oct  2 22:35:33.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:35:33.387: INFO: namespace services-8745 deletion completed in 6.330972808s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:11.743 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:35:33.388: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:35:33.452: INFO: Creating deployment "test-recreate-deployment"
Oct  2 22:35:33.473: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct  2 22:35:33.487: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct  2 22:35:35.501: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct  2 22:35:35.506: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct  2 22:35:35.539: INFO: Updating deployment test-recreate-deployment
Oct  2 22:35:35.539: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  2 22:35:35.658: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9917,SelfLink:/apis/apps/v1/namespaces/deployment-9917/deployments/test-recreate-deployment,UID:f234e573-e564-11e9-a07f-0a580aed12b5,ResourceVersion:25294,Generation:2,CreationTimestamp:2019-10-02 22:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-02 22:35:35 +0000 UTC 2019-10-02 22:35:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-02 22:35:35 +0000 UTC 2019-10-02 22:35:33 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct  2 22:35:35.666: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-9917,SelfLink:/apis/apps/v1/namespaces/deployment-9917/replicasets/test-recreate-deployment-745fb9c84c,UID:f37cffd9-e564-11e9-a07f-0a580aed12b5,ResourceVersion:25293,Generation:1,CreationTimestamp:2019-10-02 22:35:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f234e573-e564-11e9-a07f-0a580aed12b5 0xc00078bfa7 0xc00078bfa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 22:35:35.666: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct  2 22:35:35.666: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-9917,SelfLink:/apis/apps/v1/namespaces/deployment-9917/replicasets/test-recreate-deployment-6566d46b4b,UID:f23833d0-e564-11e9-a07f-0a580aed12b5,ResourceVersion:25283,Generation:2,CreationTimestamp:2019-10-02 22:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f234e573-e564-11e9-a07f-0a580aed12b5 0xc00078bed7 0xc00078bed8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  2 22:35:35.674: INFO: Pod "test-recreate-deployment-745fb9c84c-fbnhm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-fbnhm,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-9917,SelfLink:/api/v1/namespaces/deployment-9917/pods/test-recreate-deployment-745fb9c84c-fbnhm,UID:f37e830e-e564-11e9-a07f-0a580aed12b5,ResourceVersion:25295,Generation:0,CreationTimestamp:2019-10-02 22:35:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c f37cffd9-e564-11e9-a07f-0a580aed12b5 0xc0000c0f17 0xc0000c0f18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cwpm4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cwpm4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cwpm4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0006987f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000698a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 22:35:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 22:35:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-02 22:35:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-02 22:35:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2019-10-02 22:35:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:35:35.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9917" for this suite.
Oct  2 22:35:41.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:35:41.985: INFO: namespace deployment-9917 deletion completed in 6.304743515s

• [SLOW TEST:8.597 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:35:41.985: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct  2 22:35:42.658: INFO: Pod name wrapped-volume-race-f7ad8173-e564-11e9-bbfa-0a580af40203: Found 0 pods out of 5
Oct  2 22:35:47.739: INFO: Pod name wrapped-volume-race-f7ad8173-e564-11e9-bbfa-0a580af40203: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f7ad8173-e564-11e9-bbfa-0a580af40203 in namespace emptydir-wrapper-804, will wait for the garbage collector to delete the pods
Oct  2 22:35:55.920: INFO: Deleting ReplicationController wrapped-volume-race-f7ad8173-e564-11e9-bbfa-0a580af40203 took: 14.174227ms
Oct  2 22:35:56.021: INFO: Terminating ReplicationController wrapped-volume-race-f7ad8173-e564-11e9-bbfa-0a580af40203 pods took: 100.224549ms
STEP: Creating RC which spawns configmap-volume pods
Oct  2 22:36:38.855: INFO: Pod name wrapped-volume-race-192af589-e565-11e9-bbfa-0a580af40203: Found 0 pods out of 5
Oct  2 22:36:43.868: INFO: Pod name wrapped-volume-race-192af589-e565-11e9-bbfa-0a580af40203: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-192af589-e565-11e9-bbfa-0a580af40203 in namespace emptydir-wrapper-804, will wait for the garbage collector to delete the pods
Oct  2 22:36:56.026: INFO: Deleting ReplicationController wrapped-volume-race-192af589-e565-11e9-bbfa-0a580af40203 took: 21.468666ms
Oct  2 22:36:56.326: INFO: Terminating ReplicationController wrapped-volume-race-192af589-e565-11e9-bbfa-0a580af40203 pods took: 300.302158ms
STEP: Creating RC which spawns configmap-volume pods
Oct  2 22:37:38.874: INFO: Pod name wrapped-volume-race-3cef11fb-e565-11e9-bbfa-0a580af40203: Found 0 pods out of 5
Oct  2 22:37:43.885: INFO: Pod name wrapped-volume-race-3cef11fb-e565-11e9-bbfa-0a580af40203: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3cef11fb-e565-11e9-bbfa-0a580af40203 in namespace emptydir-wrapper-804, will wait for the garbage collector to delete the pods
Oct  2 22:37:56.050: INFO: Deleting ReplicationController wrapped-volume-race-3cef11fb-e565-11e9-bbfa-0a580af40203 took: 15.262221ms
Oct  2 22:37:56.350: INFO: Terminating ReplicationController wrapped-volume-race-3cef11fb-e565-11e9-bbfa-0a580af40203 pods took: 300.314742ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:38:39.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-804" for this suite.
Oct  2 22:38:49.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:38:50.079: INFO: namespace emptydir-wrapper-804 deletion completed in 10.277811256s

• [SLOW TEST:188.094 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:38:50.080: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  2 22:38:50.208: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6777ea49-e565-11e9-a07f-0a580aed12b5", Controller:(*bool)(0xc0015f02ee), BlockOwnerDeletion:(*bool)(0xc0015f02ef)}}
Oct  2 22:38:50.227: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6774cd1a-e565-11e9-a07f-0a580aed12b5", Controller:(*bool)(0xc00078beb6), BlockOwnerDeletion:(*bool)(0xc00078beb7)}}
Oct  2 22:38:50.241: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"67767fe5-e565-11e9-a07f-0a580aed12b5", Controller:(*bool)(0xc0015f04ce), BlockOwnerDeletion:(*bool)(0xc0015f04cf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:38:55.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5236" for this suite.
Oct  2 22:39:01.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:39:01.542: INFO: namespace gc-5236 deletion completed in 6.268053356s

• [SLOW TEST:11.462 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:39:01.543: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  2 22:39:01.630: INFO: Waiting up to 5m0s for pod "downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203" in namespace "downward-api-9513" to be "success or failure"
Oct  2 22:39:01.638: INFO: Pod "downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268305ms
Oct  2 22:39:03.646: INFO: Pod "downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016128684s
STEP: Saw pod success
Oct  2 22:39:03.646: INFO: Pod "downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:39:03.653: INFO: Trying to get logs from node 10.0.10.3 pod downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:39:03.712: INFO: Waiting for pod downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:39:03.719: INFO: Pod downward-api-6e46cf81-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:39:03.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9513" for this suite.
Oct  2 22:39:09.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:39:10.029: INFO: namespace downward-api-9513 deletion completed in 6.295275408s

• [SLOW TEST:8.486 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:39:10.029: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:39:14.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6025" for this suite.
Oct  2 22:39:20.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:39:20.430: INFO: namespace kubelet-test-6025 deletion completed in 6.293417038s

• [SLOW TEST:10.401 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:39:20.430: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  2 22:39:23.090: INFO: Successfully updated pod "annotationupdate798878d7-e565-11e9-bbfa-0a580af40203"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:39:25.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7112" for this suite.
Oct  2 22:39:47.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:39:47.504: INFO: namespace projected-7112 deletion completed in 22.307685219s

• [SLOW TEST:27.074 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:39:47.505: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  2 22:39:51.730: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  2 22:39:51.741: INFO: Pod pod-with-poststart-http-hook still exists
Oct  2 22:39:53.742: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  2 22:39:53.752: INFO: Pod pod-with-poststart-http-hook still exists
Oct  2 22:39:55.742: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  2 22:39:55.751: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:39:55.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6804" for this suite.
Oct  2 22:40:19.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:40:20.153: INFO: namespace container-lifecycle-hook-6804 deletion completed in 24.395632326s

• [SLOW TEST:32.649 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:40:20.154: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  2 22:40:20.252: INFO: Waiting up to 5m0s for pod "downward-api-9d23823d-e565-11e9-bbfa-0a580af40203" in namespace "downward-api-3325" to be "success or failure"
Oct  2 22:40:20.262: INFO: Pod "downward-api-9d23823d-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 9.122791ms
Oct  2 22:40:22.270: INFO: Pod "downward-api-9d23823d-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017855074s
STEP: Saw pod success
Oct  2 22:40:22.270: INFO: Pod "downward-api-9d23823d-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:40:22.277: INFO: Trying to get logs from node 10.0.10.3 pod downward-api-9d23823d-e565-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:40:22.318: INFO: Waiting for pod downward-api-9d23823d-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:40:22.326: INFO: Pod downward-api-9d23823d-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:40:22.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3325" for this suite.
Oct  2 22:40:28.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:40:28.633: INFO: namespace downward-api-3325 deletion completed in 6.300855827s

• [SLOW TEST:8.479 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:40:28.633: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct  2 22:40:28.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 create -f - --namespace=kubectl-5399'
Oct  2 22:40:28.914: INFO: stderr: ""
Oct  2 22:40:28.914: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  2 22:40:29.929: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:40:29.929: INFO: Found 0 / 1
Oct  2 22:40:30.922: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:40:30.922: INFO: Found 1 / 1
Oct  2 22:40:30.922: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct  2 22:40:30.929: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:40:30.929: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  2 22:40:30.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715202161 patch pod redis-master-c2b26 --namespace=kubectl-5399 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct  2 22:40:31.037: INFO: stderr: ""
Oct  2 22:40:31.037: INFO: stdout: "pod/redis-master-c2b26 patched\n"
STEP: checking annotations
Oct  2 22:40:31.045: INFO: Selector matched 1 pods for map[app:redis]
Oct  2 22:40:31.045: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:40:31.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5399" for this suite.
Oct  2 22:40:55.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:40:55.330: INFO: namespace kubectl-5399 deletion completed in 24.278643123s

• [SLOW TEST:26.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:40:55.330: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b21765ca-e565-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:40:55.430: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203" in namespace "projected-6750" to be "success or failure"
Oct  2 22:40:55.439: INFO: Pod "pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.849628ms
Oct  2 22:40:57.448: INFO: Pod "pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017499042s
STEP: Saw pod success
Oct  2 22:40:57.448: INFO: Pod "pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:40:57.456: INFO: Trying to get logs from node 10.0.10.4 pod pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  2 22:40:57.522: INFO: Waiting for pod pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:40:57.529: INFO: Pod pod-projected-secrets-b21a7b7a-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:40:57.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6750" for this suite.
Oct  2 22:41:03.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:41:03.815: INFO: namespace projected-6750 deletion completed in 6.278767948s

• [SLOW TEST:8.484 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:41:03.815: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b72a3a58-e565-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume secrets
Oct  2 22:41:03.921: INFO: Waiting up to 5m0s for pod "pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203" in namespace "secrets-7402" to be "success or failure"
Oct  2 22:41:03.933: INFO: Pod "pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 11.677209ms
Oct  2 22:41:05.941: INFO: Pod "pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020336085s
STEP: Saw pod success
Oct  2 22:41:05.941: INFO: Pod "pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:41:05.948: INFO: Trying to get logs from node 10.0.10.3 pod pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203 container secret-env-test: <nil>
STEP: delete the pod
Oct  2 22:41:06.013: INFO: Waiting for pod pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:41:06.021: INFO: Pod pod-secrets-b72b712e-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:41:06.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7402" for this suite.
Oct  2 22:41:12.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:41:12.319: INFO: namespace secrets-7402 deletion completed in 6.291033529s

• [SLOW TEST:8.504 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:41:12.320: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  2 22:41:12.395: INFO: Waiting up to 5m0s for pod "pod-bc382089-e565-11e9-bbfa-0a580af40203" in namespace "emptydir-5645" to be "success or failure"
Oct  2 22:41:12.407: INFO: Pod "pod-bc382089-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 12.166299ms
Oct  2 22:41:14.414: INFO: Pod "pod-bc382089-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01965265s
STEP: Saw pod success
Oct  2 22:41:14.415: INFO: Pod "pod-bc382089-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:41:14.422: INFO: Trying to get logs from node 10.0.10.4 pod pod-bc382089-e565-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:41:14.536: INFO: Waiting for pod pod-bc382089-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:41:14.544: INFO: Pod pod-bc382089-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:41:14.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5645" for this suite.
Oct  2 22:41:20.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:41:20.813: INFO: namespace emptydir-5645 deletion completed in 6.262860099s

• [SLOW TEST:8.493 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:41:20.813: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:41:22.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6831" for this suite.
Oct  2 22:42:05.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:42:05.312: INFO: namespace kubelet-test-6831 deletion completed in 42.299103086s

• [SLOW TEST:44.499 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:42:05.313: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  2 22:42:05.391: INFO: Waiting up to 5m0s for pod "pod-dbceadf8-e565-11e9-bbfa-0a580af40203" in namespace "emptydir-811" to be "success or failure"
Oct  2 22:42:05.401: INFO: Pod "pod-dbceadf8-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.165843ms
Oct  2 22:42:07.427: INFO: Pod "pod-dbceadf8-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0360285s
STEP: Saw pod success
Oct  2 22:42:07.427: INFO: Pod "pod-dbceadf8-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:42:07.435: INFO: Trying to get logs from node 10.0.10.4 pod pod-dbceadf8-e565-11e9-bbfa-0a580af40203 container test-container: <nil>
STEP: delete the pod
Oct  2 22:42:07.480: INFO: Waiting for pod pod-dbceadf8-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:42:07.488: INFO: Pod pod-dbceadf8-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:42:07.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-811" for this suite.
Oct  2 22:42:13.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:42:13.779: INFO: namespace emptydir-811 deletion completed in 6.283742547s

• [SLOW TEST:8.466 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:42:13.779: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Oct  2 22:42:13.853: INFO: Waiting up to 5m0s for pod "var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203" in namespace "var-expansion-4336" to be "success or failure"
Oct  2 22:42:13.861: INFO: Pod "var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 7.557644ms
Oct  2 22:42:15.869: INFO: Pod "var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015732054s
STEP: Saw pod success
Oct  2 22:42:15.869: INFO: Pod "var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:42:15.875: INFO: Trying to get logs from node 10.0.10.3 pod var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203 container dapi-container: <nil>
STEP: delete the pod
Oct  2 22:42:15.916: INFO: Waiting for pod var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:42:15.926: INFO: Pod var-expansion-e0da7370-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:42:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4336" for this suite.
Oct  2 22:42:21.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:42:22.250: INFO: namespace var-expansion-4336 deletion completed in 6.318045639s

• [SLOW TEST:8.471 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:42:22.251: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:42:47.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1261" for this suite.
Oct  2 22:42:53.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:42:53.826: INFO: namespace namespaces-1261 deletion completed in 6.259133386s
STEP: Destroying namespace "nsdeletetest-1558" for this suite.
Oct  2 22:42:53.832: INFO: Namespace nsdeletetest-1558 was already deleted
STEP: Destroying namespace "nsdeletetest-8839" for this suite.
Oct  2 22:42:59.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:43:00.125: INFO: namespace nsdeletetest-8839 deletion completed in 6.293492713s

• [SLOW TEST:37.874 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  2 22:43:00.125: INFO: >>> kubeConfig: /tmp/kubeconfig-715202161
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-fc7db974-e565-11e9-bbfa-0a580af40203
STEP: Creating a pod to test consume configMaps
Oct  2 22:43:00.258: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203" in namespace "projected-9487" to be "success or failure"
Oct  2 22:43:00.281: INFO: Pod "pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203": Phase="Pending", Reason="", readiness=false. Elapsed: 23.454212ms
Oct  2 22:43:02.289: INFO: Pod "pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031629595s
STEP: Saw pod success
Oct  2 22:43:02.289: INFO: Pod "pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203" satisfied condition "success or failure"
Oct  2 22:43:02.296: INFO: Trying to get logs from node 10.0.10.3 pod pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  2 22:43:02.426: INFO: Waiting for pod pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203 to disappear
Oct  2 22:43:02.455: INFO: Pod pod-projected-configmaps-fc81a8c5-e565-11e9-bbfa-0a580af40203 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  2 22:43:02.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9487" for this suite.
Oct  2 22:43:08.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  2 22:43:08.762: INFO: namespace projected-9487 deletion completed in 6.299738713s

• [SLOW TEST:8.636 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSOct  2 22:43:08.762: INFO: Running AfterSuite actions on all nodes
Oct  2 22:43:08.762: INFO: Running AfterSuite actions on node 1
Oct  2 22:43:08.762: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5713.988 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h35m15.606651671s
Test Suite Passed
