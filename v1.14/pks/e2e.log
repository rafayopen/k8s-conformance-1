I0821 19:21:17.351485      18 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-287854235
I0821 19:21:17.352480      18 e2e.go:240] Starting e2e run "d8789374-c448-11e9-8a5f-26f602588652" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566415275 - Will randomize all specs
Will run 204 of 3586 specs

Aug 21 19:21:17.580: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:17.584: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 21 19:21:17.617: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 21 19:21:17.656: INFO: 5 / 5 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 21 19:21:17.656: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Aug 21 19:21:17.656: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 21 19:21:17.669: INFO: e2e test version: v1.14.5
Aug 21 19:21:17.671: INFO: kube-apiserver version: v1.14.5
SSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:21:17.674: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
Aug 21 19:21:17.728: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 21 19:21:17.743: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-9556
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 21 19:21:23.924: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:23.924: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.069: INFO: Exec stderr: ""
Aug 21 19:21:24.069: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.069: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.226: INFO: Exec stderr: ""
Aug 21 19:21:24.227: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.227: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.358: INFO: Exec stderr: ""
Aug 21 19:21:24.358: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.358: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.504: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 21 19:21:24.504: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.505: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.619: INFO: Exec stderr: ""
Aug 21 19:21:24.619: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.619: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.735: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 21 19:21:24.735: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.736: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:24.891: INFO: Exec stderr: ""
Aug 21 19:21:24.891: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:24.891: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:25.033: INFO: Exec stderr: ""
Aug 21 19:21:25.033: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:25.033: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:25.177: INFO: Exec stderr: ""
Aug 21 19:21:25.178: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9556 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:21:25.178: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:21:25.336: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:21:25.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9556" for this suite.
Aug 21 19:22:03.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:22:03.505: INFO: namespace e2e-kubelet-etc-hosts-9556 deletion completed in 38.161443065s

â€¢ [SLOW TEST:45.832 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:22:03.507: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:22:03.696: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 19:22:03.718: INFO: Number of nodes with available pods: 0
Aug 21 19:22:03.718: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:22:04.729: INFO: Number of nodes with available pods: 0
Aug 21 19:22:04.730: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:22:05.732: INFO: Number of nodes with available pods: 2
Aug 21 19:22:05.732: INFO: Node ca867801-09fc-419b-a2c1-ae5752feb0ff is running more than one daemon pod
Aug 21 19:22:06.737: INFO: Number of nodes with available pods: 3
Aug 21 19:22:06.737: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 21 19:22:06.792: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:06.792: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:06.792: INFO: Wrong image for pod: daemon-set-qqssb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:07.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:07.816: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:07.816: INFO: Wrong image for pod: daemon-set-qqssb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:08.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:08.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:08.815: INFO: Wrong image for pod: daemon-set-qqssb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:09.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:09.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:09.814: INFO: Wrong image for pod: daemon-set-qqssb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:09.814: INFO: Pod daemon-set-qqssb is not available
Aug 21 19:22:10.815: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:10.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:10.815: INFO: Pod daemon-set-xjwqx is not available
Aug 21 19:22:11.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:11.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:11.815: INFO: Pod daemon-set-xjwqx is not available
Aug 21 19:22:12.815: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:12.815: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:12.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:13.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:13.814: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:13.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:14.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:14.814: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:14.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:15.816: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:15.816: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:15.816: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:16.816: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:16.816: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:16.816: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:17.815: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:17.815: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:17.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:18.813: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:18.814: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:18.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:19.814: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:19.814: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:19.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:20.815: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:20.815: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:20.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:21.816: INFO: Wrong image for pod: daemon-set-cmgzp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:21.816: INFO: Pod daemon-set-cmgzp is not available
Aug 21 19:22:21.816: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:22.814: INFO: Pod daemon-set-9w5md is not available
Aug 21 19:22:22.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:23.814: INFO: Pod daemon-set-9w5md is not available
Aug 21 19:22:23.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:24.813: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:25.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:25.814: INFO: Pod daemon-set-h6tbb is not available
Aug 21 19:22:26.814: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:26.814: INFO: Pod daemon-set-h6tbb is not available
Aug 21 19:22:27.815: INFO: Wrong image for pod: daemon-set-h6tbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 21 19:22:27.815: INFO: Pod daemon-set-h6tbb is not available
Aug 21 19:22:28.815: INFO: Pod daemon-set-cnwkd is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 21 19:22:28.834: INFO: Number of nodes with available pods: 2
Aug 21 19:22:28.834: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:22:29.847: INFO: Number of nodes with available pods: 2
Aug 21 19:22:29.847: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:22:30.850: INFO: Number of nodes with available pods: 3
Aug 21 19:22:30.850: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3978, will wait for the garbage collector to delete the pods
Aug 21 19:22:30.942: INFO: Deleting DaemonSet.extensions daemon-set took: 12.477663ms
Aug 21 19:22:31.343: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.429558ms
Aug 21 19:22:42.249: INFO: Number of nodes with available pods: 0
Aug 21 19:22:42.249: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 19:22:42.253: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3978/daemonsets","resourceVersion":"127947"},"items":null}

Aug 21 19:22:42.257: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3978/pods","resourceVersion":"127947"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:22:42.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3978" for this suite.
Aug 21 19:22:48.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:22:48.423: INFO: namespace daemonsets-3978 deletion completed in 6.146494014s

â€¢ [SLOW TEST:44.917 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:22:48.424: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:22:48.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652" in namespace "projected-3005" to be "success or failure"
Aug 21 19:22:48.625: INFO: Pod "downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047058ms
Aug 21 19:22:50.632: INFO: Pod "downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014646218s
STEP: Saw pod success
Aug 21 19:22:50.634: INFO: Pod "downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:22:50.639: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:22:50.672: INFO: Waiting for pod downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:22:50.676: INFO: Pod downwardapi-volume-0fab1fd1-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:22:50.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3005" for this suite.
Aug 21 19:22:56.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:22:56.829: INFO: namespace projected-3005 deletion completed in 6.147458858s

â€¢ [SLOW TEST:8.406 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:22:56.833: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:23:23.027: INFO: Container started at 2019-08-21 19:22:58 +0000 UTC, pod became ready at 2019-08-21 19:23:21 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:23:23.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6778" for this suite.
Aug 21 19:23:45.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:23:45.178: INFO: namespace container-probe-6778 deletion completed in 22.14526785s

â€¢ [SLOW TEST:48.345 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:23:45.178: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 19:23:45.334: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 19:23:45.344: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 19:23:45.348: INFO:
Logging pods the kubelet thinks is on node 978c34ce-e296-4689-bf73-826c8c556b20 before test
Aug 21 19:23:45.361: INFO: coredns-95489c5c9-8llvk from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:23:45.361: INFO: event-controller-646d78b9b8-tjz2b from pks-system started at 2019-08-21 02:16:05 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container event-controller ready: true, restart count 0
Aug 21 19:23:45.361: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:23:45.361: INFO: node-exporter-78dpq from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:23:45.361: INFO: telegraf-l2x6l from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:23:45.361: INFO: telemetry-agent-858446f4ff-m2sfm from pks-system started at 2019-08-21 02:21:02 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container fluent-bit-billing ready: true, restart count 0
Aug 21 19:23:45.361: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Aug 21 19:23:45.361: INFO: fluent-bit-jxvvq from pks-system started at 2019-08-21 02:16:18 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:23:45.361: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:23:45.361: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 19:21:12 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 21 19:23:45.361: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-xlph9 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:23:45.361: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:23:45.361: INFO: metrics-server-867b8fdb7d-j7dsn from kube-system started at 2019-08-21 02:15:55 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.361: INFO: 	Container metrics-server ready: true, restart count 0
Aug 21 19:23:45.361: INFO:
Logging pods the kubelet thinks is on node ca867801-09fc-419b-a2c1-ae5752feb0ff before test
Aug 21 19:23:45.386: INFO: sonobuoy-e2e-job-b0f9cb20d3e8417a from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.387: INFO: 	Container e2e ready: true, restart count 0
Aug 21 19:23:45.387: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:23:45.387: INFO: sink-controller-6774fd95f7-4xc2v from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.387: INFO: 	Container sink-controller ready: true, restart count 0
Aug 21 19:23:45.387: INFO: fluent-bit-9hsw7 from pks-system started at 2019-08-21 02:16:08 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.387: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:23:45.387: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:23:45.387: INFO: telegraf-z8mgq from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.388: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:23:45.388: INFO: coredns-95489c5c9-tc97f from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.388: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:23:45.388: INFO: wavefront-collector-848b9948f-6mgdc from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.388: INFO: 	Container wavefront-collector ready: true, restart count 0
Aug 21 19:23:45.388: INFO: node-exporter-dsw5w from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.388: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:23:45.388: INFO: kube-state-metrics-85bfc8cb86-hvpcs from pks-system started at 2019-08-21 02:18:27 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.388: INFO: 	Container addon-resizer ready: true, restart count 0
Aug 21 19:23:45.389: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 21 19:23:45.389: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-s8kz2 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:23:45.389: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:23:45.389: INFO: kubernetes-dashboard-558689fc66-dl7vk from kube-system started at 2019-08-21 02:15:58 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.389: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 21 19:23:45.389: INFO: cert-generator-dea87263fc8e6d3a2a122f5f5e31b36afbeef369-xgx5b from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.389: INFO: 	Container cert-generator ready: false, restart count 0
Aug 21 19:23:45.389: INFO: validator-6b677f49d4-dsk52 from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.389: INFO: 	Container validator ready: true, restart count 0
Aug 21 19:23:45.389: INFO:
Logging pods the kubelet thinks is on node f138d081-7db1-41cb-9804-f6d51b22765f before test
Aug 21 19:23:45.422: INFO: fluent-bit-bnmmv from pks-system started at 2019-08-21 02:16:12 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:23:45.422: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:23:45.422: INFO: wavefront-proxy-785c6f5c95-km2rx from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container wavefront-proxy ready: true, restart count 0
Aug 21 19:23:45.422: INFO: node-exporter-zx8fm from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:23:45.422: INFO: telegraf-v5jgb from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:23:45.422: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-lwcqg from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:23:45.422: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:23:45.422: INFO: observability-manager-6fff4d8d86-szpsb from pks-system started at 2019-08-21 02:16:01 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container observability-manager ready: true, restart count 0
Aug 21 19:23:45.422: INFO: coredns-95489c5c9-xrmnx from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:23:45.422: INFO: metric-controller-c998cb5bf-zl4n7 from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:23:45.422: INFO: 	Container metric-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-33f32956-c449-11e9-8a5f-26f602588652 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-33f32956-c449-11e9-8a5f-26f602588652 off the node 978c34ce-e296-4689-bf73-826c8c556b20
STEP: verifying the node doesn't have the label kubernetes.io/e2e-33f32956-c449-11e9-8a5f-26f602588652
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:23:51.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6873" for this suite.
Aug 21 19:24:01.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:24:01.685: INFO: namespace sched-pred-6873 deletion completed in 10.139250192s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:16.508 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:24:01.694: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1811
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4198
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:24:26.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8343" for this suite.
Aug 21 19:24:32.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:24:32.375: INFO: namespace namespaces-8343 deletion completed in 6.168614006s
STEP: Destroying namespace "nsdeletetest-1811" for this suite.
Aug 21 19:24:32.379: INFO: Namespace nsdeletetest-1811 was already deleted
STEP: Destroying namespace "nsdeletetest-4198" for this suite.
Aug 21 19:24:38.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:24:38.521: INFO: namespace nsdeletetest-4198 deletion completed in 6.14159047s

â€¢ [SLOW TEST:36.828 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:24:38.524: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1524
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 19:24:38.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-6176'
Aug 21 19:24:39.504: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 19:24:39.504: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1529
Aug 21 19:24:41.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6176'
Aug 21 19:24:41.646: INFO: stderr: ""
Aug 21 19:24:41.646: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:24:41.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6176" for this suite.
Aug 21 19:25:03.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:03.809: INFO: namespace kubectl-6176 deletion completed in 22.154498443s

â€¢ [SLOW TEST:25.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:03.816: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1857
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-605c0267-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:25:04.001: INFO: Waiting up to 5m0s for pod "pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652" in namespace "configmap-1857" to be "success or failure"
Aug 21 19:25:04.011: INFO: Pod "pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.677726ms
Aug 21 19:25:06.018: INFO: Pod "pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016196682s
STEP: Saw pod success
Aug 21 19:25:06.018: INFO: Pod "pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:25:06.023: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:25:06.055: INFO: Waiting for pod pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:25:06.059: INFO: Pod pod-configmaps-605d1e3a-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:06.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1857" for this suite.
Aug 21 19:25:12.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:12.219: INFO: namespace configmap-1857 deletion completed in 6.153685382s

â€¢ [SLOW TEST:8.403 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:12.226: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7597
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Aug 21 19:25:12.402: INFO: Waiting up to 5m0s for pod "var-expansion-655f3e91-c449-11e9-8a5f-26f602588652" in namespace "var-expansion-7597" to be "success or failure"
Aug 21 19:25:12.408: INFO: Pod "var-expansion-655f3e91-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037334ms
Aug 21 19:25:14.414: INFO: Pod "var-expansion-655f3e91-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012247199s
STEP: Saw pod success
Aug 21 19:25:14.414: INFO: Pod "var-expansion-655f3e91-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:25:14.418: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod var-expansion-655f3e91-c449-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 19:25:14.450: INFO: Waiting for pod var-expansion-655f3e91-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:25:14.454: INFO: Pod var-expansion-655f3e91-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:14.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7597" for this suite.
Aug 21 19:25:20.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:20.623: INFO: namespace var-expansion-7597 deletion completed in 6.162913069s

â€¢ [SLOW TEST:8.399 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:20.626: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:25:20.790: INFO: Creating ReplicaSet my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652
Aug 21 19:25:20.806: INFO: Pod name my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652: Found 0 pods out of 1
Aug 21 19:25:25.812: INFO: Pod name my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652: Found 1 pods out of 1
Aug 21 19:25:25.812: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652" is running
Aug 21 19:25:25.815: INFO: Pod "my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652-trqbj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 19:25:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 19:25:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 19:25:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 19:25:20 +0000 UTC Reason: Message:}])
Aug 21 19:25:25.815: INFO: Trying to dial the pod
Aug 21 19:25:30.833: INFO: Controller my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652: Got expected result from replica 1 [my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652-trqbj]: "my-hostname-basic-6a60fa82-c449-11e9-8a5f-26f602588652-trqbj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:30.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4133" for this suite.
Aug 21 19:25:36.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:36.981: INFO: namespace replicaset-4133 deletion completed in 6.141441263s

â€¢ [SLOW TEST:16.356 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:36.983: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-741f7a46-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:25:37.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-74206034-c449-11e9-8a5f-26f602588652" in namespace "configmap-5258" to be "success or failure"
Aug 21 19:25:37.165: INFO: Pod "pod-configmaps-74206034-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.997016ms
Aug 21 19:25:39.171: INFO: Pod "pod-configmaps-74206034-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014802911s
Aug 21 19:25:41.177: INFO: Pod "pod-configmaps-74206034-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021079066s
STEP: Saw pod success
Aug 21 19:25:41.178: INFO: Pod "pod-configmaps-74206034-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:25:41.182: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-74206034-c449-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:25:41.217: INFO: Waiting for pod pod-configmaps-74206034-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:25:41.221: INFO: Pod pod-configmaps-74206034-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:41.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5258" for this suite.
Aug 21 19:25:47.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:47.376: INFO: namespace configmap-5258 deletion completed in 6.150124994s

â€¢ [SLOW TEST:10.393 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:47.380: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:25:47.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652" in namespace "downward-api-9595" to be "success or failure"
Aug 21 19:25:47.570: INFO: Pod "downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 14.105181ms
Aug 21 19:25:49.576: INFO: Pod "downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019578326s
STEP: Saw pod success
Aug 21 19:25:49.576: INFO: Pod "downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:25:49.579: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:25:49.607: INFO: Waiting for pod downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:25:49.611: INFO: Pod downwardapi-volume-7a537342-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:49.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9595" for this suite.
Aug 21 19:25:55.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:25:55.759: INFO: namespace downward-api-9595 deletion completed in 6.142659186s

â€¢ [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:25:55.762: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7324
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Aug 21 19:25:55.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-7324'
Aug 21 19:25:56.212: INFO: stderr: ""
Aug 21 19:25:56.212: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 19:25:57.217: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 19:25:57.218: INFO: Found 0 / 1
Aug 21 19:25:58.218: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 19:25:58.218: INFO: Found 1 / 1
Aug 21 19:25:58.218: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 21 19:25:58.222: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 19:25:58.222: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 19:25:58.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 patch pod redis-master-zbb7m --namespace=kubectl-7324 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 21 19:25:58.340: INFO: stderr: ""
Aug 21 19:25:58.340: INFO: stdout: "pod/redis-master-zbb7m patched\n"
STEP: checking annotations
Aug 21 19:25:58.346: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 19:25:58.346: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:25:58.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7324" for this suite.
Aug 21 19:26:20.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:26:20.526: INFO: namespace kubectl-7324 deletion completed in 22.174099059s

â€¢ [SLOW TEST:24.763 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:26:20.526: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6944
I0821 19:26:20.689424      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6944, replica count: 1
I0821 19:26:21.740120      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0821 19:26:22.740376      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
Aug 21 19:26:22.860: INFO: Created: latency-svc-qjzxn
Aug 21 19:26:22.864: INFO: Got endpoints: latency-svc-qjzxn [24.018252ms]
Aug 21 19:26:22.877: INFO: Created: latency-svc-hzs6r
Aug 21 19:26:22.881: INFO: Got endpoints: latency-svc-hzs6r [16.030994ms]
Aug 21 19:26:22.887: INFO: Created: latency-svc-vct4b
Aug 21 19:26:22.897: INFO: Got endpoints: latency-svc-vct4b [27.53449ms]
Aug 21 19:26:22.901: INFO: Created: latency-svc-fftd9
Aug 21 19:26:22.906: INFO: Got endpoints: latency-svc-fftd9 [40.890257ms]
Aug 21 19:26:22.910: INFO: Created: latency-svc-rjspw
Aug 21 19:26:22.917: INFO: Got endpoints: latency-svc-rjspw [51.238633ms]
Aug 21 19:26:22.921: INFO: Created: latency-svc-vwpnw
Aug 21 19:26:22.924: INFO: Got endpoints: latency-svc-vwpnw [57.994263ms]
Aug 21 19:26:22.930: INFO: Created: latency-svc-pdrns
Aug 21 19:26:22.941: INFO: Got endpoints: latency-svc-pdrns [74.969538ms]
Aug 21 19:26:22.944: INFO: Created: latency-svc-v4cnd
Aug 21 19:26:22.948: INFO: Got endpoints: latency-svc-v4cnd [81.643325ms]
Aug 21 19:26:22.956: INFO: Created: latency-svc-tzl62
Aug 21 19:26:22.967: INFO: Got endpoints: latency-svc-tzl62 [100.460059ms]
Aug 21 19:26:22.969: INFO: Created: latency-svc-m4wb4
Aug 21 19:26:22.976: INFO: Got endpoints: latency-svc-m4wb4 [108.701059ms]
Aug 21 19:26:22.977: INFO: Created: latency-svc-ts2jm
Aug 21 19:26:22.988: INFO: Got endpoints: latency-svc-ts2jm [120.121489ms]
Aug 21 19:26:22.995: INFO: Created: latency-svc-nb8b4
Aug 21 19:26:22.995: INFO: Got endpoints: latency-svc-nb8b4 [126.003028ms]
Aug 21 19:26:23.001: INFO: Created: latency-svc-scgs9
Aug 21 19:26:23.005: INFO: Got endpoints: latency-svc-scgs9 [135.566109ms]
Aug 21 19:26:23.016: INFO: Created: latency-svc-qn8qj
Aug 21 19:26:23.019: INFO: Got endpoints: latency-svc-qn8qj [149.708695ms]
Aug 21 19:26:23.023: INFO: Created: latency-svc-q56m6
Aug 21 19:26:23.030: INFO: Created: latency-svc-x78zk
Aug 21 19:26:23.043: INFO: Created: latency-svc-6qdr4
Aug 21 19:26:23.044: INFO: Got endpoints: latency-svc-x78zk [176.109025ms]
Aug 21 19:26:23.044: INFO: Got endpoints: latency-svc-q56m6 [174.806046ms]
Aug 21 19:26:23.047: INFO: Got endpoints: latency-svc-6qdr4 [166.598392ms]
Aug 21 19:26:23.052: INFO: Created: latency-svc-8g54n
Aug 21 19:26:23.061: INFO: Got endpoints: latency-svc-8g54n [164.346468ms]
Aug 21 19:26:23.068: INFO: Created: latency-svc-vqgpm
Aug 21 19:26:23.073: INFO: Created: latency-svc-f2dqv
Aug 21 19:26:23.075: INFO: Got endpoints: latency-svc-vqgpm [168.706477ms]
Aug 21 19:26:23.084: INFO: Got endpoints: latency-svc-f2dqv [167.05ms]
Aug 21 19:26:23.089: INFO: Created: latency-svc-gsmgb
Aug 21 19:26:23.094: INFO: Created: latency-svc-zph4m
Aug 21 19:26:23.099: INFO: Got endpoints: latency-svc-gsmgb [175.603904ms]
Aug 21 19:26:23.107: INFO: Got endpoints: latency-svc-zph4m [165.766819ms]
Aug 21 19:26:23.111: INFO: Created: latency-svc-rf86w
Aug 21 19:26:23.115: INFO: Got endpoints: latency-svc-rf86w [166.567884ms]
Aug 21 19:26:23.119: INFO: Created: latency-svc-5dd24
Aug 21 19:26:23.123: INFO: Got endpoints: latency-svc-5dd24 [155.673926ms]
Aug 21 19:26:23.134: INFO: Created: latency-svc-hggqq
Aug 21 19:26:23.137: INFO: Got endpoints: latency-svc-hggqq [160.752726ms]
Aug 21 19:26:23.141: INFO: Created: latency-svc-hz2v9
Aug 21 19:26:23.144: INFO: Got endpoints: latency-svc-hz2v9 [156.547385ms]
Aug 21 19:26:23.159: INFO: Created: latency-svc-dc6tv
Aug 21 19:26:23.165: INFO: Created: latency-svc-b9j9f
Aug 21 19:26:23.168: INFO: Got endpoints: latency-svc-dc6tv [172.814834ms]
Aug 21 19:26:23.170: INFO: Got endpoints: latency-svc-b9j9f [165.233003ms]
Aug 21 19:26:23.179: INFO: Created: latency-svc-7r4h8
Aug 21 19:26:23.186: INFO: Got endpoints: latency-svc-7r4h8 [167.392994ms]
Aug 21 19:26:23.196: INFO: Created: latency-svc-2qsrh
Aug 21 19:26:23.204: INFO: Got endpoints: latency-svc-2qsrh [160.147143ms]
Aug 21 19:26:23.204: INFO: Created: latency-svc-c494d
Aug 21 19:26:23.210: INFO: Got endpoints: latency-svc-c494d [165.835071ms]
Aug 21 19:26:23.224: INFO: Created: latency-svc-4d9d6
Aug 21 19:26:23.225: INFO: Got endpoints: latency-svc-4d9d6 [177.878664ms]
Aug 21 19:26:23.233: INFO: Created: latency-svc-ll6tm
Aug 21 19:26:23.245: INFO: Got endpoints: latency-svc-ll6tm [183.811979ms]
Aug 21 19:26:23.253: INFO: Created: latency-svc-9tm8g
Aug 21 19:26:23.253: INFO: Got endpoints: latency-svc-9tm8g [177.167628ms]
Aug 21 19:26:23.259: INFO: Created: latency-svc-fdr62
Aug 21 19:26:23.271: INFO: Got endpoints: latency-svc-fdr62 [186.558492ms]
Aug 21 19:26:23.279: INFO: Created: latency-svc-xs886
Aug 21 19:26:23.280: INFO: Got endpoints: latency-svc-xs886 [180.059952ms]
Aug 21 19:26:23.289: INFO: Created: latency-svc-kbz6h
Aug 21 19:26:23.292: INFO: Created: latency-svc-ljkxf
Aug 21 19:26:23.300: INFO: Got endpoints: latency-svc-kbz6h [191.901337ms]
Aug 21 19:26:23.305: INFO: Got endpoints: latency-svc-ljkxf [189.352831ms]
Aug 21 19:26:23.310: INFO: Created: latency-svc-f425f
Aug 21 19:26:23.314: INFO: Got endpoints: latency-svc-f425f [190.423988ms]
Aug 21 19:26:23.329: INFO: Created: latency-svc-lg9lv
Aug 21 19:26:23.337: INFO: Created: latency-svc-lfj84
Aug 21 19:26:23.346: INFO: Created: latency-svc-8vjhf
Aug 21 19:26:23.347: INFO: Created: latency-svc-2rct9
Aug 21 19:26:23.354: INFO: Created: latency-svc-fxg5f
Aug 21 19:26:23.370: INFO: Got endpoints: latency-svc-lg9lv [233.340553ms]
Aug 21 19:26:23.382: INFO: Created: latency-svc-msq6t
Aug 21 19:26:23.385: INFO: Created: latency-svc-lfkqr
Aug 21 19:26:23.389: INFO: Created: latency-svc-kbtp5
Aug 21 19:26:23.404: INFO: Created: latency-svc-jmfkc
Aug 21 19:26:23.418: INFO: Got endpoints: latency-svc-lfj84 [273.977691ms]
Aug 21 19:26:23.423: INFO: Created: latency-svc-sfql6
Aug 21 19:26:23.428: INFO: Created: latency-svc-msh48
Aug 21 19:26:23.439: INFO: Created: latency-svc-gn7j2
Aug 21 19:26:23.450: INFO: Created: latency-svc-bhqmm
Aug 21 19:26:23.451: INFO: Created: latency-svc-69w6c
Aug 21 19:26:23.458: INFO: Created: latency-svc-zlmnr
Aug 21 19:26:23.465: INFO: Got endpoints: latency-svc-8vjhf [297.037441ms]
Aug 21 19:26:23.474: INFO: Created: latency-svc-s7n8q
Aug 21 19:26:23.477: INFO: Created: latency-svc-lmgv4
Aug 21 19:26:23.482: INFO: Created: latency-svc-rrgw5
Aug 21 19:26:23.514: INFO: Got endpoints: latency-svc-2rct9 [343.850359ms]
Aug 21 19:26:23.528: INFO: Created: latency-svc-gsn7z
Aug 21 19:26:23.566: INFO: Got endpoints: latency-svc-fxg5f [379.134961ms]
Aug 21 19:26:23.579: INFO: Created: latency-svc-lnnfw
Aug 21 19:26:23.614: INFO: Got endpoints: latency-svc-msq6t [410.591133ms]
Aug 21 19:26:23.627: INFO: Created: latency-svc-jdvfr
Aug 21 19:26:23.666: INFO: Got endpoints: latency-svc-lfkqr [455.979284ms]
Aug 21 19:26:23.680: INFO: Created: latency-svc-rw5r9
Aug 21 19:26:23.715: INFO: Got endpoints: latency-svc-kbtp5 [489.876737ms]
Aug 21 19:26:23.728: INFO: Created: latency-svc-j4r7l
Aug 21 19:26:23.766: INFO: Got endpoints: latency-svc-jmfkc [520.350009ms]
Aug 21 19:26:23.779: INFO: Created: latency-svc-6dwxb
Aug 21 19:26:23.817: INFO: Got endpoints: latency-svc-sfql6 [563.757615ms]
Aug 21 19:26:23.829: INFO: Created: latency-svc-bbpfb
Aug 21 19:26:23.866: INFO: Got endpoints: latency-svc-msh48 [595.445085ms]
Aug 21 19:26:23.881: INFO: Created: latency-svc-9b99v
Aug 21 19:26:23.916: INFO: Got endpoints: latency-svc-gn7j2 [636.095551ms]
Aug 21 19:26:23.928: INFO: Created: latency-svc-7ln7c
Aug 21 19:26:23.967: INFO: Got endpoints: latency-svc-69w6c [667.683793ms]
Aug 21 19:26:23.986: INFO: Created: latency-svc-fgh5w
Aug 21 19:26:24.016: INFO: Got endpoints: latency-svc-bhqmm [711.231258ms]
Aug 21 19:26:24.030: INFO: Created: latency-svc-g4hc7
Aug 21 19:26:24.066: INFO: Got endpoints: latency-svc-zlmnr [751.784863ms]
Aug 21 19:26:24.080: INFO: Created: latency-svc-4kz6v
Aug 21 19:26:24.116: INFO: Got endpoints: latency-svc-s7n8q [745.303621ms]
Aug 21 19:26:24.134: INFO: Created: latency-svc-2kmvg
Aug 21 19:26:24.167: INFO: Got endpoints: latency-svc-lmgv4 [748.839212ms]
Aug 21 19:26:24.181: INFO: Created: latency-svc-q4bzm
Aug 21 19:26:24.216: INFO: Got endpoints: latency-svc-rrgw5 [750.609378ms]
Aug 21 19:26:24.229: INFO: Created: latency-svc-hrbmw
Aug 21 19:26:24.265: INFO: Got endpoints: latency-svc-gsn7z [750.933854ms]
Aug 21 19:26:24.293: INFO: Created: latency-svc-jnbgp
Aug 21 19:26:24.316: INFO: Got endpoints: latency-svc-lnnfw [750.034355ms]
Aug 21 19:26:24.332: INFO: Created: latency-svc-75wbz
Aug 21 19:26:24.369: INFO: Got endpoints: latency-svc-jdvfr [754.71963ms]
Aug 21 19:26:24.383: INFO: Created: latency-svc-qn6rf
Aug 21 19:26:24.416: INFO: Got endpoints: latency-svc-rw5r9 [750.109405ms]
Aug 21 19:26:24.431: INFO: Created: latency-svc-g4jhj
Aug 21 19:26:24.467: INFO: Got endpoints: latency-svc-j4r7l [751.560201ms]
Aug 21 19:26:24.483: INFO: Created: latency-svc-j5tbr
Aug 21 19:26:24.516: INFO: Got endpoints: latency-svc-6dwxb [750.014597ms]
Aug 21 19:26:24.528: INFO: Created: latency-svc-shdqd
Aug 21 19:26:24.564: INFO: Got endpoints: latency-svc-bbpfb [747.570087ms]
Aug 21 19:26:24.577: INFO: Created: latency-svc-zt2mb
Aug 21 19:26:24.615: INFO: Got endpoints: latency-svc-9b99v [748.647714ms]
Aug 21 19:26:24.628: INFO: Created: latency-svc-97mhj
Aug 21 19:26:24.665: INFO: Got endpoints: latency-svc-7ln7c [749.205145ms]
Aug 21 19:26:24.677: INFO: Created: latency-svc-gh87x
Aug 21 19:26:24.715: INFO: Got endpoints: latency-svc-fgh5w [747.20294ms]
Aug 21 19:26:24.727: INFO: Created: latency-svc-zll8v
Aug 21 19:26:24.765: INFO: Got endpoints: latency-svc-g4hc7 [749.0769ms]
Aug 21 19:26:24.776: INFO: Created: latency-svc-4n47l
Aug 21 19:26:24.816: INFO: Got endpoints: latency-svc-4kz6v [749.601688ms]
Aug 21 19:26:24.827: INFO: Created: latency-svc-lg5xt
Aug 21 19:26:24.865: INFO: Got endpoints: latency-svc-2kmvg [748.787802ms]
Aug 21 19:26:24.881: INFO: Created: latency-svc-vz8rj
Aug 21 19:26:24.917: INFO: Got endpoints: latency-svc-q4bzm [748.989673ms]
Aug 21 19:26:24.933: INFO: Created: latency-svc-9pfxb
Aug 21 19:26:24.965: INFO: Got endpoints: latency-svc-hrbmw [748.829787ms]
Aug 21 19:26:24.976: INFO: Created: latency-svc-q6wmt
Aug 21 19:26:25.020: INFO: Got endpoints: latency-svc-jnbgp [753.928261ms]
Aug 21 19:26:25.038: INFO: Created: latency-svc-bjnzw
Aug 21 19:26:25.069: INFO: Got endpoints: latency-svc-75wbz [753.206886ms]
Aug 21 19:26:25.082: INFO: Created: latency-svc-fbhn4
Aug 21 19:26:25.116: INFO: Got endpoints: latency-svc-qn6rf [747.018048ms]
Aug 21 19:26:25.128: INFO: Created: latency-svc-srl6f
Aug 21 19:26:25.169: INFO: Got endpoints: latency-svc-g4jhj [752.157064ms]
Aug 21 19:26:25.184: INFO: Created: latency-svc-7j7bf
Aug 21 19:26:25.221: INFO: Got endpoints: latency-svc-j5tbr [753.872933ms]
Aug 21 19:26:25.235: INFO: Created: latency-svc-fc5jh
Aug 21 19:26:25.266: INFO: Got endpoints: latency-svc-shdqd [749.85481ms]
Aug 21 19:26:25.278: INFO: Created: latency-svc-lrmqc
Aug 21 19:26:25.317: INFO: Got endpoints: latency-svc-zt2mb [751.427211ms]
Aug 21 19:26:25.328: INFO: Created: latency-svc-7q9g9
Aug 21 19:26:25.371: INFO: Got endpoints: latency-svc-97mhj [756.071083ms]
Aug 21 19:26:25.391: INFO: Created: latency-svc-75jpm
Aug 21 19:26:25.415: INFO: Got endpoints: latency-svc-gh87x [749.603221ms]
Aug 21 19:26:25.428: INFO: Created: latency-svc-46v9j
Aug 21 19:26:25.466: INFO: Got endpoints: latency-svc-zll8v [751.013745ms]
Aug 21 19:26:25.479: INFO: Created: latency-svc-tltpz
Aug 21 19:26:25.515: INFO: Got endpoints: latency-svc-4n47l [750.021613ms]
Aug 21 19:26:25.526: INFO: Created: latency-svc-hlmkx
Aug 21 19:26:25.565: INFO: Got endpoints: latency-svc-lg5xt [749.283763ms]
Aug 21 19:26:25.578: INFO: Created: latency-svc-4r7d4
Aug 21 19:26:25.616: INFO: Got endpoints: latency-svc-vz8rj [750.673392ms]
Aug 21 19:26:25.639: INFO: Created: latency-svc-npwnl
Aug 21 19:26:25.666: INFO: Got endpoints: latency-svc-9pfxb [749.064008ms]
Aug 21 19:26:25.677: INFO: Created: latency-svc-tj95b
Aug 21 19:26:25.715: INFO: Got endpoints: latency-svc-q6wmt [749.999869ms]
Aug 21 19:26:25.727: INFO: Created: latency-svc-dkb2t
Aug 21 19:26:25.765: INFO: Got endpoints: latency-svc-bjnzw [744.951931ms]
Aug 21 19:26:25.776: INFO: Created: latency-svc-kgpz4
Aug 21 19:26:25.815: INFO: Got endpoints: latency-svc-fbhn4 [745.804411ms]
Aug 21 19:26:25.827: INFO: Created: latency-svc-wpdjg
Aug 21 19:26:25.866: INFO: Got endpoints: latency-svc-srl6f [748.92943ms]
Aug 21 19:26:25.878: INFO: Created: latency-svc-n8p7d
Aug 21 19:26:25.915: INFO: Got endpoints: latency-svc-7j7bf [745.19574ms]
Aug 21 19:26:25.927: INFO: Created: latency-svc-m8knr
Aug 21 19:26:25.966: INFO: Got endpoints: latency-svc-fc5jh [745.064692ms]
Aug 21 19:26:25.977: INFO: Created: latency-svc-58t7x
Aug 21 19:26:26.015: INFO: Got endpoints: latency-svc-lrmqc [749.122782ms]
Aug 21 19:26:26.026: INFO: Created: latency-svc-j9vqg
Aug 21 19:26:26.066: INFO: Got endpoints: latency-svc-7q9g9 [748.286977ms]
Aug 21 19:26:26.079: INFO: Created: latency-svc-67bvb
Aug 21 19:26:26.115: INFO: Got endpoints: latency-svc-75jpm [736.261623ms]
Aug 21 19:26:26.132: INFO: Created: latency-svc-ffpft
Aug 21 19:26:26.165: INFO: Got endpoints: latency-svc-46v9j [749.663146ms]
Aug 21 19:26:26.178: INFO: Created: latency-svc-8wqh6
Aug 21 19:26:26.215: INFO: Got endpoints: latency-svc-tltpz [749.124319ms]
Aug 21 19:26:26.226: INFO: Created: latency-svc-mctmw
Aug 21 19:26:26.265: INFO: Got endpoints: latency-svc-hlmkx [749.669544ms]
Aug 21 19:26:26.284: INFO: Created: latency-svc-bqktd
Aug 21 19:26:26.315: INFO: Got endpoints: latency-svc-4r7d4 [749.816297ms]
Aug 21 19:26:26.327: INFO: Created: latency-svc-x6vpb
Aug 21 19:26:26.365: INFO: Got endpoints: latency-svc-npwnl [749.088831ms]
Aug 21 19:26:26.383: INFO: Created: latency-svc-vfnd6
Aug 21 19:26:26.416: INFO: Got endpoints: latency-svc-tj95b [749.87187ms]
Aug 21 19:26:26.428: INFO: Created: latency-svc-6dwqs
Aug 21 19:26:26.466: INFO: Got endpoints: latency-svc-dkb2t [750.656011ms]
Aug 21 19:26:26.480: INFO: Created: latency-svc-wbrqd
Aug 21 19:26:26.516: INFO: Got endpoints: latency-svc-kgpz4 [751.054024ms]
Aug 21 19:26:26.528: INFO: Created: latency-svc-qsvnh
Aug 21 19:26:26.566: INFO: Got endpoints: latency-svc-wpdjg [750.045384ms]
Aug 21 19:26:26.577: INFO: Created: latency-svc-c65ck
Aug 21 19:26:26.615: INFO: Got endpoints: latency-svc-n8p7d [749.424677ms]
Aug 21 19:26:26.627: INFO: Created: latency-svc-g55rw
Aug 21 19:26:26.667: INFO: Got endpoints: latency-svc-m8knr [751.88023ms]
Aug 21 19:26:26.685: INFO: Created: latency-svc-mb7gf
Aug 21 19:26:26.715: INFO: Got endpoints: latency-svc-58t7x [748.777937ms]
Aug 21 19:26:26.727: INFO: Created: latency-svc-bb8b4
Aug 21 19:26:26.766: INFO: Got endpoints: latency-svc-j9vqg [751.106307ms]
Aug 21 19:26:26.780: INFO: Created: latency-svc-69vcx
Aug 21 19:26:26.822: INFO: Got endpoints: latency-svc-67bvb [756.160038ms]
Aug 21 19:26:26.834: INFO: Created: latency-svc-bm7s4
Aug 21 19:26:26.864: INFO: Got endpoints: latency-svc-ffpft [748.765886ms]
Aug 21 19:26:26.881: INFO: Created: latency-svc-wczcp
Aug 21 19:26:26.915: INFO: Got endpoints: latency-svc-8wqh6 [750.049083ms]
Aug 21 19:26:26.926: INFO: Created: latency-svc-kj8pq
Aug 21 19:26:26.965: INFO: Got endpoints: latency-svc-mctmw [749.815941ms]
Aug 21 19:26:26.977: INFO: Created: latency-svc-8jl5q
Aug 21 19:26:27.015: INFO: Got endpoints: latency-svc-bqktd [749.600819ms]
Aug 21 19:26:27.027: INFO: Created: latency-svc-fwwtb
Aug 21 19:26:27.066: INFO: Got endpoints: latency-svc-x6vpb [750.440187ms]
Aug 21 19:26:27.082: INFO: Created: latency-svc-4pvsg
Aug 21 19:26:27.116: INFO: Got endpoints: latency-svc-vfnd6 [751.051111ms]
Aug 21 19:26:27.127: INFO: Created: latency-svc-9plxl
Aug 21 19:26:27.165: INFO: Got endpoints: latency-svc-6dwqs [749.44274ms]
Aug 21 19:26:27.177: INFO: Created: latency-svc-5vsx5
Aug 21 19:26:27.217: INFO: Got endpoints: latency-svc-wbrqd [750.660862ms]
Aug 21 19:26:27.228: INFO: Created: latency-svc-gcbpp
Aug 21 19:26:27.265: INFO: Got endpoints: latency-svc-qsvnh [748.683681ms]
Aug 21 19:26:27.277: INFO: Created: latency-svc-hkfdp
Aug 21 19:26:27.315: INFO: Got endpoints: latency-svc-c65ck [749.641006ms]
Aug 21 19:26:27.326: INFO: Created: latency-svc-nbtb2
Aug 21 19:26:27.366: INFO: Got endpoints: latency-svc-g55rw [750.35026ms]
Aug 21 19:26:27.378: INFO: Created: latency-svc-lcz6t
Aug 21 19:26:27.415: INFO: Got endpoints: latency-svc-mb7gf [747.390581ms]
Aug 21 19:26:27.433: INFO: Created: latency-svc-wwxg5
Aug 21 19:26:27.464: INFO: Got endpoints: latency-svc-bb8b4 [749.006285ms]
Aug 21 19:26:27.475: INFO: Created: latency-svc-qsghh
Aug 21 19:26:27.515: INFO: Got endpoints: latency-svc-69vcx [747.852797ms]
Aug 21 19:26:27.531: INFO: Created: latency-svc-2spbk
Aug 21 19:26:27.565: INFO: Got endpoints: latency-svc-bm7s4 [742.29651ms]
Aug 21 19:26:27.576: INFO: Created: latency-svc-l94hk
Aug 21 19:26:27.615: INFO: Got endpoints: latency-svc-wczcp [750.705532ms]
Aug 21 19:26:27.638: INFO: Created: latency-svc-qlxkg
Aug 21 19:26:27.665: INFO: Got endpoints: latency-svc-kj8pq [749.542902ms]
Aug 21 19:26:27.676: INFO: Created: latency-svc-z2gb4
Aug 21 19:26:27.715: INFO: Got endpoints: latency-svc-8jl5q [749.786519ms]
Aug 21 19:26:27.730: INFO: Created: latency-svc-txdp5
Aug 21 19:26:27.765: INFO: Got endpoints: latency-svc-fwwtb [750.352542ms]
Aug 21 19:26:27.776: INFO: Created: latency-svc-sbsjm
Aug 21 19:26:27.816: INFO: Got endpoints: latency-svc-4pvsg [749.844504ms]
Aug 21 19:26:27.828: INFO: Created: latency-svc-l7jwh
Aug 21 19:26:27.865: INFO: Got endpoints: latency-svc-9plxl [748.902632ms]
Aug 21 19:26:27.876: INFO: Created: latency-svc-tqsvb
Aug 21 19:26:27.918: INFO: Got endpoints: latency-svc-5vsx5 [752.568726ms]
Aug 21 19:26:27.929: INFO: Created: latency-svc-zz8tz
Aug 21 19:26:27.966: INFO: Got endpoints: latency-svc-gcbpp [749.073198ms]
Aug 21 19:26:27.976: INFO: Created: latency-svc-8zbrx
Aug 21 19:26:28.015: INFO: Got endpoints: latency-svc-hkfdp [749.71434ms]
Aug 21 19:26:28.033: INFO: Created: latency-svc-twtqf
Aug 21 19:26:28.066: INFO: Got endpoints: latency-svc-nbtb2 [749.699047ms]
Aug 21 19:26:28.076: INFO: Created: latency-svc-5bw2q
Aug 21 19:26:28.116: INFO: Got endpoints: latency-svc-lcz6t [749.910361ms]
Aug 21 19:26:28.132: INFO: Created: latency-svc-ffrpz
Aug 21 19:26:28.165: INFO: Got endpoints: latency-svc-wwxg5 [749.69775ms]
Aug 21 19:26:28.177: INFO: Created: latency-svc-cxx9k
Aug 21 19:26:28.216: INFO: Got endpoints: latency-svc-qsghh [751.26035ms]
Aug 21 19:26:28.229: INFO: Created: latency-svc-4nd2t
Aug 21 19:26:28.266: INFO: Got endpoints: latency-svc-2spbk [751.243273ms]
Aug 21 19:26:28.290: INFO: Created: latency-svc-ddtc8
Aug 21 19:26:28.317: INFO: Got endpoints: latency-svc-l94hk [751.950425ms]
Aug 21 19:26:28.329: INFO: Created: latency-svc-wg9hz
Aug 21 19:26:28.367: INFO: Got endpoints: latency-svc-qlxkg [751.55381ms]
Aug 21 19:26:28.378: INFO: Created: latency-svc-thkcj
Aug 21 19:26:28.414: INFO: Got endpoints: latency-svc-z2gb4 [749.778569ms]
Aug 21 19:26:28.427: INFO: Created: latency-svc-hfznd
Aug 21 19:26:28.467: INFO: Got endpoints: latency-svc-txdp5 [751.726753ms]
Aug 21 19:26:28.482: INFO: Created: latency-svc-s9zp2
Aug 21 19:26:28.516: INFO: Got endpoints: latency-svc-sbsjm [750.752776ms]
Aug 21 19:26:28.528: INFO: Created: latency-svc-lfwb7
Aug 21 19:26:28.565: INFO: Got endpoints: latency-svc-l7jwh [749.558046ms]
Aug 21 19:26:28.580: INFO: Created: latency-svc-s58fj
Aug 21 19:26:28.615: INFO: Got endpoints: latency-svc-tqsvb [749.551573ms]
Aug 21 19:26:28.625: INFO: Created: latency-svc-qldrx
Aug 21 19:26:28.665: INFO: Got endpoints: latency-svc-zz8tz [747.261056ms]
Aug 21 19:26:28.684: INFO: Created: latency-svc-swxdd
Aug 21 19:26:28.715: INFO: Got endpoints: latency-svc-8zbrx [749.171108ms]
Aug 21 19:26:28.724: INFO: Created: latency-svc-5stpj
Aug 21 19:26:28.767: INFO: Got endpoints: latency-svc-twtqf [752.058034ms]
Aug 21 19:26:28.790: INFO: Created: latency-svc-bmghc
Aug 21 19:26:28.816: INFO: Got endpoints: latency-svc-5bw2q [750.266058ms]
Aug 21 19:26:28.828: INFO: Created: latency-svc-tbf4f
Aug 21 19:26:28.866: INFO: Got endpoints: latency-svc-ffrpz [750.643137ms]
Aug 21 19:26:28.880: INFO: Created: latency-svc-l4ql6
Aug 21 19:26:28.916: INFO: Got endpoints: latency-svc-cxx9k [751.039339ms]
Aug 21 19:26:28.928: INFO: Created: latency-svc-mfmfj
Aug 21 19:26:28.965: INFO: Got endpoints: latency-svc-4nd2t [749.643221ms]
Aug 21 19:26:28.978: INFO: Created: latency-svc-9485q
Aug 21 19:26:29.015: INFO: Got endpoints: latency-svc-ddtc8 [748.913213ms]
Aug 21 19:26:29.027: INFO: Created: latency-svc-drpqz
Aug 21 19:26:29.065: INFO: Got endpoints: latency-svc-wg9hz [748.590779ms]
Aug 21 19:26:29.082: INFO: Created: latency-svc-pmhc6
Aug 21 19:26:29.115: INFO: Got endpoints: latency-svc-thkcj [748.097089ms]
Aug 21 19:26:29.125: INFO: Created: latency-svc-8n2wc
Aug 21 19:26:29.164: INFO: Got endpoints: latency-svc-hfznd [749.668309ms]
Aug 21 19:26:29.177: INFO: Created: latency-svc-2zkms
Aug 21 19:26:29.215: INFO: Got endpoints: latency-svc-s9zp2 [748.613697ms]
Aug 21 19:26:29.226: INFO: Created: latency-svc-npmcq
Aug 21 19:26:29.265: INFO: Got endpoints: latency-svc-lfwb7 [748.821165ms]
Aug 21 19:26:29.278: INFO: Created: latency-svc-l2nmj
Aug 21 19:26:29.315: INFO: Got endpoints: latency-svc-s58fj [750.095595ms]
Aug 21 19:26:29.327: INFO: Created: latency-svc-sfx9k
Aug 21 19:26:29.369: INFO: Got endpoints: latency-svc-qldrx [754.364024ms]
Aug 21 19:26:29.385: INFO: Created: latency-svc-9nl5f
Aug 21 19:26:29.414: INFO: Got endpoints: latency-svc-swxdd [749.123318ms]
Aug 21 19:26:29.429: INFO: Created: latency-svc-5mnts
Aug 21 19:26:29.464: INFO: Got endpoints: latency-svc-5stpj [749.079497ms]
Aug 21 19:26:29.476: INFO: Created: latency-svc-pb2zp
Aug 21 19:26:29.514: INFO: Got endpoints: latency-svc-bmghc [747.217835ms]
Aug 21 19:26:29.533: INFO: Created: latency-svc-ztvg9
Aug 21 19:26:29.564: INFO: Got endpoints: latency-svc-tbf4f [748.030045ms]
Aug 21 19:26:29.576: INFO: Created: latency-svc-dmc2t
Aug 21 19:26:29.617: INFO: Got endpoints: latency-svc-l4ql6 [750.307656ms]
Aug 21 19:26:29.629: INFO: Created: latency-svc-2qnj7
Aug 21 19:26:29.665: INFO: Got endpoints: latency-svc-mfmfj [749.359827ms]
Aug 21 19:26:29.682: INFO: Created: latency-svc-5mbm5
Aug 21 19:26:29.715: INFO: Got endpoints: latency-svc-9485q [749.644417ms]
Aug 21 19:26:29.728: INFO: Created: latency-svc-fn48h
Aug 21 19:26:29.765: INFO: Got endpoints: latency-svc-drpqz [749.938516ms]
Aug 21 19:26:29.778: INFO: Created: latency-svc-2b7z2
Aug 21 19:26:29.816: INFO: Got endpoints: latency-svc-pmhc6 [749.534159ms]
Aug 21 19:26:29.827: INFO: Created: latency-svc-d5257
Aug 21 19:26:29.864: INFO: Got endpoints: latency-svc-8n2wc [749.175467ms]
Aug 21 19:26:29.876: INFO: Created: latency-svc-ktzf8
Aug 21 19:26:29.923: INFO: Got endpoints: latency-svc-2zkms [758.540522ms]
Aug 21 19:26:29.946: INFO: Created: latency-svc-mmgkw
Aug 21 19:26:29.965: INFO: Got endpoints: latency-svc-npmcq [749.387951ms]
Aug 21 19:26:29.974: INFO: Created: latency-svc-2clk6
Aug 21 19:26:30.015: INFO: Got endpoints: latency-svc-l2nmj [749.992381ms]
Aug 21 19:26:30.032: INFO: Created: latency-svc-5644k
Aug 21 19:26:30.065: INFO: Got endpoints: latency-svc-sfx9k [748.942485ms]
Aug 21 19:26:30.076: INFO: Created: latency-svc-5nvz9
Aug 21 19:26:30.115: INFO: Got endpoints: latency-svc-9nl5f [746.057679ms]
Aug 21 19:26:30.132: INFO: Created: latency-svc-zbbdp
Aug 21 19:26:30.165: INFO: Got endpoints: latency-svc-5mnts [750.223935ms]
Aug 21 19:26:30.176: INFO: Created: latency-svc-zqxs8
Aug 21 19:26:30.215: INFO: Got endpoints: latency-svc-pb2zp [751.181456ms]
Aug 21 19:26:30.232: INFO: Created: latency-svc-42fkc
Aug 21 19:26:30.267: INFO: Got endpoints: latency-svc-ztvg9 [752.436503ms]
Aug 21 19:26:30.278: INFO: Created: latency-svc-q4vnd
Aug 21 19:26:30.322: INFO: Got endpoints: latency-svc-dmc2t [757.535805ms]
Aug 21 19:26:30.333: INFO: Created: latency-svc-t6hn4
Aug 21 19:26:30.365: INFO: Got endpoints: latency-svc-2qnj7 [747.885841ms]
Aug 21 19:26:30.380: INFO: Created: latency-svc-d2lpt
Aug 21 19:26:30.422: INFO: Got endpoints: latency-svc-5mbm5 [756.279202ms]
Aug 21 19:26:30.477: INFO: Got endpoints: latency-svc-fn48h [762.010454ms]
Aug 21 19:26:30.478: INFO: Created: latency-svc-pbpz2
Aug 21 19:26:30.500: INFO: Created: latency-svc-k9hws
Aug 21 19:26:30.514: INFO: Got endpoints: latency-svc-2b7z2 [748.57622ms]
Aug 21 19:26:30.525: INFO: Created: latency-svc-4fbkv
Aug 21 19:26:30.566: INFO: Got endpoints: latency-svc-d5257 [750.130934ms]
Aug 21 19:26:30.582: INFO: Created: latency-svc-9nhvd
Aug 21 19:26:30.614: INFO: Got endpoints: latency-svc-ktzf8 [750.006942ms]
Aug 21 19:26:30.626: INFO: Created: latency-svc-2t9mw
Aug 21 19:26:30.666: INFO: Got endpoints: latency-svc-mmgkw [742.616107ms]
Aug 21 19:26:30.678: INFO: Created: latency-svc-8p6d8
Aug 21 19:26:30.714: INFO: Got endpoints: latency-svc-2clk6 [748.888097ms]
Aug 21 19:26:30.765: INFO: Got endpoints: latency-svc-5644k [749.736024ms]
Aug 21 19:26:30.815: INFO: Got endpoints: latency-svc-5nvz9 [750.83289ms]
Aug 21 19:26:30.866: INFO: Got endpoints: latency-svc-zbbdp [750.09559ms]
Aug 21 19:26:30.915: INFO: Got endpoints: latency-svc-zqxs8 [750.299717ms]
Aug 21 19:26:30.965: INFO: Got endpoints: latency-svc-42fkc [749.115159ms]
Aug 21 19:26:31.016: INFO: Got endpoints: latency-svc-q4vnd [748.570009ms]
Aug 21 19:26:31.065: INFO: Got endpoints: latency-svc-t6hn4 [743.301472ms]
Aug 21 19:26:31.115: INFO: Got endpoints: latency-svc-d2lpt [750.575019ms]
Aug 21 19:26:31.165: INFO: Got endpoints: latency-svc-pbpz2 [743.643311ms]
Aug 21 19:26:31.215: INFO: Got endpoints: latency-svc-k9hws [737.326337ms]
Aug 21 19:26:31.264: INFO: Got endpoints: latency-svc-4fbkv [750.468189ms]
Aug 21 19:26:31.316: INFO: Got endpoints: latency-svc-9nhvd [749.929025ms]
Aug 21 19:26:31.368: INFO: Got endpoints: latency-svc-2t9mw [753.416618ms]
Aug 21 19:26:31.415: INFO: Got endpoints: latency-svc-8p6d8 [749.340662ms]
Aug 21 19:26:31.415: INFO: Latencies: [16.030994ms 27.53449ms 40.890257ms 51.238633ms 57.994263ms 74.969538ms 81.643325ms 100.460059ms 108.701059ms 120.121489ms 126.003028ms 135.566109ms 149.708695ms 155.673926ms 156.547385ms 160.147143ms 160.752726ms 164.346468ms 165.233003ms 165.766819ms 165.835071ms 166.567884ms 166.598392ms 167.05ms 167.392994ms 168.706477ms 172.814834ms 174.806046ms 175.603904ms 176.109025ms 177.167628ms 177.878664ms 180.059952ms 183.811979ms 186.558492ms 189.352831ms 190.423988ms 191.901337ms 233.340553ms 273.977691ms 297.037441ms 343.850359ms 379.134961ms 410.591133ms 455.979284ms 489.876737ms 520.350009ms 563.757615ms 595.445085ms 636.095551ms 667.683793ms 711.231258ms 736.261623ms 737.326337ms 742.29651ms 742.616107ms 743.301472ms 743.643311ms 744.951931ms 745.064692ms 745.19574ms 745.303621ms 745.804411ms 746.057679ms 747.018048ms 747.20294ms 747.217835ms 747.261056ms 747.390581ms 747.570087ms 747.852797ms 747.885841ms 748.030045ms 748.097089ms 748.286977ms 748.570009ms 748.57622ms 748.590779ms 748.613697ms 748.647714ms 748.683681ms 748.765886ms 748.777937ms 748.787802ms 748.821165ms 748.829787ms 748.839212ms 748.888097ms 748.902632ms 748.913213ms 748.92943ms 748.942485ms 748.989673ms 749.006285ms 749.064008ms 749.073198ms 749.0769ms 749.079497ms 749.088831ms 749.115159ms 749.122782ms 749.123318ms 749.124319ms 749.171108ms 749.175467ms 749.205145ms 749.283763ms 749.340662ms 749.359827ms 749.387951ms 749.424677ms 749.44274ms 749.534159ms 749.542902ms 749.551573ms 749.558046ms 749.600819ms 749.601688ms 749.603221ms 749.641006ms 749.643221ms 749.644417ms 749.663146ms 749.668309ms 749.669544ms 749.69775ms 749.699047ms 749.71434ms 749.736024ms 749.778569ms 749.786519ms 749.815941ms 749.816297ms 749.844504ms 749.85481ms 749.87187ms 749.910361ms 749.929025ms 749.938516ms 749.992381ms 749.999869ms 750.006942ms 750.014597ms 750.021613ms 750.034355ms 750.045384ms 750.049083ms 750.09559ms 750.095595ms 750.109405ms 750.130934ms 750.223935ms 750.266058ms 750.299717ms 750.307656ms 750.35026ms 750.352542ms 750.440187ms 750.468189ms 750.575019ms 750.609378ms 750.643137ms 750.656011ms 750.660862ms 750.673392ms 750.705532ms 750.752776ms 750.83289ms 750.933854ms 751.013745ms 751.039339ms 751.051111ms 751.054024ms 751.106307ms 751.181456ms 751.243273ms 751.26035ms 751.427211ms 751.55381ms 751.560201ms 751.726753ms 751.784863ms 751.88023ms 751.950425ms 752.058034ms 752.157064ms 752.436503ms 752.568726ms 753.206886ms 753.416618ms 753.872933ms 753.928261ms 754.364024ms 754.71963ms 756.071083ms 756.160038ms 756.279202ms 757.535805ms 758.540522ms 762.010454ms]
Aug 21 19:26:31.415: INFO: 50 %ile: 749.122782ms
Aug 21 19:26:31.415: INFO: 90 %ile: 751.726753ms
Aug 21 19:26:31.415: INFO: 99 %ile: 758.540522ms
Aug 21 19:26:31.415: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:26:31.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6944" for this suite.
Aug 21 19:26:53.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:26:53.555: INFO: namespace svc-latency-6944 deletion completed in 22.13417229s

â€¢ [SLOW TEST:33.029 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:26:53.556: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:26:53.721: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652" in namespace "downward-api-8975" to be "success or failure"
Aug 21 19:26:53.728: INFO: Pod "downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.321175ms
Aug 21 19:26:55.733: INFO: Pod "downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011956477s
STEP: Saw pod success
Aug 21 19:26:55.734: INFO: Pod "downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:26:55.737: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:26:55.779: INFO: Waiting for pod downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:26:55.784: INFO: Pod downwardapi-volume-a1c34c6c-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:26:55.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8975" for this suite.
Aug 21 19:27:01.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:27:01.935: INFO: namespace downward-api-8975 deletion completed in 6.146026575s

â€¢ [SLOW TEST:8.379 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:27:01.938: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:27:02.104: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 21 19:27:07.110: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 19:27:07.111: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 21 19:27:09.117: INFO: Creating deployment "test-rollover-deployment"
Aug 21 19:27:09.130: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 21 19:27:11.140: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 21 19:27:11.150: INFO: Ensure that both replica sets have 1 created replica
Aug 21 19:27:11.157: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 21 19:27:11.170: INFO: Updating deployment test-rollover-deployment
Aug 21 19:27:11.171: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 21 19:27:13.197: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 21 19:27:13.210: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 21 19:27:13.217: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 19:27:13.218: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:15.231: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 19:27:15.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:17.234: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 19:27:17.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:19.227: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 19:27:19.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:21.229: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 19:27:21.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:23.232: INFO:
Aug 21 19:27:23.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012433, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702012429, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 19:27:25.229: INFO:
Aug 21 19:27:25.230: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 19:27:25.245: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-5146,SelfLink:/apis/apps/v1/namespaces/deployment-5146/deployments/test-rollover-deployment,UID:aaf35ade-c449-11e9-b964-005056a55cb1,ResourceVersion:130227,Generation:2,CreationTimestamp:2019-08-21 19:27:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-21 19:27:09 +0000 UTC 2019-08-21 19:27:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-21 19:27:23 +0000 UTC 2019-08-21 19:27:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 21 19:27:25.249: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-5146,SelfLink:/apis/apps/v1/namespaces/deployment-5146/replicasets/test-rollover-deployment-659c699649,UID:ac2b6ae5-c449-11e9-8bc3-005056a5e556,ResourceVersion:130216,Generation:2,CreationTimestamp:2019-08-21 19:27:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aaf35ade-c449-11e9-b964-005056a55cb1 0xc002d6ece7 0xc002d6ece8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 19:27:25.250: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 21 19:27:25.251: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-5146,SelfLink:/apis/apps/v1/namespaces/deployment-5146/replicasets/test-rollover-controller,UID:a6c38019-c449-11e9-b964-005056a55cb1,ResourceVersion:130225,Generation:2,CreationTimestamp:2019-08-21 19:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aaf35ade-c449-11e9-b964-005056a55cb1 0xc002d6ec17 0xc002d6ec18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 19:27:25.252: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-5146,SelfLink:/apis/apps/v1/namespaces/deployment-5146/replicasets/test-rollover-deployment-7b45b6464,UID:aaf54522-c449-11e9-8bc3-005056a5e556,ResourceVersion:130183,Generation:2,CreationTimestamp:2019-08-21 19:27:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aaf35ade-c449-11e9-b964-005056a55cb1 0xc002d6edb0 0xc002d6edb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 19:27:25.258: INFO: Pod "test-rollover-deployment-659c699649-kswgq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-kswgq,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-5146,SelfLink:/api/v1/namespaces/deployment-5146/pods/test-rollover-deployment-659c699649-kswgq,UID:ac346ca1-c449-11e9-8bc3-005056a5e556,ResourceVersion:130197,Generation:0,CreationTimestamp:2019-08-21 19:27:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 ac2b6ae5-c449-11e9-8bc3-005056a5e556 0xc0029283a7 0xc0029283a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hzzss {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hzzss,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hzzss true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002928420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002928440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:27:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:27:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:27:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:27:11 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.146,StartTime:2019-08-21 19:27:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-21 19:27:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4eb9a9b34673ac556d9470bd6e0f831f64843aa164d2278bf7837d46b0088649}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:27:25.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5146" for this suite.
Aug 21 19:27:31.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:27:31.406: INFO: namespace deployment-5146 deletion completed in 6.140820192s

â€¢ [SLOW TEST:29.469 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:27:31.409: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-6047
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6047 to expose endpoints map[]
Aug 21 19:27:31.599: INFO: successfully validated that service endpoint-test2 in namespace services-6047 exposes endpoints map[] (3.264905ms elapsed)
STEP: Creating pod pod1 in namespace services-6047
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6047 to expose endpoints map[pod1:[80]]
Aug 21 19:27:33.641: INFO: successfully validated that service endpoint-test2 in namespace services-6047 exposes endpoints map[pod1:[80]] (2.030469028s elapsed)
STEP: Creating pod pod2 in namespace services-6047
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6047 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 21 19:27:35.706: INFO: successfully validated that service endpoint-test2 in namespace services-6047 exposes endpoints map[pod1:[80] pod2:[80]] (2.057435054s elapsed)
STEP: Deleting pod pod1 in namespace services-6047
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6047 to expose endpoints map[pod2:[80]]
Aug 21 19:27:36.734: INFO: successfully validated that service endpoint-test2 in namespace services-6047 exposes endpoints map[pod2:[80]] (1.017931288s elapsed)
STEP: Deleting pod pod2 in namespace services-6047
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6047 to expose endpoints map[]
Aug 21 19:27:36.756: INFO: successfully validated that service endpoint-test2 in namespace services-6047 exposes endpoints map[] (9.410303ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:27:36.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6047" for this suite.
Aug 21 19:27:58.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:27:58.938: INFO: namespace services-6047 deletion completed in 22.148230144s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:27.529 seconds]
[sig-network] Services
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:27:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c8bd153c-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 19:27:59.115: INFO: Waiting up to 5m0s for pod "pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652" in namespace "secrets-6121" to be "success or failure"
Aug 21 19:27:59.126: INFO: Pod "pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 10.878903ms
Aug 21 19:28:01.134: INFO: Pod "pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018609495s
STEP: Saw pod success
Aug 21 19:28:01.134: INFO: Pod "pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:28:01.138: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 19:28:01.197: INFO: Waiting for pod pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:28:01.201: INFO: Pod pod-secrets-c8bde80d-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:01.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6121" for this suite.
Aug 21 19:28:07.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:07.355: INFO: namespace secrets-6121 deletion completed in 6.148135246s

â€¢ [SLOW TEST:8.415 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:07.356: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-cdc13eec-c449-11e9-8a5f-26f602588652
STEP: Creating secret with name secret-projected-all-test-volume-cdc13ed6-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 21 19:28:07.540: INFO: Waiting up to 5m0s for pod "projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652" in namespace "projected-5286" to be "success or failure"
Aug 21 19:28:07.545: INFO: Pod "projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.380868ms
Aug 21 19:28:09.551: INFO: Pod "projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011711192s
STEP: Saw pod success
Aug 21 19:28:09.552: INFO: Pod "projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:28:09.556: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 21 19:28:09.588: INFO: Waiting for pod projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:28:09.591: INFO: Pod projected-volume-cdc13dda-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:09.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5286" for this suite.
Aug 21 19:28:15.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:15.738: INFO: namespace projected-5286 deletion completed in 6.140060661s

â€¢ [SLOW TEST:8.383 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:15.739: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:28:15.908: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652" in namespace "projected-5394" to be "success or failure"
Aug 21 19:28:15.914: INFO: Pod "downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.330968ms
Aug 21 19:28:17.920: INFO: Pod "downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01170919s
STEP: Saw pod success
Aug 21 19:28:17.920: INFO: Pod "downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:28:17.924: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:28:17.957: INFO: Waiting for pod downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:28:17.960: INFO: Pod downwardapi-volume-d2bfd835-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:17.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5394" for this suite.
Aug 21 19:28:23.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:24.119: INFO: namespace projected-5394 deletion completed in 6.149701792s

â€¢ [SLOW TEST:8.381 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:24.132: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-d7c14a10-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:28:24.318: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652" in namespace "projected-3169" to be "success or failure"
Aug 21 19:28:24.327: INFO: Pod "pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.6404ms
Aug 21 19:28:26.334: INFO: Pod "pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016232057s
STEP: Saw pod success
Aug 21 19:28:26.334: INFO: Pod "pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:28:26.338: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:28:26.370: INFO: Waiting for pod pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:28:26.375: INFO: Pod pod-projected-configmaps-d7c2d906-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:26.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3169" for this suite.
Aug 21 19:28:32.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:32.541: INFO: namespace projected-3169 deletion completed in 6.159456452s

â€¢ [SLOW TEST:8.409 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:32.544: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:32.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1166" for this suite.
Aug 21 19:28:38.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:38.855: INFO: namespace services-1166 deletion completed in 6.143771192s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:6.312 seconds]
[sig-network] Services
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:38.857: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-e08763de-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 19:28:39.031: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652" in namespace "projected-9915" to be "success or failure"
Aug 21 19:28:39.044: INFO: Pod "pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 12.74158ms
Aug 21 19:28:41.051: INFO: Pod "pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019403411s
STEP: Saw pod success
Aug 21 19:28:41.051: INFO: Pod "pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:28:41.055: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 19:28:41.088: INFO: Waiting for pod pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:28:41.092: INFO: Pod pod-projected-secrets-e0888307-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:41.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9915" for this suite.
Aug 21 19:28:47.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:47.244: INFO: namespace projected-9915 deletion completed in 6.146050744s

â€¢ [SLOW TEST:8.388 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:47.250: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 19:28:47.407: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 19:28:47.422: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 19:28:47.427: INFO:
Logging pods the kubelet thinks is on node 978c34ce-e296-4689-bf73-826c8c556b20 before test
Aug 21 19:28:47.437: INFO: coredns-95489c5c9-8llvk from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:28:47.437: INFO: event-controller-646d78b9b8-tjz2b from pks-system started at 2019-08-21 02:16:05 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container event-controller ready: true, restart count 0
Aug 21 19:28:47.437: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:28:47.437: INFO: node-exporter-78dpq from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:28:47.437: INFO: telegraf-l2x6l from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:28:47.437: INFO: telemetry-agent-858446f4ff-m2sfm from pks-system started at 2019-08-21 02:21:02 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container fluent-bit-billing ready: true, restart count 0
Aug 21 19:28:47.437: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Aug 21 19:28:47.437: INFO: fluent-bit-jxvvq from pks-system started at 2019-08-21 02:16:18 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:28:47.437: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:28:47.437: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 19:21:12 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 21 19:28:47.437: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-xlph9 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:28:47.437: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:28:47.437: INFO: metrics-server-867b8fdb7d-j7dsn from kube-system started at 2019-08-21 02:15:55 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.437: INFO: 	Container metrics-server ready: true, restart count 0
Aug 21 19:28:47.437: INFO:
Logging pods the kubelet thinks is on node ca867801-09fc-419b-a2c1-ae5752feb0ff before test
Aug 21 19:28:47.450: INFO: coredns-95489c5c9-tc97f from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:28:47.450: INFO: wavefront-collector-848b9948f-6mgdc from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container wavefront-collector ready: true, restart count 0
Aug 21 19:28:47.450: INFO: node-exporter-dsw5w from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:28:47.450: INFO: validator-6b677f49d4-dsk52 from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container validator ready: true, restart count 0
Aug 21 19:28:47.450: INFO: kube-state-metrics-85bfc8cb86-hvpcs from pks-system started at 2019-08-21 02:18:27 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container addon-resizer ready: true, restart count 0
Aug 21 19:28:47.450: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 21 19:28:47.450: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-s8kz2 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:28:47.450: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:28:47.450: INFO: kubernetes-dashboard-558689fc66-dl7vk from kube-system started at 2019-08-21 02:15:58 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 21 19:28:47.450: INFO: cert-generator-dea87263fc8e6d3a2a122f5f5e31b36afbeef369-xgx5b from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container cert-generator ready: false, restart count 0
Aug 21 19:28:47.450: INFO: telegraf-z8mgq from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:28:47.450: INFO: sonobuoy-e2e-job-b0f9cb20d3e8417a from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.450: INFO: 	Container e2e ready: true, restart count 0
Aug 21 19:28:47.450: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:28:47.450: INFO: sink-controller-6774fd95f7-4xc2v from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.451: INFO: 	Container sink-controller ready: true, restart count 0
Aug 21 19:28:47.451: INFO: fluent-bit-9hsw7 from pks-system started at 2019-08-21 02:16:08 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.451: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:28:47.451: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:28:47.451: INFO:
Logging pods the kubelet thinks is on node f138d081-7db1-41cb-9804-f6d51b22765f before test
Aug 21 19:28:47.463: INFO: coredns-95489c5c9-xrmnx from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container coredns ready: true, restart count 0
Aug 21 19:28:47.463: INFO: metric-controller-c998cb5bf-zl4n7 from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container metric-controller ready: true, restart count 0
Aug 21 19:28:47.463: INFO: fluent-bit-bnmmv from pks-system started at 2019-08-21 02:16:12 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 19:28:47.463: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 19:28:47.463: INFO: wavefront-proxy-785c6f5c95-km2rx from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container wavefront-proxy ready: true, restart count 0
Aug 21 19:28:47.463: INFO: node-exporter-zx8fm from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 19:28:47.463: INFO: telegraf-v5jgb from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 19:28:47.463: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-lwcqg from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 19:28:47.463: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 19:28:47.463: INFO: observability-manager-6fff4d8d86-szpsb from pks-system started at 2019-08-21 02:16:01 +0000 UTC (1 container statuses recorded)
Aug 21 19:28:47.463: INFO: 	Container observability-manager ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 978c34ce-e296-4689-bf73-826c8c556b20
STEP: verifying the node has the label node ca867801-09fc-419b-a2c1-ae5752feb0ff
STEP: verifying the node has the label node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.542: INFO: Pod sonobuoy requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.542: INFO: Pod sonobuoy-e2e-job-b0f9cb20d3e8417a requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.542: INFO: Pod sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-lwcqg requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.542: INFO: Pod sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-s8kz2 requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.543: INFO: Pod sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-xlph9 requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.543: INFO: Pod coredns-95489c5c9-8llvk requesting resource cpu=100m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.543: INFO: Pod coredns-95489c5c9-tc97f requesting resource cpu=100m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.543: INFO: Pod coredns-95489c5c9-xrmnx requesting resource cpu=100m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.543: INFO: Pod kubernetes-dashboard-558689fc66-dl7vk requesting resource cpu=50m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.544: INFO: Pod metrics-server-867b8fdb7d-j7dsn requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.544: INFO: Pod event-controller-646d78b9b8-tjz2b requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.544: INFO: Pod fluent-bit-9hsw7 requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.544: INFO: Pod fluent-bit-bnmmv requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.544: INFO: Pod fluent-bit-jxvvq requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.545: INFO: Pod kube-state-metrics-85bfc8cb86-hvpcs requesting resource cpu=203m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.545: INFO: Pod metric-controller-c998cb5bf-zl4n7 requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.545: INFO: Pod node-exporter-78dpq requesting resource cpu=10m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.545: INFO: Pod node-exporter-dsw5w requesting resource cpu=10m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.545: INFO: Pod node-exporter-zx8fm requesting resource cpu=10m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.545: INFO: Pod observability-manager-6fff4d8d86-szpsb requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.546: INFO: Pod sink-controller-6774fd95f7-4xc2v requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.546: INFO: Pod telegraf-l2x6l requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.546: INFO: Pod telegraf-v5jgb requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
Aug 21 19:28:47.546: INFO: Pod telegraf-z8mgq requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.546: INFO: Pod telemetry-agent-858446f4ff-m2sfm requesting resource cpu=0m on Node 978c34ce-e296-4689-bf73-826c8c556b20
Aug 21 19:28:47.546: INFO: Pod validator-6b677f49d4-dsk52 requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.547: INFO: Pod wavefront-collector-848b9948f-6mgdc requesting resource cpu=0m on Node ca867801-09fc-419b-a2c1-ae5752feb0ff
Aug 21 19:28:47.547: INFO: Pod wavefront-proxy-785c6f5c95-km2rx requesting resource cpu=0m on Node f138d081-7db1-41cb-9804-f6d51b22765f
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652.15bd06ce146fa12d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7540/filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652 to 978c34ce-e296-4689-bf73-826c8c556b20]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652.15bd06ce5033f9b7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652.15bd06ce5385831b], Reason = [Created], Message = [Created container filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652.15bd06ce5da70786], Reason = [Started], Message = [Started container filler-pod-e59d8c67-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652.15bd06ce157d3c8d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7540/filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652 to ca867801-09fc-419b-a2c1-ae5752feb0ff]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652.15bd06ce4da64f7b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652.15bd06ce5182cff4], Reason = [Created], Message = [Created container filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652.15bd06ce5d087728], Reason = [Started], Message = [Started container filler-pod-e59fe6db-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652.15bd06ce177ba798], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7540/filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652 to f138d081-7db1-41cb-9804-f6d51b22765f]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652.15bd06ce50b20e71], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652.15bd06ce55266e6b], Reason = [Created], Message = [Created container filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Normal], Name = [filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652.15bd06ce649ce4d9], Reason = [Started], Message = [Started container filler-pod-e5a2c657-c449-11e9-8a5f-26f602588652]
STEP: Considering event:
Type = [Warning], Name = [additional-pod.15bd06cf07fb9ebe], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node f138d081-7db1-41cb-9804-f6d51b22765f
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 978c34ce-e296-4689-bf73-826c8c556b20
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ca867801-09fc-419b-a2c1-ae5752feb0ff
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:28:52.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7540" for this suite.
Aug 21 19:28:58.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:28:58.875: INFO: namespace sched-pred-7540 deletion completed in 6.140144284s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.626 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:28:58.876: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-567/secret-test-ec77588f-c449-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 19:28:59.057: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652" in namespace "secrets-567" to be "success or failure"
Aug 21 19:28:59.064: INFO: Pod "pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.41878ms
Aug 21 19:29:01.069: INFO: Pod "pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012295265s
STEP: Saw pod success
Aug 21 19:29:01.069: INFO: Pod "pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:29:01.073: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652 container env-test: <nil>
STEP: delete the pod
Aug 21 19:29:01.103: INFO: Waiting for pod pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652 to disappear
Aug 21 19:29:01.106: INFO: Pod pod-configmaps-ec78488f-c449-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:29:01.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-567" for this suite.
Aug 21 19:29:07.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:29:07.262: INFO: namespace secrets-567 deletion completed in 6.152119953s

â€¢ [SLOW TEST:8.386 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:29:07.264: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1947
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:29:07.436: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 21 19:29:12.443: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 19:29:12.443: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 19:29:12.474: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-1947,SelfLink:/apis/apps/v1/namespaces/deployment-1947/deployments/test-cleanup-deployment,UID:f476475a-c449-11e9-b964-005056a55cb1,ResourceVersion:130763,Generation:1,CreationTimestamp:2019-08-21 19:29:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Aug 21 19:29:12.488: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-1947,SelfLink:/apis/apps/v1/namespaces/deployment-1947/replicasets/test-cleanup-deployment-6865c98b76,UID:f4785831-c449-11e9-8bc3-005056a5e556,ResourceVersion:130765,Generation:1,CreationTimestamp:2019-08-21 19:29:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f476475a-c449-11e9-b964-005056a55cb1 0xc00366cf67 0xc00366cf68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 19:29:12.488: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 21 19:29:12.489: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-1947,SelfLink:/apis/apps/v1/namespaces/deployment-1947/replicasets/test-cleanup-controller,UID:f1779f2e-c449-11e9-b964-005056a55cb1,ResourceVersion:130764,Generation:1,CreationTimestamp:2019-08-21 19:29:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f476475a-c449-11e9-b964-005056a55cb1 0xc00366ce97 0xc00366ce98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 19:29:12.505: INFO: Pod "test-cleanup-controller-2n8fv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-2n8fv,GenerateName:test-cleanup-controller-,Namespace:deployment-1947,SelfLink:/api/v1/namespaces/deployment-1947/pods/test-cleanup-controller-2n8fv,UID:f17874bf-c449-11e9-8bc3-005056a5e556,ResourceVersion:130759,Generation:0,CreationTimestamp:2019-08-21 19:29:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller f1779f2e-c449-11e9-b964-005056a55cb1 0xc00366d937 0xc00366d938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4gnnj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4gnnj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4gnnj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00366d9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00366d9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:29:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:29:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:29:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:29:07 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.43,StartTime:2019-08-21 19:29:07 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:29:08 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8246cac93e68480f2655d3b6adb1107f1b061078552851468267f6b15b54ff12}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:29:12.505: INFO: Pod "test-cleanup-deployment-6865c98b76-sfdqj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-sfdqj,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-1947,SelfLink:/api/v1/namespaces/deployment-1947/pods/test-cleanup-deployment-6865c98b76-sfdqj,UID:f47a2f50-c449-11e9-8bc3-005056a5e556,ResourceVersion:130768,Generation:0,CreationTimestamp:2019-08-21 19:29:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 f4785831-c449-11e9-8bc3-005056a5e556 0xc00366da97 0xc00366da98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4gnnj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4gnnj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4gnnj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00366db00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00366db20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:29:12.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1947" for this suite.
Aug 21 19:29:18.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:29:18.692: INFO: namespace deployment-1947 deletion completed in 6.165918583s

â€¢ [SLOW TEST:11.429 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:29:18.695: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7433
Aug 21 19:29:20.871: INFO: Started pod liveness-http in namespace container-probe-7433
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 19:29:20.876: INFO: Initial restart count of pod liveness-http is 0
Aug 21 19:29:40.949: INFO: Restart count of pod container-probe-7433/liveness-http is now 1 (20.072862504s elapsed)
Aug 21 19:30:01.012: INFO: Restart count of pod container-probe-7433/liveness-http is now 2 (40.135807277s elapsed)
Aug 21 19:30:21.093: INFO: Restart count of pod container-probe-7433/liveness-http is now 3 (1m0.216385293s elapsed)
Aug 21 19:30:41.158: INFO: Restart count of pod container-probe-7433/liveness-http is now 4 (1m20.281406217s elapsed)
Aug 21 19:31:51.406: INFO: Restart count of pod container-probe-7433/liveness-http is now 5 (2m30.529669118s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:31:51.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7433" for this suite.
Aug 21 19:31:57.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:31:57.603: INFO: namespace container-probe-7433 deletion completed in 6.171649483s

â€¢ [SLOW TEST:158.908 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:31:57.604: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 19:31:57.819: INFO: Number of nodes with available pods: 0
Aug 21 19:31:57.819: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:31:58.833: INFO: Number of nodes with available pods: 0
Aug 21 19:31:58.833: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:31:59.831: INFO: Number of nodes with available pods: 1
Aug 21 19:31:59.831: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:32:00.831: INFO: Number of nodes with available pods: 3
Aug 21 19:32:00.831: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 21 19:32:00.866: INFO: Number of nodes with available pods: 2
Aug 21 19:32:00.866: INFO: Node ca867801-09fc-419b-a2c1-ae5752feb0ff is running more than one daemon pod
Aug 21 19:32:01.876: INFO: Number of nodes with available pods: 2
Aug 21 19:32:01.876: INFO: Node ca867801-09fc-419b-a2c1-ae5752feb0ff is running more than one daemon pod
Aug 21 19:32:02.879: INFO: Number of nodes with available pods: 3
Aug 21 19:32:02.879: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4406, will wait for the garbage collector to delete the pods
Aug 21 19:32:02.955: INFO: Deleting DaemonSet.extensions daemon-set took: 12.70998ms
Aug 21 19:32:03.355: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.3918ms
Aug 21 19:32:15.462: INFO: Number of nodes with available pods: 0
Aug 21 19:32:15.462: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 19:32:15.466: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4406/daemonsets","resourceVersion":"131240"},"items":null}

Aug 21 19:32:15.469: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4406/pods","resourceVersion":"131240"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:32:15.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4406" for this suite.
Aug 21 19:32:21.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:32:21.643: INFO: namespace daemonsets-4406 deletion completed in 6.148064457s

â€¢ [SLOW TEST:24.039 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:32:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 21 19:32:24.358: INFO: Successfully updated pod "annotationupdate65518dc4-c44a-11e9-8a5f-26f602588652"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:32:26.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2421" for this suite.
Aug 21 19:32:48.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:32:48.585: INFO: namespace projected-2421 deletion completed in 22.192323331s

â€¢ [SLOW TEST:26.941 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:32:48.588: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jdp2l in namespace proxy-1913
I0821 19:32:48.788710      18 runners.go:184] Created replication controller with name: proxy-service-jdp2l, namespace: proxy-1913, replica count: 1
I0821 19:32:49.840602      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0821 19:32:50.841157      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:51.842105      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:52.842581      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:53.843367      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:54.843679      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:55.844373      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady
I0821 19:32:56.844796      18 runners.go:184] proxy-service-jdp2l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
Aug 21 19:32:56.850: INFO: setup took 8.092512202s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 21 19:32:56.859: INFO: (0) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 8.791006ms)
Aug 21 19:32:56.861: INFO: (0) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.436676ms)
Aug 21 19:32:56.866: INFO: (0) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 14.33754ms)
Aug 21 19:32:56.870: INFO: (0) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 18.63899ms)
Aug 21 19:32:56.870: INFO: (0) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 18.078125ms)
Aug 21 19:32:56.871: INFO: (0) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 18.879583ms)
Aug 21 19:32:56.871: INFO: (0) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 19.055632ms)
Aug 21 19:32:56.872: INFO: (0) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 19.969779ms)
Aug 21 19:32:56.872: INFO: (0) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 20.059948ms)
Aug 21 19:32:56.875: INFO: (0) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 22.79054ms)
Aug 21 19:32:56.875: INFO: (0) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 24.181155ms)
Aug 21 19:32:56.876: INFO: (0) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 24.21854ms)
Aug 21 19:32:56.877: INFO: (0) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 26.084718ms)
Aug 21 19:32:56.878: INFO: (0) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 28.02813ms)
Aug 21 19:32:56.879: INFO: (0) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 27.132136ms)
Aug 21 19:32:56.879: INFO: (0) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 27.842119ms)
Aug 21 19:32:56.889: INFO: (1) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 8.629247ms)
Aug 21 19:32:56.891: INFO: (1) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 8.124537ms)
Aug 21 19:32:56.892: INFO: (1) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.996022ms)
Aug 21 19:32:56.892: INFO: (1) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 10.599236ms)
Aug 21 19:32:56.892: INFO: (1) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 11.079072ms)
Aug 21 19:32:56.894: INFO: (1) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 11.20621ms)
Aug 21 19:32:56.895: INFO: (1) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 12.01809ms)
Aug 21 19:32:56.897: INFO: (1) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 12.020055ms)
Aug 21 19:32:56.898: INFO: (1) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 14.329671ms)
Aug 21 19:32:56.898: INFO: (1) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 18.112146ms)
Aug 21 19:32:56.899: INFO: (1) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 16.079549ms)
Aug 21 19:32:56.900: INFO: (1) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 17.23477ms)
Aug 21 19:32:56.900: INFO: (1) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 17.04434ms)
Aug 21 19:32:56.900: INFO: (1) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 18.759083ms)
Aug 21 19:32:56.901: INFO: (1) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 18.077035ms)
Aug 21 19:32:56.906: INFO: (1) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 22.439272ms)
Aug 21 19:32:56.918: INFO: (2) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 12.398915ms)
Aug 21 19:32:56.920: INFO: (2) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 13.02957ms)
Aug 21 19:32:56.920: INFO: (2) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 13.630402ms)
Aug 21 19:32:56.924: INFO: (2) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 17.053767ms)
Aug 21 19:32:56.930: INFO: (2) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 22.053174ms)
Aug 21 19:32:56.930: INFO: (2) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 23.311781ms)
Aug 21 19:32:56.932: INFO: (2) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 24.428388ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 22.93261ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 25.784473ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 24.849246ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 23.79179ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 24.719803ms)
Aug 21 19:32:56.933: INFO: (2) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 24.517219ms)
Aug 21 19:32:56.934: INFO: (2) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 25.941474ms)
Aug 21 19:32:56.934: INFO: (2) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 24.980396ms)
Aug 21 19:32:56.935: INFO: (2) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 25.48979ms)
Aug 21 19:32:56.941: INFO: (3) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 5.931921ms)
Aug 21 19:32:56.945: INFO: (3) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 10.234761ms)
Aug 21 19:32:56.947: INFO: (3) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 11.925443ms)
Aug 21 19:32:56.948: INFO: (3) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 13.15208ms)
Aug 21 19:32:56.949: INFO: (3) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 13.688918ms)
Aug 21 19:32:56.949: INFO: (3) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 14.15221ms)
Aug 21 19:32:56.949: INFO: (3) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 13.922179ms)
Aug 21 19:32:56.950: INFO: (3) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 14.111146ms)
Aug 21 19:32:56.950: INFO: (3) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.136913ms)
Aug 21 19:32:56.951: INFO: (3) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 15.1671ms)
Aug 21 19:32:56.951: INFO: (3) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 15.288185ms)
Aug 21 19:32:56.951: INFO: (3) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.105421ms)
Aug 21 19:32:56.952: INFO: (3) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 16.370722ms)
Aug 21 19:32:56.952: INFO: (3) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 16.274855ms)
Aug 21 19:32:56.952: INFO: (3) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 16.800422ms)
Aug 21 19:32:56.952: INFO: (3) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 16.841972ms)
Aug 21 19:32:56.962: INFO: (4) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 8.606061ms)
Aug 21 19:32:56.962: INFO: (4) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 9.246246ms)
Aug 21 19:32:56.963: INFO: (4) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 9.945042ms)
Aug 21 19:32:56.963: INFO: (4) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 9.710026ms)
Aug 21 19:32:56.965: INFO: (4) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 11.655247ms)
Aug 21 19:32:56.966: INFO: (4) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 12.114678ms)
Aug 21 19:32:56.968: INFO: (4) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 14.534699ms)
Aug 21 19:32:56.968: INFO: (4) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.403119ms)
Aug 21 19:32:56.968: INFO: (4) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 15.456059ms)
Aug 21 19:32:56.968: INFO: (4) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 15.217824ms)
Aug 21 19:32:56.968: INFO: (4) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.789916ms)
Aug 21 19:32:56.969: INFO: (4) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 15.706243ms)
Aug 21 19:32:56.969: INFO: (4) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.21549ms)
Aug 21 19:32:56.971: INFO: (4) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 18.020706ms)
Aug 21 19:32:56.972: INFO: (4) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 18.426594ms)
Aug 21 19:32:56.976: INFO: (4) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 23.528279ms)
Aug 21 19:32:56.992: INFO: (5) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 14.896228ms)
Aug 21 19:32:56.996: INFO: (5) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 19.678128ms)
Aug 21 19:32:56.998: INFO: (5) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 21.01828ms)
Aug 21 19:32:57.003: INFO: (5) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 25.395136ms)
Aug 21 19:32:57.003: INFO: (5) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 26.056666ms)
Aug 21 19:32:57.003: INFO: (5) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 26.507361ms)
Aug 21 19:32:57.003: INFO: (5) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 26.480832ms)
Aug 21 19:32:57.004: INFO: (5) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 26.870079ms)
Aug 21 19:32:57.004: INFO: (5) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 26.651485ms)
Aug 21 19:32:57.004: INFO: (5) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 27.275934ms)
Aug 21 19:32:57.004: INFO: (5) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 26.968978ms)
Aug 21 19:32:57.004: INFO: (5) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 27.221865ms)
Aug 21 19:32:57.005: INFO: (5) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 27.675491ms)
Aug 21 19:32:57.005: INFO: (5) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 28.635982ms)
Aug 21 19:32:57.005: INFO: (5) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 27.750399ms)
Aug 21 19:32:57.005: INFO: (5) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 28.458313ms)
Aug 21 19:32:57.016: INFO: (6) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 8.201461ms)
Aug 21 19:32:57.017: INFO: (6) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 9.416746ms)
Aug 21 19:32:57.017: INFO: (6) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 10.237961ms)
Aug 21 19:32:57.018: INFO: (6) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 10.291889ms)
Aug 21 19:32:57.020: INFO: (6) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 12.19798ms)
Aug 21 19:32:57.024: INFO: (6) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 15.743869ms)
Aug 21 19:32:57.024: INFO: (6) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 16.660082ms)
Aug 21 19:32:57.026: INFO: (6) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 17.882593ms)
Aug 21 19:32:57.026: INFO: (6) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 18.264526ms)
Aug 21 19:32:57.028: INFO: (6) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 20.236347ms)
Aug 21 19:32:57.028: INFO: (6) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 20.593301ms)
Aug 21 19:32:57.030: INFO: (6) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 22.223816ms)
Aug 21 19:32:57.030: INFO: (6) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 22.47069ms)
Aug 21 19:32:57.031: INFO: (6) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 23.226656ms)
Aug 21 19:32:57.031: INFO: (6) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 23.163206ms)
Aug 21 19:32:57.030: INFO: (6) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 22.198759ms)
Aug 21 19:32:57.037: INFO: (7) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 5.237384ms)
Aug 21 19:32:57.038: INFO: (7) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 5.668323ms)
Aug 21 19:32:57.042: INFO: (7) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 9.366431ms)
Aug 21 19:32:57.044: INFO: (7) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 10.976202ms)
Aug 21 19:32:57.044: INFO: (7) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 10.133509ms)
Aug 21 19:32:57.045: INFO: (7) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 11.621855ms)
Aug 21 19:32:57.045: INFO: (7) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 11.837594ms)
Aug 21 19:32:57.046: INFO: (7) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 13.628277ms)
Aug 21 19:32:57.046: INFO: (7) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 13.251768ms)
Aug 21 19:32:57.047: INFO: (7) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 13.867599ms)
Aug 21 19:32:57.047: INFO: (7) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 15.318ms)
Aug 21 19:32:57.047: INFO: (7) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 13.626185ms)
Aug 21 19:32:57.047: INFO: (7) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 13.84584ms)
Aug 21 19:32:57.048: INFO: (7) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.17776ms)
Aug 21 19:32:57.048: INFO: (7) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 16.486251ms)
Aug 21 19:32:57.050: INFO: (7) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 16.496452ms)
Aug 21 19:32:57.058: INFO: (8) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 7.832309ms)
Aug 21 19:32:57.060: INFO: (8) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 9.434978ms)
Aug 21 19:32:57.061: INFO: (8) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.182697ms)
Aug 21 19:32:57.061: INFO: (8) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 10.191288ms)
Aug 21 19:32:57.064: INFO: (8) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 12.697138ms)
Aug 21 19:32:57.065: INFO: (8) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 14.203505ms)
Aug 21 19:32:57.066: INFO: (8) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 15.718794ms)
Aug 21 19:32:57.066: INFO: (8) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 14.297312ms)
Aug 21 19:32:57.066: INFO: (8) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 15.104992ms)
Aug 21 19:32:57.067: INFO: (8) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 15.044682ms)
Aug 21 19:32:57.068: INFO: (8) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 16.056609ms)
Aug 21 19:32:57.069: INFO: (8) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 17.364866ms)
Aug 21 19:32:57.069: INFO: (8) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 17.076115ms)
Aug 21 19:32:57.069: INFO: (8) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 17.950478ms)
Aug 21 19:32:57.070: INFO: (8) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 19.525646ms)
Aug 21 19:32:57.071: INFO: (8) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 20.071694ms)
Aug 21 19:32:57.077: INFO: (9) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 5.351439ms)
Aug 21 19:32:57.078: INFO: (9) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 6.396663ms)
Aug 21 19:32:57.083: INFO: (9) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 11.544012ms)
Aug 21 19:32:57.084: INFO: (9) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 12.087992ms)
Aug 21 19:32:57.084: INFO: (9) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 12.015992ms)
Aug 21 19:32:57.085: INFO: (9) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 13.405401ms)
Aug 21 19:32:57.087: INFO: (9) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 14.642379ms)
Aug 21 19:32:57.087: INFO: (9) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.630283ms)
Aug 21 19:32:57.087: INFO: (9) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 14.681974ms)
Aug 21 19:32:57.087: INFO: (9) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.794424ms)
Aug 21 19:32:57.087: INFO: (9) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 16.036853ms)
Aug 21 19:32:57.088: INFO: (9) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 15.412832ms)
Aug 21 19:32:57.088: INFO: (9) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 16.08103ms)
Aug 21 19:32:57.089: INFO: (9) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 16.844629ms)
Aug 21 19:32:57.089: INFO: (9) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 17.592447ms)
Aug 21 19:32:57.089: INFO: (9) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 18.040659ms)
Aug 21 19:32:57.094: INFO: (10) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 4.870565ms)
Aug 21 19:32:57.096: INFO: (10) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 5.985066ms)
Aug 21 19:32:57.097: INFO: (10) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 7.2675ms)
Aug 21 19:32:57.100: INFO: (10) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 9.737672ms)
Aug 21 19:32:57.100: INFO: (10) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 10.181794ms)
Aug 21 19:32:57.101: INFO: (10) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 10.695091ms)
Aug 21 19:32:57.101: INFO: (10) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.746264ms)
Aug 21 19:32:57.101: INFO: (10) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 10.984572ms)
Aug 21 19:32:57.103: INFO: (10) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 13.502518ms)
Aug 21 19:32:57.103: INFO: (10) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 13.493679ms)
Aug 21 19:32:57.104: INFO: (10) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 14.140105ms)
Aug 21 19:32:57.105: INFO: (10) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 14.964228ms)
Aug 21 19:32:57.105: INFO: (10) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.582059ms)
Aug 21 19:32:57.106: INFO: (10) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 15.494858ms)
Aug 21 19:32:57.106: INFO: (10) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 16.282743ms)
Aug 21 19:32:57.106: INFO: (10) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 16.392571ms)
Aug 21 19:32:57.113: INFO: (11) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 5.799928ms)
Aug 21 19:32:57.115: INFO: (11) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 7.229149ms)
Aug 21 19:32:57.116: INFO: (11) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 8.061171ms)
Aug 21 19:32:57.117: INFO: (11) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 7.408424ms)
Aug 21 19:32:57.117: INFO: (11) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 8.091198ms)
Aug 21 19:32:57.117: INFO: (11) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 8.602912ms)
Aug 21 19:32:57.121: INFO: (11) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 13.464867ms)
Aug 21 19:32:57.122: INFO: (11) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 14.03925ms)
Aug 21 19:32:57.122: INFO: (11) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 14.944937ms)
Aug 21 19:32:57.123: INFO: (11) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 12.631184ms)
Aug 21 19:32:57.124: INFO: (11) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 14.65458ms)
Aug 21 19:32:57.124: INFO: (11) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 14.737245ms)
Aug 21 19:32:57.125: INFO: (11) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 16.390783ms)
Aug 21 19:32:57.125: INFO: (11) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 14.710775ms)
Aug 21 19:32:57.125: INFO: (11) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.530423ms)
Aug 21 19:32:57.125: INFO: (11) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 15.602984ms)
Aug 21 19:32:57.136: INFO: (12) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 9.065781ms)
Aug 21 19:32:57.138: INFO: (12) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 11.675524ms)
Aug 21 19:32:57.139: INFO: (12) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 12.352264ms)
Aug 21 19:32:57.140: INFO: (12) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 12.563442ms)
Aug 21 19:32:57.143: INFO: (12) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 17.858145ms)
Aug 21 19:32:57.144: INFO: (12) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 16.614963ms)
Aug 21 19:32:57.146: INFO: (12) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 18.637109ms)
Aug 21 19:32:57.146: INFO: (12) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 19.887978ms)
Aug 21 19:32:57.146: INFO: (12) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 18.786681ms)
Aug 21 19:32:57.147: INFO: (12) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 19.052157ms)
Aug 21 19:32:57.147: INFO: (12) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 20.7632ms)
Aug 21 19:32:57.151: INFO: (12) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 24.946051ms)
Aug 21 19:32:57.151: INFO: (12) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 23.968914ms)
Aug 21 19:32:57.151: INFO: (12) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 24.321095ms)
Aug 21 19:32:57.151: INFO: (12) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 24.149968ms)
Aug 21 19:32:57.151: INFO: (12) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 23.812719ms)
Aug 21 19:32:57.159: INFO: (13) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 6.297856ms)
Aug 21 19:32:57.161: INFO: (13) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 7.897516ms)
Aug 21 19:32:57.162: INFO: (13) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 8.169275ms)
Aug 21 19:32:57.163: INFO: (13) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 9.823008ms)
Aug 21 19:32:57.163: INFO: (13) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 9.145776ms)
Aug 21 19:32:57.163: INFO: (13) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 8.813063ms)
Aug 21 19:32:57.165: INFO: (13) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.034095ms)
Aug 21 19:32:57.165: INFO: (13) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 9.870294ms)
Aug 21 19:32:57.165: INFO: (13) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 10.207297ms)
Aug 21 19:32:57.165: INFO: (13) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 10.866094ms)
Aug 21 19:32:57.167: INFO: (13) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 11.804298ms)
Aug 21 19:32:57.167: INFO: (13) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 12.540623ms)
Aug 21 19:32:57.168: INFO: (13) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 14.682083ms)
Aug 21 19:32:57.168: INFO: (13) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 13.902682ms)
Aug 21 19:32:57.168: INFO: (13) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 14.852977ms)
Aug 21 19:32:57.168: INFO: (13) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 13.624906ms)
Aug 21 19:32:57.176: INFO: (14) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 7.021112ms)
Aug 21 19:32:57.179: INFO: (14) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 10.033537ms)
Aug 21 19:32:57.180: INFO: (14) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 10.668301ms)
Aug 21 19:32:57.180: INFO: (14) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 11.434048ms)
Aug 21 19:32:57.181: INFO: (14) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 12.176994ms)
Aug 21 19:32:57.181: INFO: (14) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 12.056491ms)
Aug 21 19:32:57.182: INFO: (14) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 13.277139ms)
Aug 21 19:32:57.182: INFO: (14) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 13.523566ms)
Aug 21 19:32:57.183: INFO: (14) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 14.631146ms)
Aug 21 19:32:57.184: INFO: (14) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.054121ms)
Aug 21 19:32:57.184: INFO: (14) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 15.111408ms)
Aug 21 19:32:57.184: INFO: (14) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 15.12905ms)
Aug 21 19:32:57.184: INFO: (14) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.103478ms)
Aug 21 19:32:57.185: INFO: (14) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 15.981024ms)
Aug 21 19:32:57.185: INFO: (14) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 16.146881ms)
Aug 21 19:32:57.185: INFO: (14) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 16.046408ms)
Aug 21 19:32:57.191: INFO: (15) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 5.623802ms)
Aug 21 19:32:57.192: INFO: (15) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 5.820421ms)
Aug 21 19:32:57.192: INFO: (15) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 6.69548ms)
Aug 21 19:32:57.193: INFO: (15) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 7.496615ms)
Aug 21 19:32:57.202: INFO: (15) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 15.139631ms)
Aug 21 19:32:57.202: INFO: (15) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 15.934269ms)
Aug 21 19:32:57.202: INFO: (15) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 14.598425ms)
Aug 21 19:32:57.202: INFO: (15) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.123543ms)
Aug 21 19:32:57.202: INFO: (15) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 14.817527ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.46917ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 16.400553ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 16.559269ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 15.813135ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 16.223868ms)
Aug 21 19:32:57.203: INFO: (15) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 16.030774ms)
Aug 21 19:32:57.204: INFO: (15) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 17.29915ms)
Aug 21 19:32:57.212: INFO: (16) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 7.195288ms)
Aug 21 19:32:57.214: INFO: (16) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 8.03455ms)
Aug 21 19:32:57.215: INFO: (16) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 9.168951ms)
Aug 21 19:32:57.216: INFO: (16) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 11.99388ms)
Aug 21 19:32:57.216: INFO: (16) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 10.569974ms)
Aug 21 19:32:57.217: INFO: (16) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 12.318028ms)
Aug 21 19:32:57.217: INFO: (16) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 12.740095ms)
Aug 21 19:32:57.219: INFO: (16) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 14.017812ms)
Aug 21 19:32:57.220: INFO: (16) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 13.899561ms)
Aug 21 19:32:57.221: INFO: (16) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 14.758226ms)
Aug 21 19:32:57.222: INFO: (16) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 17.196926ms)
Aug 21 19:32:57.223: INFO: (16) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 16.657424ms)
Aug 21 19:32:57.223: INFO: (16) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 16.925684ms)
Aug 21 19:32:57.223: INFO: (16) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 17.008531ms)
Aug 21 19:32:57.223: INFO: (16) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 17.495536ms)
Aug 21 19:32:57.224: INFO: (16) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 17.486388ms)
Aug 21 19:32:57.231: INFO: (17) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 6.911257ms)
Aug 21 19:32:57.232: INFO: (17) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 7.569235ms)
Aug 21 19:32:57.233: INFO: (17) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 8.033103ms)
Aug 21 19:32:57.234: INFO: (17) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 9.805033ms)
Aug 21 19:32:57.234: INFO: (17) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 8.594125ms)
Aug 21 19:32:57.234: INFO: (17) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 9.90156ms)
Aug 21 19:32:57.236: INFO: (17) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 10.646504ms)
Aug 21 19:32:57.238: INFO: (17) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 13.030796ms)
Aug 21 19:32:57.239: INFO: (17) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 13.151946ms)
Aug 21 19:32:57.239: INFO: (17) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 14.33232ms)
Aug 21 19:32:57.240: INFO: (17) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 14.070518ms)
Aug 21 19:32:57.240: INFO: (17) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.64788ms)
Aug 21 19:32:57.240: INFO: (17) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.291687ms)
Aug 21 19:32:57.240: INFO: (17) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 16.356054ms)
Aug 21 19:32:57.240: INFO: (17) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 15.093391ms)
Aug 21 19:32:57.241: INFO: (17) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 15.920584ms)
Aug 21 19:32:57.250: INFO: (18) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 7.92578ms)
Aug 21 19:32:57.250: INFO: (18) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 9.217854ms)
Aug 21 19:32:57.251: INFO: (18) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 9.14282ms)
Aug 21 19:32:57.252: INFO: (18) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 9.338738ms)
Aug 21 19:32:57.253: INFO: (18) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 9.464575ms)
Aug 21 19:32:57.253: INFO: (18) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 10.005238ms)
Aug 21 19:32:57.254: INFO: (18) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 11.804288ms)
Aug 21 19:32:57.254: INFO: (18) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 11.028085ms)
Aug 21 19:32:57.256: INFO: (18) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 12.441452ms)
Aug 21 19:32:57.257: INFO: (18) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 13.172558ms)
Aug 21 19:32:57.258: INFO: (18) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 15.687911ms)
Aug 21 19:32:57.259: INFO: (18) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 15.306595ms)
Aug 21 19:32:57.259: INFO: (18) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 15.915308ms)
Aug 21 19:32:57.259: INFO: (18) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 15.145738ms)
Aug 21 19:32:57.259: INFO: (18) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 16.279292ms)
Aug 21 19:32:57.260: INFO: (18) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 17.937879ms)
Aug 21 19:32:57.267: INFO: (19) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">test<... (200; 6.227346ms)
Aug 21 19:32:57.268: INFO: (19) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:460/proxy/: tls baz (200; 7.196483ms)
Aug 21 19:32:57.268: INFO: (19) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:1080/proxy/rewriteme">... (200; 7.682967ms)
Aug 21 19:32:57.269: INFO: (19) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 7.802295ms)
Aug 21 19:32:57.275: INFO: (19) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname1/proxy/: foo (200; 13.121318ms)
Aug 21 19:32:57.275: INFO: (19) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:162/proxy/: bar (200; 14.299416ms)
Aug 21 19:32:57.275: INFO: (19) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:462/proxy/: tls qux (200; 12.844769ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/https:proxy-service-jdp2l-k5pzr:443/proxy/tlsrewritem... (200; 13.09335ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/pods/http:proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 13.523771ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/: <a href="/api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr/proxy/rewriteme">test</a> (200; 12.878842ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/services/proxy-service-jdp2l:portname2/proxy/: bar (200; 14.009318ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname1/proxy/: foo (200; 14.358771ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/services/http:proxy-service-jdp2l:portname2/proxy/: bar (200; 14.360999ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname1/proxy/: tls baz (200; 13.397546ms)
Aug 21 19:32:57.276: INFO: (19) /api/v1/namespaces/proxy-1913/services/https:proxy-service-jdp2l:tlsportname2/proxy/: tls qux (200; 13.447667ms)
Aug 21 19:32:57.278: INFO: (19) /api/v1/namespaces/proxy-1913/pods/proxy-service-jdp2l-k5pzr:160/proxy/: foo (200; 17.057712ms)
STEP: deleting ReplicationController proxy-service-jdp2l in namespace proxy-1913, will wait for the garbage collector to delete the pods
Aug 21 19:32:57.346: INFO: Deleting ReplicationController proxy-service-jdp2l took: 14.036669ms
Aug 21 19:32:57.746: INFO: Terminating ReplicationController proxy-service-jdp2l pods took: 400.397598ms
[AfterEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:33:08.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1913" for this suite.
Aug 21 19:33:14.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:33:14.306: INFO: namespace proxy-1913 deletion completed in 6.15282893s

â€¢ [SLOW TEST:25.719 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:33:14.307: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1752
Aug 21 19:33:16.511: INFO: Started pod liveness-http in namespace container-probe-1752
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 19:33:16.516: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:37:17.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1752" for this suite.
Aug 21 19:37:23.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:37:23.472: INFO: namespace container-probe-1752 deletion completed in 6.147674047s

â€¢ [SLOW TEST:249.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:37:23.474: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 21 19:37:26.183: INFO: Successfully updated pod "pod-update-1939b04d-c44b-11e9-8a5f-26f602588652"
STEP: verifying the updated pod is in kubernetes
Aug 21 19:37:26.191: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:37:26.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1982" for this suite.
Aug 21 19:37:48.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:37:48.347: INFO: namespace pods-1982 deletion completed in 22.150132928s

â€¢ [SLOW TEST:24.873 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:37:48.353: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0821 19:37:58.624669      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 19:37:58.624: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:37:58.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3142" for this suite.
Aug 21 19:38:04.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:38:04.763: INFO: namespace gc-3142 deletion completed in 6.134436963s

â€¢ [SLOW TEST:16.410 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:38:04.770: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6020
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 21 19:38:04.936: INFO: Waiting up to 5m0s for pod "pod-31d6f0d2-c44b-11e9-8a5f-26f602588652" in namespace "emptydir-6020" to be "success or failure"
Aug 21 19:38:04.943: INFO: Pod "pod-31d6f0d2-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024912ms
Aug 21 19:38:06.948: INFO: Pod "pod-31d6f0d2-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011355871s
Aug 21 19:38:08.956: INFO: Pod "pod-31d6f0d2-c44b-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019756439s
STEP: Saw pod success
Aug 21 19:38:08.958: INFO: Pod "pod-31d6f0d2-c44b-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:38:08.963: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-31d6f0d2-c44b-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:38:08.997: INFO: Waiting for pod pod-31d6f0d2-c44b-11e9-8a5f-26f602588652 to disappear
Aug 21 19:38:09.002: INFO: Pod pod-31d6f0d2-c44b-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:38:09.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6020" for this suite.
Aug 21 19:38:15.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:38:15.165: INFO: namespace emptydir-6020 deletion completed in 6.158195025s

â€¢ [SLOW TEST:10.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:38:15.174: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-900
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 21 19:38:15.355: INFO: Waiting up to 5m0s for pod "pod-380c648b-c44b-11e9-8a5f-26f602588652" in namespace "emptydir-900" to be "success or failure"
Aug 21 19:38:15.364: INFO: Pod "pod-380c648b-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.338379ms
Aug 21 19:38:17.371: INFO: Pod "pod-380c648b-c44b-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016126821s
STEP: Saw pod success
Aug 21 19:38:17.371: INFO: Pod "pod-380c648b-c44b-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:38:17.376: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-380c648b-c44b-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:38:17.411: INFO: Waiting for pod pod-380c648b-c44b-11e9-8a5f-26f602588652 to disappear
Aug 21 19:38:17.416: INFO: Pod pod-380c648b-c44b-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:38:17.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-900" for this suite.
Aug 21 19:38:23.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:38:23.563: INFO: namespace emptydir-900 deletion completed in 6.142038922s

â€¢ [SLOW TEST:8.389 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:38:23.566: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Aug 21 19:38:23.735: INFO: Waiting up to 5m0s for pod "var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652" in namespace "var-expansion-1316" to be "success or failure"
Aug 21 19:38:23.743: INFO: Pod "var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.123552ms
Aug 21 19:38:25.749: INFO: Pod "var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014413749s
STEP: Saw pod success
Aug 21 19:38:25.749: INFO: Pod "var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:38:25.753: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 19:38:25.783: INFO: Waiting for pod var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652 to disappear
Aug 21 19:38:25.786: INFO: Pod var-expansion-3d0af5c9-c44b-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:38:25.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1316" for this suite.
Aug 21 19:38:31.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:38:31.942: INFO: namespace var-expansion-1316 deletion completed in 6.150715882s

â€¢ [SLOW TEST:8.376 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:38:31.942: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0821 19:38:32.739218      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 19:38:32.739: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:38:32.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2030" for this suite.
Aug 21 19:38:38.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:38:38.889: INFO: namespace gc-2030 deletion completed in 6.144614603s

â€¢ [SLOW TEST:6.948 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:38:38.892: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 21 19:38:43.086: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-462d7f9e-c44b-11e9-8a5f-26f602588652,GenerateName:,Namespace:events-190,SelfLink:/api/v1/namespaces/events-190/pods/send-events-462d7f9e-c44b-11e9-8a5f-26f602588652,UID:462f1f52-c44b-11e9-b964-005056a55cb1,ResourceVersion:132391,Generation:0,CreationTimestamp:2019-08-21 19:38:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 48904652,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wz2gk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wz2gk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-wz2gk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002217a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002217a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:38:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:38:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:38:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:38:39 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.58,StartTime:2019-08-21 19:38:39 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-21 19:38:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://119625ed2e0c3f6231471c36ed735e05644fed9e0d434da52c110961d192c440}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 21 19:38:45.093: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 21 19:38:47.099: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:38:47.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-190" for this suite.
Aug 21 19:39:25.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:39:25.281: INFO: namespace events-190 deletion completed in 38.162775048s

â€¢ [SLOW TEST:46.390 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:39:25.284: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Aug 21 19:39:25.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-9099'
Aug 21 19:39:26.584: INFO: stderr: ""
Aug 21 19:39:26.584: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 19:39:26.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9099'
Aug 21 19:39:26.711: INFO: stderr: ""
Aug 21 19:39:26.711: INFO: stdout: "update-demo-nautilus-vdxl2 update-demo-nautilus-wg4gz "
Aug 21 19:39:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-vdxl2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:26.815: INFO: stderr: ""
Aug 21 19:39:26.815: INFO: stdout: ""
Aug 21 19:39:26.815: INFO: update-demo-nautilus-vdxl2 is created but not running
Aug 21 19:39:31.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9099'
Aug 21 19:39:31.918: INFO: stderr: ""
Aug 21 19:39:31.918: INFO: stdout: "update-demo-nautilus-vdxl2 update-demo-nautilus-wg4gz "
Aug 21 19:39:31.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-vdxl2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:32.037: INFO: stderr: ""
Aug 21 19:39:32.037: INFO: stdout: "true"
Aug 21 19:39:32.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-vdxl2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:32.148: INFO: stderr: ""
Aug 21 19:39:32.148: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 19:39:32.148: INFO: validating pod update-demo-nautilus-vdxl2
Aug 21 19:39:32.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 19:39:32.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 19:39:32.157: INFO: update-demo-nautilus-vdxl2 is verified up and running
Aug 21 19:39:32.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-wg4gz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:32.252: INFO: stderr: ""
Aug 21 19:39:32.252: INFO: stdout: "true"
Aug 21 19:39:32.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-wg4gz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:32.359: INFO: stderr: ""
Aug 21 19:39:32.359: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 19:39:32.359: INFO: validating pod update-demo-nautilus-wg4gz
Aug 21 19:39:32.367: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 19:39:32.367: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 19:39:32.367: INFO: update-demo-nautilus-wg4gz is verified up and running
STEP: rolling-update to new replication controller
Aug 21 19:39:32.371: INFO: scanned /root for discovery docs: <nil>
Aug 21 19:39:32.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9099'
Aug 21 19:39:55.112: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 21 19:39:55.112: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 19:39:55.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9099'
Aug 21 19:39:55.223: INFO: stderr: ""
Aug 21 19:39:55.223: INFO: stdout: "update-demo-kitten-6r72n update-demo-kitten-qlr5z "
Aug 21 19:39:55.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-kitten-6r72n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:55.331: INFO: stderr: ""
Aug 21 19:39:55.331: INFO: stdout: "true"
Aug 21 19:39:55.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-kitten-6r72n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:55.448: INFO: stderr: ""
Aug 21 19:39:55.448: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 21 19:39:55.448: INFO: validating pod update-demo-kitten-6r72n
Aug 21 19:39:55.457: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 21 19:39:55.457: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 21 19:39:55.457: INFO: update-demo-kitten-6r72n is verified up and running
Aug 21 19:39:55.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-kitten-qlr5z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:55.569: INFO: stderr: ""
Aug 21 19:39:55.569: INFO: stdout: "true"
Aug 21 19:39:55.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-kitten-qlr5z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9099'
Aug 21 19:39:55.669: INFO: stderr: ""
Aug 21 19:39:55.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 21 19:39:55.669: INFO: validating pod update-demo-kitten-qlr5z
Aug 21 19:39:55.677: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 21 19:39:55.677: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 21 19:39:55.677: INFO: update-demo-kitten-qlr5z is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:39:55.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9099" for this suite.
Aug 21 19:40:17.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:40:17.852: INFO: namespace kubectl-9099 deletion completed in 22.168192676s

â€¢ [SLOW TEST:52.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:40:17.853: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4763
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 19:40:18.022: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 19:40:40.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.49.161:8080/dial?request=hostName&protocol=udp&host=10.200.89.107&port=8081&tries=1'] Namespace:pod-network-test-4763 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:40:40.162: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:40:40.303: INFO: Waiting for endpoints: map[]
Aug 21 19:40:40.308: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.49.161:8080/dial?request=hostName&protocol=udp&host=10.200.38.61&port=8081&tries=1'] Namespace:pod-network-test-4763 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:40:40.308: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:40:40.437: INFO: Waiting for endpoints: map[]
Aug 21 19:40:40.443: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.49.161:8080/dial?request=hostName&protocol=udp&host=10.200.49.160&port=8081&tries=1'] Namespace:pod-network-test-4763 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 19:40:40.443: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 19:40:40.572: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:40:40.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4763" for this suite.
Aug 21 19:41:02.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:41:02.723: INFO: namespace pod-network-test-4763 deletion completed in 22.144083372s

â€¢ [SLOW TEST:44.870 seconds]
[sig-network] Networking
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:41:02.726: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 21 19:41:02.891: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:41:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5151" for this suite.
Aug 21 19:41:28.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:41:29.041: INFO: namespace init-container-5151 deletion completed in 22.155855905s

â€¢ [SLOW TEST:26.316 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:41:29.043: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:41:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2157" for this suite.
Aug 21 19:41:51.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:41:51.422: INFO: namespace pods-2157 deletion completed in 22.187463118s

â€¢ [SLOW TEST:22.379 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:41:51.422: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 21 19:41:51.588: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 21 19:41:56.595: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:41:56.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7720" for this suite.
Aug 21 19:42:02.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:42:02.785: INFO: namespace replication-controller-7720 deletion completed in 6.157247048s

â€¢ [SLOW TEST:11.363 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:42:02.788: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 21 19:42:02.954: INFO: Waiting up to 5m0s for pod "pod-bfb5733d-c44b-11e9-8a5f-26f602588652" in namespace "emptydir-9383" to be "success or failure"
Aug 21 19:42:02.961: INFO: Pod "pod-bfb5733d-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.162914ms
Aug 21 19:42:04.966: INFO: Pod "pod-bfb5733d-c44b-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011758711s
STEP: Saw pod success
Aug 21 19:42:04.966: INFO: Pod "pod-bfb5733d-c44b-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:42:04.971: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-bfb5733d-c44b-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:42:05.009: INFO: Waiting for pod pod-bfb5733d-c44b-11e9-8a5f-26f602588652 to disappear
Aug 21 19:42:05.017: INFO: Pod pod-bfb5733d-c44b-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:42:05.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9383" for this suite.
Aug 21 19:42:11.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:42:11.191: INFO: namespace emptydir-9383 deletion completed in 6.168132584s

â€¢ [SLOW TEST:8.404 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:42:11.193: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:42:13.403: INFO: Waiting up to 5m0s for pod "client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652" in namespace "pods-2505" to be "success or failure"
Aug 21 19:42:13.417: INFO: Pod "client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 14.628282ms
Aug 21 19:42:15.424: INFO: Pod "client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021063042s
Aug 21 19:42:17.431: INFO: Pod "client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027884758s
STEP: Saw pod success
Aug 21 19:42:17.431: INFO: Pod "client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:42:17.435: INFO: Trying to get logs from node ca867801-09fc-419b-a2c1-ae5752feb0ff pod client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652 container env3cont: <nil>
STEP: delete the pod
Aug 21 19:42:17.467: INFO: Waiting for pod client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652 to disappear
Aug 21 19:42:17.471: INFO: Pod client-envvars-c5efe114-c44b-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:42:17.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2505" for this suite.
Aug 21 19:42:55.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:42:55.640: INFO: namespace pods-2505 deletion completed in 38.161846533s

â€¢ [SLOW TEST:44.447 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:42:55.644: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:42:55.802: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:42:59.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5258" for this suite.
Aug 21 19:43:51.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:43:52.132: INFO: namespace pods-5258 deletion completed in 52.17045345s

â€¢ [SLOW TEST:56.489 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:43:52.141: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-00e4cb78-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:43:52.324: INFO: Waiting up to 5m0s for pod "pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652" in namespace "configmap-8660" to be "success or failure"
Aug 21 19:43:52.334: INFO: Pod "pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 10.333107ms
Aug 21 19:43:54.341: INFO: Pod "pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017360557s
STEP: Saw pod success
Aug 21 19:43:54.343: INFO: Pod "pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:43:54.348: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:43:54.378: INFO: Waiting for pod pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:43:54.383: INFO: Pod pod-configmaps-00e5e92d-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:43:54.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8660" for this suite.
Aug 21 19:44:00.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:44:00.540: INFO: namespace configmap-8660 deletion completed in 6.15157123s

â€¢ [SLOW TEST:8.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:44:00.543: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Aug 21 19:44:00.712: INFO: Waiting up to 5m0s for pod "client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652" in namespace "containers-3277" to be "success or failure"
Aug 21 19:44:00.722: INFO: Pod "client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379571ms
Aug 21 19:44:02.727: INFO: Pod "client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015290061s
Aug 21 19:44:04.733: INFO: Pod "client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021216921s
STEP: Saw pod success
Aug 21 19:44:04.733: INFO: Pod "client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:44:04.738: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:44:04.765: INFO: Waiting for pod client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:44:04.769: INFO: Pod client-containers-05e5c3ba-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:44:04.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3277" for this suite.
Aug 21 19:44:10.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:44:10.920: INFO: namespace containers-3277 deletion completed in 6.14479614s

â€¢ [SLOW TEST:10.378 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:44:10.921: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0c166e51-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:44:11.102: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652" in namespace "projected-578" to be "success or failure"
Aug 21 19:44:11.110: INFO: Pod "pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.815226ms
Aug 21 19:44:13.121: INFO: Pod "pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019674727s
STEP: Saw pod success
Aug 21 19:44:13.122: INFO: Pod "pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:44:13.128: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:44:13.158: INFO: Waiting for pod pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:44:13.161: INFO: Pod pod-projected-configmaps-0c174292-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:44:13.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-578" for this suite.
Aug 21 19:44:19.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:44:19.327: INFO: namespace projected-578 deletion completed in 6.159670042s

â€¢ [SLOW TEST:8.407 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:44:19.328: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3648
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-1119e01e-c44c-11e9-8a5f-26f602588652
STEP: Creating secret with name s-test-opt-upd-1119e08e-c44c-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1119e01e-c44c-11e9-8a5f-26f602588652
STEP: Updating secret s-test-opt-upd-1119e08e-c44c-11e9-8a5f-26f602588652
STEP: Creating secret with name s-test-opt-create-1119e0e0-c44c-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:44:23.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3648" for this suite.
Aug 21 19:44:45.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:44:45.811: INFO: namespace secrets-3648 deletion completed in 22.145187581s

â€¢ [SLOW TEST:26.483 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:44:45.812: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-20e0bff0-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 19:44:45.987: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652" in namespace "projected-3163" to be "success or failure"
Aug 21 19:44:46.005: INFO: Pod "pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 17.812586ms
Aug 21 19:44:48.012: INFO: Pod "pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025200661s
STEP: Saw pod success
Aug 21 19:44:48.013: INFO: Pod "pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:44:48.017: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 19:44:48.058: INFO: Waiting for pod pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:44:48.062: INFO: Pod pod-projected-secrets-20e1ebda-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:44:48.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3163" for this suite.
Aug 21 19:44:54.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:44:54.213: INFO: namespace projected-3163 deletion completed in 6.143860601s

â€¢ [SLOW TEST:8.402 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:44:54.215: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 21 19:44:54.391: INFO: Waiting up to 5m0s for pod "pod-25e4132f-c44c-11e9-8a5f-26f602588652" in namespace "emptydir-3564" to be "success or failure"
Aug 21 19:44:54.401: INFO: Pod "pod-25e4132f-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.780919ms
Aug 21 19:44:56.406: INFO: Pod "pod-25e4132f-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015412061s
STEP: Saw pod success
Aug 21 19:44:56.406: INFO: Pod "pod-25e4132f-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:44:56.411: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-25e4132f-c44c-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:44:56.447: INFO: Waiting for pod pod-25e4132f-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:44:56.452: INFO: Pod pod-25e4132f-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:44:56.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3564" for this suite.
Aug 21 19:45:02.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:45:02.609: INFO: namespace emptydir-3564 deletion completed in 6.149555809s

â€¢ [SLOW TEST:8.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:45:02.610: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:45:04.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2192" for this suite.
Aug 21 19:45:10.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:45:10.993: INFO: namespace emptydir-wrapper-2192 deletion completed in 6.142718076s

â€¢ [SLOW TEST:8.383 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:45:10.996: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 21 19:45:11.161: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133696,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 19:45:11.161: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133696,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 21 19:45:21.176: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133713,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 21 19:45:21.177: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133713,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 21 19:45:31.189: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133732,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 19:45:31.189: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133732,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 21 19:45:41.202: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133749,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 19:45:41.202: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-a,UID:2fe55f0c-c44c-11e9-b964-005056a55cb1,ResourceVersion:133749,Generation:0,CreationTimestamp:2019-08-21 19:45:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 21 19:45:51.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-b,UID:47c436ac-c44c-11e9-b964-005056a55cb1,ResourceVersion:133768,Generation:0,CreationTimestamp:2019-08-21 19:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 19:45:51.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-b,UID:47c436ac-c44c-11e9-b964-005056a55cb1,ResourceVersion:133768,Generation:0,CreationTimestamp:2019-08-21 19:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 21 19:46:01.224: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-b,UID:47c436ac-c44c-11e9-b964-005056a55cb1,ResourceVersion:133785,Generation:0,CreationTimestamp:2019-08-21 19:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 19:46:01.224: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1662,SelfLink:/api/v1/namespaces/watch-1662/configmaps/e2e-watch-test-configmap-b,UID:47c436ac-c44c-11e9-b964-005056a55cb1,ResourceVersion:133785,Generation:0,CreationTimestamp:2019-08-21 19:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:46:11.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1662" for this suite.
Aug 21 19:46:17.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:46:17.380: INFO: namespace watch-1662 deletion completed in 6.146323265s

â€¢ [SLOW TEST:66.384 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:46:17.381: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:46:17.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652" in namespace "projected-6810" to be "success or failure"
Aug 21 19:46:17.560: INFO: Pod "downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.538516ms
Aug 21 19:46:19.565: INFO: Pod "downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013071079s
STEP: Saw pod success
Aug 21 19:46:19.565: INFO: Pod "downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:46:19.570: INFO: Trying to get logs from node f138d081-7db1-41cb-9804-f6d51b22765f pod downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:46:19.605: INFO: Waiting for pod downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:46:19.609: INFO: Pod downwardapi-volume-5775a23c-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:46:19.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6810" for this suite.
Aug 21 19:46:25.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:46:25.766: INFO: namespace projected-6810 deletion completed in 6.150230644s

â€¢ [SLOW TEST:8.385 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:46:25.767: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-5c74e206-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:46:25.938: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652" in namespace "configmap-4456" to be "success or failure"
Aug 21 19:46:25.943: INFO: Pod "pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.287464ms
Aug 21 19:46:27.950: INFO: Pod "pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011404479s
STEP: Saw pod success
Aug 21 19:46:27.950: INFO: Pod "pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:46:27.954: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:46:27.987: INFO: Waiting for pod pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:46:27.994: INFO: Pod pod-configmaps-5c75be99-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:46:27.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4456" for this suite.
Aug 21 19:46:34.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:46:34.143: INFO: namespace configmap-4456 deletion completed in 6.144716492s

â€¢ [SLOW TEST:8.377 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:46:34.147: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:46:34.310: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:46:36.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5514" for this suite.
Aug 21 19:47:20.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:47:20.533: INFO: namespace pods-5514 deletion completed in 44.165927095s

â€¢ [SLOW TEST:46.386 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:47:20.533: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:47:20.702: INFO: (0) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.138059ms)
Aug 21 19:47:20.707: INFO: (1) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.89816ms)
Aug 21 19:47:20.711: INFO: (2) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.298642ms)
Aug 21 19:47:20.715: INFO: (3) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.835881ms)
Aug 21 19:47:20.719: INFO: (4) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.719228ms)
Aug 21 19:47:20.724: INFO: (5) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.744672ms)
Aug 21 19:47:20.729: INFO: (6) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.684885ms)
Aug 21 19:47:20.733: INFO: (7) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.542312ms)
Aug 21 19:47:20.737: INFO: (8) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.148309ms)
Aug 21 19:47:20.745: INFO: (9) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.239749ms)
Aug 21 19:47:20.749: INFO: (10) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.97545ms)
Aug 21 19:47:20.753: INFO: (11) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.99539ms)
Aug 21 19:47:20.757: INFO: (12) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.445043ms)
Aug 21 19:47:20.762: INFO: (13) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.076007ms)
Aug 21 19:47:20.765: INFO: (14) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.69736ms)
Aug 21 19:47:20.769: INFO: (15) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.539633ms)
Aug 21 19:47:20.773: INFO: (16) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.936517ms)
Aug 21 19:47:20.777: INFO: (17) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.535464ms)
Aug 21 19:47:20.781: INFO: (18) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.767263ms)
Aug 21 19:47:20.784: INFO: (19) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.540205ms)
[AfterEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:47:20.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5874" for this suite.
Aug 21 19:47:26.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:47:26.958: INFO: namespace proxy-5874 deletion completed in 6.169737377s

â€¢ [SLOW TEST:6.425 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:47:26.965: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-80ef4c49-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 19:47:27.141: INFO: Waiting up to 5m0s for pod "pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652" in namespace "secrets-9206" to be "success or failure"
Aug 21 19:47:27.152: INFO: Pod "pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 10.686482ms
Aug 21 19:47:29.158: INFO: Pod "pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016878582s
STEP: Saw pod success
Aug 21 19:47:29.158: INFO: Pod "pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:47:29.162: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 19:47:29.190: INFO: Waiting for pod pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:47:29.194: INFO: Pod pod-secrets-80f040ef-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:47:29.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9206" for this suite.
Aug 21 19:47:35.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:47:35.343: INFO: namespace secrets-9206 deletion completed in 6.144878905s

â€¢ [SLOW TEST:8.378 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:47:35.346: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 21 19:47:35.860: INFO: Pod name wrapped-volume-race-862126b6-c44c-11e9-8a5f-26f602588652: Found 0 pods out of 5
Aug 21 19:47:40.872: INFO: Pod name wrapped-volume-race-862126b6-c44c-11e9-8a5f-26f602588652: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-862126b6-c44c-11e9-8a5f-26f602588652 in namespace emptydir-wrapper-4380, will wait for the garbage collector to delete the pods
Aug 21 19:47:50.984: INFO: Deleting ReplicationController wrapped-volume-race-862126b6-c44c-11e9-8a5f-26f602588652 took: 15.175561ms
Aug 21 19:47:51.384: INFO: Terminating ReplicationController wrapped-volume-race-862126b6-c44c-11e9-8a5f-26f602588652 pods took: 400.412835ms
STEP: Creating RC which spawns configmap-volume pods
Aug 21 19:48:39.212: INFO: Pod name wrapped-volume-race-abe2f8a9-c44c-11e9-8a5f-26f602588652: Found 0 pods out of 5
Aug 21 19:48:44.226: INFO: Pod name wrapped-volume-race-abe2f8a9-c44c-11e9-8a5f-26f602588652: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-abe2f8a9-c44c-11e9-8a5f-26f602588652 in namespace emptydir-wrapper-4380, will wait for the garbage collector to delete the pods
Aug 21 19:48:56.343: INFO: Deleting ReplicationController wrapped-volume-race-abe2f8a9-c44c-11e9-8a5f-26f602588652 took: 24.814018ms
Aug 21 19:48:56.744: INFO: Terminating ReplicationController wrapped-volume-race-abe2f8a9-c44c-11e9-8a5f-26f602588652 pods took: 401.070826ms
STEP: Creating RC which spawns configmap-volume pods
Aug 21 19:49:39.171: INFO: Pod name wrapped-volume-race-cfa046c3-c44c-11e9-8a5f-26f602588652: Found 0 pods out of 5
Aug 21 19:49:44.183: INFO: Pod name wrapped-volume-race-cfa046c3-c44c-11e9-8a5f-26f602588652: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cfa046c3-c44c-11e9-8a5f-26f602588652 in namespace emptydir-wrapper-4380, will wait for the garbage collector to delete the pods
Aug 21 19:49:56.306: INFO: Deleting ReplicationController wrapped-volume-race-cfa046c3-c44c-11e9-8a5f-26f602588652 took: 24.085141ms
Aug 21 19:49:56.707: INFO: Terminating ReplicationController wrapped-volume-race-cfa046c3-c44c-11e9-8a5f-26f602588652 pods took: 400.429949ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:50:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4380" for this suite.
Aug 21 19:50:47.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:50:47.136: INFO: namespace emptydir-wrapper-4380 deletion completed in 8.138610243s

â€¢ [SLOW TEST:191.790 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:50:47.136: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-f83e0ff4-c44c-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 19:50:47.305: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652" in namespace "projected-3832" to be "success or failure"
Aug 21 19:50:47.311: INFO: Pod "pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028513ms
Aug 21 19:50:49.316: INFO: Pod "pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011886499s
Aug 21 19:50:51.325: INFO: Pod "pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02049718s
STEP: Saw pod success
Aug 21 19:50:51.325: INFO: Pod "pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:50:51.330: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 19:50:51.368: INFO: Waiting for pod pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:50:51.372: INFO: Pod pod-projected-configmaps-f83ef47b-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:50:51.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3832" for this suite.
Aug 21 19:50:57.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:50:57.531: INFO: namespace projected-3832 deletion completed in 6.154301213s

â€¢ [SLOW TEST:10.395 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:50:57.531: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 19:50:57.697: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652" in namespace "projected-1549" to be "success or failure"
Aug 21 19:50:57.703: INFO: Pod "downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.364989ms
Aug 21 19:50:59.712: INFO: Pod "downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014962411s
STEP: Saw pod success
Aug 21 19:50:59.712: INFO: Pod "downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:50:59.716: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 19:50:59.748: INFO: Waiting for pod downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652 to disappear
Aug 21 19:50:59.752: INFO: Pod downwardapi-volume-fe7068b9-c44c-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:50:59.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1549" for this suite.
Aug 21 19:51:05.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:51:05.914: INFO: namespace projected-1549 deletion completed in 6.15652572s

â€¢ [SLOW TEST:8.383 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:51:05.915: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6279
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 21 19:51:06.086: INFO: Waiting up to 5m0s for pod "pod-03709504-c44d-11e9-8a5f-26f602588652" in namespace "emptydir-6279" to be "success or failure"
Aug 21 19:51:06.094: INFO: Pod "pod-03709504-c44d-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122422ms
Aug 21 19:51:08.099: INFO: Pod "pod-03709504-c44d-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013003637s
STEP: Saw pod success
Aug 21 19:51:08.099: INFO: Pod "pod-03709504-c44d-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:51:08.103: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-03709504-c44d-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:51:08.132: INFO: Waiting for pod pod-03709504-c44d-11e9-8a5f-26f602588652 to disappear
Aug 21 19:51:08.135: INFO: Pod pod-03709504-c44d-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:51:08.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6279" for this suite.
Aug 21 19:51:14.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:51:14.295: INFO: namespace emptydir-6279 deletion completed in 6.154475781s

â€¢ [SLOW TEST:8.380 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:51:14.296: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:51:16.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7116" for this suite.
Aug 21 19:51:58.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:51:58.644: INFO: namespace kubelet-test-7116 deletion completed in 42.137791969s

â€¢ [SLOW TEST:44.348 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:51:58.646: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-1716
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1716
STEP: Deleting pre-stop pod
Aug 21 19:52:09.875: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:52:09.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1716" for this suite.
Aug 21 19:52:47.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:52:48.070: INFO: namespace prestop-1716 deletion completed in 38.175898481s

â€¢ [SLOW TEST:49.424 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:52:48.072: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 21 19:52:50.806: INFO: Successfully updated pod "labelsupdate405485f3-c44d-11e9-8a5f-26f602588652"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:52:54.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5082" for this suite.
Aug 21 19:53:16.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:53:17.019: INFO: namespace downward-api-5082 deletion completed in 22.164420065s

â€¢ [SLOW TEST:28.947 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:53:17.021: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:53:19.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3351" for this suite.
Aug 21 19:53:57.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:53:57.386: INFO: namespace kubelet-test-3351 deletion completed in 38.156135848s

â€¢ [SLOW TEST:40.366 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:53:57.388: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-71
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Aug 21 19:53:57.541: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-287854235 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:53:57.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-71" for this suite.
Aug 21 19:54:03.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:54:03.786: INFO: namespace kubectl-71 deletion completed in 6.153327219s

â€¢ [SLOW TEST:6.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:54:03.787: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4184
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 21 19:54:03.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135784,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 19:54:03.967: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135785,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 21 19:54:03.967: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135786,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 21 19:54:14.010: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135804,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 19:54:14.011: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135805,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 21 19:54:14.011: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4184,SelfLink:/api/v1/namespaces/watch-4184/configmaps/e2e-watch-test-label-changed,UID:6d76a8b8-c44d-11e9-b964-005056a55cb1,ResourceVersion:135806,Generation:0,CreationTimestamp:2019-08-21 19:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:54:14.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4184" for this suite.
Aug 21 19:54:20.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:54:20.168: INFO: namespace watch-4184 deletion completed in 6.151043045s

â€¢ [SLOW TEST:16.381 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:54:20.170: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1652
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 19:54:20.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8168'
Aug 21 19:54:21.307: INFO: stderr: ""
Aug 21 19:54:21.307: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1657
Aug 21 19:54:21.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete pods e2e-test-nginx-pod --namespace=kubectl-8168'
Aug 21 19:54:38.129: INFO: stderr: ""
Aug 21 19:54:38.129: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:54:38.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8168" for this suite.
Aug 21 19:54:44.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:54:44.297: INFO: namespace kubectl-8168 deletion completed in 6.161845654s

â€¢ [SLOW TEST:24.127 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:54:44.302: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9516
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9516
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9516
Aug 21 19:54:44.504: INFO: Found 0 stateful pods, waiting for 1
Aug 21 19:54:54.510: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 21 19:54:54.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 19:54:54.763: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 19:54:54.763: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 19:54:54.763: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 19:54:54.769: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 21 19:55:04.777: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 19:55:04.777: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 19:55:04.804: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999585s
Aug 21 19:55:05.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989102757s
Aug 21 19:55:06.816: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982566911s
Aug 21 19:55:07.822: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.976837605s
Aug 21 19:55:08.829: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.971333147s
Aug 21 19:55:09.837: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.964602326s
Aug 21 19:55:10.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.956653205s
Aug 21 19:55:11.851: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.949758393s
Aug 21 19:55:12.858: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.942373905s
Aug 21 19:55:13.865: INFO: Verifying statefulset ss doesn't scale past 1 for another 935.686314ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9516
Aug 21 19:55:14.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 19:55:15.122: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 19:55:15.122: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 19:55:15.122: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 19:55:15.127: INFO: Found 1 stateful pods, waiting for 3
Aug 21 19:55:25.135: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 19:55:25.135: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 19:55:25.135: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 21 19:55:25.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 19:55:25.377: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 19:55:25.377: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 19:55:25.377: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 19:55:25.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 19:55:25.631: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 19:55:25.631: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 19:55:25.631: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 19:55:25.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 19:55:25.910: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 19:55:25.910: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 19:55:25.910: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 19:55:25.910: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 19:55:25.917: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 21 19:55:35.930: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 19:55:35.930: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 19:55:35.930: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 19:55:35.953: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999065s
Aug 21 19:55:36.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988636892s
Aug 21 19:55:37.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982595721s
Aug 21 19:55:38.974: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974768361s
Aug 21 19:55:39.981: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967595751s
Aug 21 19:55:40.987: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960764004s
Aug 21 19:55:41.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954272426s
Aug 21 19:55:43.004: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.945107641s
Aug 21 19:55:44.010: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.937771894s
Aug 21 19:55:45.015: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.121299ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9516
Aug 21 19:55:46.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 19:55:46.258: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 19:55:46.258: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 19:55:46.258: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 19:55:46.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 19:55:46.496: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 19:55:46.496: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 19:55:46.496: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 19:55:46.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-9516 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 19:55:46.766: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 19:55:46.767: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 19:55:46.767: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 19:55:46.767: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 19:56:06.789: INFO: Deleting all statefulset in ns statefulset-9516
Aug 21 19:56:06.793: INFO: Scaling statefulset ss to 0
Aug 21 19:56:06.804: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 19:56:06.807: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:56:06.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9516" for this suite.
Aug 21 19:56:12.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:56:12.981: INFO: namespace statefulset-9516 deletion completed in 6.145282283s

â€¢ [SLOW TEST:88.680 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:56:12.983: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 21 19:56:13.138: INFO: PodSpec: initContainers in spec.initContainers
Aug 21 19:56:59.866: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ba76c186-c44d-11e9-8a5f-26f602588652", GenerateName:"", Namespace:"init-container-8920", SelfLink:"/api/v1/namespaces/init-container-8920/pods/pod-init-ba76c186-c44d-11e9-8a5f-26f602588652", UID:"ba7864ad-c44d-11e9-b964-005056a55cb1", ResourceVersion:"136343", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702014173, loc:(*time.Location)(0x8a1d140)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"138169624"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-p6fkg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002e61240), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-p6fkg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-p6fkg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-p6fkg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00314e688), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"978c34ce-e296-4689-bf73-826c8c556b20", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001aca2a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00314e700)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00314e720)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00314e728), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00314e72c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014173, loc:(*time.Location)(0x8a1d140)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014173, loc:(*time.Location)(0x8a1d140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014173, loc:(*time.Location)(0x8a1d140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014173, loc:(*time.Location)(0x8a1d140)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.85.21.98", PodIP:"10.200.38.104", StartTime:(*v1.Time)(0xc0032b2440), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0020eaee0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0020eaf50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://904434665de870210c21064972362649864c946ff7918f3e90f5c88f0b8129e1"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0032b2480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0032b2460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:56:59.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8920" for this suite.
Aug 21 19:57:21.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:57:22.038: INFO: namespace init-container-8920 deletion completed in 22.161409101s

â€¢ [SLOW TEST:69.055 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:57:22.039: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 21 19:57:22.219: INFO: Waiting up to 5m0s for pod "pod-e3a1e120-c44d-11e9-8a5f-26f602588652" in namespace "emptydir-4102" to be "success or failure"
Aug 21 19:57:22.225: INFO: Pod "pod-e3a1e120-c44d-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.727064ms
Aug 21 19:57:24.232: INFO: Pod "pod-e3a1e120-c44d-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013218675s
STEP: Saw pod success
Aug 21 19:57:24.232: INFO: Pod "pod-e3a1e120-c44d-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 19:57:24.236: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-e3a1e120-c44d-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 19:57:24.272: INFO: Waiting for pod pod-e3a1e120-c44d-11e9-8a5f-26f602588652 to disappear
Aug 21 19:57:24.281: INFO: Pod pod-e3a1e120-c44d-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:57:24.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4102" for this suite.
Aug 21 19:57:30.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:57:30.445: INFO: namespace emptydir-4102 deletion completed in 6.15390416s

â€¢ [SLOW TEST:8.406 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:57:30.447: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 19:57:30.650: INFO: Number of nodes with available pods: 0
Aug 21 19:57:30.650: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:57:31.662: INFO: Number of nodes with available pods: 0
Aug 21 19:57:31.662: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 19:57:32.660: INFO: Number of nodes with available pods: 2
Aug 21 19:57:32.660: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:33.661: INFO: Number of nodes with available pods: 3
Aug 21 19:57:33.662: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 21 19:57:33.689: INFO: Number of nodes with available pods: 2
Aug 21 19:57:33.689: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:34.702: INFO: Number of nodes with available pods: 2
Aug 21 19:57:34.702: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:35.700: INFO: Number of nodes with available pods: 2
Aug 21 19:57:35.700: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:36.701: INFO: Number of nodes with available pods: 2
Aug 21 19:57:36.701: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:37.703: INFO: Number of nodes with available pods: 2
Aug 21 19:57:37.703: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:38.700: INFO: Number of nodes with available pods: 2
Aug 21 19:57:38.700: INFO: Node f138d081-7db1-41cb-9804-f6d51b22765f is running more than one daemon pod
Aug 21 19:57:39.700: INFO: Number of nodes with available pods: 3
Aug 21 19:57:39.700: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1669, will wait for the garbage collector to delete the pods
Aug 21 19:57:39.774: INFO: Deleting DaemonSet.extensions daemon-set took: 15.816688ms
Aug 21 19:57:40.175: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.566832ms
Aug 21 19:57:48.181: INFO: Number of nodes with available pods: 0
Aug 21 19:57:48.181: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 19:57:48.186: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1669/daemonsets","resourceVersion":"136539"},"items":null}

Aug 21 19:57:48.190: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1669/pods","resourceVersion":"136539"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:57:48.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1669" for this suite.
Aug 21 19:57:54.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:57:54.378: INFO: namespace daemonsets-1669 deletion completed in 6.16237453s

â€¢ [SLOW TEST:23.932 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:57:54.380: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:57:57.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-566" for this suite.
Aug 21 19:58:19.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:58:19.757: INFO: namespace replication-controller-566 deletion completed in 22.157325593s

â€¢ [SLOW TEST:25.377 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:58:19.759: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 21 19:58:24.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:24.025: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:26.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:26.033: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:28.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:28.031: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:30.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:30.033: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:32.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:32.033: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:34.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:34.033: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:36.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:36.033: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:38.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:38.032: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:40.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:40.031: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:42.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:42.032: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:44.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:44.032: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:46.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:46.034: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:48.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:48.032: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 19:58:50.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 19:58:50.032: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:58:50.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7161" for this suite.
Aug 21 19:59:12.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:59:12.205: INFO: namespace container-lifecycle-hook-7161 deletion completed in 22.166893787s

â€¢ [SLOW TEST:52.446 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:59:12.207: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 21 19:59:15.422: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:59:16.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1509" for this suite.
Aug 21 19:59:38.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:59:38.630: INFO: namespace replicaset-1509 deletion completed in 22.169964897s

â€¢ [SLOW TEST:26.423 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:59:38.633: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 19:59:38.796: INFO: Creating deployment "nginx-deployment"
Aug 21 19:59:38.806: INFO: Waiting for observed generation 1
Aug 21 19:59:40.822: INFO: Waiting for all required pods to come up
Aug 21 19:59:40.831: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 21 19:59:42.852: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 21 19:59:42.860: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 21 19:59:42.874: INFO: Updating deployment nginx-deployment
Aug 21 19:59:42.874: INFO: Waiting for observed generation 2
Aug 21 19:59:44.886: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 21 19:59:44.891: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 21 19:59:44.896: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 21 19:59:44.908: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 21 19:59:44.908: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 21 19:59:44.913: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 21 19:59:44.921: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 21 19:59:44.921: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 21 19:59:44.938: INFO: Updating deployment nginx-deployment
Aug 21 19:59:44.938: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 21 19:59:44.964: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 21 19:59:46.996: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 19:59:47.008: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8924,SelfLink:/apis/apps/v1/namespaces/deployment-8924/deployments/nginx-deployment,UID:350cfe75-c44e-11e9-b964-005056a55cb1,ResourceVersion:137219,Generation:3,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-08-21 19:59:44 +0000 UTC 2019-08-21 19:59:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-21 19:59:46 +0000 UTC 2019-08-21 19:59:38 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Aug 21 19:59:47.016: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-8924,SelfLink:/apis/apps/v1/namespaces/deployment-8924/replicasets/nginx-deployment-b79c9d74d,UID:377957c6-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137154,Generation:3,CreationTimestamp:2019-08-21 19:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 350cfe75-c44e-11e9-b964-005056a55cb1 0xc0022c60d7 0xc0022c60d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 19:59:47.016: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 21 19:59:47.016: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-8924,SelfLink:/apis/apps/v1/namespaces/deployment-8924/replicasets/nginx-deployment-85db8c99c5,UID:350d557f-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137217,Generation:3,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 350cfe75-c44e-11e9-b964-005056a55cb1 0xc0022c6007 0xc0022c6008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Aug 21 19:59:47.030: INFO: Pod "nginx-deployment-85db8c99c5-2qfcx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2qfcx,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-2qfcx,UID:3516920e-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136985,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c6ab7 0xc0022c6ab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c6b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c6b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.114,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f16568fc8ffc1323633cd467a869795a197a9e908cfeca144095afe26e1fcfea}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.030: INFO: Pod "nginx-deployment-85db8c99c5-5rnxk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5rnxk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-5rnxk,UID:351b952c-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136977,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c6c10 0xc0022c6c11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c6c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c6c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:10.200.89.113,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1fa4f5250cdb07325040e51b9ecb4ccbbb1fee5cbc3acd6ed088f168c0716496}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.030: INFO: Pod "nginx-deployment-85db8c99c5-b6kp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-b6kp9,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-b6kp9,UID:38bfde00-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137155,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c6d60 0xc0022c6d61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c6dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c6de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.031: INFO: Pod "nginx-deployment-85db8c99c5-cqcsw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-cqcsw,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-cqcsw,UID:38c89746-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137194,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c6eb0 0xc0022c6eb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c6f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c6f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.031: INFO: Pod "nginx-deployment-85db8c99c5-dczx4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dczx4,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-dczx4,UID:351700bf-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136998,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c6ff0 0xc0022c6ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.167,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://974b810a623930ef19dcb7b772407d3964d6aa8809ed3ed130c067f2317ff59a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.031: INFO: Pod "nginx-deployment-85db8c99c5-dxft4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dxft4,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-dxft4,UID:351b404a-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136982,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7150 0xc0022c7151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c71b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c71d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:10.200.89.114,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://13a49bb1e003152b088e9ec4c9b0ae9bdaf15df64eed6baa48a5244d7bdf413a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.031: INFO: Pod "nginx-deployment-85db8c99c5-f5mzl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-f5mzl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-f5mzl,UID:38c7ae34-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137165,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c72a0 0xc0022c72a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.031: INFO: Pod "nginx-deployment-85db8c99c5-fhd7c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fhd7c,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-fhd7c,UID:38c09d00-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137238,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c73e0 0xc0022c73e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.173,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8251fdac9ce027f9d1caa54853a9715f6f819b3dc834e3bb151750bed49f1b00}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-hh8xj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hh8xj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-hh8xj,UID:350fd95e-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136979,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7530 0xc0022c7531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c75b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.112,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://656e17a009891c8be172db33cb8e443bfb13d4c3d6a8c891d44bb4b1beed0401}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-jvqss" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-jvqss,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-jvqss,UID:351790a2-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136995,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7680 0xc0022c7681}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c76e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.169,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b1e13fb0b97fba45982bb9884303c7d22d0c8da7b86681f9171d06d7123f2805}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-lb4sq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-lb4sq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-lb4sq,UID:38b61153-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137100,Generation:0,CreationTimestamp:2019-08-21 19:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c77d0 0xc0022c77d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-q2gtz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-q2gtz,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-q2gtz,UID:35129679-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136964,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7910 0xc0022c7911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:10.200.89.112,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a1b27785a3fa66126adf3f949ad5c755e12eff72d42e26148f6d26be7ff29e84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-rxzvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rxzvv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-rxzvv,UID:38c8cb48-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137189,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7a60 0xc0022c7a61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.032: INFO: Pod "nginx-deployment-85db8c99c5-tgpwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tgpwg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-tgpwg,UID:38bf22bb-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137145,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7ba0 0xc0022c7ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-wfh5w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wfh5w,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-wfh5w,UID:38b7dbe5-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137216,Generation:0,CreationTimestamp:2019-08-21 19:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7ce0 0xc0022c7ce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.172,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8794da75cc240311a462e31e7b24225ecdb0d6c411deffc71c60b8207a50a1b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-wfwxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wfwxc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-wfwxc,UID:38b8ae51-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137152,Generation:0,CreationTimestamp:2019-08-21 19:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7e30 0xc0022c7e31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-wpvc5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wpvc5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-wpvc5,UID:351b8f32-c44e-11e9-8bc3-005056a5e556,ResourceVersion:136992,Generation:0,CreationTimestamp:2019-08-21 19:59:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc0022c7f70 0xc0022c7f71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c7fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c7ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:38 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.168,StartTime:2019-08-21 19:59:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 19:59:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://fed747f839d2c78c7a46ba4ba09b230d82d78ee91fb4f7a83e08fcc127003274}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-xb8mj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xb8mj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-xb8mj,UID:38c93fad-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137184,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc002f4e0c0 0xc002f4e0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-xdkvt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xdkvt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-xdkvt,UID:38c90b1f-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137149,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc002f4e200 0xc002f4e201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-85db8c99c5-zqntp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-zqntp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-85db8c99c5-zqntp,UID:38be905a-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137163,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 350d557f-c44e-11e9-8bc3-005056a5e556 0xc002f4e340 0xc002f4e341}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.033: INFO: Pod "nginx-deployment-b79c9d74d-9qr5w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-9qr5w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-9qr5w,UID:377c788d-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137102,Generation:0,CreationTimestamp:2019-08-21 19:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4e480 0xc002f4e481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.170,StartTime:2019-08-21 19:59:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.034: INFO: Pod "nginx-deployment-b79c9d74d-f974w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-f974w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-f974w,UID:38c9d7e4-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137200,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4e600 0xc002f4e601}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.034: INFO: Pod "nginx-deployment-b79c9d74d-g2rfc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-g2rfc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-g2rfc,UID:378a5150-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137049,Generation:0,CreationTimestamp:2019-08-21 19:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4e760 0xc002f4e761}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e7d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e7f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.034: INFO: Pod "nginx-deployment-b79c9d74d-gj896" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gj896,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-gj896,UID:38beeed4-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137168,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4e8c0 0xc002f4e8c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4e930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4e950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.034: INFO: Pod "nginx-deployment-b79c9d74d-h58hn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-h58hn,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-h58hn,UID:38bdc8c3-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137128,Generation:0,CreationTimestamp:2019-08-21 19:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4ea20 0xc002f4ea21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4ea90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4eab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.034: INFO: Pod "nginx-deployment-b79c9d74d-hvx2v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hvx2v,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-hvx2v,UID:377cc517-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137031,Generation:0,CreationTimestamp:2019-08-21 19:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4eb80 0xc002f4eb81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4ebf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4ec10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.035: INFO: Pod "nginx-deployment-b79c9d74d-lgpnj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-lgpnj,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-lgpnj,UID:38b93a98-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137160,Generation:0,CreationTimestamp:2019-08-21 19:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4ece0 0xc002f4ece1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4ed50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4ed90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:44 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.035: INFO: Pod "nginx-deployment-b79c9d74d-mb4w9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mb4w9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-mb4w9,UID:378dd6dc-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137088,Generation:0,CreationTimestamp:2019-08-21 19:59:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4ee80 0xc002f4ee81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4eef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4ef10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:43 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:10.200.49.171,StartTime:2019-08-21 19:59:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.035: INFO: Pod "nginx-deployment-b79c9d74d-sndjf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-sndjf,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-sndjf,UID:38d116cd-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137205,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4f000 0xc002f4f001}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4f070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4f090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.035: INFO: Pod "nginx-deployment-b79c9d74d-tgfkc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tgfkc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-tgfkc,UID:38c85de4-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137186,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4f160 0xc002f4f161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ca867801-09fc-419b-a2c1-ae5752feb0ff,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4f1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4f1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.96,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.036: INFO: Pod "nginx-deployment-b79c9d74d-tlm5f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tlm5f,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-tlm5f,UID:38ca2bbb-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137199,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4f2c0 0xc002f4f2c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4f330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4f350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.036: INFO: Pod "nginx-deployment-b79c9d74d-v8mq6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-v8mq6,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-v8mq6,UID:377b0090-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137127,Generation:0,CreationTimestamp:2019-08-21 19:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4f420 0xc002f4f421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4f490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4f4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:42 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.115,StartTime:2019-08-21 19:59:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 19:59:47.036: INFO: Pod "nginx-deployment-b79c9d74d-w8zdk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-w8zdk,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-8924,SelfLink:/api/v1/namespaces/deployment-8924/pods/nginx-deployment-b79c9d74d-w8zdk,UID:38c996dc-c44e-11e9-8bc3-005056a5e556,ResourceVersion:137195,Generation:0,CreationTimestamp:2019-08-21 19:59:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 377957c6-c44e-11e9-8bc3-005056a5e556 0xc002f4f5a0 0xc002f4f5a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z2nzc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2nzc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-z2nzc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:f138d081-7db1-41cb-9804-f6d51b22765f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f4f610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f4f630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 19:59:45 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.97,PodIP:,StartTime:2019-08-21 19:59:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 19:59:47.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8924" for this suite.
Aug 21 19:59:55.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 19:59:55.181: INFO: namespace deployment-8924 deletion completed in 8.139953827s

â€¢ [SLOW TEST:16.547 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 19:59:55.183: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9411.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9411.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9411.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9411.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.121_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9411.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9411.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9411.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9411.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9411.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9411.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.121_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 21 19:59:57.416: INFO: Unable to read wheezy_udp@dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.421: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.425: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.432: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.460: INFO: Unable to read jessie_udp@dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.463: INFO: Unable to read jessie_tcp@dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.467: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.471: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local from pod dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652: the server could not find the requested resource (get pods dns-test-3eee3649-c44e-11e9-8a5f-26f602588652)
Aug 21 19:59:57.496: INFO: Lookups using dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652 failed for: [wheezy_udp@dns-test-service.dns-9411.svc.cluster.local wheezy_tcp@dns-test-service.dns-9411.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local jessie_udp@dns-test-service.dns-9411.svc.cluster.local jessie_tcp@dns-test-service.dns-9411.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9411.svc.cluster.local]

Aug 21 20:00:02.610: INFO: DNS probes using dns-9411/dns-test-3eee3649-c44e-11e9-8a5f-26f602588652 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:00:02.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9411" for this suite.
Aug 21 20:00:08.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:00:08.882: INFO: namespace dns-9411 deletion completed in 6.147540975s

â€¢ [SLOW TEST:13.700 seconds]
[sig-network] DNS
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:00:08.884: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 21 20:00:09.060: INFO: Waiting up to 5m0s for pod "pod-4713c28b-c44e-11e9-8a5f-26f602588652" in namespace "emptydir-9466" to be "success or failure"
Aug 21 20:00:09.075: INFO: Pod "pod-4713c28b-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 15.142449ms
Aug 21 20:00:11.081: INFO: Pod "pod-4713c28b-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020860885s
STEP: Saw pod success
Aug 21 20:00:11.081: INFO: Pod "pod-4713c28b-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:00:11.086: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-4713c28b-c44e-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:00:11.116: INFO: Waiting for pod pod-4713c28b-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:00:11.120: INFO: Pod pod-4713c28b-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:00:11.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9466" for this suite.
Aug 21 20:00:17.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:00:17.256: INFO: namespace emptydir-9466 deletion completed in 6.131550699s

â€¢ [SLOW TEST:8.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:00:17.259: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6282
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6282
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6282
Aug 21 20:00:17.452: INFO: Found 0 stateful pods, waiting for 1
Aug 21 20:00:27.459: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 21 20:00:27.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:00:27.719: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:00:27.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:00:27.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 20:00:27.725: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 21 20:00:37.733: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 20:00:37.733: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:00:37.755: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:00:37.755: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:00:37.755: INFO:
Aug 21 20:00:37.755: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 21 20:00:38.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994286481s
Aug 21 20:00:39.768: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987978582s
Aug 21 20:00:40.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981836972s
Aug 21 20:00:41.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975281067s
Aug 21 20:00:42.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969676574s
Aug 21 20:00:43.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963669886s
Aug 21 20:00:44.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955387129s
Aug 21 20:00:45.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.947233821s
Aug 21 20:00:46.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.228566ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6282
Aug 21 20:00:47.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 20:00:48.070: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 20:00:48.070: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 20:00:48.070: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 20:00:48.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 20:00:48.314: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 21 20:00:48.314: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 20:00:48.314: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 20:00:48.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 20:00:48.551: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 21 20:00:48.551: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 20:00:48.551: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 20:00:48.560: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 21 20:00:58.567: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:00:58.567: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:00:58.567: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 21 20:00:58.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:00:58.798: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:00:58.798: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:00:58.798: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 20:00:58.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:00:59.064: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:00:59.064: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:00:59.064: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 20:00:59.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-6282 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:00:59.326: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:00:59.326: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:00:59.326: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 20:00:59.326: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:00:59.331: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 21 20:01:09.342: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 20:01:09.342: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 20:01:09.342: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 20:01:09.359: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:09.359: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:09.359: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:09.359: INFO: ss-2  f138d081-7db1-41cb-9804-f6d51b22765f  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:09.359: INFO:
Aug 21 20:01:09.359: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 21 20:01:10.368: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:10.368: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:10.368: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:10.368: INFO: ss-2  f138d081-7db1-41cb-9804-f6d51b22765f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:10.368: INFO:
Aug 21 20:01:10.368: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 21 20:01:11.373: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:11.374: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:11.374: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:11.374: INFO:
Aug 21 20:01:11.374: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 20:01:12.380: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:12.380: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:12.380: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:12.380: INFO:
Aug 21 20:01:12.380: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 20:01:13.387: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:13.387: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:13.387: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:13.387: INFO:
Aug 21 20:01:13.387: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 20:01:14.396: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:14.396: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:14.396: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:14.397: INFO:
Aug 21 20:01:14.397: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 20:01:15.403: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:15.403: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:15.403: INFO: ss-1  ca867801-09fc-419b-a2c1-ae5752feb0ff  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:37 +0000 UTC  }]
Aug 21 20:01:15.403: INFO:
Aug 21 20:01:15.403: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 20:01:16.408: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:16.409: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:16.409: INFO:
Aug 21 20:01:16.409: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 21 20:01:17.414: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Aug 21 20:01:17.414: INFO: ss-0  978c34ce-e296-4689-bf73-826c8c556b20  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:00:17 +0000 UTC  }]
Aug 21 20:01:17.414: INFO:
Aug 21 20:01:17.414: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 21 20:01:18.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 938.42813ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6282
Aug 21 20:01:19.431: INFO: Scaling statefulset ss to 0
Aug 21 20:01:19.444: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 20:01:19.447: INFO: Deleting all statefulset in ns statefulset-6282
Aug 21 20:01:19.451: INFO: Scaling statefulset ss to 0
Aug 21 20:01:19.463: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:01:19.466: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:01:19.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6282" for this suite.
Aug 21 20:01:25.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:01:25.637: INFO: namespace statefulset-6282 deletion completed in 6.145131281s

â€¢ [SLOW TEST:68.378 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:01:25.637: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Aug 21 20:01:27.825: INFO: Pod pod-hostip-74d218b0-c44e-11e9-8a5f-26f602588652 has hostIP: 10.85.21.98
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:01:27.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4988" for this suite.
Aug 21 20:01:49.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:01:49.989: INFO: namespace pods-4988 deletion completed in 22.158614671s

â€¢ [SLOW TEST:24.352 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:01:49.992: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-wf9g
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 20:01:50.190: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wf9g" in namespace "subpath-4123" to be "success or failure"
Aug 21 20:01:50.199: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Pending", Reason="", readiness=false. Elapsed: 8.352518ms
Aug 21 20:01:52.205: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 2.014813574s
Aug 21 20:01:54.211: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 4.020700249s
Aug 21 20:01:56.217: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 6.026874529s
Aug 21 20:01:58.223: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 8.032981157s
Aug 21 20:02:00.230: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 10.040064069s
Aug 21 20:02:02.238: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 12.04734921s
Aug 21 20:02:04.246: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 14.055313475s
Aug 21 20:02:06.253: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 16.062332534s
Aug 21 20:02:08.259: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 18.068622889s
Aug 21 20:02:10.264: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Running", Reason="", readiness=true. Elapsed: 20.074084705s
Aug 21 20:02:12.274: INFO: Pod "pod-subpath-test-secret-wf9g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.083211038s
STEP: Saw pod success
Aug 21 20:02:12.274: INFO: Pod "pod-subpath-test-secret-wf9g" satisfied condition "success or failure"
Aug 21 20:02:12.278: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-subpath-test-secret-wf9g container test-container-subpath-secret-wf9g: <nil>
STEP: delete the pod
Aug 21 20:02:12.315: INFO: Waiting for pod pod-subpath-test-secret-wf9g to disappear
Aug 21 20:02:12.318: INFO: Pod pod-subpath-test-secret-wf9g no longer exists
STEP: Deleting pod pod-subpath-test-secret-wf9g
Aug 21 20:02:12.319: INFO: Deleting pod "pod-subpath-test-secret-wf9g" in namespace "subpath-4123"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:02:12.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4123" for this suite.
Aug 21 20:02:18.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:02:18.483: INFO: namespace subpath-4123 deletion completed in 6.155791229s

â€¢ [SLOW TEST:28.491 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:02:18.484: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:02:18.656: INFO: Waiting up to 5m0s for pod "downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652" in namespace "downward-api-6348" to be "success or failure"
Aug 21 20:02:18.662: INFO: Pod "downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.545422ms
Aug 21 20:02:20.669: INFO: Pod "downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013033243s
STEP: Saw pod success
Aug 21 20:02:20.669: INFO: Pod "downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:02:20.673: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:02:20.701: INFO: Waiting for pod downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:02:20.705: INFO: Pod downwardapi-volume-945252e7-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:02:20.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6348" for this suite.
Aug 21 20:02:26.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:02:26.875: INFO: namespace downward-api-6348 deletion completed in 6.163442443s

â€¢ [SLOW TEST:8.391 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:02:26.876: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4191
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8546
STEP: Creating secret with name secret-test-9953091e-c44e-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:02:27.210: INFO: Waiting up to 5m0s for pod "pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652" in namespace "secrets-4191" to be "success or failure"
Aug 21 20:02:27.219: INFO: Pod "pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.395987ms
Aug 21 20:02:29.224: INFO: Pod "pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013711052s
STEP: Saw pod success
Aug 21 20:02:29.224: INFO: Pod "pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:02:29.227: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:02:29.257: INFO: Waiting for pod pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:02:29.262: INFO: Pod pod-secrets-996c03e3-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:02:29.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4191" for this suite.
Aug 21 20:02:35.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:02:35.421: INFO: namespace secrets-4191 deletion completed in 6.154746495s
STEP: Destroying namespace "secret-namespace-8546" for this suite.
Aug 21 20:02:41.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:02:41.589: INFO: namespace secret-namespace-8546 deletion completed in 6.168195095s

â€¢ [SLOW TEST:14.713 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:02:41.590: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:02:41.754: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 21 20:02:41.768: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 21 20:02:46.775: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 20:02:46.775: INFO: Creating deployment "test-rolling-update-deployment"
Aug 21 20:02:46.783: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 21 20:02:46.803: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 21 20:02:48.813: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 21 20:02:48.820: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014566, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014566, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014568, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702014566, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 20:02:50.826: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 20:02:50.838: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5255,SelfLink:/apis/apps/v1/namespaces/deployment-5255/deployments/test-rolling-update-deployment,UID:a51818dc-c44e-11e9-b964-005056a55cb1,ResourceVersion:138242,Generation:1,CreationTimestamp:2019-08-21 20:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-21 20:02:46 +0000 UTC 2019-08-21 20:02:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-21 20:02:48 +0000 UTC 2019-08-21 20:02:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 21 20:02:50.843: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-5255,SelfLink:/apis/apps/v1/namespaces/deployment-5255/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:a51a2112-c44e-11e9-8bc3-005056a5e556,ResourceVersion:138231,Generation:1,CreationTimestamp:2019-08-21 20:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a51818dc-c44e-11e9-b964-005056a55cb1 0xc00314fdf7 0xc00314fdf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 20:02:50.843: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 21 20:02:50.843: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5255,SelfLink:/apis/apps/v1/namespaces/deployment-5255/replicasets/test-rolling-update-controller,UID:a219e49e-c44e-11e9-b964-005056a55cb1,ResourceVersion:138241,Generation:2,CreationTimestamp:2019-08-21 20:02:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a51818dc-c44e-11e9-b964-005056a55cb1 0xc00314fd27 0xc00314fd28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 20:02:50.850: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-f4dwm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-f4dwm,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-5255,SelfLink:/api/v1/namespaces/deployment-5255/pods/test-rolling-update-deployment-57b6b5bb54-f4dwm,UID:a51bb057-c44e-11e9-8bc3-005056a5e556,ResourceVersion:138230,Generation:0,CreationTimestamp:2019-08-21 20:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 a51a2112-c44e-11e9-8bc3-005056a5e556 0xc002d946f7 0xc002d946f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbtfd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbtfd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bbtfd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d94760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d94780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:02:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:02:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:02:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:02:46 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:10.200.38.132,StartTime:2019-08-21 20:02:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-21 20:02:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://62b9264020a8527f9ea7a3cd2a202f32b5a68c30ffec3fec165ec156df67f479}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:02:50.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5255" for this suite.
Aug 21 20:02:56.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:02:57.014: INFO: namespace deployment-5255 deletion completed in 6.159286712s

â€¢ [SLOW TEST:15.425 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:02:57.017: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:02:59.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3257" for this suite.
Aug 21 20:03:37.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:03:37.371: INFO: namespace kubelet-test-3257 deletion completed in 38.144840549s

â€¢ [SLOW TEST:40.354 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:03:37.372: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 21 20:03:42.107: INFO: Successfully updated pod "labelsupdatec359c39d-c44e-11e9-8a5f-26f602588652"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:03:44.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9470" for this suite.
Aug 21 20:04:06.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:06.298: INFO: namespace projected-9470 deletion completed in 22.162804657s

â€¢ [SLOW TEST:28.927 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:06.299: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:04:06.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652" in namespace "downward-api-3219" to be "success or failure"
Aug 21 20:04:06.479: INFO: Pod "downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.53782ms
Aug 21 20:04:08.484: INFO: Pod "downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014314725s
STEP: Saw pod success
Aug 21 20:04:08.484: INFO: Pod "downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:04:08.488: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:04:08.523: INFO: Waiting for pod downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:04:08.527: INFO: Pod downwardapi-volume-d4959803-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:08.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3219" for this suite.
Aug 21 20:04:14.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:14.686: INFO: namespace downward-api-3219 deletion completed in 6.152818973s

â€¢ [SLOW TEST:8.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:14.688: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 21 20:04:14.846: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:17.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4156" for this suite.
Aug 21 20:04:23.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:24.106: INFO: namespace init-container-4156 deletion completed in 6.149116657s

â€¢ [SLOW TEST:9.418 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:24.109: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-df33865c-c44e-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:04:24.298: INFO: Waiting up to 5m0s for pod "pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652" in namespace "secrets-4127" to be "success or failure"
Aug 21 20:04:24.312: INFO: Pod "pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 13.690723ms
Aug 21 20:04:26.317: INFO: Pod "pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019481244s
STEP: Saw pod success
Aug 21 20:04:26.317: INFO: Pod "pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:04:26.321: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:04:26.350: INFO: Waiting for pod pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:04:26.353: INFO: Pod pod-secrets-df36021f-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:26.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4127" for this suite.
Aug 21 20:04:32.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:32.537: INFO: namespace secrets-4127 deletion completed in 6.179100587s

â€¢ [SLOW TEST:8.428 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:32.538: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 21 20:04:32.710: INFO: Waiting up to 5m0s for pod "pod-e4399c5b-c44e-11e9-8a5f-26f602588652" in namespace "emptydir-2448" to be "success or failure"
Aug 21 20:04:32.720: INFO: Pod "pod-e4399c5b-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.932051ms
Aug 21 20:04:34.726: INFO: Pod "pod-e4399c5b-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015904984s
STEP: Saw pod success
Aug 21 20:04:34.728: INFO: Pod "pod-e4399c5b-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:04:34.733: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-e4399c5b-c44e-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:04:34.761: INFO: Waiting for pod pod-e4399c5b-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:04:34.765: INFO: Pod pod-e4399c5b-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:34.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2448" for this suite.
Aug 21 20:04:40.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:40.920: INFO: namespace emptydir-2448 deletion completed in 6.149960298s

â€¢ [SLOW TEST:8.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:40.920: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-750.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-750.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-750.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-750.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-750.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-750.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 21 20:04:43.160: INFO: DNS probes using dns-750/dns-test-e93930ce-c44e-11e9-8a5f-26f602588652 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:43.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-750" for this suite.
Aug 21 20:04:49.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:49.334: INFO: namespace dns-750 deletion completed in 6.145921106s

â€¢ [SLOW TEST:8.414 seconds]
[sig-network] DNS
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:49.336: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ee3b5865-c44e-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:04:49.507: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652" in namespace "configmap-8967" to be "success or failure"
Aug 21 20:04:49.521: INFO: Pod "pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 13.88808ms
Aug 21 20:04:51.527: INFO: Pod "pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019527295s
STEP: Saw pod success
Aug 21 20:04:51.527: INFO: Pod "pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:04:51.531: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:04:51.557: INFO: Waiting for pod pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:04:51.560: INFO: Pod pod-configmaps-ee3c22cf-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:51.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8967" for this suite.
Aug 21 20:04:57.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:04:57.718: INFO: namespace configmap-8967 deletion completed in 6.152897643s

â€¢ [SLOW TEST:8.382 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:04:57.725: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:04:57.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652" in namespace "projected-9487" to be "success or failure"
Aug 21 20:04:57.911: INFO: Pod "downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047828ms
Aug 21 20:04:59.919: INFO: Pod "downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016098033s
STEP: Saw pod success
Aug 21 20:04:59.919: INFO: Pod "downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:04:59.924: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:04:59.954: INFO: Waiting for pod downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:04:59.958: INFO: Pod downwardapi-volume-f33d7f38-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:04:59.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9487" for this suite.
Aug 21 20:05:05.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:05:06.125: INFO: namespace projected-9487 deletion completed in 6.160430887s

â€¢ [SLOW TEST:8.401 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:05:06.134: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f83f5e0e-c44e-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:05:06.313: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652" in namespace "projected-962" to be "success or failure"
Aug 21 20:05:06.331: INFO: Pod "pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 17.381581ms
Aug 21 20:05:08.338: INFO: Pod "pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024451829s
STEP: Saw pod success
Aug 21 20:05:08.338: INFO: Pod "pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:05:08.341: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:05:08.372: INFO: Waiting for pod pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652 to disappear
Aug 21 20:05:08.376: INFO: Pod pod-projected-configmaps-f840585d-c44e-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:05:08.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-962" for this suite.
Aug 21 20:05:14.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:05:14.537: INFO: namespace projected-962 deletion completed in 6.155018963s

â€¢ [SLOW TEST:8.403 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:05:14.540: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Aug 21 20:05:14.720: INFO: namespace kubectl-9996
Aug 21 20:05:14.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-9996'
Aug 21 20:05:15.805: INFO: stderr: ""
Aug 21 20:05:15.805: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 20:05:16.810: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:05:16.810: INFO: Found 0 / 1
Aug 21 20:05:17.811: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:05:17.811: INFO: Found 1 / 1
Aug 21 20:05:17.811: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 20:05:17.815: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:05:17.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 20:05:17.815: INFO: wait on redis-master startup in kubectl-9996
Aug 21 20:05:17.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 logs redis-master-md7ng redis-master --namespace=kubectl-9996'
Aug 21 20:05:17.949: INFO: stderr: ""
Aug 21 20:05:17.949: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 20:05:17.095 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 20:05:17.095 # Server started, Redis version 3.2.12\n1:M 21 Aug 20:05:17.095 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 20:05:17.095 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 21 20:05:17.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9996'
Aug 21 20:05:18.096: INFO: stderr: ""
Aug 21 20:05:18.099: INFO: stdout: "service/rm2 exposed\n"
Aug 21 20:05:18.103: INFO: Service rm2 in namespace kubectl-9996 found.
STEP: exposing service
Aug 21 20:05:20.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9996'
Aug 21 20:05:20.232: INFO: stderr: ""
Aug 21 20:05:20.232: INFO: stdout: "service/rm3 exposed\n"
Aug 21 20:05:20.236: INFO: Service rm3 in namespace kubectl-9996 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:05:22.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9996" for this suite.
Aug 21 20:05:44.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:05:44.410: INFO: namespace kubectl-9996 deletion completed in 22.159416014s

â€¢ [SLOW TEST:29.870 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:05:44.412: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:05:44.594: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652" in namespace "downward-api-6946" to be "success or failure"
Aug 21 20:05:44.602: INFO: Pod "downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.410487ms
Aug 21 20:05:46.608: INFO: Pod "downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014439198s
STEP: Saw pod success
Aug 21 20:05:46.608: INFO: Pod "downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:05:46.613: INFO: Trying to get logs from node f138d081-7db1-41cb-9804-f6d51b22765f pod downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:05:46.649: INFO: Waiting for pod downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652 to disappear
Aug 21 20:05:46.652: INFO: Pod downwardapi-volume-0f11dedb-c44f-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:05:46.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6946" for this suite.
Aug 21 20:05:52.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:05:52.820: INFO: namespace downward-api-6946 deletion completed in 6.160441433s

â€¢ [SLOW TEST:8.408 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:05:52.823: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-14141af0-c44f-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:05:53.004: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652" in namespace "projected-6333" to be "success or failure"
Aug 21 20:05:53.011: INFO: Pod "pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.559402ms
Aug 21 20:05:55.017: INFO: Pod "pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652": Phase="Running", Reason="", readiness=true. Elapsed: 2.012735147s
Aug 21 20:05:57.023: INFO: Pod "pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019385341s
STEP: Saw pod success
Aug 21 20:05:57.023: INFO: Pod "pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:05:57.028: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:05:57.061: INFO: Waiting for pod pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652 to disappear
Aug 21 20:05:57.065: INFO: Pod pod-projected-secrets-141558d3-c44f-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:05:57.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6333" for this suite.
Aug 21 20:06:03.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:06:03.222: INFO: namespace projected-6333 deletion completed in 6.15025117s

â€¢ [SLOW TEST:10.400 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:06:03.223: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 21 20:06:03.386: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:06:18.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9424" for this suite.
Aug 21 20:06:24.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:06:24.302: INFO: namespace pods-9424 deletion completed in 6.159477928s

â€¢ [SLOW TEST:21.079 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:06:24.304: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2082
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-26d9e84e-c44f-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:06:26.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2082" for this suite.
Aug 21 20:06:48.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:06:48.717: INFO: namespace configmap-2082 deletion completed in 22.157535986s

â€¢ [SLOW TEST:24.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:06:48.719: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Aug 21 20:06:48.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 cluster-info'
Aug 21 20:06:49.011: INFO: stderr: ""
Aug 21 20:06:49.011: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:06:49.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4944" for this suite.
Aug 21 20:06:55.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:06:55.166: INFO: namespace kubectl-4944 deletion completed in 6.148695099s

â€¢ [SLOW TEST:6.447 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:06:55.171: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:06:55.357: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 21 20:06:55.382: INFO: Number of nodes with available pods: 0
Aug 21 20:06:55.382: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 21 20:06:55.406: INFO: Number of nodes with available pods: 0
Aug 21 20:06:55.407: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:06:56.413: INFO: Number of nodes with available pods: 0
Aug 21 20:06:56.413: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:06:57.413: INFO: Number of nodes with available pods: 1
Aug 21 20:06:57.413: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 21 20:06:57.434: INFO: Number of nodes with available pods: 1
Aug 21 20:06:57.434: INFO: Number of running nodes: 0, number of available pods: 1
Aug 21 20:06:58.440: INFO: Number of nodes with available pods: 0
Aug 21 20:06:58.440: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 21 20:06:58.456: INFO: Number of nodes with available pods: 0
Aug 21 20:06:58.456: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:06:59.462: INFO: Number of nodes with available pods: 0
Aug 21 20:06:59.462: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:00.469: INFO: Number of nodes with available pods: 0
Aug 21 20:07:00.469: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:01.463: INFO: Number of nodes with available pods: 0
Aug 21 20:07:01.463: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:02.463: INFO: Number of nodes with available pods: 0
Aug 21 20:07:02.464: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:03.462: INFO: Number of nodes with available pods: 0
Aug 21 20:07:03.463: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:04.465: INFO: Number of nodes with available pods: 0
Aug 21 20:07:04.466: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:05.462: INFO: Number of nodes with available pods: 0
Aug 21 20:07:05.462: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:06.462: INFO: Number of nodes with available pods: 0
Aug 21 20:07:06.462: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:07.464: INFO: Number of nodes with available pods: 0
Aug 21 20:07:07.464: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:08.463: INFO: Number of nodes with available pods: 0
Aug 21 20:07:08.463: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:09.462: INFO: Number of nodes with available pods: 0
Aug 21 20:07:09.462: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:07:10.462: INFO: Number of nodes with available pods: 1
Aug 21 20:07:10.462: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9487, will wait for the garbage collector to delete the pods
Aug 21 20:07:10.539: INFO: Deleting DaemonSet.extensions daemon-set took: 14.051527ms
Aug 21 20:07:10.939: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.367517ms
Aug 21 20:07:18.144: INFO: Number of nodes with available pods: 0
Aug 21 20:07:18.144: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 20:07:18.147: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9487/daemonsets","resourceVersion":"139236"},"items":null}

Aug 21 20:07:18.151: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9487/pods","resourceVersion":"139236"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:07:18.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9487" for this suite.
Aug 21 20:07:24.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:07:24.333: INFO: namespace daemonsets-9487 deletion completed in 6.151153113s

â€¢ [SLOW TEST:29.162 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:07:24.333: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 21 20:07:29.076: INFO: Successfully updated pod "annotationupdate4a9e717e-c44f-11e9-8a5f-26f602588652"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:07:31.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8545" for this suite.
Aug 21 20:07:53.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:07:53.276: INFO: namespace downward-api-8545 deletion completed in 22.157175703s

â€¢ [SLOW TEST:28.944 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:07:53.277: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7070
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0821 20:08:03.478560      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 20:08:03.478: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:08:03.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7070" for this suite.
Aug 21 20:08:09.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:08:09.626: INFO: namespace gc-7070 deletion completed in 6.142194697s

â€¢ [SLOW TEST:16.349 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:08:09.627: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-659e0903-c44f-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:08:09.802: INFO: Waiting up to 5m0s for pod "pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652" in namespace "secrets-9360" to be "success or failure"
Aug 21 20:08:09.815: INFO: Pod "pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 12.653413ms
Aug 21 20:08:11.822: INFO: Pod "pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019761252s
STEP: Saw pod success
Aug 21 20:08:11.822: INFO: Pod "pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:08:11.827: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:08:11.859: INFO: Waiting for pod pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652 to disappear
Aug 21 20:08:11.864: INFO: Pod pod-secrets-659f20e2-c44f-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:08:11.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9360" for this suite.
Aug 21 20:08:17.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:08:18.025: INFO: namespace secrets-9360 deletion completed in 6.154949943s

â€¢ [SLOW TEST:8.399 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:08:18.025: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4736
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 20:08:18.193: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 20:08:42.382: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.38.152:8080/dial?request=hostName&protocol=http&host=10.200.49.180&port=8080&tries=1'] Namespace:pod-network-test-4736 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:08:42.383: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:08:42.526: INFO: Waiting for endpoints: map[]
Aug 21 20:08:42.532: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.38.152:8080/dial?request=hostName&protocol=http&host=10.200.89.126&port=8080&tries=1'] Namespace:pod-network-test-4736 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:08:42.532: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:08:42.679: INFO: Waiting for endpoints: map[]
Aug 21 20:08:42.685: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.38.152:8080/dial?request=hostName&protocol=http&host=10.200.38.151&port=8080&tries=1'] Namespace:pod-network-test-4736 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:08:42.685: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:08:42.819: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:08:42.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4736" for this suite.
Aug 21 20:09:04.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:09:04.975: INFO: namespace pod-network-test-4736 deletion completed in 22.147938521s

â€¢ [SLOW TEST:46.949 seconds]
[sig-network] Networking
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:09:04.978: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3312
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 20:09:05.151: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 20:09:27.306: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.38.153:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:09:27.306: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:09:27.484: INFO: Found all expected endpoints: [netserver-0]
Aug 21 20:09:27.491: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.89.127:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:09:27.491: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:09:27.627: INFO: Found all expected endpoints: [netserver-1]
Aug 21 20:09:27.633: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.49.181:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:09:27.633: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:09:27.767: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:09:27.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3312" for this suite.
Aug 21 20:09:49.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:09:49.939: INFO: namespace pod-network-test-3312 deletion completed in 22.166909787s

â€¢ [SLOW TEST:44.961 seconds]
[sig-network] Networking
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:09:49.942: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7187.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7187.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 21 20:09:54.196: INFO: DNS probes using dns-7187/dns-test-a16bf267-c44f-11e9-8a5f-26f602588652 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:09:54.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7187" for this suite.
Aug 21 20:10:00.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:10:00.393: INFO: namespace dns-7187 deletion completed in 6.168171932s

â€¢ [SLOW TEST:10.451 seconds]
[sig-network] DNS
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:10:00.399: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 21 20:10:00.569: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9095,SelfLink:/api/v1/namespaces/watch-9095/configmaps/e2e-watch-test-watch-closed,UID:a7a576a6-c44f-11e9-b964-005056a55cb1,ResourceVersion:139854,Generation:0,CreationTimestamp:2019-08-21 20:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 20:10:00.569: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9095,SelfLink:/api/v1/namespaces/watch-9095/configmaps/e2e-watch-test-watch-closed,UID:a7a576a6-c44f-11e9-b964-005056a55cb1,ResourceVersion:139855,Generation:0,CreationTimestamp:2019-08-21 20:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 21 20:10:00.587: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9095,SelfLink:/api/v1/namespaces/watch-9095/configmaps/e2e-watch-test-watch-closed,UID:a7a576a6-c44f-11e9-b964-005056a55cb1,ResourceVersion:139856,Generation:0,CreationTimestamp:2019-08-21 20:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 20:10:00.587: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9095,SelfLink:/api/v1/namespaces/watch-9095/configmaps/e2e-watch-test-watch-closed,UID:a7a576a6-c44f-11e9-b964-005056a55cb1,ResourceVersion:139857,Generation:0,CreationTimestamp:2019-08-21 20:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:10:00.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9095" for this suite.
Aug 21 20:10:06.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:10:06.740: INFO: namespace watch-9095 deletion completed in 6.145374163s

â€¢ [SLOW TEST:6.342 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:10:06.741: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:10:06.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 version --client'
Aug 21 20:10:06.975: INFO: stderr: ""
Aug 21 20:10:06.975: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.5\", GitCommit:\"0e9fcb426b100a2aea5ed5c25b3d8cfbb01a8acf\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:21:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 21 20:10:06.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-7890'
Aug 21 20:10:07.277: INFO: stderr: ""
Aug 21 20:10:07.277: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 21 20:10:07.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-7890'
Aug 21 20:10:07.563: INFO: stderr: ""
Aug 21 20:10:07.563: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 20:10:08.568: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:08.568: INFO: Found 0 / 1
Aug 21 20:10:09.568: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:09.568: INFO: Found 1 / 1
Aug 21 20:10:09.568: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 20:10:09.572: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:09.572: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 20:10:09.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 describe pod redis-master-hbhfw --namespace=kubectl-7890'
Aug 21 20:10:09.702: INFO: stderr: ""
Aug 21 20:10:09.702: INFO: stdout: "Name:               redis-master-hbhfw\nNamespace:          kubectl-7890\nPriority:           0\nPriorityClassName:  <none>\nNode:               978c34ce-e296-4689-bf73-826c8c556b20/10.85.21.98\nStart Time:         Wed, 21 Aug 2019 20:10:07 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 10.200.38.156\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://0a2cc51ddd77b08bc23310b5b3a286f0b6bafee2a75bfeded0b16c60b9158cf7\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 21 Aug 2019 20:10:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-b9cn4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-b9cn4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b9cn4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  2s    default-scheduler                              Successfully assigned kubectl-7890/redis-master-hbhfw to 978c34ce-e296-4689-bf73-826c8c556b20\n  Normal  Pulled     1s    kubelet, 978c34ce-e296-4689-bf73-826c8c556b20  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 978c34ce-e296-4689-bf73-826c8c556b20  Created container redis-master\n  Normal  Started    1s    kubelet, 978c34ce-e296-4689-bf73-826c8c556b20  Started container redis-master\n"
Aug 21 20:10:09.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 describe rc redis-master --namespace=kubectl-7890'
Aug 21 20:10:09.834: INFO: stderr: ""
Aug 21 20:10:09.834: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7890\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-hbhfw\n"
Aug 21 20:10:09.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 describe service redis-master --namespace=kubectl-7890'
Aug 21 20:10:09.954: INFO: stderr: ""
Aug 21 20:10:09.954: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7890\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.225\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.200.38.156:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 21 20:10:09.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 describe node 978c34ce-e296-4689-bf73-826c8c556b20'
Aug 21 20:10:10.103: INFO: stderr: ""
Aug 21 20:10:10.103: INFO: stdout: "Name:               978c34ce-e296-4689-bf73-826c8c556b20\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=7fdbc434-a959-49bd-ae5c-95ab54767eea\n                    bosh.zone=default\n                    failure-domain.beta.kubernetes.io/zone=default\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.85.21.98\n                    kubernetes.io/os=linux\n                    pks-system/cluster.name=9343ce7e-5572-462c-a5d6-6e0f94b29fd8.internal\n                    pks-system/cluster.uuid=service-instance_3c19192b-3b12-4104-9e40-b863ed9f261d\n                    spec.ip=10.85.21.98\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 21 Aug 2019 02:11:48 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 21 Aug 2019 20:09:44 +0000   Wed, 21 Aug 2019 02:11:48 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 21 Aug 2019 20:09:44 +0000   Wed, 21 Aug 2019 02:11:48 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 21 Aug 2019 20:09:44 +0000   Wed, 21 Aug 2019 02:11:48 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 21 Aug 2019 20:09:44 +0000   Wed, 21 Aug 2019 02:11:48 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.85.21.98\n  InternalIP:  10.85.21.98\n  Hostname:    10.85.21.98\nCapacity:\n cpu:                2\n ephemeral-storage:  28917748Ki\n hugepages-2Mi:      0\n memory:             4039960Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  26650596513\n hugepages-2Mi:      0\n memory:             3937560Ki\n pods:               110\nSystem Info:\n Machine ID:                 1da185012fe239e9cec683c499cbfa23\n System UUID:                4225B08C-5D2B-F5D3-6359-ECA12D801DE3\n Boot ID:                    0f0f47b4-a2f6-4bed-8e74-686d1aeaff89\n Kernel Version:             4.15.0-55-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.8\n Kubelet Version:            v1.14.5\n Kube-Proxy Version:         v1.14.5\nProviderID:                  vsphere://4225b08c-5d2b-f5d3-6359-eca12d801de3\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-xlph9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                coredns-95489c5c9-8llvk                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     17h\n  kube-system                metrics-server-867b8fdb7d-j7dsn                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         17h\n  kubectl-7890               redis-master-hbhfw                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  pks-system                 event-controller-646d78b9b8-tjz2b                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         17h\n  pks-system                 fluent-bit-jxvvq                                           0 (0%)        0 (0%)      100Mi (2%)       100Mi (2%)     17h\n  pks-system                 node-exporter-78dpq                                        10m (0%)      10m (0%)    50Mi (1%)        50Mi (1%)      17h\n  pks-system                 telegraf-l2x6l                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         17h\n  pks-system                 telemetry-agent-858446f4ff-m2sfm                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         17h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                110m (5%)   10m (0%)\n  memory             220Mi (5%)  320Mi (8%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug 21 20:10:10.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 describe namespace kubectl-7890'
Aug 21 20:10:10.235: INFO: stderr: ""
Aug 21 20:10:10.235: INFO: stdout: "Name:         kubectl-7890\nLabels:       e2e-framework=kubectl\n              e2e-run=d8789374-c448-11e9-8a5f-26f602588652\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:10:10.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7890" for this suite.
Aug 21 20:10:32.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:10:32.400: INFO: namespace kubectl-7890 deletion completed in 22.158789374s

â€¢ [SLOW TEST:25.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:10:32.401: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9017
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-bab79499-c44f-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:10:32.572: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652" in namespace "projected-9017" to be "success or failure"
Aug 21 20:10:32.584: INFO: Pod "pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 12.331688ms
Aug 21 20:10:34.593: INFO: Pod "pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020803375s
Aug 21 20:10:36.598: INFO: Pod "pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026219636s
STEP: Saw pod success
Aug 21 20:10:36.598: INFO: Pod "pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:10:36.602: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:10:36.636: INFO: Waiting for pod pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652 to disappear
Aug 21 20:10:36.640: INFO: Pod pod-projected-configmaps-bab8951a-c44f-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:10:36.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9017" for this suite.
Aug 21 20:10:42.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:10:42.791: INFO: namespace projected-9017 deletion completed in 6.145540285s

â€¢ [SLOW TEST:10.390 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:10:42.791: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1259
STEP: creating an rc
Aug 21 20:10:42.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-72'
Aug 21 20:10:43.246: INFO: stderr: ""
Aug 21 20:10:43.246: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Aug 21 20:10:44.253: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:44.253: INFO: Found 0 / 1
Aug 21 20:10:45.252: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:45.252: INFO: Found 1 / 1
Aug 21 20:10:45.252: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 20:10:45.257: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 20:10:45.257: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 21 20:10:45.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 logs redis-master-6jglq redis-master --namespace=kubectl-72'
Aug 21 20:10:45.379: INFO: stderr: ""
Aug 21 20:10:45.379: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 20:10:44.431 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 20:10:44.431 # Server started, Redis version 3.2.12\n1:M 21 Aug 20:10:44.432 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 20:10:44.432 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 21 20:10:45.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 log redis-master-6jglq redis-master --namespace=kubectl-72 --tail=1'
Aug 21 20:10:45.533: INFO: stderr: ""
Aug 21 20:10:45.533: INFO: stdout: "1:M 21 Aug 20:10:44.432 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 21 20:10:45.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 log redis-master-6jglq redis-master --namespace=kubectl-72 --limit-bytes=1'
Aug 21 20:10:45.689: INFO: stderr: ""
Aug 21 20:10:45.689: INFO: stdout: " "
STEP: exposing timestamps
Aug 21 20:10:45.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 log redis-master-6jglq redis-master --namespace=kubectl-72 --tail=1 --timestamps'
Aug 21 20:10:45.821: INFO: stderr: ""
Aug 21 20:10:45.821: INFO: stdout: "2019-08-21T20:10:44.432918228Z 1:M 21 Aug 20:10:44.432 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 21 20:10:48.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 log redis-master-6jglq redis-master --namespace=kubectl-72 --since=1s'
Aug 21 20:10:48.439: INFO: stderr: ""
Aug 21 20:10:48.439: INFO: stdout: ""
Aug 21 20:10:48.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 log redis-master-6jglq redis-master --namespace=kubectl-72 --since=24h'
Aug 21 20:10:48.570: INFO: stderr: ""
Aug 21 20:10:48.570: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 20:10:44.431 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 20:10:44.431 # Server started, Redis version 3.2.12\n1:M 21 Aug 20:10:44.432 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 20:10:44.432 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1265
STEP: using delete to clean up resources
Aug 21 20:10:48.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-72'
Aug 21 20:10:48.683: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:10:48.683: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 21 20:10:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=nginx --no-headers --namespace=kubectl-72'
Aug 21 20:10:48.806: INFO: stderr: "No resources found.\n"
Aug 21 20:10:48.806: INFO: stdout: ""
Aug 21 20:10:48.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=nginx --namespace=kubectl-72 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:10:48.896: INFO: stderr: ""
Aug 21 20:10:48.896: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:10:48.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-72" for this suite.
Aug 21 20:11:10.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:11:11.061: INFO: namespace kubectl-72 deletion completed in 22.156184579s

â€¢ [SLOW TEST:28.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:11:11.065: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d1c31fe2-c44f-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:11:11.236: INFO: Waiting up to 5m0s for pod "pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652" in namespace "secrets-9733" to be "success or failure"
Aug 21 20:11:11.246: INFO: Pod "pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 10.385678ms
Aug 21 20:11:13.253: INFO: Pod "pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016688233s
STEP: Saw pod success
Aug 21 20:11:13.253: INFO: Pod "pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:11:13.257: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652 container secret-env-test: <nil>
STEP: delete the pod
Aug 21 20:11:13.290: INFO: Waiting for pod pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652 to disappear
Aug 21 20:11:13.294: INFO: Pod pod-secrets-d1c41cd1-c44f-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:11:13.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9733" for this suite.
Aug 21 20:11:19.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:11:19.462: INFO: namespace secrets-9733 deletion completed in 6.162754445s

â€¢ [SLOW TEST:8.397 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:11:19.467: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1837
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Aug 21 20:11:19.647: INFO: Found 0 stateful pods, waiting for 3
Aug 21 20:11:29.654: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:11:29.654: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:11:29.654: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:11:29.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-1837 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:11:29.921: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:11:29.921: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:11:29.921: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 21 20:11:39.968: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 21 20:11:50.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-1837 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 20:11:50.266: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 20:11:50.266: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 20:11:50.266: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 20:12:00.301: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:12:00.301: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:00.301: INFO: Waiting for Pod statefulset-1837/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:00.301: INFO: Waiting for Pod statefulset-1837/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:10.312: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:12:10.312: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:10.312: INFO: Waiting for Pod statefulset-1837/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:20.320: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:12:20.321: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:12:30.313: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
STEP: Rolling back to a previous revision
Aug 21 20:12:40.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-1837 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 20:12:40.553: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 21 20:12:40.553: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 20:12:40.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 20:12:50.599: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 21 20:13:00.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 exec --namespace=statefulset-1837 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 20:13:00.865: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 21 20:13:00.865: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 20:13:00.865: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 20:13:10.896: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:13:10.897: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 21 20:13:10.897: INFO: Waiting for Pod statefulset-1837/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 21 20:13:10.897: INFO: Waiting for Pod statefulset-1837/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 21 20:13:20.907: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:13:20.907: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 21 20:13:20.907: INFO: Waiting for Pod statefulset-1837/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 21 20:13:30.911: INFO: Waiting for StatefulSet statefulset-1837/ss2 to complete update
Aug 21 20:13:30.911: INFO: Waiting for Pod statefulset-1837/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 20:13:40.906: INFO: Deleting all statefulset in ns statefulset-1837
Aug 21 20:13:40.910: INFO: Scaling statefulset ss2 to 0
Aug 21 20:14:10.943: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:14:10.947: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:14:10.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1837" for this suite.
Aug 21 20:14:16.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:14:17.119: INFO: namespace statefulset-1837 deletion completed in 6.137789058s

â€¢ [SLOW TEST:177.652 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:14:17.123: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-40a9c34b-c450-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:14:17.296: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652" in namespace "projected-7631" to be "success or failure"
Aug 21 20:14:17.310: INFO: Pod "pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 13.629057ms
Aug 21 20:14:19.315: INFO: Pod "pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652": Phase="Running", Reason="", readiness=true. Elapsed: 2.019199748s
Aug 21 20:14:21.322: INFO: Pod "pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025282742s
STEP: Saw pod success
Aug 21 20:14:21.322: INFO: Pod "pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:14:21.328: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:14:21.367: INFO: Waiting for pod pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:14:21.370: INFO: Pod pod-projected-secrets-40aaabb5-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:14:21.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7631" for this suite.
Aug 21 20:14:27.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:14:27.533: INFO: namespace projected-7631 deletion completed in 6.156045484s

â€¢ [SLOW TEST:10.411 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:14:27.536: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 21 20:14:27.708: INFO: Waiting up to 5m0s for pod "downward-api-46def2b1-c450-11e9-8a5f-26f602588652" in namespace "downward-api-8966" to be "success or failure"
Aug 21 20:14:27.716: INFO: Pod "downward-api-46def2b1-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.543151ms
Aug 21 20:14:29.723: INFO: Pod "downward-api-46def2b1-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014651893s
STEP: Saw pod success
Aug 21 20:14:29.723: INFO: Pod "downward-api-46def2b1-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:14:29.727: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downward-api-46def2b1-c450-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:14:29.757: INFO: Waiting for pod downward-api-46def2b1-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:14:29.760: INFO: Pod downward-api-46def2b1-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:14:29.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8966" for this suite.
Aug 21 20:14:35.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:14:35.912: INFO: namespace downward-api-8966 deletion completed in 6.145241671s

â€¢ [SLOW TEST:8.376 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:14:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4800
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-4bdf20bb-c450-11e9-8a5f-26f602588652
STEP: Creating configMap with name cm-test-opt-upd-4bdf2209-c450-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4bdf20bb-c450-11e9-8a5f-26f602588652
STEP: Updating configmap cm-test-opt-upd-4bdf2209-c450-11e9-8a5f-26f602588652
STEP: Creating configMap with name cm-test-opt-create-4bdf2241-c450-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:14:40.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4800" for this suite.
Aug 21 20:15:02.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:15:02.379: INFO: namespace configmap-4800 deletion completed in 22.15841215s

â€¢ [SLOW TEST:26.467 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:15:02.380: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-520
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 21 20:15:02.561: INFO: Waiting up to 5m0s for pod "pod-5ba5035d-c450-11e9-8a5f-26f602588652" in namespace "emptydir-520" to be "success or failure"
Aug 21 20:15:02.573: INFO: Pod "pod-5ba5035d-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 11.787693ms
Aug 21 20:15:04.579: INFO: Pod "pod-5ba5035d-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017948772s
STEP: Saw pod success
Aug 21 20:15:04.579: INFO: Pod "pod-5ba5035d-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:15:04.583: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-5ba5035d-c450-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:15:04.613: INFO: Waiting for pod pod-5ba5035d-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:15:04.617: INFO: Pod pod-5ba5035d-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:15:04.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-520" for this suite.
Aug 21 20:15:10.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:15:10.764: INFO: namespace emptydir-520 deletion completed in 6.141737894s

â€¢ [SLOW TEST:8.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:15:10.767: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 20:15:10.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3692'
Aug 21 20:15:11.025: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 20:15:11.025: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 21 20:15:11.042: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-w9bgs]
Aug 21 20:15:11.042: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-w9bgs" in namespace "kubectl-3692" to be "running and ready"
Aug 21 20:15:11.056: INFO: Pod "e2e-test-nginx-rc-w9bgs": Phase="Pending", Reason="", readiness=false. Elapsed: 14.097888ms
Aug 21 20:15:13.061: INFO: Pod "e2e-test-nginx-rc-w9bgs": Phase="Running", Reason="", readiness=true. Elapsed: 2.019726976s
Aug 21 20:15:13.061: INFO: Pod "e2e-test-nginx-rc-w9bgs" satisfied condition "running and ready"
Aug 21 20:15:13.061: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-w9bgs]
Aug 21 20:15:13.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 logs rc/e2e-test-nginx-rc --namespace=kubectl-3692'
Aug 21 20:15:13.199: INFO: stderr: ""
Aug 21 20:15:13.199: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1428
Aug 21 20:15:13.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete rc e2e-test-nginx-rc --namespace=kubectl-3692'
Aug 21 20:15:13.300: INFO: stderr: ""
Aug 21 20:15:13.300: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:15:13.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3692" for this suite.
Aug 21 20:15:35.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:15:35.451: INFO: namespace kubectl-3692 deletion completed in 22.145582728s

â€¢ [SLOW TEST:24.685 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:15:35.452: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652
Aug 21 20:15:35.629: INFO: Pod name my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652: Found 0 pods out of 1
Aug 21 20:15:40.636: INFO: Pod name my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652: Found 1 pods out of 1
Aug 21 20:15:40.637: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652" are running
Aug 21 20:15:40.643: INFO: Pod "my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652-pbmcr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 20:15:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 20:15:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 20:15:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 20:15:35 +0000 UTC Reason: Message:}])
Aug 21 20:15:40.643: INFO: Trying to dial the pod
Aug 21 20:15:45.658: INFO: Controller my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652: Got expected result from replica 1 [my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652-pbmcr]: "my-hostname-basic-6f5a9ffe-c450-11e9-8a5f-26f602588652-pbmcr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:15:45.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6610" for this suite.
Aug 21 20:15:51.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:15:51.795: INFO: namespace replication-controller-6610 deletion completed in 6.130235809s

â€¢ [SLOW TEST:16.342 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:15:51.795: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:16:51.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1653" for this suite.
Aug 21 20:17:13.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:17:14.111: INFO: namespace container-probe-1653 deletion completed in 22.139550178s

â€¢ [SLOW TEST:82.316 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:17:14.112: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6919
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 21 20:17:14.284: INFO: Waiting up to 5m0s for pod "pod-aa28913a-c450-11e9-8a5f-26f602588652" in namespace "emptydir-6919" to be "success or failure"
Aug 21 20:17:14.293: INFO: Pod "pod-aa28913a-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.628896ms
Aug 21 20:17:16.299: INFO: Pod "pod-aa28913a-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014527454s
STEP: Saw pod success
Aug 21 20:17:16.299: INFO: Pod "pod-aa28913a-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:17:16.303: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-aa28913a-c450-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:17:16.332: INFO: Waiting for pod pod-aa28913a-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:17:16.335: INFO: Pod pod-aa28913a-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:17:16.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6919" for this suite.
Aug 21 20:17:22.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:17:22.489: INFO: namespace emptydir-6919 deletion completed in 6.148513888s

â€¢ [SLOW TEST:8.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:17:22.493: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-af268edf-c450-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:17:22.665: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652" in namespace "projected-1443" to be "success or failure"
Aug 21 20:17:22.678: INFO: Pod "pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 12.630589ms
Aug 21 20:17:24.684: INFO: Pod "pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019246374s
STEP: Saw pod success
Aug 21 20:17:24.684: INFO: Pod "pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:17:24.688: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:17:24.718: INFO: Waiting for pod pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:17:24.721: INFO: Pod pod-projected-configmaps-af27660f-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:17:24.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1443" for this suite.
Aug 21 20:17:30.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:17:30.882: INFO: namespace projected-1443 deletion completed in 6.155464851s

â€¢ [SLOW TEST:8.390 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:17:30.885: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:17:31.050: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652" in namespace "downward-api-4998" to be "success or failure"
Aug 21 20:17:31.074: INFO: Pod "downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 24.14275ms
Aug 21 20:17:33.081: INFO: Pod "downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030679344s
STEP: Saw pod success
Aug 21 20:17:33.081: INFO: Pod "downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:17:33.086: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:17:33.118: INFO: Waiting for pod downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:17:33.122: INFO: Pod downwardapi-volume-b426cd7e-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:17:33.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4998" for this suite.
Aug 21 20:17:39.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:17:39.277: INFO: namespace downward-api-4998 deletion completed in 6.150499711s

â€¢ [SLOW TEST:8.392 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:17:39.278: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-hzd2
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 20:17:39.463: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hzd2" in namespace "subpath-4289" to be "success or failure"
Aug 21 20:17:39.472: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.815141ms
Aug 21 20:17:41.479: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015210286s
Aug 21 20:17:43.485: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 4.021153559s
Aug 21 20:17:45.491: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 6.027065947s
Aug 21 20:17:47.498: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 8.034040514s
Aug 21 20:17:49.503: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 10.039230243s
Aug 21 20:17:51.509: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 12.045348504s
Aug 21 20:17:53.515: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 14.051419201s
Aug 21 20:17:55.521: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 16.057226447s
Aug 21 20:17:57.527: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 18.063779899s
Aug 21 20:17:59.533: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 20.069642884s
Aug 21 20:18:01.539: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Running", Reason="", readiness=true. Elapsed: 22.075467273s
Aug 21 20:18:03.545: INFO: Pod "pod-subpath-test-configmap-hzd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.081501651s
STEP: Saw pod success
Aug 21 20:18:03.545: INFO: Pod "pod-subpath-test-configmap-hzd2" satisfied condition "success or failure"
Aug 21 20:18:03.549: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-subpath-test-configmap-hzd2 container test-container-subpath-configmap-hzd2: <nil>
STEP: delete the pod
Aug 21 20:18:03.580: INFO: Waiting for pod pod-subpath-test-configmap-hzd2 to disappear
Aug 21 20:18:03.584: INFO: Pod pod-subpath-test-configmap-hzd2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hzd2
Aug 21 20:18:03.584: INFO: Deleting pod "pod-subpath-test-configmap-hzd2" in namespace "subpath-4289"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:03.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4289" for this suite.
Aug 21 20:18:09.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:09.750: INFO: namespace subpath-4289 deletion completed in 6.155689183s

â€¢ [SLOW TEST:30.472 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:09.752: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:18:09.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 version'
Aug 21 20:18:10.020: INFO: stderr: ""
Aug 21 20:18:10.020: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.5\", GitCommit:\"0e9fcb426b100a2aea5ed5c25b3d8cfbb01a8acf\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:21:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.5\", GitCommit:\"0e9fcb426b100a2aea5ed5c25b3d8cfbb01a8acf\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:13:08Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:10.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2012" for this suite.
Aug 21 20:18:16.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:16.175: INFO: namespace kubectl-2012 deletion completed in 6.145208943s

â€¢ [SLOW TEST:6.423 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:16.176: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5200
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 21 20:18:16.346: INFO: Waiting up to 5m0s for pod "pod-cf266d6e-c450-11e9-8a5f-26f602588652" in namespace "emptydir-5200" to be "success or failure"
Aug 21 20:18:16.353: INFO: Pod "pod-cf266d6e-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.502378ms
Aug 21 20:18:18.359: INFO: Pod "pod-cf266d6e-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012378433s
STEP: Saw pod success
Aug 21 20:18:18.359: INFO: Pod "pod-cf266d6e-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:18:18.362: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-cf266d6e-c450-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:18:18.391: INFO: Waiting for pod pod-cf266d6e-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:18:18.395: INFO: Pod pod-cf266d6e-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:18.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5200" for this suite.
Aug 21 20:18:24.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:24.545: INFO: namespace emptydir-5200 deletion completed in 6.145080126s

â€¢ [SLOW TEST:8.369 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:24.547: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 21 20:18:24.697: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:28.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9289" for this suite.
Aug 21 20:18:34.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:34.812: INFO: namespace init-container-9289 deletion completed in 6.134372048s

â€¢ [SLOW TEST:10.266 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:34.815: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:18:34.977: INFO: (0) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.877709ms)
Aug 21 20:18:34.982: INFO: (1) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.793993ms)
Aug 21 20:18:34.987: INFO: (2) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.726712ms)
Aug 21 20:18:34.991: INFO: (3) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.32316ms)
Aug 21 20:18:34.996: INFO: (4) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.710012ms)
Aug 21 20:18:35.001: INFO: (5) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.676669ms)
Aug 21 20:18:35.006: INFO: (6) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.315197ms)
Aug 21 20:18:35.010: INFO: (7) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.183221ms)
Aug 21 20:18:35.014: INFO: (8) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.506649ms)
Aug 21 20:18:35.019: INFO: (9) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.055903ms)
Aug 21 20:18:35.024: INFO: (10) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.1962ms)
Aug 21 20:18:35.030: INFO: (11) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.307268ms)
Aug 21 20:18:35.035: INFO: (12) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.985654ms)
Aug 21 20:18:35.040: INFO: (13) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.785587ms)
Aug 21 20:18:35.045: INFO: (14) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.401587ms)
Aug 21 20:18:35.050: INFO: (15) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.824483ms)
Aug 21 20:18:35.055: INFO: (16) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.570902ms)
Aug 21 20:18:35.060: INFO: (17) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.586134ms)
Aug 21 20:18:35.065: INFO: (18) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.06558ms)
Aug 21 20:18:35.069: INFO: (19) /api/v1/nodes/978c34ce-e296-4689-bf73-826c8c556b20:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.384604ms)
[AfterEach] version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:35.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8304" for this suite.
Aug 21 20:18:41.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:41.210: INFO: namespace proxy-8304 deletion completed in 6.135807704s

â€¢ [SLOW TEST:6.396 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:41.217: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 21 20:18:41.387: INFO: Waiting up to 5m0s for pod "downward-api-de1380e1-c450-11e9-8a5f-26f602588652" in namespace "downward-api-891" to be "success or failure"
Aug 21 20:18:41.401: INFO: Pod "downward-api-de1380e1-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 13.87267ms
Aug 21 20:18:43.407: INFO: Pod "downward-api-de1380e1-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019429537s
STEP: Saw pod success
Aug 21 20:18:43.407: INFO: Pod "downward-api-de1380e1-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:18:43.417: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downward-api-de1380e1-c450-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:18:43.450: INFO: Waiting for pod downward-api-de1380e1-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:18:43.458: INFO: Pod downward-api-de1380e1-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:43.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-891" for this suite.
Aug 21 20:18:49.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:49.624: INFO: namespace downward-api-891 deletion completed in 6.158891866s

â€¢ [SLOW TEST:8.408 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:49.624: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3683
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 21 20:18:49.796: INFO: Waiting up to 5m0s for pod "downward-api-e316835a-c450-11e9-8a5f-26f602588652" in namespace "downward-api-3683" to be "success or failure"
Aug 21 20:18:49.800: INFO: Pod "downward-api-e316835a-c450-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 3.783579ms
Aug 21 20:18:51.805: INFO: Pod "downward-api-e316835a-c450-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008791299s
STEP: Saw pod success
Aug 21 20:18:51.805: INFO: Pod "downward-api-e316835a-c450-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:18:51.809: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downward-api-e316835a-c450-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:18:51.840: INFO: Waiting for pod downward-api-e316835a-c450-11e9-8a5f-26f602588652 to disappear
Aug 21 20:18:51.844: INFO: Pod downward-api-e316835a-c450-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:18:51.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3683" for this suite.
Aug 21 20:18:57.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:18:58.001: INFO: namespace downward-api-3683 deletion completed in 6.151496867s

â€¢ [SLOW TEST:8.376 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:18:58.001: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8764
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-e8157771-c450-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e8157771-c450-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:19:02.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8764" for this suite.
Aug 21 20:19:24.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:19:24.423: INFO: namespace configmap-8764 deletion completed in 22.169313368s

â€¢ [SLOW TEST:26.422 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:19:24.427: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 21 20:19:28.680: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 20:19:28.684: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 20:19:30.685: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 20:19:30.693: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 20:19:32.685: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 20:19:32.691: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 20:19:34.685: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 20:19:34.694: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 20:19:36.685: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 20:19:36.691: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:19:36.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3769" for this suite.
Aug 21 20:19:58.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:19:58.864: INFO: namespace container-lifecycle-hook-3769 deletion completed in 22.14720189s

â€¢ [SLOW TEST:34.437 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:19:58.867: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5036
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:19:59.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652" in namespace "downward-api-5036" to be "success or failure"
Aug 21 20:19:59.057: INFO: Pod "downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 14.104803ms
Aug 21 20:20:01.064: INFO: Pod "downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020502618s
STEP: Saw pod success
Aug 21 20:20:01.064: INFO: Pod "downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:20:01.072: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:20:01.104: INFO: Waiting for pod downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:20:01.108: INFO: Pod downwardapi-volume-0c5c19a1-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:20:01.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5036" for this suite.
Aug 21 20:20:07.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:20:07.282: INFO: namespace downward-api-5036 deletion completed in 6.168434733s

â€¢ [SLOW TEST:8.415 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:20:07.284: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8654
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-8654
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8654 to expose endpoints map[]
Aug 21 20:20:07.462: INFO: successfully validated that service multi-endpoint-test in namespace services-8654 exposes endpoints map[] (6.526591ms elapsed)
STEP: Creating pod pod1 in namespace services-8654
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8654 to expose endpoints map[pod1:[100]]
Aug 21 20:20:09.504: INFO: successfully validated that service multi-endpoint-test in namespace services-8654 exposes endpoints map[pod1:[100]] (2.029732779s elapsed)
STEP: Creating pod pod2 in namespace services-8654
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8654 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 21 20:20:11.579: INFO: successfully validated that service multi-endpoint-test in namespace services-8654 exposes endpoints map[pod1:[100] pod2:[101]] (2.062862501s elapsed)
STEP: Deleting pod pod1 in namespace services-8654
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8654 to expose endpoints map[pod2:[101]]
Aug 21 20:20:11.601: INFO: successfully validated that service multi-endpoint-test in namespace services-8654 exposes endpoints map[pod2:[101]] (13.056372ms elapsed)
STEP: Deleting pod pod2 in namespace services-8654
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8654 to expose endpoints map[]
Aug 21 20:20:11.618: INFO: successfully validated that service multi-endpoint-test in namespace services-8654 exposes endpoints map[] (5.288476ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:20:11.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8654" for this suite.
Aug 21 20:20:33.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:20:33.800: INFO: namespace services-8654 deletion completed in 22.15406311s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:26.517 seconds]
[sig-network] Services
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:20:33.801: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-212ef708-c451-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:20:33.981: INFO: Waiting up to 5m0s for pod "pod-secrets-21300fda-c451-11e9-8a5f-26f602588652" in namespace "secrets-4867" to be "success or failure"
Aug 21 20:20:33.995: INFO: Pod "pod-secrets-21300fda-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 13.492841ms
Aug 21 20:20:36.001: INFO: Pod "pod-secrets-21300fda-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019019529s
STEP: Saw pod success
Aug 21 20:20:36.001: INFO: Pod "pod-secrets-21300fda-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:20:36.005: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-21300fda-c451-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:20:36.038: INFO: Waiting for pod pod-secrets-21300fda-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:20:36.042: INFO: Pod pod-secrets-21300fda-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:20:36.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4867" for this suite.
Aug 21 20:20:42.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:20:42.196: INFO: namespace secrets-4867 deletion completed in 6.148917608s

â€¢ [SLOW TEST:8.395 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:20:42.198: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4663
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:20:42.367: INFO: Waiting up to 5m0s for pod "downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652" in namespace "projected-4663" to be "success or failure"
Aug 21 20:20:42.376: INFO: Pod "downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.794415ms
Aug 21 20:20:44.381: INFO: Pod "downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0141559s
STEP: Saw pod success
Aug 21 20:20:44.381: INFO: Pod "downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:20:44.385: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:20:44.423: INFO: Waiting for pod downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:20:44.427: INFO: Pod downwardapi-volume-262f7b0d-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:20:44.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4663" for this suite.
Aug 21 20:20:50.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:20:50.585: INFO: namespace projected-4663 deletion completed in 6.15104318s

â€¢ [SLOW TEST:8.387 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:20:50.585: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Aug 21 20:20:50.760: INFO: Waiting up to 5m0s for pod "client-containers-2b305ce7-c451-11e9-8a5f-26f602588652" in namespace "containers-8908" to be "success or failure"
Aug 21 20:20:50.775: INFO: Pod "client-containers-2b305ce7-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 14.046557ms
Aug 21 20:20:52.780: INFO: Pod "client-containers-2b305ce7-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01918656s
STEP: Saw pod success
Aug 21 20:20:52.780: INFO: Pod "client-containers-2b305ce7-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:20:52.784: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod client-containers-2b305ce7-c451-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:20:52.813: INFO: Waiting for pod client-containers-2b305ce7-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:20:52.817: INFO: Pod client-containers-2b305ce7-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:20:52.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8908" for this suite.
Aug 21 20:20:58.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:20:58.963: INFO: namespace containers-8908 deletion completed in 6.140244296s

â€¢ [SLOW TEST:8.379 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:20:58.969: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 21 20:21:01.674: INFO: Successfully updated pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652"
Aug 21 20:21:01.674: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652" in namespace "pods-4608" to be "terminated due to deadline exceeded"
Aug 21 20:21:01.682: INFO: Pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652": Phase="Running", Reason="", readiness=true. Elapsed: 7.976332ms
Aug 21 20:21:03.688: INFO: Pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652": Phase="Running", Reason="", readiness=true. Elapsed: 2.013761239s
Aug 21 20:21:05.694: INFO: Pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.019698261s
Aug 21 20:21:05.694: INFO: Pod "pod-update-activedeadlineseconds-302e468e-c451-11e9-8a5f-26f602588652" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:21:05.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4608" for this suite.
Aug 21 20:21:11.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:21:11.861: INFO: namespace pods-4608 deletion completed in 6.158244817s

â€¢ [SLOW TEST:12.893 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:21:11.864: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Aug 21 20:21:12.031: INFO: Waiting up to 5m0s for pod "client-containers-37ddcb98-c451-11e9-8a5f-26f602588652" in namespace "containers-4321" to be "success or failure"
Aug 21 20:21:12.039: INFO: Pod "client-containers-37ddcb98-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.177072ms
Aug 21 20:21:14.044: INFO: Pod "client-containers-37ddcb98-c451-11e9-8a5f-26f602588652": Phase="Running", Reason="", readiness=true. Elapsed: 2.012557293s
Aug 21 20:21:16.050: INFO: Pod "client-containers-37ddcb98-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018660559s
STEP: Saw pod success
Aug 21 20:21:16.050: INFO: Pod "client-containers-37ddcb98-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:21:16.055: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod client-containers-37ddcb98-c451-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:21:16.089: INFO: Waiting for pod client-containers-37ddcb98-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:21:16.092: INFO: Pod client-containers-37ddcb98-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:21:16.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4321" for this suite.
Aug 21 20:21:22.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:21:22.238: INFO: namespace containers-4321 deletion completed in 6.141349159s

â€¢ [SLOW TEST:10.375 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:21:22.238: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7520
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 21 20:21:22.408: INFO: Waiting up to 5m0s for pod "downward-api-3e0d784c-c451-11e9-8a5f-26f602588652" in namespace "downward-api-7520" to be "success or failure"
Aug 21 20:21:22.417: INFO: Pod "downward-api-3e0d784c-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.119721ms
Aug 21 20:21:24.423: INFO: Pod "downward-api-3e0d784c-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015206231s
STEP: Saw pod success
Aug 21 20:21:24.424: INFO: Pod "downward-api-3e0d784c-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:21:24.430: INFO: Trying to get logs from node f138d081-7db1-41cb-9804-f6d51b22765f pod downward-api-3e0d784c-c451-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:21:24.467: INFO: Waiting for pod downward-api-3e0d784c-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:21:24.479: INFO: Pod downward-api-3e0d784c-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:21:24.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7520" for this suite.
Aug 21 20:21:30.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:21:30.637: INFO: namespace downward-api-7520 deletion completed in 6.150512274s

â€¢ [SLOW TEST:8.398 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:21:30.637: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 21 20:21:34.874: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:34.878: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:36.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:36.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:38.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:38.886: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:40.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:40.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:42.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:42.886: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:44.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:44.886: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:46.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:46.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:48.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:48.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:50.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:50.888: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:52.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:52.889: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:54.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:54.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:56.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:56.885: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 20:21:58.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 20:21:58.884: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:21:58.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8066" for this suite.
Aug 21 20:22:20.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:22:21.049: INFO: namespace container-lifecycle-hook-8066 deletion completed in 22.147798396s

â€¢ [SLOW TEST:50.412 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:22:21.050: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 20:22:21.208: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 20:22:21.219: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 20:22:21.223: INFO:
Logging pods the kubelet thinks is on node 978c34ce-e296-4689-bf73-826c8c556b20 before test
Aug 21 20:22:21.232: INFO: coredns-95489c5c9-8llvk from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.232: INFO: 	Container coredns ready: true, restart count 0
Aug 21 20:22:21.232: INFO: event-controller-646d78b9b8-tjz2b from pks-system started at 2019-08-21 02:16:05 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.232: INFO: 	Container event-controller ready: true, restart count 0
Aug 21 20:22:21.233: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 20:22:21.233: INFO: node-exporter-78dpq from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 20:22:21.233: INFO: telegraf-l2x6l from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 20:22:21.233: INFO: telemetry-agent-858446f4ff-m2sfm from pks-system started at 2019-08-21 02:21:02 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container fluent-bit-billing ready: true, restart count 0
Aug 21 20:22:21.233: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Aug 21 20:22:21.233: INFO: fluent-bit-jxvvq from pks-system started at 2019-08-21 02:16:18 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 20:22:21.233: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 20:22:21.233: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 19:21:12 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 21 20:22:21.233: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-xlph9 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 20:22:21.233: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 20:22:21.233: INFO: metrics-server-867b8fdb7d-j7dsn from kube-system started at 2019-08-21 02:15:55 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.233: INFO: 	Container metrics-server ready: true, restart count 0
Aug 21 20:22:21.233: INFO:
Logging pods the kubelet thinks is on node ca867801-09fc-419b-a2c1-ae5752feb0ff before test
Aug 21 20:22:21.244: INFO: sink-controller-6774fd95f7-4xc2v from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container sink-controller ready: true, restart count 0
Aug 21 20:22:21.244: INFO: fluent-bit-9hsw7 from pks-system started at 2019-08-21 02:16:08 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 20:22:21.244: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 20:22:21.244: INFO: telegraf-z8mgq from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container telegraf ready: true, restart count 0
Aug 21 20:22:21.244: INFO: sonobuoy-e2e-job-b0f9cb20d3e8417a from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container e2e ready: true, restart count 0
Aug 21 20:22:21.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 20:22:21.244: INFO: coredns-95489c5c9-tc97f from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container coredns ready: true, restart count 0
Aug 21 20:22:21.244: INFO: wavefront-collector-848b9948f-6mgdc from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container wavefront-collector ready: true, restart count 0
Aug 21 20:22:21.244: INFO: node-exporter-dsw5w from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 20:22:21.244: INFO: kubernetes-dashboard-558689fc66-dl7vk from kube-system started at 2019-08-21 02:15:58 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 21 20:22:21.244: INFO: cert-generator-dea87263fc8e6d3a2a122f5f5e31b36afbeef369-xgx5b from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container cert-generator ready: false, restart count 0
Aug 21 20:22:21.244: INFO: validator-6b677f49d4-dsk52 from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container validator ready: true, restart count 0
Aug 21 20:22:21.244: INFO: kube-state-metrics-85bfc8cb86-hvpcs from pks-system started at 2019-08-21 02:18:27 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container addon-resizer ready: true, restart count 0
Aug 21 20:22:21.244: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 21 20:22:21.244: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-s8kz2 from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.244: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 20:22:21.244: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 20:22:21.244: INFO:
Logging pods the kubelet thinks is on node f138d081-7db1-41cb-9804-f6d51b22765f before test
Aug 21 20:22:21.256: INFO: sonobuoy-systemd-logs-daemon-set-0beabd41f4174020-lwcqg from heptio-sonobuoy started at 2019-08-21 19:21:13 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.256: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 20:22:21.256: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 20:22:21.256: INFO: observability-manager-6fff4d8d86-szpsb from pks-system started at 2019-08-21 02:16:01 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.256: INFO: 	Container observability-manager ready: true, restart count 0
Aug 21 20:22:21.257: INFO: coredns-95489c5c9-xrmnx from kube-system started at 2019-08-21 02:15:52 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.257: INFO: 	Container coredns ready: true, restart count 0
Aug 21 20:22:21.257: INFO: metric-controller-c998cb5bf-zl4n7 from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.257: INFO: 	Container metric-controller ready: true, restart count 0
Aug 21 20:22:21.257: INFO: fluent-bit-bnmmv from pks-system started at 2019-08-21 02:16:12 +0000 UTC (2 container statuses recorded)
Aug 21 20:22:21.257: INFO: 	Container fluent-bit ready: true, restart count 0
Aug 21 20:22:21.257: INFO: 	Container ghostunnel ready: true, restart count 0
Aug 21 20:22:21.258: INFO: wavefront-proxy-785c6f5c95-km2rx from pks-system started at 2019-08-21 02:18:26 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.258: INFO: 	Container wavefront-proxy ready: true, restart count 0
Aug 21 20:22:21.258: INFO: node-exporter-zx8fm from pks-system started at 2019-08-21 02:16:05 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.258: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Aug 21 20:22:21.258: INFO: telegraf-v5jgb from pks-system started at 2019-08-21 02:16:06 +0000 UTC (1 container statuses recorded)
Aug 21 20:22:21.258: INFO: 	Container telegraf ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event:
Type = [Warning], Name = [restricted-pod.15bd09ba55118acc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:22:22.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6252" for this suite.
Aug 21 20:22:28.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:22:28.451: INFO: namespace sched-pred-6252 deletion completed in 6.149672106s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.403 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:22:28.454: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8554
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:22:28.617: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:22:34.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8554" for this suite.
Aug 21 20:22:40.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:22:40.850: INFO: namespace custom-resource-definition-8554 deletion completed in 6.138963976s

â€¢ [SLOW TEST:12.396 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:22:40.850: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0821 20:23:11.616888      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 20:23:11.616: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:23:11.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1883" for this suite.
Aug 21 20:23:17.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:23:17.768: INFO: namespace gc-1883 deletion completed in 6.145450672s

â€¢ [SLOW TEST:36.918 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:23:17.769: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-82ed366b-c451-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:23:17.966: INFO: Waiting up to 5m0s for pod "pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652" in namespace "secrets-4629" to be "success or failure"
Aug 21 20:23:17.974: INFO: Pod "pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.869212ms
Aug 21 20:23:19.980: INFO: Pod "pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013967922s
STEP: Saw pod success
Aug 21 20:23:19.981: INFO: Pod "pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:23:19.985: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652 container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:23:20.042: INFO: Waiting for pod pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:23:20.046: INFO: Pod pod-secrets-82ee4809-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:23:20.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4629" for this suite.
Aug 21 20:23:26.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:23:26.192: INFO: namespace secrets-4629 deletion completed in 6.14142567s

â€¢ [SLOW TEST:8.423 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:23:26.193: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 21 20:23:30.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:30.428: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:32.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:32.437: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:34.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:34.436: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:36.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:36.434: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:38.429: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:38.435: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:40.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:40.434: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:42.429: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:42.434: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:44.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:44.434: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 20:23:46.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 20:23:46.434: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:23:46.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9937" for this suite.
Aug 21 20:24:08.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:24:08.601: INFO: namespace container-lifecycle-hook-9937 deletion completed in 22.161944651s

â€¢ [SLOW TEST:42.408 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:24:08.601: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:24:08.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652" in namespace "projected-992" to be "success or failure"
Aug 21 20:24:08.787: INFO: Pod "downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.892665ms
Aug 21 20:24:10.793: INFO: Pod "downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012057823s
Aug 21 20:24:12.799: INFO: Pod "downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018693938s
STEP: Saw pod success
Aug 21 20:24:12.799: INFO: Pod "downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:24:12.805: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:24:12.840: INFO: Waiting for pod downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:24:12.844: INFO: Pod downwardapi-volume-a137c4f4-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:24:12.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-992" for this suite.
Aug 21 20:24:18.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:24:19.011: INFO: namespace projected-992 deletion completed in 6.160683062s

â€¢ [SLOW TEST:10.410 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:24:19.013: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-a76b0c40-c451-11e9-8a5f-26f602588652
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:24:19.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4897" for this suite.
Aug 21 20:24:25.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:24:25.320: INFO: namespace configmap-4897 deletion completed in 6.141529256s

â€¢ [SLOW TEST:6.307 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:24:25.322: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 21 20:24:25.501: INFO: Waiting up to 5m0s for pod "pod-ab2ed980-c451-11e9-8a5f-26f602588652" in namespace "emptydir-5000" to be "success or failure"
Aug 21 20:24:25.508: INFO: Pod "pod-ab2ed980-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.6249ms
Aug 21 20:24:27.515: INFO: Pod "pod-ab2ed980-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013838044s
STEP: Saw pod success
Aug 21 20:24:27.515: INFO: Pod "pod-ab2ed980-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:24:27.519: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-ab2ed980-c451-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:24:27.548: INFO: Waiting for pod pod-ab2ed980-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:24:27.552: INFO: Pod pod-ab2ed980-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:24:27.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5000" for this suite.
Aug 21 20:24:33.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:24:33.699: INFO: namespace emptydir-5000 deletion completed in 6.141864611s

â€¢ [SLOW TEST:8.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:24:33.700: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Aug 21 20:24:33.855: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 21 20:24:33.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:34.933: INFO: stderr: ""
Aug 21 20:24:34.934: INFO: stdout: "service/redis-slave created\n"
Aug 21 20:24:34.936: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 21 20:24:34.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:35.175: INFO: stderr: ""
Aug 21 20:24:35.175: INFO: stdout: "service/redis-master created\n"
Aug 21 20:24:35.175: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 21 20:24:35.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:35.501: INFO: stderr: ""
Aug 21 20:24:35.501: INFO: stdout: "service/frontend created\n"
Aug 21 20:24:35.502: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 21 20:24:35.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:35.816: INFO: stderr: ""
Aug 21 20:24:35.816: INFO: stdout: "deployment.apps/frontend created\n"
Aug 21 20:24:35.816: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 21 20:24:35.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:36.124: INFO: stderr: ""
Aug 21 20:24:36.124: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 21 20:24:36.125: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 21 20:24:36.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-6227'
Aug 21 20:24:36.448: INFO: stderr: ""
Aug 21 20:24:36.448: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 21 20:24:36.448: INFO: Waiting for all frontend pods to be Running.
Aug 21 20:24:41.499: INFO: Waiting for frontend to serve content.
Aug 21 20:24:41.521: INFO: Trying to add a new entry to the guestbook.
Aug 21 20:24:41.542: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 21 20:24:41.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:41.686: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:41.686: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 20:24:41.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:41.823: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:41.823: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 20:24:41.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:41.955: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:41.955: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 20:24:41.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:42.104: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:42.104: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 20:24:42.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:42.231: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:42.231: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 20:24:42.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-6227'
Aug 21 20:24:42.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:24:42.348: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:24:42.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6227" for this suite.
Aug 21 20:25:28.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:25:28.526: INFO: namespace kubectl-6227 deletion completed in 46.168594461s

â€¢ [SLOW TEST:54.827 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:25:28.530: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-d0d97489-c451-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:25:28.696: INFO: Waiting up to 5m0s for pod "pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652" in namespace "configmap-7249" to be "success or failure"
Aug 21 20:25:28.704: INFO: Pod "pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.398072ms
Aug 21 20:25:30.710: INFO: Pod "pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014022772s
STEP: Saw pod success
Aug 21 20:25:30.710: INFO: Pod "pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:25:30.716: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:25:30.747: INFO: Waiting for pod pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:25:30.751: INFO: Pod pod-configmaps-d0da48a3-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:25:30.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7249" for this suite.
Aug 21 20:25:36.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:25:36.900: INFO: namespace configmap-7249 deletion completed in 6.14409787s

â€¢ [SLOW TEST:8.371 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:25:36.902: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Aug 21 20:25:37.967: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 21 20:25:40.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702015937, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702015937, loc:(*time.Location)(0x8a1d140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702015938, loc:(*time.Location)(0x8a1d140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702015937, loc:(*time.Location)(0x8a1d140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 20:25:43.088: INFO: Waited 1.03367361s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:25:43.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4686" for this suite.
Aug 21 20:25:49.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:25:49.851: INFO: namespace aggregator-4686 deletion completed in 6.226468556s

â€¢ [SLOW TEST:12.949 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:25:49.853: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 21 20:25:50.032: INFO: Waiting up to 5m0s for pod "downward-api-dd90874f-c451-11e9-8a5f-26f602588652" in namespace "downward-api-2208" to be "success or failure"
Aug 21 20:25:50.040: INFO: Pod "downward-api-dd90874f-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014101ms
Aug 21 20:25:52.046: INFO: Pod "downward-api-dd90874f-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014632793s
STEP: Saw pod success
Aug 21 20:25:52.048: INFO: Pod "downward-api-dd90874f-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:25:52.054: INFO: Trying to get logs from node f138d081-7db1-41cb-9804-f6d51b22765f pod downward-api-dd90874f-c451-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:25:52.090: INFO: Waiting for pod downward-api-dd90874f-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:25:52.094: INFO: Pod downward-api-dd90874f-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:25:52.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2208" for this suite.
Aug 21 20:25:58.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:25:58.246: INFO: namespace downward-api-2208 deletion completed in 6.147063081s

â€¢ [SLOW TEST:8.393 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:25:58.248: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e29149ff-c451-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:25:58.429: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652" in namespace "projected-1932" to be "success or failure"
Aug 21 20:25:58.435: INFO: Pod "pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.534685ms
Aug 21 20:26:00.441: INFO: Pod "pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012418258s
STEP: Saw pod success
Aug 21 20:26:00.442: INFO: Pod "pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:26:00.446: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:26:00.483: INFO: Waiting for pod pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652 to disappear
Aug 21 20:26:00.487: INFO: Pod pod-projected-secrets-e2927ce8-c451-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:26:00.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1932" for this suite.
Aug 21 20:26:06.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:26:06.640: INFO: namespace projected-1932 deletion completed in 6.144591446s

â€¢ [SLOW TEST:8.394 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:26:06.642: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:26:10.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-264" for this suite.
Aug 21 20:26:16.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:26:17.001: INFO: namespace kubelet-test-264 deletion completed in 6.167761872s

â€¢ [SLOW TEST:10.359 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:26:17.002: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-662
Aug 21 20:26:19.188: INFO: Started pod liveness-http in namespace container-probe-662
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 20:26:19.194: INFO: Initial restart count of pod liveness-http is 0
Aug 21 20:26:41.268: INFO: Restart count of pod container-probe-662/liveness-http is now 1 (22.074051228s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:26:41.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-662" for this suite.
Aug 21 20:26:47.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:26:47.457: INFO: namespace container-probe-662 deletion completed in 6.163251388s

â€¢ [SLOW TEST:30.455 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:26:47.458: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Aug 21 20:26:47.639: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8073" to be "success or failure"
Aug 21 20:26:47.647: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.63924ms
Aug 21 20:26:49.654: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01449783s
Aug 21 20:26:51.661: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021371111s
STEP: Saw pod success
Aug 21 20:26:51.661: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 21 20:26:51.665: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 21 20:26:51.698: INFO: Waiting for pod pod-host-path-test to disappear
Aug 21 20:26:51.702: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:26:51.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8073" for this suite.
Aug 21 20:26:57.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:26:57.852: INFO: namespace hostpath-8073 deletion completed in 6.1442969s

â€¢ [SLOW TEST:10.394 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:26:57.853: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:26:58.076: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"061b52ee-c452-11e9-b964-005056a55cb1", Controller:(*bool)(0xc002653b3a), BlockOwnerDeletion:(*bool)(0xc002653b3b)}}
Aug 21 20:26:58.088: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"061843c7-c452-11e9-b964-005056a55cb1", Controller:(*bool)(0xc002653d6a), BlockOwnerDeletion:(*bool)(0xc002653d6b)}}
Aug 21 20:26:58.095: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"06197846-c452-11e9-b964-005056a55cb1", Controller:(*bool)(0xc0028d3f8a), BlockOwnerDeletion:(*bool)(0xc0028d3f8b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:27:03.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6967" for this suite.
Aug 21 20:27:09.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:27:09.243: INFO: namespace gc-6967 deletion completed in 6.130930457s

â€¢ [SLOW TEST:11.390 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:27:09.244: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Aug 21 20:27:09.930: INFO: created pod pod-service-account-defaultsa
Aug 21 20:27:09.930: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 21 20:27:09.944: INFO: created pod pod-service-account-mountsa
Aug 21 20:27:09.944: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 21 20:27:09.962: INFO: created pod pod-service-account-nomountsa
Aug 21 20:27:09.962: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 21 20:27:09.985: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 21 20:27:09.985: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 21 20:27:10.003: INFO: created pod pod-service-account-mountsa-mountspec
Aug 21 20:27:10.003: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 21 20:27:10.029: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 21 20:27:10.029: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 21 20:27:10.043: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 21 20:27:10.043: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 21 20:27:10.060: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 21 20:27:10.060: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 21 20:27:10.077: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 21 20:27:10.077: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:27:10.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9292" for this suite.
Aug 21 20:27:16.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:27:16.230: INFO: namespace svcaccounts-9292 deletion completed in 6.137201867s

â€¢ [SLOW TEST:6.986 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:27:16.232: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:27:16.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652" in namespace "downward-api-3023" to be "success or failure"
Aug 21 20:27:16.410: INFO: Pod "downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.864379ms
Aug 21 20:27:18.417: INFO: Pod "downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012769599s
STEP: Saw pod success
Aug 21 20:27:18.417: INFO: Pod "downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:27:18.421: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:27:18.449: INFO: Waiting for pod downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652 to disappear
Aug 21 20:27:18.453: INFO: Pod downwardapi-volume-110cf9b9-c452-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:27:18.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3023" for this suite.
Aug 21 20:27:24.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:27:24.599: INFO: namespace downward-api-3023 deletion completed in 6.140557159s

â€¢ [SLOW TEST:8.367 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:27:24.600: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0821 20:27:30.795534      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 20:27:30.795: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:27:30.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3860" for this suite.
Aug 21 20:27:36.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:27:36.940: INFO: namespace gc-3860 deletion completed in 6.140420983s

â€¢ [SLOW TEST:12.340 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:27:36.942: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9846
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:28:04.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9846" for this suite.
Aug 21 20:28:10.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:28:10.604: INFO: namespace container-runtime-9846 deletion completed in 6.150884092s

â€¢ [SLOW TEST:33.663 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:28:10.612: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6139
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-3176e35b-c452-11e9-8a5f-26f602588652
STEP: Creating configMap with name cm-test-opt-upd-3176e47b-c452-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3176e35b-c452-11e9-8a5f-26f602588652
STEP: Updating configmap cm-test-opt-upd-3176e47b-c452-11e9-8a5f-26f602588652
STEP: Creating configMap with name cm-test-opt-create-3176e4eb-c452-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:29:27.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6139" for this suite.
Aug 21 20:29:49.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:29:49.631: INFO: namespace projected-6139 deletion completed in 22.142037717s

â€¢ [SLOW TEST:99.019 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:29:49.633: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-6c7c19a9-c452-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume secrets
Aug 21 20:29:49.814: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652" in namespace "projected-5409" to be "success or failure"
Aug 21 20:29:49.826: INFO: Pod "pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 11.456612ms
Aug 21 20:29:51.833: INFO: Pod "pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019243043s
STEP: Saw pod success
Aug 21 20:29:51.833: INFO: Pod "pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:29:51.840: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 20:29:51.876: INFO: Waiting for pod pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652 to disappear
Aug 21 20:29:51.880: INFO: Pod pod-projected-secrets-6c7d3d42-c452-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:29:51.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5409" for this suite.
Aug 21 20:29:57.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:29:58.046: INFO: namespace projected-5409 deletion completed in 6.161662745s

â€¢ [SLOW TEST:8.414 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:29:58.048: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1688
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 20:29:58.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7666'
Aug 21 20:29:58.335: INFO: stderr: ""
Aug 21 20:29:58.335: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 21 20:30:03.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pod e2e-test-nginx-pod --namespace=kubectl-7666 -o json'
Aug 21 20:30:03.498: INFO: stderr: ""
Aug 21 20:30:03.498: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-21T20:29:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7666\",\n        \"resourceVersion\": \"144439\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7666/pods/e2e-test-nginx-pod\",\n        \"uid\": \"71900cdb-c452-11e9-8bc3-005056a5e556\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pqts6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"978c34ce-e296-4689-bf73-826c8c556b20\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pqts6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pqts6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T20:29:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T20:30:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T20:30:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T20:29:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f59a321fdd1c02af298c07628dfcd90411450500b26e5c56502626cb85718950\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-21T20:29:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.85.21.98\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.38.220\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-21T20:29:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 21 20:30:03.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 replace -f - --namespace=kubectl-7666'
Aug 21 20:30:03.825: INFO: stderr: ""
Aug 21 20:30:03.825: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
Aug 21 20:30:03.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete pods e2e-test-nginx-pod --namespace=kubectl-7666'
Aug 21 20:30:08.129: INFO: stderr: ""
Aug 21 20:30:08.129: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:30:08.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7666" for this suite.
Aug 21 20:30:14.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:30:14.276: INFO: namespace kubectl-7666 deletion completed in 6.139366427s

â€¢ [SLOW TEST:16.228 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:30:14.277: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-zwbp
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 20:30:14.454: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zwbp" in namespace "subpath-1438" to be "success or failure"
Aug 21 20:30:14.465: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.952993ms
Aug 21 20:30:16.473: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018933264s
Aug 21 20:30:18.493: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 4.039521005s
Aug 21 20:30:20.500: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 6.046065374s
Aug 21 20:30:22.505: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 8.05149603s
Aug 21 20:30:24.511: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 10.057330378s
Aug 21 20:30:26.520: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 12.066021749s
Aug 21 20:30:28.527: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 14.07323407s
Aug 21 20:30:30.533: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 16.079362606s
Aug 21 20:30:32.540: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 18.086427763s
Aug 21 20:30:34.547: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Running", Reason="", readiness=true. Elapsed: 20.093154272s
Aug 21 20:30:36.554: INFO: Pod "pod-subpath-test-projected-zwbp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.099811567s
STEP: Saw pod success
Aug 21 20:30:36.554: INFO: Pod "pod-subpath-test-projected-zwbp" satisfied condition "success or failure"
Aug 21 20:30:36.557: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-subpath-test-projected-zwbp container test-container-subpath-projected-zwbp: <nil>
STEP: delete the pod
Aug 21 20:30:36.591: INFO: Waiting for pod pod-subpath-test-projected-zwbp to disappear
Aug 21 20:30:36.595: INFO: Pod pod-subpath-test-projected-zwbp no longer exists
STEP: Deleting pod pod-subpath-test-projected-zwbp
Aug 21 20:30:36.595: INFO: Deleting pod "pod-subpath-test-projected-zwbp" in namespace "subpath-1438"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:30:36.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1438" for this suite.
Aug 21 20:30:42.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:30:42.747: INFO: namespace subpath-1438 deletion completed in 6.143130308s

â€¢ [SLOW TEST:28.470 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:30:42.749: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Aug 21 20:30:42.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 --namespace=kubectl-8700 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 21 20:30:45.505: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 21 20:30:45.505: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:30:47.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8700" for this suite.
Aug 21 20:31:01.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:31:01.662: INFO: namespace kubectl-8700 deletion completed in 14.142147037s

â€¢ [SLOW TEST:18.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:31:01.662: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-312
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2269
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:31:08.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4987" for this suite.
Aug 21 20:31:14.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:31:14.338: INFO: namespace namespaces-4987 deletion completed in 6.132434643s
STEP: Destroying namespace "nsdeletetest-312" for this suite.
Aug 21 20:31:14.341: INFO: Namespace nsdeletetest-312 was already deleted
STEP: Destroying namespace "nsdeletetest-2269" for this suite.
Aug 21 20:31:20.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:31:20.505: INFO: namespace nsdeletetest-2269 deletion completed in 6.163394239s

â€¢ [SLOW TEST:18.844 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:31:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9661
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1177
STEP: creating the pod
Aug 21 20:31:20.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-9661'
Aug 21 20:31:20.951: INFO: stderr: ""
Aug 21 20:31:20.951: INFO: stdout: "pod/pause created\n"
Aug 21 20:31:20.951: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 21 20:31:20.951: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9661" to be "running and ready"
Aug 21 20:31:20.960: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.363714ms
Aug 21 20:31:22.965: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013686002s
Aug 21 20:31:24.971: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.019603818s
Aug 21 20:31:24.971: INFO: Pod "pause" satisfied condition "running and ready"
Aug 21 20:31:24.971: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 21 20:31:24.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 label pods pause testing-label=testing-label-value --namespace=kubectl-9661'
Aug 21 20:31:25.131: INFO: stderr: ""
Aug 21 20:31:25.131: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 21 20:31:25.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pod pause -L testing-label --namespace=kubectl-9661'
Aug 21 20:31:25.266: INFO: stderr: ""
Aug 21 20:31:25.266: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 21 20:31:25.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 label pods pause testing-label- --namespace=kubectl-9661'
Aug 21 20:31:25.369: INFO: stderr: ""
Aug 21 20:31:25.369: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 21 20:31:25.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pod pause -L testing-label --namespace=kubectl-9661'
Aug 21 20:31:25.479: INFO: stderr: ""
Aug 21 20:31:25.479: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1184
STEP: using delete to clean up resources
Aug 21 20:31:25.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-9661'
Aug 21 20:31:25.596: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:31:25.596: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 21 20:31:25.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=pause --no-headers --namespace=kubectl-9661'
Aug 21 20:31:25.719: INFO: stderr: "No resources found.\n"
Aug 21 20:31:25.719: INFO: stdout: ""
Aug 21 20:31:25.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=pause --namespace=kubectl-9661 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:31:25.816: INFO: stderr: ""
Aug 21 20:31:25.816: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:31:25.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9661" for this suite.
Aug 21 20:31:31.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:31:31.986: INFO: namespace kubectl-9661 deletion completed in 6.163737843s

â€¢ [SLOW TEST:11.475 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:31:31.989: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9444
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Aug 21 20:31:32.175: INFO: Found 0 stateful pods, waiting for 3
Aug 21 20:31:42.182: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:31:42.182: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:31:42.182: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 21 20:31:42.214: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 21 20:31:52.259: INFO: Updating stateful set ss2
Aug 21 20:31:52.272: INFO: Waiting for Pod statefulset-9444/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 21 20:32:02.354: INFO: Found 2 stateful pods, waiting for 3
Aug 21 20:32:12.363: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:32:12.363: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 20:32:12.363: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 21 20:32:12.394: INFO: Updating stateful set ss2
Aug 21 20:32:12.420: INFO: Waiting for Pod statefulset-9444/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:32:22.433: INFO: Waiting for Pod statefulset-9444/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 21 20:32:32.453: INFO: Updating stateful set ss2
Aug 21 20:32:32.462: INFO: Waiting for StatefulSet statefulset-9444/ss2 to complete update
Aug 21 20:32:32.462: INFO: Waiting for Pod statefulset-9444/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 20:32:42.474: INFO: Deleting all statefulset in ns statefulset-9444
Aug 21 20:32:42.477: INFO: Scaling statefulset ss2 to 0
Aug 21 20:33:02.513: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:33:02.518: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:33:02.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9444" for this suite.
Aug 21 20:33:08.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:33:08.719: INFO: namespace statefulset-9444 deletion completed in 6.179914157s

â€¢ [SLOW TEST:96.731 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:33:08.728: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6671
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-e328cc73-c452-11e9-8a5f-26f602588652
STEP: Creating secret with name s-test-opt-upd-e328ccdd-c452-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e328cc73-c452-11e9-8a5f-26f602588652
STEP: Updating secret s-test-opt-upd-e328ccdd-c452-11e9-8a5f-26f602588652
STEP: Creating secret with name s-test-opt-create-e328cd06-c452-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:33:13.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6671" for this suite.
Aug 21 20:33:35.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:33:35.224: INFO: namespace projected-6671 deletion completed in 22.157442814s

â€¢ [SLOW TEST:26.496 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:33:35.225: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-7794
Aug 21 20:33:37.424: INFO: Started pod liveness-exec in namespace container-probe-7794
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 20:33:37.428: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:37:38.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7794" for this suite.
Aug 21 20:37:44.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:37:44.409: INFO: namespace container-probe-7794 deletion completed in 6.173742468s

â€¢ [SLOW TEST:249.185 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:37:44.412: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7579
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 21 20:37:47.121: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7579 pod-service-account-87c91911-c453-11e9-8a5f-26f602588652 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 21 20:37:47.355: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7579 pod-service-account-87c91911-c453-11e9-8a5f-26f602588652 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 21 20:37:47.614: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7579 pod-service-account-87c91911-c453-11e9-8a5f-26f602588652 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:37:47.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7579" for this suite.
Aug 21 20:37:53.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:37:54.024: INFO: namespace svcaccounts-7579 deletion completed in 6.15617617s

â€¢ [SLOW TEST:9.612 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:37:54.029: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1579
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 20:37:54.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7535'
Aug 21 20:37:55.159: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 20:37:55.159: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1584
Aug 21 20:37:55.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete jobs e2e-test-nginx-job --namespace=kubectl-7535'
Aug 21 20:37:55.278: INFO: stderr: ""
Aug 21 20:37:55.278: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:37:55.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7535" for this suite.
Aug 21 20:38:17.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:38:17.438: INFO: namespace kubectl-7535 deletion completed in 22.152475305s

â€¢ [SLOW TEST:23.409 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:38:17.440: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1483
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 20:38:17.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4625'
Aug 21 20:38:17.715: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 20:38:17.715: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 21 20:38:17.735: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 21 20:38:17.760: INFO: scanned /root for discovery docs: <nil>
Aug 21 20:38:17.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4625'
Aug 21 20:38:33.624: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 21 20:38:33.624: INFO: stdout: "Created e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745\nScaling up e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 21 20:38:33.624: INFO: stdout: "Created e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745\nScaling up e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 21 20:38:33.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4625'
Aug 21 20:38:33.723: INFO: stderr: ""
Aug 21 20:38:33.723: INFO: stdout: "e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745-nmhsn "
Aug 21 20:38:33.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745-nmhsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4625'
Aug 21 20:38:33.835: INFO: stderr: ""
Aug 21 20:38:33.835: INFO: stdout: "true"
Aug 21 20:38:33.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745-nmhsn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4625'
Aug 21 20:38:33.935: INFO: stderr: ""
Aug 21 20:38:33.935: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 21 20:38:33.935: INFO: e2e-test-nginx-rc-9328d79bee276449c2df3c90ecdbb745-nmhsn is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
Aug 21 20:38:33.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete rc e2e-test-nginx-rc --namespace=kubectl-4625'
Aug 21 20:38:34.040: INFO: stderr: ""
Aug 21 20:38:34.040: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:38:34.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4625" for this suite.
Aug 21 20:38:40.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:38:40.237: INFO: namespace kubectl-4625 deletion completed in 6.182509382s

â€¢ [SLOW TEST:22.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:38:40.238: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a8c0678b-c453-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:38:40.421: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652" in namespace "projected-7529" to be "success or failure"
Aug 21 20:38:40.430: INFO: Pod "pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.787913ms
Aug 21 20:38:42.438: INFO: Pod "pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015372106s
Aug 21 20:38:44.446: INFO: Pod "pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024292238s
STEP: Saw pod success
Aug 21 20:38:44.447: INFO: Pod "pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:38:44.452: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:38:44.493: INFO: Waiting for pod pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652 to disappear
Aug 21 20:38:44.499: INFO: Pod pod-projected-configmaps-a8c17b77-c453-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:38:44.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7529" for this suite.
Aug 21 20:38:50.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:38:50.661: INFO: namespace projected-7529 deletion completed in 6.15580785s

â€¢ [SLOW TEST:10.424 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:38:50.674: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:38:50.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-113" for this suite.
Aug 21 20:39:12.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:39:13.032: INFO: namespace kubelet-test-113 deletion completed in 22.15831451s

â€¢ [SLOW TEST:22.358 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:39:13.035: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:39:13.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652" in namespace "projected-1529" to be "success or failure"
Aug 21 20:39:13.217: INFO: Pod "downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.985361ms
Aug 21 20:39:15.222: INFO: Pod "downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010693177s
STEP: Saw pod success
Aug 21 20:39:15.222: INFO: Pod "downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:39:15.226: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:39:15.256: INFO: Waiting for pod downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652 to disappear
Aug 21 20:39:15.260: INFO: Pod downwardapi-volume-bc4cb1c2-c453-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:39:15.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1529" for this suite.
Aug 21 20:39:21.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:39:21.424: INFO: namespace projected-1529 deletion completed in 6.159067181s

â€¢ [SLOW TEST:8.389 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:39:21.425: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 21 20:39:21.598: INFO: Waiting up to 5m0s for pod "pod-c14cb3ab-c453-11e9-8a5f-26f602588652" in namespace "emptydir-3364" to be "success or failure"
Aug 21 20:39:21.606: INFO: Pod "pod-c14cb3ab-c453-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.494259ms
Aug 21 20:39:23.611: INFO: Pod "pod-c14cb3ab-c453-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013062217s
STEP: Saw pod success
Aug 21 20:39:23.611: INFO: Pod "pod-c14cb3ab-c453-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:39:23.615: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-c14cb3ab-c453-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:39:23.655: INFO: Waiting for pod pod-c14cb3ab-c453-11e9-8a5f-26f602588652 to disappear
Aug 21 20:39:23.658: INFO: Pod pod-c14cb3ab-c453-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:39:23.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3364" for this suite.
Aug 21 20:39:29.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:39:29.821: INFO: namespace emptydir-3364 deletion completed in 6.157703011s

â€¢ [SLOW TEST:8.397 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:39:29.824: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8892
Aug 21 20:39:32.021: INFO: Started pod liveness-exec in namespace container-probe-8892
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 20:39:32.025: INFO: Initial restart count of pod liveness-exec is 0
Aug 21 20:40:20.182: INFO: Restart count of pod container-probe-8892/liveness-exec is now 1 (48.156569067s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:40:20.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8892" for this suite.
Aug 21 20:40:26.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:40:26.343: INFO: namespace container-probe-8892 deletion completed in 6.138811465s

â€¢ [SLOW TEST:56.519 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:40:26.348: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8656
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e8005e3a-c453-11e9-8a5f-26f602588652
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e8005e3a-c453-11e9-8a5f-26f602588652
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:40:30.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8656" for this suite.
Aug 21 20:41:02.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:41:02.765: INFO: namespace projected-8656 deletion completed in 32.157734306s

â€¢ [SLOW TEST:36.418 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:41:02.767: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Aug 21 20:41:02.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 api-versions'
Aug 21 20:41:03.061: INFO: stderr: ""
Aug 21 20:41:03.061: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npksapi.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:41:03.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1456" for this suite.
Aug 21 20:41:09.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:41:09.229: INFO: namespace kubectl-1456 deletion completed in 6.159318646s

â€¢ [SLOW TEST:6.462 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:41:09.229: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-fw4c
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 20:41:09.420: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fw4c" in namespace "subpath-4027" to be "success or failure"
Aug 21 20:41:09.429: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.767261ms
Aug 21 20:41:11.436: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015523744s
Aug 21 20:41:13.443: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.023045295s
Aug 21 20:41:15.449: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.029195841s
Aug 21 20:41:17.457: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 8.036874932s
Aug 21 20:41:19.464: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 10.044102033s
Aug 21 20:41:21.470: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 12.050041345s
Aug 21 20:41:23.479: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 14.058855047s
Aug 21 20:41:25.486: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 16.065263554s
Aug 21 20:41:27.495: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.07490259s
Aug 21 20:41:29.500: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Running", Reason="", readiness=true. Elapsed: 20.079848234s
Aug 21 20:41:31.506: INFO: Pod "pod-subpath-test-downwardapi-fw4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.085787876s
STEP: Saw pod success
Aug 21 20:41:31.506: INFO: Pod "pod-subpath-test-downwardapi-fw4c" satisfied condition "success or failure"
Aug 21 20:41:31.510: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-subpath-test-downwardapi-fw4c container test-container-subpath-downwardapi-fw4c: <nil>
STEP: delete the pod
Aug 21 20:41:31.546: INFO: Waiting for pod pod-subpath-test-downwardapi-fw4c to disappear
Aug 21 20:41:31.553: INFO: Pod pod-subpath-test-downwardapi-fw4c no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fw4c
Aug 21 20:41:31.553: INFO: Deleting pod "pod-subpath-test-downwardapi-fw4c" in namespace "subpath-4027"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:41:31.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4027" for this suite.
Aug 21 20:41:37.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:41:37.709: INFO: namespace subpath-4027 deletion completed in 6.14704852s

â€¢ [SLOW TEST:28.479 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:41:37.711: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-s2b8
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 20:41:37.894: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-s2b8" in namespace "subpath-181" to be "success or failure"
Aug 21 20:41:37.903: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.792256ms
Aug 21 20:41:39.911: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016727911s
Aug 21 20:41:41.916: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 4.021915668s
Aug 21 20:41:43.926: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 6.031566995s
Aug 21 20:41:45.932: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 8.037537558s
Aug 21 20:41:47.940: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 10.045528709s
Aug 21 20:41:49.946: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 12.051496303s
Aug 21 20:41:51.953: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 14.058265212s
Aug 21 20:41:53.959: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 16.064352603s
Aug 21 20:41:55.967: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 18.072327649s
Aug 21 20:41:57.974: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Running", Reason="", readiness=true. Elapsed: 20.079572614s
Aug 21 20:41:59.982: INFO: Pod "pod-subpath-test-configmap-s2b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.087395328s
STEP: Saw pod success
Aug 21 20:41:59.982: INFO: Pod "pod-subpath-test-configmap-s2b8" satisfied condition "success or failure"
Aug 21 20:41:59.986: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-subpath-test-configmap-s2b8 container test-container-subpath-configmap-s2b8: <nil>
STEP: delete the pod
Aug 21 20:42:00.048: INFO: Waiting for pod pod-subpath-test-configmap-s2b8 to disappear
Aug 21 20:42:00.052: INFO: Pod pod-subpath-test-configmap-s2b8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-s2b8
Aug 21 20:42:00.052: INFO: Deleting pod "pod-subpath-test-configmap-s2b8" in namespace "subpath-181"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:42:00.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-181" for this suite.
Aug 21 20:42:06.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:42:06.213: INFO: namespace subpath-181 deletion completed in 6.15005456s

â€¢ [SLOW TEST:28.502 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:42:06.214: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:42:06.399: INFO: Create a RollingUpdate DaemonSet
Aug 21 20:42:06.407: INFO: Check that daemon pods launch on every node of the cluster
Aug 21 20:42:06.418: INFO: Number of nodes with available pods: 0
Aug 21 20:42:06.418: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:42:07.428: INFO: Number of nodes with available pods: 0
Aug 21 20:42:07.428: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:42:08.431: INFO: Number of nodes with available pods: 2
Aug 21 20:42:08.431: INFO: Node 978c34ce-e296-4689-bf73-826c8c556b20 is running more than one daemon pod
Aug 21 20:42:09.430: INFO: Number of nodes with available pods: 3
Aug 21 20:42:09.431: INFO: Number of running nodes: 3, number of available pods: 3
Aug 21 20:42:09.431: INFO: Update the DaemonSet to trigger a rollout
Aug 21 20:42:09.441: INFO: Updating DaemonSet daemon-set
Aug 21 20:42:12.459: INFO: Roll back the DaemonSet before rollout is complete
Aug 21 20:42:12.509: INFO: Updating DaemonSet daemon-set
Aug 21 20:42:12.509: INFO: Make sure DaemonSet rollback is complete
Aug 21 20:42:12.520: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:12.520: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:13.535: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:13.535: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:14.535: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:14.535: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:15.534: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:15.534: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:16.535: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:16.535: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:17.534: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:17.534: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:18.536: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:18.536: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:19.534: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:19.534: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:20.534: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:20.534: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:21.533: INFO: Wrong image for pod: daemon-set-rns6v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 21 20:42:21.533: INFO: Pod daemon-set-rns6v is not available
Aug 21 20:42:22.534: INFO: Pod daemon-set-wrqwz is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9889, will wait for the garbage collector to delete the pods
Aug 21 20:42:22.617: INFO: Deleting DaemonSet.extensions daemon-set took: 13.970443ms
Aug 21 20:42:23.017: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.588545ms
Aug 21 20:42:35.523: INFO: Number of nodes with available pods: 0
Aug 21 20:42:35.523: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 20:42:35.526: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9889/daemonsets","resourceVersion":"146624"},"items":null}

Aug 21 20:42:35.530: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9889/pods","resourceVersion":"146624"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:42:35.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9889" for this suite.
Aug 21 20:42:41.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:42:41.697: INFO: namespace daemonsets-9889 deletion completed in 6.141558615s

â€¢ [SLOW TEST:35.482 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:42:41.698: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Aug 21 20:42:41.874: INFO: Waiting up to 5m0s for pod "var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652" in namespace "var-expansion-2289" to be "success or failure"
Aug 21 20:42:41.879: INFO: Pod "var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.055522ms
Aug 21 20:42:43.885: INFO: Pod "var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010833091s
STEP: Saw pod success
Aug 21 20:42:43.885: INFO: Pod "var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:42:43.888: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652 container dapi-container: <nil>
STEP: delete the pod
Aug 21 20:42:43.915: INFO: Waiting for pod var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:42:43.918: INFO: Pod var-expansion-38ac0f2c-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:42:43.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2289" for this suite.
Aug 21 20:42:49.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:42:50.095: INFO: namespace var-expansion-2289 deletion completed in 6.17289121s

â€¢ [SLOW TEST:8.397 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:42:50.096: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0821 20:43:30.303370      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 20:43:30.303: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:43:30.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1607" for this suite.
Aug 21 20:43:36.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:43:36.436: INFO: namespace gc-1607 deletion completed in 6.127045067s

â€¢ [SLOW TEST:46.340 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:43:36.438: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Aug 21 20:43:36.610: INFO: Waiting up to 5m0s for pod "client-containers-594cd006-c454-11e9-8a5f-26f602588652" in namespace "containers-3717" to be "success or failure"
Aug 21 20:43:36.616: INFO: Pod "client-containers-594cd006-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.329863ms
Aug 21 20:43:38.622: INFO: Pod "client-containers-594cd006-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012267926s
Aug 21 20:43:40.627: INFO: Pod "client-containers-594cd006-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017280302s
STEP: Saw pod success
Aug 21 20:43:40.627: INFO: Pod "client-containers-594cd006-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:43:40.630: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod client-containers-594cd006-c454-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:43:40.658: INFO: Waiting for pod client-containers-594cd006-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:43:40.662: INFO: Pod client-containers-594cd006-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:43:40.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3717" for this suite.
Aug 21 20:43:46.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:43:46.806: INFO: namespace containers-3717 deletion completed in 6.139068113s

â€¢ [SLOW TEST:10.368 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:43:46.806: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6363/configmap-test-5f793ebf-c454-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:43:46.975: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652" in namespace "configmap-6363" to be "success or failure"
Aug 21 20:43:46.982: INFO: Pod "pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 7.262501ms
Aug 21 20:43:48.989: INFO: Pod "pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013823712s
STEP: Saw pod success
Aug 21 20:43:48.989: INFO: Pod "pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:43:48.993: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652 container env-test: <nil>
STEP: delete the pod
Aug 21 20:43:49.032: INFO: Waiting for pod pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:43:49.035: INFO: Pod pod-configmaps-5f7a146c-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:43:49.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6363" for this suite.
Aug 21 20:43:55.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:43:55.181: INFO: namespace configmap-6363 deletion completed in 6.140106482s

â€¢ [SLOW TEST:8.375 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:43:55.183: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1588
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 20:43:55.348: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 20:44:15.501: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.38.249 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1588 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:44:15.501: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:44:16.621: INFO: Found all expected endpoints: [netserver-0]
Aug 21 20:44:16.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.49.205 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1588 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:44:16.628: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:44:17.759: INFO: Found all expected endpoints: [netserver-1]
Aug 21 20:44:17.765: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.89.145 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1588 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 20:44:17.765: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
Aug 21 20:44:18.893: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:44:18.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1588" for this suite.
Aug 21 20:44:40.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:44:41.061: INFO: namespace pod-network-test-1588 deletion completed in 22.160973057s

â€¢ [SLOW TEST:45.878 seconds]
[sig-network] Networking
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:44:41.063: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:44:41.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652" in namespace "downward-api-2335" to be "success or failure"
Aug 21 20:44:41.243: INFO: Pod "downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 5.361584ms
Aug 21 20:44:43.249: INFO: Pod "downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011054059s
STEP: Saw pod success
Aug 21 20:44:43.249: INFO: Pod "downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:44:43.253: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:44:43.284: INFO: Waiting for pod downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:44:43.288: INFO: Pod downwardapi-volume-7fd1506a-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:44:43.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2335" for this suite.
Aug 21 20:44:49.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:44:49.450: INFO: namespace downward-api-2335 deletion completed in 6.155716474s

â€¢ [SLOW TEST:8.387 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:44:49.451: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2794
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2794
STEP: Creating statefulset with conflicting port in namespace statefulset-2794
STEP: Waiting until pod test-pod will start running in namespace statefulset-2794
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2794
Aug 21 20:44:51.666: INFO: Observed stateful pod in namespace: statefulset-2794, name: ss-0, uid: 84e8fbdc-c454-11e9-8bc3-005056a5e556, status phase: Pending. Waiting for statefulset controller to delete.
Aug 21 20:44:58.110: INFO: Observed stateful pod in namespace: statefulset-2794, name: ss-0, uid: 84e8fbdc-c454-11e9-8bc3-005056a5e556, status phase: Failed. Waiting for statefulset controller to delete.
Aug 21 20:44:58.128: INFO: Observed stateful pod in namespace: statefulset-2794, name: ss-0, uid: 84e8fbdc-c454-11e9-8bc3-005056a5e556, status phase: Failed. Waiting for statefulset controller to delete.
Aug 21 20:44:58.133: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2794
STEP: Removing pod with conflicting port in namespace statefulset-2794
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2794 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 20:45:00.187: INFO: Deleting all statefulset in ns statefulset-2794
Aug 21 20:45:00.191: INFO: Scaling statefulset ss to 0
Aug 21 20:45:10.215: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 20:45:10.219: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:45:10.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2794" for this suite.
Aug 21 20:45:16.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:45:16.394: INFO: namespace statefulset-2794 deletion completed in 6.153916152s

â€¢ [SLOW TEST:26.943 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:45:16.396: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 21 20:45:16.565: INFO: Waiting up to 5m0s for pod "pod-94e039d9-c454-11e9-8a5f-26f602588652" in namespace "emptydir-4891" to be "success or failure"
Aug 21 20:45:16.574: INFO: Pod "pod-94e039d9-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.327127ms
Aug 21 20:45:18.580: INFO: Pod "pod-94e039d9-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01511113s
STEP: Saw pod success
Aug 21 20:45:18.580: INFO: Pod "pod-94e039d9-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:45:18.585: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-94e039d9-c454-11e9-8a5f-26f602588652 container test-container: <nil>
STEP: delete the pod
Aug 21 20:45:18.620: INFO: Waiting for pod pod-94e039d9-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:45:18.624: INFO: Pod pod-94e039d9-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:45:18.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4891" for this suite.
Aug 21 20:45:24.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:45:24.776: INFO: namespace emptydir-4891 deletion completed in 6.145978498s

â€¢ [SLOW TEST:8.380 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:45:24.778: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 21 20:45:24.934: INFO: Creating deployment "test-recreate-deployment"
Aug 21 20:45:24.944: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 21 20:45:24.958: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 21 20:45:26.967: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 21 20:45:26.972: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 21 20:45:26.986: INFO: Updating deployment test-recreate-deployment
Aug 21 20:45:26.986: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 20:45:27.121: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8633,SelfLink:/apis/apps/v1/namespaces/deployment-8633/deployments/test-recreate-deployment,UID:99e00195-c454-11e9-b964-005056a55cb1,ResourceVersion:147495,Generation:2,CreationTimestamp:2019-08-21 20:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-21 20:45:27 +0000 UTC 2019-08-21 20:45:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-21 20:45:27 +0000 UTC 2019-08-21 20:45:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 21 20:45:27.126: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-8633,SelfLink:/apis/apps/v1/namespaces/deployment-8633/replicasets/test-recreate-deployment-745fb9c84c,UID:9b219182-c454-11e9-8bc3-005056a5e556,ResourceVersion:147492,Generation:1,CreationTimestamp:2019-08-21 20:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 99e00195-c454-11e9-b964-005056a55cb1 0xc001e65207 0xc001e65208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 20:45:27.126: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 21 20:45:27.127: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-8633,SelfLink:/apis/apps/v1/namespaces/deployment-8633/replicasets/test-recreate-deployment-6566d46b4b,UID:99e09699-c454-11e9-8bc3-005056a5e556,ResourceVersion:147483,Generation:2,CreationTimestamp:2019-08-21 20:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 99e00195-c454-11e9-b964-005056a55cb1 0xc001e65137 0xc001e65138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 20:45:27.132: INFO: Pod "test-recreate-deployment-745fb9c84c-frl8p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-frl8p,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-8633,SelfLink:/api/v1/namespaces/deployment-8633/pods/test-recreate-deployment-745fb9c84c-frl8p,UID:9b23e56b-c454-11e9-8bc3-005056a5e556,ResourceVersion:147494,Generation:0,CreationTimestamp:2019-08-21 20:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 9b219182-c454-11e9-8bc3-005056a5e556 0xc001e65ac7 0xc001e65ac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bj5kh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bj5kh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bj5kh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:978c34ce-e296-4689-bf73-826c8c556b20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e65b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e65b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:45:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:45:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:45:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 20:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.85.21.98,PodIP:,StartTime:2019-08-21 20:45:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:45:27.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8633" for this suite.
Aug 21 20:45:33.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:45:33.287: INFO: namespace deployment-8633 deletion completed in 6.14724924s

â€¢ [SLOW TEST:8.509 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:45:33.288: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Aug 21 20:45:33.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-7277'
Aug 21 20:45:33.664: INFO: stderr: ""
Aug 21 20:45:33.664: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 20:45:33.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7277'
Aug 21 20:45:33.802: INFO: stderr: ""
Aug 21 20:45:33.802: INFO: stdout: "update-demo-nautilus-gdmxh update-demo-nautilus-rnjdc "
Aug 21 20:45:33.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-gdmxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7277'
Aug 21 20:45:33.904: INFO: stderr: ""
Aug 21 20:45:33.904: INFO: stdout: ""
Aug 21 20:45:33.904: INFO: update-demo-nautilus-gdmxh is created but not running
Aug 21 20:45:38.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7277'
Aug 21 20:45:39.011: INFO: stderr: ""
Aug 21 20:45:39.011: INFO: stdout: "update-demo-nautilus-gdmxh update-demo-nautilus-rnjdc "
Aug 21 20:45:39.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-gdmxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7277'
Aug 21 20:45:39.118: INFO: stderr: ""
Aug 21 20:45:39.118: INFO: stdout: "true"
Aug 21 20:45:39.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-gdmxh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7277'
Aug 21 20:45:39.210: INFO: stderr: ""
Aug 21 20:45:39.210: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:45:39.210: INFO: validating pod update-demo-nautilus-gdmxh
Aug 21 20:45:39.218: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:45:39.218: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:45:39.218: INFO: update-demo-nautilus-gdmxh is verified up and running
Aug 21 20:45:39.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-rnjdc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7277'
Aug 21 20:45:39.314: INFO: stderr: ""
Aug 21 20:45:39.314: INFO: stdout: "true"
Aug 21 20:45:39.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-rnjdc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7277'
Aug 21 20:45:39.428: INFO: stderr: ""
Aug 21 20:45:39.428: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:45:39.428: INFO: validating pod update-demo-nautilus-rnjdc
Aug 21 20:45:39.434: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:45:39.434: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:45:39.434: INFO: update-demo-nautilus-rnjdc is verified up and running
STEP: using delete to clean up resources
Aug 21 20:45:39.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-7277'
Aug 21 20:45:39.542: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:45:39.542: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 21 20:45:39.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7277'
Aug 21 20:45:39.664: INFO: stderr: "No resources found.\n"
Aug 21 20:45:39.664: INFO: stdout: ""
Aug 21 20:45:39.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=update-demo --namespace=kubectl-7277 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:45:39.770: INFO: stderr: ""
Aug 21 20:45:39.770: INFO: stdout: "update-demo-nautilus-gdmxh\nupdate-demo-nautilus-rnjdc\n"
Aug 21 20:45:40.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7277'
Aug 21 20:45:40.386: INFO: stderr: "No resources found.\n"
Aug 21 20:45:40.386: INFO: stdout: ""
Aug 21 20:45:40.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=update-demo --namespace=kubectl-7277 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:45:40.496: INFO: stderr: ""
Aug 21 20:45:40.496: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:45:40.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7277" for this suite.
Aug 21 20:46:02.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:46:02.641: INFO: namespace kubectl-7277 deletion completed in 22.138024027s

â€¢ [SLOW TEST:29.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:46:02.643: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Aug 21 20:46:02.806: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-287854235 proxy --unix-socket=/tmp/kubectl-proxy-unix020274514/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:46:02.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7201" for this suite.
Aug 21 20:46:08.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:46:09.025: INFO: namespace kubectl-7201 deletion completed in 6.14572103s

â€¢ [SLOW TEST:6.382 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:46:09.025: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Aug 21 20:46:09.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 create -f - --namespace=kubectl-2060'
Aug 21 20:46:09.454: INFO: stderr: ""
Aug 21 20:46:09.454: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 20:46:09.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:09.560: INFO: stderr: ""
Aug 21 20:46:09.560: INFO: stdout: "update-demo-nautilus-7pqqc update-demo-nautilus-jgwfg "
Aug 21 20:46:09.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-7pqqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:09.641: INFO: stderr: ""
Aug 21 20:46:09.641: INFO: stdout: ""
Aug 21 20:46:09.641: INFO: update-demo-nautilus-7pqqc is created but not running
Aug 21 20:46:14.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:14.752: INFO: stderr: ""
Aug 21 20:46:14.752: INFO: stdout: "update-demo-nautilus-7pqqc update-demo-nautilus-jgwfg "
Aug 21 20:46:14.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-7pqqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:14.854: INFO: stderr: ""
Aug 21 20:46:14.854: INFO: stdout: "true"
Aug 21 20:46:14.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-7pqqc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:14.964: INFO: stderr: ""
Aug 21 20:46:14.964: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:46:14.964: INFO: validating pod update-demo-nautilus-7pqqc
Aug 21 20:46:14.973: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:46:14.973: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:46:14.973: INFO: update-demo-nautilus-7pqqc is verified up and running
Aug 21 20:46:14.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:15.076: INFO: stderr: ""
Aug 21 20:46:15.076: INFO: stdout: "true"
Aug 21 20:46:15.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:15.169: INFO: stderr: ""
Aug 21 20:46:15.169: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:46:15.169: INFO: validating pod update-demo-nautilus-jgwfg
Aug 21 20:46:15.175: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:46:15.175: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:46:15.175: INFO: update-demo-nautilus-jgwfg is verified up and running
STEP: scaling down the replication controller
Aug 21 20:46:15.177: INFO: scanned /root for discovery docs: <nil>
Aug 21 20:46:15.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2060'
Aug 21 20:46:16.327: INFO: stderr: ""
Aug 21 20:46:16.327: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 20:46:16.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:16.434: INFO: stderr: ""
Aug 21 20:46:16.434: INFO: stdout: "update-demo-nautilus-7pqqc update-demo-nautilus-jgwfg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 21 20:46:21.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:21.539: INFO: stderr: ""
Aug 21 20:46:21.539: INFO: stdout: "update-demo-nautilus-7pqqc update-demo-nautilus-jgwfg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 21 20:46:26.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:26.650: INFO: stderr: ""
Aug 21 20:46:26.650: INFO: stdout: "update-demo-nautilus-7pqqc update-demo-nautilus-jgwfg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 21 20:46:31.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:31.747: INFO: stderr: ""
Aug 21 20:46:31.747: INFO: stdout: "update-demo-nautilus-jgwfg "
Aug 21 20:46:31.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:31.838: INFO: stderr: ""
Aug 21 20:46:31.838: INFO: stdout: "true"
Aug 21 20:46:31.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:31.946: INFO: stderr: ""
Aug 21 20:46:31.947: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:46:31.947: INFO: validating pod update-demo-nautilus-jgwfg
Aug 21 20:46:31.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:46:31.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:46:31.953: INFO: update-demo-nautilus-jgwfg is verified up and running
STEP: scaling up the replication controller
Aug 21 20:46:31.955: INFO: scanned /root for discovery docs: <nil>
Aug 21 20:46:31.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2060'
Aug 21 20:46:33.094: INFO: stderr: ""
Aug 21 20:46:33.094: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 20:46:33.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:33.199: INFO: stderr: ""
Aug 21 20:46:33.199: INFO: stdout: "update-demo-nautilus-468t4 update-demo-nautilus-jgwfg "
Aug 21 20:46:33.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-468t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:33.330: INFO: stderr: ""
Aug 21 20:46:33.330: INFO: stdout: ""
Aug 21 20:46:33.330: INFO: update-demo-nautilus-468t4 is created but not running
Aug 21 20:46:38.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2060'
Aug 21 20:46:38.438: INFO: stderr: ""
Aug 21 20:46:38.438: INFO: stdout: "update-demo-nautilus-468t4 update-demo-nautilus-jgwfg "
Aug 21 20:46:38.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-468t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:38.539: INFO: stderr: ""
Aug 21 20:46:38.539: INFO: stdout: "true"
Aug 21 20:46:38.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-468t4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:38.643: INFO: stderr: ""
Aug 21 20:46:38.643: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:46:38.643: INFO: validating pod update-demo-nautilus-468t4
Aug 21 20:46:38.651: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:46:38.651: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:46:38.651: INFO: update-demo-nautilus-468t4 is verified up and running
Aug 21 20:46:38.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:38.756: INFO: stderr: ""
Aug 21 20:46:38.756: INFO: stdout: "true"
Aug 21 20:46:38.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods update-demo-nautilus-jgwfg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2060'
Aug 21 20:46:38.859: INFO: stderr: ""
Aug 21 20:46:38.859: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 20:46:38.859: INFO: validating pod update-demo-nautilus-jgwfg
Aug 21 20:46:38.867: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 20:46:38.867: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 20:46:38.867: INFO: update-demo-nautilus-jgwfg is verified up and running
STEP: using delete to clean up resources
Aug 21 20:46:38.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete --grace-period=0 --force -f - --namespace=kubectl-2060'
Aug 21 20:46:38.968: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 20:46:38.968: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 21 20:46:38.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2060'
Aug 21 20:46:39.090: INFO: stderr: "No resources found.\n"
Aug 21 20:46:39.090: INFO: stdout: ""
Aug 21 20:46:39.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=update-demo --namespace=kubectl-2060 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:46:39.193: INFO: stderr: ""
Aug 21 20:46:39.193: INFO: stdout: "update-demo-nautilus-468t4\nupdate-demo-nautilus-jgwfg\n"
Aug 21 20:46:39.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2060'
Aug 21 20:46:39.851: INFO: stderr: "No resources found.\n"
Aug 21 20:46:39.851: INFO: stdout: ""
Aug 21 20:46:39.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 get pods -l name=update-demo --namespace=kubectl-2060 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 20:46:39.961: INFO: stderr: ""
Aug 21 20:46:39.961: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:46:39.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2060" for this suite.
Aug 21 20:47:01.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:47:02.113: INFO: namespace kubectl-2060 deletion completed in 22.14506645s

â€¢ [SLOW TEST:53.088 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:47:02.114: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 21 20:47:02.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652" in namespace "projected-8231" to be "success or failure"
Aug 21 20:47:02.290: INFO: Pod "downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.837767ms
Aug 21 20:47:04.298: INFO: Pod "downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014652607s
Aug 21 20:47:06.305: INFO: Pod "downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021115388s
STEP: Saw pod success
Aug 21 20:47:06.305: INFO: Pod "downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:47:06.309: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652 container client-container: <nil>
STEP: delete the pod
Aug 21 20:47:06.344: INFO: Waiting for pod downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:47:06.348: INFO: Pod downwardapi-volume-d3e3b7aa-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:47:06.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8231" for this suite.
Aug 21 20:47:12.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:47:12.529: INFO: namespace projected-8231 deletion completed in 6.173895816s

â€¢ [SLOW TEST:10.414 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:47:12.531: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1387
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 20:47:12.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5021'
Aug 21 20:47:12.791: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 20:47:12.791: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1393
Aug 21 20:47:14.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-287854235 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5021'
Aug 21 20:47:14.896: INFO: stderr: ""
Aug 21 20:47:14.896: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:47:14.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5021" for this suite.
Aug 21 20:47:36.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:47:37.053: INFO: namespace kubectl-5021 deletion completed in 22.151195349s

â€¢ [SLOW TEST:24.522 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:47:37.053: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 21 20:47:37.242: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-911,SelfLink:/api/v1/namespaces/watch-911/configmaps/e2e-watch-test-resource-version,UID:e8b75cb1-c454-11e9-b964-005056a55cb1,ResourceVersion:147974,Generation:0,CreationTimestamp:2019-08-21 20:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 20:47:37.242: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-911,SelfLink:/api/v1/namespaces/watch-911/configmaps/e2e-watch-test-resource-version,UID:e8b75cb1-c454-11e9-b964-005056a55cb1,ResourceVersion:147975,Generation:0,CreationTimestamp:2019-08-21 20:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:47:37.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-911" for this suite.
Aug 21 20:47:43.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:47:43.393: INFO: namespace watch-911 deletion completed in 6.1450669s

â€¢ [SLOW TEST:6.340 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:47:43.393: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8953
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-ec7e0b3a-c454-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:47:43.568: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652" in namespace "configmap-8953" to be "success or failure"
Aug 21 20:47:43.574: INFO: Pod "pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.272576ms
Aug 21 20:47:45.586: INFO: Pod "pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01799742s
STEP: Saw pod success
Aug 21 20:47:45.586: INFO: Pod "pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:47:45.595: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 20:47:45.631: INFO: Waiting for pod pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:47:45.637: INFO: Pod pod-configmaps-ec7f0749-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:47:45.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8953" for this suite.
Aug 21 20:47:51.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:47:51.790: INFO: namespace configmap-8953 deletion completed in 6.147025772s

â€¢ [SLOW TEST:8.396 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 21 20:47:51.792: INFO: >>> kubeConfig: /tmp/kubeconfig-287854235
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8359/configmap-test-f180f8d4-c454-11e9-8a5f-26f602588652
STEP: Creating a pod to test consume configMaps
Aug 21 20:47:51.975: INFO: Waiting up to 5m0s for pod "pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652" in namespace "configmap-8359" to be "success or failure"
Aug 21 20:47:51.984: INFO: Pod "pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652": Phase="Pending", Reason="", readiness=false. Elapsed: 9.502954ms
Aug 21 20:47:53.991: INFO: Pod "pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015926341s
STEP: Saw pod success
Aug 21 20:47:53.991: INFO: Pod "pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652" satisfied condition "success or failure"
Aug 21 20:47:53.996: INFO: Trying to get logs from node 978c34ce-e296-4689-bf73-826c8c556b20 pod pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652 container env-test: <nil>
STEP: delete the pod
Aug 21 20:47:54.025: INFO: Waiting for pod pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652 to disappear
Aug 21 20:47:54.030: INFO: Pod pod-configmaps-f181ff16-c454-11e9-8a5f-26f602588652 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 21 20:47:54.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8359" for this suite.
Aug 21 20:48:00.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 20:48:00.186: INFO: namespace configmap-8359 deletion completed in 6.1496286s

â€¢ [SLOW TEST:8.394 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.5-beta.0.7+0e9fcb426b100a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSAug 21 20:48:00.187: INFO: Running AfterSuite actions on all nodes
Aug 21 20:48:00.187: INFO: Running AfterSuite actions on node 1
Aug 21 20:48:00.187: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5202.608 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h26m44.463935256s
Test Suite Passed
