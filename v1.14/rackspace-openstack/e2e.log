I0703 22:06:13.334171      21 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-411152090
I0703 22:06:13.334295      21 e2e.go:240] Starting e2e run "c47d9d74-9dde-11e9-b0a2-a612d8f3003c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1562191571 - Will randomize all specs
Will run 182 of 3584 specs

Jul  3 22:06:13.585: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:06:13.589: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul  3 22:06:13.615: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul  3 22:06:13.680: INFO: 34 / 34 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul  3 22:06:13.680: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jul  3 22:06:13.680: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul  3 22:06:13.693: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jul  3 22:06:13.693: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jul  3 22:06:13.693: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Jul  3 22:06:13.693: INFO: e2e test version: v1.14.0
Jul  3 22:06:13.695: INFO: kube-apiserver version: v1.14.3
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:06:13.695: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
Jul  3 22:06:13.756: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jul  3 22:06:13.779: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-c5d6ccec-9dde-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:06:13.919: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c" in namespace "configmap-4858" to be "success or failure"
Jul  3 22:06:13.925: INFO: Pod "pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.838402ms
Jul  3 22:06:15.932: INFO: Pod "pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012702516s
Jul  3 22:06:17.938: INFO: Pod "pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019277238s
STEP: Saw pod success
Jul  3 22:06:17.938: INFO: Pod "pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:06:17.943: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:06:17.996: INFO: Waiting for pod pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:06:18.001: INFO: Pod pod-configmaps-c5d7d9ed-9dde-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:06:18.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4858" for this suite.
Jul  3 22:06:24.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:06:24.188: INFO: namespace configmap-4858 deletion completed in 6.181217256s

• [SLOW TEST:10.493 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:06:24.189: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-cc10e210-9dde-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:06:24.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c" in namespace "configmap-5550" to be "success or failure"
Jul  3 22:06:24.368: INFO: Pod "pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098015ms
Jul  3 22:06:26.375: INFO: Pod "pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010788496s
Jul  3 22:06:28.383: INFO: Pod "pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018830192s
STEP: Saw pod success
Jul  3 22:06:28.383: INFO: Pod "pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:06:28.388: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:06:28.434: INFO: Waiting for pod pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:06:28.438: INFO: Pod pod-configmaps-cc11d158-9dde-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:06:28.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5550" for this suite.
Jul  3 22:06:34.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:06:34.613: INFO: namespace configmap-5550 deletion completed in 6.169087286s

• [SLOW TEST:10.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:06:34.614: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:06:34.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c" in namespace "projected-4280" to be "success or failure"
Jul  3 22:06:34.793: INFO: Pod "downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.99854ms
Jul  3 22:06:36.799: INFO: Pod "downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010742935s
Jul  3 22:06:38.806: INFO: Pod "downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01757225s
STEP: Saw pod success
Jul  3 22:06:38.806: INFO: Pod "downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:06:38.811: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:06:38.859: INFO: Waiting for pod downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:06:38.862: INFO: Pod downwardapi-volume-d24862e0-9dde-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:06:38.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4280" for this suite.
Jul  3 22:06:44.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:06:45.043: INFO: namespace projected-4280 deletion completed in 6.175278341s

• [SLOW TEST:10.429 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:06:45.043: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2992.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2992.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2992.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 14.139.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.139.14_udp@PTR;check="$$(dig +tcp +noall +answer +search 14.139.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.139.14_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2992.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2992.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2992.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2992.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2992.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2992.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 14.139.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.139.14_udp@PTR;check="$$(dig +tcp +noall +answer +search 14.139.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.139.14_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  3 22:07:03.389: INFO: DNS probes using dns-2992/dns-test-d8850a69-9dde-11e9-b0a2-a612d8f3003c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:07:03.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2992" for this suite.
Jul  3 22:07:09.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:07:09.657: INFO: namespace dns-2992 deletion completed in 6.185700232s

• [SLOW TEST:24.614 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:07:09.657: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-8370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8370
I0703 22:07:09.841923      21 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8370, replica count: 1
I0703 22:07:10.892711      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0703 22:07:11.892886      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0703 22:07:12.893074      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  3 22:07:13.011: INFO: Created: latency-svc-2ww6l
Jul  3 22:07:13.022: INFO: Got endpoints: latency-svc-2ww6l [29.352005ms]
Jul  3 22:07:13.043: INFO: Created: latency-svc-qsbz8
Jul  3 22:07:13.052: INFO: Got endpoints: latency-svc-qsbz8 [29.779109ms]
Jul  3 22:07:13.054: INFO: Created: latency-svc-n8h5j
Jul  3 22:07:13.060: INFO: Got endpoints: latency-svc-n8h5j [37.277019ms]
Jul  3 22:07:13.065: INFO: Created: latency-svc-p6b9x
Jul  3 22:07:13.073: INFO: Got endpoints: latency-svc-p6b9x [49.471651ms]
Jul  3 22:07:13.081: INFO: Created: latency-svc-lpztb
Jul  3 22:07:13.085: INFO: Created: latency-svc-nbtbs
Jul  3 22:07:13.087: INFO: Got endpoints: latency-svc-lpztb [64.306106ms]
Jul  3 22:07:13.092: INFO: Got endpoints: latency-svc-nbtbs [68.743143ms]
Jul  3 22:07:13.098: INFO: Created: latency-svc-9kddt
Jul  3 22:07:13.115: INFO: Got endpoints: latency-svc-9kddt [91.739123ms]
Jul  3 22:07:13.122: INFO: Created: latency-svc-k2hwt
Jul  3 22:07:13.129: INFO: Got endpoints: latency-svc-k2hwt [106.526541ms]
Jul  3 22:07:13.131: INFO: Created: latency-svc-dgwv4
Jul  3 22:07:13.141: INFO: Got endpoints: latency-svc-dgwv4 [118.33778ms]
Jul  3 22:07:13.144: INFO: Created: latency-svc-k8knh
Jul  3 22:07:13.153: INFO: Created: latency-svc-4tb7c
Jul  3 22:07:13.153: INFO: Got endpoints: latency-svc-k8knh [130.402682ms]
Jul  3 22:07:13.161: INFO: Got endpoints: latency-svc-4tb7c [137.756697ms]
Jul  3 22:07:13.165: INFO: Created: latency-svc-lrbc7
Jul  3 22:07:13.172: INFO: Got endpoints: latency-svc-lrbc7 [149.38547ms]
Jul  3 22:07:13.175: INFO: Created: latency-svc-fxhnd
Jul  3 22:07:13.184: INFO: Got endpoints: latency-svc-fxhnd [160.766447ms]
Jul  3 22:07:13.185: INFO: Created: latency-svc-f56bn
Jul  3 22:07:13.192: INFO: Got endpoints: latency-svc-f56bn [169.177469ms]
Jul  3 22:07:13.194: INFO: Created: latency-svc-jp29n
Jul  3 22:07:13.205: INFO: Got endpoints: latency-svc-jp29n [182.619234ms]
Jul  3 22:07:13.214: INFO: Created: latency-svc-k569b
Jul  3 22:07:13.222: INFO: Got endpoints: latency-svc-k569b [199.3182ms]
Jul  3 22:07:13.227: INFO: Created: latency-svc-np6qc
Jul  3 22:07:13.235: INFO: Got endpoints: latency-svc-np6qc [183.181745ms]
Jul  3 22:07:13.241: INFO: Created: latency-svc-k7fxs
Jul  3 22:07:13.247: INFO: Created: latency-svc-kfd9t
Jul  3 22:07:13.248: INFO: Got endpoints: latency-svc-k7fxs [187.785834ms]
Jul  3 22:07:13.252: INFO: Got endpoints: latency-svc-kfd9t [179.031657ms]
Jul  3 22:07:13.255: INFO: Created: latency-svc-pbjll
Jul  3 22:07:13.264: INFO: Got endpoints: latency-svc-pbjll [176.907062ms]
Jul  3 22:07:13.285: INFO: Created: latency-svc-zpc2l
Jul  3 22:07:13.298: INFO: Got endpoints: latency-svc-zpc2l [205.613532ms]
Jul  3 22:07:13.306: INFO: Created: latency-svc-tjz2r
Jul  3 22:07:13.318: INFO: Created: latency-svc-plp6l
Jul  3 22:07:13.328: INFO: Got endpoints: latency-svc-tjz2r [213.077933ms]
Jul  3 22:07:13.332: INFO: Got endpoints: latency-svc-plp6l [202.324553ms]
Jul  3 22:07:13.336: INFO: Created: latency-svc-72wzf
Jul  3 22:07:13.346: INFO: Got endpoints: latency-svc-72wzf [204.744771ms]
Jul  3 22:07:13.350: INFO: Created: latency-svc-8zbcf
Jul  3 22:07:13.355: INFO: Got endpoints: latency-svc-8zbcf [201.041778ms]
Jul  3 22:07:13.360: INFO: Created: latency-svc-qgkcn
Jul  3 22:07:13.367: INFO: Got endpoints: latency-svc-qgkcn [206.741642ms]
Jul  3 22:07:13.372: INFO: Created: latency-svc-mkd4m
Jul  3 22:07:13.379: INFO: Got endpoints: latency-svc-mkd4m [206.75422ms]
Jul  3 22:07:13.382: INFO: Created: latency-svc-8f8l8
Jul  3 22:07:13.398: INFO: Created: latency-svc-jvh87
Jul  3 22:07:13.399: INFO: Got endpoints: latency-svc-8f8l8 [215.488671ms]
Jul  3 22:07:13.406: INFO: Got endpoints: latency-svc-jvh87 [213.539068ms]
Jul  3 22:07:13.420: INFO: Created: latency-svc-98z9g
Jul  3 22:07:13.428: INFO: Got endpoints: latency-svc-98z9g [222.534215ms]
Jul  3 22:07:13.440: INFO: Created: latency-svc-r4tfh
Jul  3 22:07:13.441: INFO: Got endpoints: latency-svc-r4tfh [218.210164ms]
Jul  3 22:07:13.453: INFO: Created: latency-svc-rmkkz
Jul  3 22:07:13.460: INFO: Got endpoints: latency-svc-rmkkz [223.844433ms]
Jul  3 22:07:13.463: INFO: Created: latency-svc-89nn2
Jul  3 22:07:13.477: INFO: Got endpoints: latency-svc-89nn2 [228.550515ms]
Jul  3 22:07:13.484: INFO: Created: latency-svc-wzpkv
Jul  3 22:07:13.495: INFO: Created: latency-svc-f6sbc
Jul  3 22:07:13.502: INFO: Got endpoints: latency-svc-wzpkv [249.647462ms]
Jul  3 22:07:13.504: INFO: Got endpoints: latency-svc-f6sbc [239.561006ms]
Jul  3 22:07:13.510: INFO: Created: latency-svc-x22p9
Jul  3 22:07:13.521: INFO: Created: latency-svc-stmnk
Jul  3 22:07:13.529: INFO: Created: latency-svc-g28wf
Jul  3 22:07:13.532: INFO: Got endpoints: latency-svc-x22p9 [233.971737ms]
Jul  3 22:07:13.536: INFO: Created: latency-svc-pmpmg
Jul  3 22:07:13.546: INFO: Created: latency-svc-7lp4c
Jul  3 22:07:13.552: INFO: Got endpoints: latency-svc-g28wf [219.93198ms]
Jul  3 22:07:13.552: INFO: Got endpoints: latency-svc-stmnk [224.471672ms]
Jul  3 22:07:13.556: INFO: Got endpoints: latency-svc-7lp4c [201.193794ms]
Jul  3 22:07:13.556: INFO: Got endpoints: latency-svc-pmpmg [209.915651ms]
Jul  3 22:07:13.560: INFO: Created: latency-svc-g8hzg
Jul  3 22:07:13.571: INFO: Created: latency-svc-7qdl8
Jul  3 22:07:13.575: INFO: Got endpoints: latency-svc-g8hzg [207.853003ms]
Jul  3 22:07:13.582: INFO: Created: latency-svc-dxxcf
Jul  3 22:07:13.603: INFO: Created: latency-svc-s9vgd
Jul  3 22:07:13.603: INFO: Created: latency-svc-xwmph
Jul  3 22:07:13.622: INFO: Created: latency-svc-rgrth
Jul  3 22:07:13.625: INFO: Got endpoints: latency-svc-7qdl8 [245.651375ms]
Jul  3 22:07:13.638: INFO: Created: latency-svc-4jdzw
Jul  3 22:07:13.646: INFO: Created: latency-svc-dv8zj
Jul  3 22:07:13.658: INFO: Created: latency-svc-pk76r
Jul  3 22:07:13.670: INFO: Got endpoints: latency-svc-dxxcf [270.946837ms]
Jul  3 22:07:13.673: INFO: Created: latency-svc-7n4tc
Jul  3 22:07:13.687: INFO: Created: latency-svc-wx7db
Jul  3 22:07:13.691: INFO: Created: latency-svc-m9thk
Jul  3 22:07:13.703: INFO: Created: latency-svc-mvrfg
Jul  3 22:07:13.722: INFO: Created: latency-svc-glqlm
Jul  3 22:07:13.730: INFO: Created: latency-svc-z4c2r
Jul  3 22:07:13.732: INFO: Got endpoints: latency-svc-s9vgd [326.375586ms]
Jul  3 22:07:13.751: INFO: Created: latency-svc-b99kz
Jul  3 22:07:13.768: INFO: Created: latency-svc-522g7
Jul  3 22:07:13.778: INFO: Created: latency-svc-7gmzp
Jul  3 22:07:13.781: INFO: Got endpoints: latency-svc-xwmph [352.188206ms]
Jul  3 22:07:13.784: INFO: Created: latency-svc-8klpj
Jul  3 22:07:13.798: INFO: Created: latency-svc-wj6g6
Jul  3 22:07:13.820: INFO: Got endpoints: latency-svc-rgrth [379.33412ms]
Jul  3 22:07:13.835: INFO: Created: latency-svc-jgqdb
Jul  3 22:07:13.869: INFO: Got endpoints: latency-svc-4jdzw [409.037602ms]
Jul  3 22:07:13.886: INFO: Created: latency-svc-2b8g7
Jul  3 22:07:13.944: INFO: Got endpoints: latency-svc-dv8zj [466.638508ms]
Jul  3 22:07:13.968: INFO: Created: latency-svc-qztj8
Jul  3 22:07:13.972: INFO: Got endpoints: latency-svc-pk76r [470.450709ms]
Jul  3 22:07:13.989: INFO: Created: latency-svc-wvcnn
Jul  3 22:07:14.023: INFO: Got endpoints: latency-svc-7n4tc [519.048041ms]
Jul  3 22:07:14.043: INFO: Created: latency-svc-q7rd7
Jul  3 22:07:14.083: INFO: Got endpoints: latency-svc-wx7db [551.179834ms]
Jul  3 22:07:14.102: INFO: Created: latency-svc-hcbf9
Jul  3 22:07:14.142: INFO: Got endpoints: latency-svc-m9thk [589.67022ms]
Jul  3 22:07:14.163: INFO: Created: latency-svc-q24jr
Jul  3 22:07:14.173: INFO: Got endpoints: latency-svc-mvrfg [620.349653ms]
Jul  3 22:07:14.191: INFO: Created: latency-svc-hd448
Jul  3 22:07:14.228: INFO: Got endpoints: latency-svc-glqlm [671.605883ms]
Jul  3 22:07:14.249: INFO: Created: latency-svc-2tjjp
Jul  3 22:07:14.273: INFO: Got endpoints: latency-svc-z4c2r [716.523272ms]
Jul  3 22:07:14.290: INFO: Created: latency-svc-b8rbs
Jul  3 22:07:14.322: INFO: Got endpoints: latency-svc-b99kz [746.417747ms]
Jul  3 22:07:14.349: INFO: Created: latency-svc-6vpjq
Jul  3 22:07:14.372: INFO: Got endpoints: latency-svc-522g7 [746.33678ms]
Jul  3 22:07:14.392: INFO: Created: latency-svc-rqsbn
Jul  3 22:07:14.424: INFO: Got endpoints: latency-svc-7gmzp [753.056404ms]
Jul  3 22:07:14.440: INFO: Created: latency-svc-kbkvp
Jul  3 22:07:14.472: INFO: Got endpoints: latency-svc-8klpj [738.904408ms]
Jul  3 22:07:14.488: INFO: Created: latency-svc-ckgzd
Jul  3 22:07:14.523: INFO: Got endpoints: latency-svc-wj6g6 [741.788293ms]
Jul  3 22:07:14.538: INFO: Created: latency-svc-rm446
Jul  3 22:07:14.574: INFO: Got endpoints: latency-svc-jgqdb [753.888341ms]
Jul  3 22:07:14.589: INFO: Created: latency-svc-ssbng
Jul  3 22:07:14.619: INFO: Got endpoints: latency-svc-2b8g7 [750.286505ms]
Jul  3 22:07:14.638: INFO: Created: latency-svc-d27lf
Jul  3 22:07:14.670: INFO: Got endpoints: latency-svc-qztj8 [725.730886ms]
Jul  3 22:07:14.694: INFO: Created: latency-svc-7z8q2
Jul  3 22:07:14.726: INFO: Got endpoints: latency-svc-wvcnn [753.257104ms]
Jul  3 22:07:14.759: INFO: Created: latency-svc-tt7h9
Jul  3 22:07:14.776: INFO: Got endpoints: latency-svc-q7rd7 [752.515196ms]
Jul  3 22:07:14.793: INFO: Created: latency-svc-bpmj8
Jul  3 22:07:14.819: INFO: Got endpoints: latency-svc-hcbf9 [736.096563ms]
Jul  3 22:07:14.836: INFO: Created: latency-svc-fzp4z
Jul  3 22:07:14.873: INFO: Got endpoints: latency-svc-q24jr [731.352886ms]
Jul  3 22:07:14.894: INFO: Created: latency-svc-gw887
Jul  3 22:07:14.921: INFO: Got endpoints: latency-svc-hd448 [747.898328ms]
Jul  3 22:07:14.937: INFO: Created: latency-svc-ztf6t
Jul  3 22:07:14.973: INFO: Got endpoints: latency-svc-2tjjp [744.849983ms]
Jul  3 22:07:14.993: INFO: Created: latency-svc-88d9b
Jul  3 22:07:15.030: INFO: Got endpoints: latency-svc-b8rbs [756.088676ms]
Jul  3 22:07:15.071: INFO: Created: latency-svc-twgl2
Jul  3 22:07:15.073: INFO: Got endpoints: latency-svc-6vpjq [750.994335ms]
Jul  3 22:07:15.089: INFO: Created: latency-svc-bdgrb
Jul  3 22:07:15.135: INFO: Got endpoints: latency-svc-rqsbn [763.021166ms]
Jul  3 22:07:15.173: INFO: Created: latency-svc-xhgh5
Jul  3 22:07:15.176: INFO: Got endpoints: latency-svc-kbkvp [751.960906ms]
Jul  3 22:07:15.192: INFO: Created: latency-svc-sbw57
Jul  3 22:07:15.219: INFO: Got endpoints: latency-svc-ckgzd [746.731649ms]
Jul  3 22:07:15.238: INFO: Created: latency-svc-5lp8f
Jul  3 22:07:15.271: INFO: Got endpoints: latency-svc-rm446 [747.557748ms]
Jul  3 22:07:15.286: INFO: Created: latency-svc-bbbqx
Jul  3 22:07:15.320: INFO: Got endpoints: latency-svc-ssbng [745.833804ms]
Jul  3 22:07:15.336: INFO: Created: latency-svc-vd66n
Jul  3 22:07:15.371: INFO: Got endpoints: latency-svc-d27lf [751.411867ms]
Jul  3 22:07:15.386: INFO: Created: latency-svc-qpslr
Jul  3 22:07:15.425: INFO: Got endpoints: latency-svc-7z8q2 [750.737262ms]
Jul  3 22:07:15.446: INFO: Created: latency-svc-c7j5w
Jul  3 22:07:15.472: INFO: Got endpoints: latency-svc-tt7h9 [746.112319ms]
Jul  3 22:07:15.489: INFO: Created: latency-svc-b7p8b
Jul  3 22:07:15.521: INFO: Got endpoints: latency-svc-bpmj8 [744.489476ms]
Jul  3 22:07:15.561: INFO: Created: latency-svc-9h6qz
Jul  3 22:07:15.571: INFO: Got endpoints: latency-svc-fzp4z [751.224579ms]
Jul  3 22:07:15.654: INFO: Got endpoints: latency-svc-gw887 [779.810043ms]
Jul  3 22:07:15.688: INFO: Created: latency-svc-wbgmm
Jul  3 22:07:15.693: INFO: Got endpoints: latency-svc-ztf6t [771.720979ms]
Jul  3 22:07:15.709: INFO: Created: latency-svc-zfk48
Jul  3 22:07:15.720: INFO: Created: latency-svc-bjn4w
Jul  3 22:07:15.723: INFO: Got endpoints: latency-svc-88d9b [749.977398ms]
Jul  3 22:07:15.753: INFO: Created: latency-svc-jh75k
Jul  3 22:07:15.777: INFO: Got endpoints: latency-svc-twgl2 [746.779858ms]
Jul  3 22:07:15.814: INFO: Created: latency-svc-vxrtf
Jul  3 22:07:15.822: INFO: Got endpoints: latency-svc-bdgrb [748.153596ms]
Jul  3 22:07:15.841: INFO: Created: latency-svc-xtltv
Jul  3 22:07:15.880: INFO: Got endpoints: latency-svc-xhgh5 [744.865294ms]
Jul  3 22:07:15.901: INFO: Created: latency-svc-w5wxs
Jul  3 22:07:15.920: INFO: Got endpoints: latency-svc-sbw57 [743.807309ms]
Jul  3 22:07:15.936: INFO: Created: latency-svc-8sjtq
Jul  3 22:07:15.976: INFO: Got endpoints: latency-svc-5lp8f [757.006446ms]
Jul  3 22:07:15.991: INFO: Created: latency-svc-5gv2g
Jul  3 22:07:16.022: INFO: Got endpoints: latency-svc-bbbqx [751.056732ms]
Jul  3 22:07:16.040: INFO: Created: latency-svc-z4n9h
Jul  3 22:07:16.074: INFO: Got endpoints: latency-svc-vd66n [753.930609ms]
Jul  3 22:07:16.093: INFO: Created: latency-svc-7q2wc
Jul  3 22:07:16.133: INFO: Got endpoints: latency-svc-qpslr [762.159058ms]
Jul  3 22:07:16.155: INFO: Created: latency-svc-x5zht
Jul  3 22:07:16.170: INFO: Got endpoints: latency-svc-c7j5w [745.245454ms]
Jul  3 22:07:16.208: INFO: Created: latency-svc-w665g
Jul  3 22:07:16.221: INFO: Got endpoints: latency-svc-b7p8b [748.810337ms]
Jul  3 22:07:16.237: INFO: Created: latency-svc-n8cc2
Jul  3 22:07:16.278: INFO: Got endpoints: latency-svc-9h6qz [757.068699ms]
Jul  3 22:07:16.302: INFO: Created: latency-svc-chh97
Jul  3 22:07:16.320: INFO: Got endpoints: latency-svc-wbgmm [749.003871ms]
Jul  3 22:07:16.337: INFO: Created: latency-svc-2xf5w
Jul  3 22:07:16.371: INFO: Got endpoints: latency-svc-zfk48 [716.946872ms]
Jul  3 22:07:16.389: INFO: Created: latency-svc-rclpq
Jul  3 22:07:16.419: INFO: Got endpoints: latency-svc-bjn4w [725.615085ms]
Jul  3 22:07:16.437: INFO: Created: latency-svc-dl6v5
Jul  3 22:07:16.471: INFO: Got endpoints: latency-svc-jh75k [747.452778ms]
Jul  3 22:07:16.488: INFO: Created: latency-svc-clkx8
Jul  3 22:07:16.520: INFO: Got endpoints: latency-svc-vxrtf [742.529667ms]
Jul  3 22:07:16.537: INFO: Created: latency-svc-9mfxq
Jul  3 22:07:16.575: INFO: Got endpoints: latency-svc-xtltv [752.517112ms]
Jul  3 22:07:16.591: INFO: Created: latency-svc-92nnb
Jul  3 22:07:16.622: INFO: Got endpoints: latency-svc-w5wxs [741.887784ms]
Jul  3 22:07:16.643: INFO: Created: latency-svc-wkqmp
Jul  3 22:07:16.671: INFO: Got endpoints: latency-svc-8sjtq [751.144996ms]
Jul  3 22:07:16.688: INFO: Created: latency-svc-w8zvc
Jul  3 22:07:16.723: INFO: Got endpoints: latency-svc-5gv2g [746.803447ms]
Jul  3 22:07:16.741: INFO: Created: latency-svc-6fhk7
Jul  3 22:07:16.771: INFO: Got endpoints: latency-svc-z4n9h [749.595346ms]
Jul  3 22:07:16.791: INFO: Created: latency-svc-jf7f9
Jul  3 22:07:16.834: INFO: Got endpoints: latency-svc-7q2wc [759.640593ms]
Jul  3 22:07:16.860: INFO: Created: latency-svc-q42cs
Jul  3 22:07:16.870: INFO: Got endpoints: latency-svc-x5zht [733.074967ms]
Jul  3 22:07:16.889: INFO: Created: latency-svc-q6mnf
Jul  3 22:07:16.926: INFO: Got endpoints: latency-svc-w665g [755.447627ms]
Jul  3 22:07:16.943: INFO: Created: latency-svc-zh97m
Jul  3 22:07:16.973: INFO: Got endpoints: latency-svc-n8cc2 [751.955575ms]
Jul  3 22:07:16.991: INFO: Created: latency-svc-qs2qg
Jul  3 22:07:17.023: INFO: Got endpoints: latency-svc-chh97 [745.698881ms]
Jul  3 22:07:17.037: INFO: Created: latency-svc-7d6zh
Jul  3 22:07:17.072: INFO: Got endpoints: latency-svc-2xf5w [751.747036ms]
Jul  3 22:07:17.088: INFO: Created: latency-svc-7dgjk
Jul  3 22:07:17.123: INFO: Got endpoints: latency-svc-rclpq [751.710166ms]
Jul  3 22:07:17.158: INFO: Created: latency-svc-dmzjm
Jul  3 22:07:17.172: INFO: Got endpoints: latency-svc-dl6v5 [750.990973ms]
Jul  3 22:07:17.197: INFO: Created: latency-svc-swm42
Jul  3 22:07:17.239: INFO: Got endpoints: latency-svc-clkx8 [767.735981ms]
Jul  3 22:07:17.260: INFO: Created: latency-svc-7pvs4
Jul  3 22:07:17.292: INFO: Got endpoints: latency-svc-9mfxq [771.12535ms]
Jul  3 22:07:17.321: INFO: Created: latency-svc-x6hv8
Jul  3 22:07:17.329: INFO: Got endpoints: latency-svc-92nnb [753.853188ms]
Jul  3 22:07:17.360: INFO: Created: latency-svc-skjdz
Jul  3 22:07:17.399: INFO: Got endpoints: latency-svc-wkqmp [777.05739ms]
Jul  3 22:07:17.428: INFO: Created: latency-svc-ttc2b
Jul  3 22:07:17.432: INFO: Got endpoints: latency-svc-w8zvc [760.745678ms]
Jul  3 22:07:17.472: INFO: Created: latency-svc-r652k
Jul  3 22:07:17.475: INFO: Got endpoints: latency-svc-6fhk7 [751.663479ms]
Jul  3 22:07:17.496: INFO: Created: latency-svc-7z5bn
Jul  3 22:07:17.536: INFO: Got endpoints: latency-svc-jf7f9 [764.754099ms]
Jul  3 22:07:17.552: INFO: Created: latency-svc-rrqgj
Jul  3 22:07:17.576: INFO: Got endpoints: latency-svc-q42cs [741.689295ms]
Jul  3 22:07:17.599: INFO: Created: latency-svc-84glf
Jul  3 22:07:17.622: INFO: Got endpoints: latency-svc-q6mnf [752.328006ms]
Jul  3 22:07:17.639: INFO: Created: latency-svc-frpkt
Jul  3 22:07:17.700: INFO: Got endpoints: latency-svc-zh97m [774.462862ms]
Jul  3 22:07:17.724: INFO: Got endpoints: latency-svc-qs2qg [750.750703ms]
Jul  3 22:07:17.726: INFO: Created: latency-svc-zt4hm
Jul  3 22:07:17.743: INFO: Created: latency-svc-rjz2m
Jul  3 22:07:17.784: INFO: Got endpoints: latency-svc-7d6zh [760.065328ms]
Jul  3 22:07:17.802: INFO: Created: latency-svc-v6j9j
Jul  3 22:07:17.820: INFO: Got endpoints: latency-svc-7dgjk [747.942113ms]
Jul  3 22:07:17.836: INFO: Created: latency-svc-p7p67
Jul  3 22:07:17.870: INFO: Got endpoints: latency-svc-dmzjm [747.038142ms]
Jul  3 22:07:17.917: INFO: Created: latency-svc-9bfj8
Jul  3 22:07:17.926: INFO: Got endpoints: latency-svc-swm42 [754.401883ms]
Jul  3 22:07:17.942: INFO: Created: latency-svc-fr8wb
Jul  3 22:07:17.984: INFO: Got endpoints: latency-svc-7pvs4 [744.125105ms]
Jul  3 22:07:18.002: INFO: Created: latency-svc-dsgv5
Jul  3 22:07:18.020: INFO: Got endpoints: latency-svc-x6hv8 [728.349386ms]
Jul  3 22:07:18.040: INFO: Created: latency-svc-fkrjl
Jul  3 22:07:18.070: INFO: Got endpoints: latency-svc-skjdz [741.649581ms]
Jul  3 22:07:18.100: INFO: Created: latency-svc-txb7l
Jul  3 22:07:18.126: INFO: Got endpoints: latency-svc-ttc2b [726.405747ms]
Jul  3 22:07:18.181: INFO: Got endpoints: latency-svc-r652k [749.372844ms]
Jul  3 22:07:18.182: INFO: Created: latency-svc-dw4b9
Jul  3 22:07:18.196: INFO: Created: latency-svc-gzw55
Jul  3 22:07:18.250: INFO: Got endpoints: latency-svc-7z5bn [774.888495ms]
Jul  3 22:07:18.268: INFO: Created: latency-svc-shzjj
Jul  3 22:07:18.270: INFO: Got endpoints: latency-svc-rrqgj [733.251069ms]
Jul  3 22:07:18.286: INFO: Created: latency-svc-5lxjm
Jul  3 22:07:18.331: INFO: Got endpoints: latency-svc-84glf [755.122474ms]
Jul  3 22:07:18.349: INFO: Created: latency-svc-fqp47
Jul  3 22:07:18.374: INFO: Got endpoints: latency-svc-frpkt [751.699233ms]
Jul  3 22:07:18.389: INFO: Created: latency-svc-8m7fw
Jul  3 22:07:18.423: INFO: Got endpoints: latency-svc-zt4hm [722.206882ms]
Jul  3 22:07:18.438: INFO: Created: latency-svc-68tcb
Jul  3 22:07:18.477: INFO: Got endpoints: latency-svc-rjz2m [752.723849ms]
Jul  3 22:07:18.496: INFO: Created: latency-svc-zpdvx
Jul  3 22:07:18.519: INFO: Got endpoints: latency-svc-v6j9j [735.638035ms]
Jul  3 22:07:18.536: INFO: Created: latency-svc-j9gm4
Jul  3 22:07:18.584: INFO: Got endpoints: latency-svc-p7p67 [763.655919ms]
Jul  3 22:07:18.602: INFO: Created: latency-svc-rkbss
Jul  3 22:07:18.621: INFO: Got endpoints: latency-svc-9bfj8 [750.545079ms]
Jul  3 22:07:18.637: INFO: Created: latency-svc-7r48d
Jul  3 22:07:18.670: INFO: Got endpoints: latency-svc-fr8wb [743.869327ms]
Jul  3 22:07:18.693: INFO: Created: latency-svc-2ljxl
Jul  3 22:07:18.720: INFO: Got endpoints: latency-svc-dsgv5 [736.132246ms]
Jul  3 22:07:18.736: INFO: Created: latency-svc-jmpzc
Jul  3 22:07:18.781: INFO: Got endpoints: latency-svc-fkrjl [760.511796ms]
Jul  3 22:07:18.796: INFO: Created: latency-svc-x5jn7
Jul  3 22:07:18.839: INFO: Got endpoints: latency-svc-txb7l [767.988817ms]
Jul  3 22:07:18.866: INFO: Created: latency-svc-v6lv7
Jul  3 22:07:18.870: INFO: Got endpoints: latency-svc-dw4b9 [743.927416ms]
Jul  3 22:07:18.886: INFO: Created: latency-svc-pn6kq
Jul  3 22:07:18.953: INFO: Got endpoints: latency-svc-gzw55 [771.201832ms]
Jul  3 22:07:18.972: INFO: Created: latency-svc-9vks8
Jul  3 22:07:18.974: INFO: Got endpoints: latency-svc-shzjj [724.130316ms]
Jul  3 22:07:18.996: INFO: Created: latency-svc-vpmdd
Jul  3 22:07:19.021: INFO: Got endpoints: latency-svc-5lxjm [751.523159ms]
Jul  3 22:07:19.043: INFO: Created: latency-svc-x8sph
Jul  3 22:07:19.071: INFO: Got endpoints: latency-svc-fqp47 [739.193301ms]
Jul  3 22:07:19.088: INFO: Created: latency-svc-r727k
Jul  3 22:07:19.120: INFO: Got endpoints: latency-svc-8m7fw [745.689833ms]
Jul  3 22:07:19.138: INFO: Created: latency-svc-r7chq
Jul  3 22:07:19.174: INFO: Got endpoints: latency-svc-68tcb [750.908732ms]
Jul  3 22:07:19.206: INFO: Created: latency-svc-jxj7v
Jul  3 22:07:19.221: INFO: Got endpoints: latency-svc-zpdvx [744.62228ms]
Jul  3 22:07:19.238: INFO: Created: latency-svc-ps5w5
Jul  3 22:07:19.272: INFO: Got endpoints: latency-svc-j9gm4 [752.371668ms]
Jul  3 22:07:19.293: INFO: Created: latency-svc-g9cfw
Jul  3 22:07:19.321: INFO: Got endpoints: latency-svc-rkbss [737.315345ms]
Jul  3 22:07:19.345: INFO: Created: latency-svc-2fmrf
Jul  3 22:07:19.371: INFO: Got endpoints: latency-svc-7r48d [750.187565ms]
Jul  3 22:07:19.388: INFO: Created: latency-svc-x2n6q
Jul  3 22:07:19.422: INFO: Got endpoints: latency-svc-2ljxl [751.555285ms]
Jul  3 22:07:19.444: INFO: Created: latency-svc-bnr4x
Jul  3 22:07:19.521: INFO: Got endpoints: latency-svc-jmpzc [801.408236ms]
Jul  3 22:07:19.524: INFO: Got endpoints: latency-svc-x5jn7 [743.315481ms]
Jul  3 22:07:19.541: INFO: Created: latency-svc-g7g7c
Jul  3 22:07:19.553: INFO: Created: latency-svc-wzpp7
Jul  3 22:07:19.570: INFO: Got endpoints: latency-svc-v6lv7 [730.888794ms]
Jul  3 22:07:19.589: INFO: Created: latency-svc-xxmhw
Jul  3 22:07:19.621: INFO: Got endpoints: latency-svc-pn6kq [751.307736ms]
Jul  3 22:07:19.640: INFO: Created: latency-svc-j9t5w
Jul  3 22:07:19.671: INFO: Got endpoints: latency-svc-9vks8 [718.577452ms]
Jul  3 22:07:19.689: INFO: Created: latency-svc-n64dk
Jul  3 22:07:19.722: INFO: Got endpoints: latency-svc-vpmdd [747.904278ms]
Jul  3 22:07:19.743: INFO: Created: latency-svc-tx8p6
Jul  3 22:07:19.772: INFO: Got endpoints: latency-svc-x8sph [750.035512ms]
Jul  3 22:07:19.791: INFO: Created: latency-svc-88kt8
Jul  3 22:07:19.821: INFO: Got endpoints: latency-svc-r727k [750.156502ms]
Jul  3 22:07:19.840: INFO: Created: latency-svc-f4dhx
Jul  3 22:07:19.877: INFO: Got endpoints: latency-svc-r7chq [757.057578ms]
Jul  3 22:07:19.893: INFO: Created: latency-svc-ms99r
Jul  3 22:07:19.924: INFO: Got endpoints: latency-svc-jxj7v [749.617596ms]
Jul  3 22:07:19.943: INFO: Created: latency-svc-sz6v6
Jul  3 22:07:19.972: INFO: Got endpoints: latency-svc-ps5w5 [750.604951ms]
Jul  3 22:07:19.991: INFO: Created: latency-svc-2bn7n
Jul  3 22:07:20.022: INFO: Got endpoints: latency-svc-g9cfw [750.303793ms]
Jul  3 22:07:20.043: INFO: Created: latency-svc-94mxt
Jul  3 22:07:20.072: INFO: Got endpoints: latency-svc-2fmrf [750.337488ms]
Jul  3 22:07:20.091: INFO: Created: latency-svc-cjcsn
Jul  3 22:07:20.124: INFO: Got endpoints: latency-svc-x2n6q [752.87774ms]
Jul  3 22:07:20.141: INFO: Created: latency-svc-gtq2q
Jul  3 22:07:20.172: INFO: Got endpoints: latency-svc-bnr4x [749.816503ms]
Jul  3 22:07:20.187: INFO: Created: latency-svc-v6m8x
Jul  3 22:07:20.220: INFO: Got endpoints: latency-svc-g7g7c [698.343694ms]
Jul  3 22:07:20.242: INFO: Created: latency-svc-hzpdr
Jul  3 22:07:20.287: INFO: Got endpoints: latency-svc-wzpp7 [762.975796ms]
Jul  3 22:07:20.311: INFO: Created: latency-svc-9qgm9
Jul  3 22:07:20.321: INFO: Got endpoints: latency-svc-xxmhw [750.799711ms]
Jul  3 22:07:20.343: INFO: Created: latency-svc-zrbsh
Jul  3 22:07:20.373: INFO: Got endpoints: latency-svc-j9t5w [751.042004ms]
Jul  3 22:07:20.392: INFO: Created: latency-svc-qcn5v
Jul  3 22:07:20.419: INFO: Got endpoints: latency-svc-n64dk [748.116323ms]
Jul  3 22:07:20.440: INFO: Created: latency-svc-4tgmt
Jul  3 22:07:20.473: INFO: Got endpoints: latency-svc-tx8p6 [750.812733ms]
Jul  3 22:07:20.490: INFO: Created: latency-svc-bcxdj
Jul  3 22:07:20.520: INFO: Got endpoints: latency-svc-88kt8 [748.553025ms]
Jul  3 22:07:20.541: INFO: Created: latency-svc-7x8sv
Jul  3 22:07:20.571: INFO: Got endpoints: latency-svc-f4dhx [749.562312ms]
Jul  3 22:07:20.588: INFO: Created: latency-svc-gt824
Jul  3 22:07:20.624: INFO: Got endpoints: latency-svc-ms99r [746.65356ms]
Jul  3 22:07:20.642: INFO: Created: latency-svc-fvk7d
Jul  3 22:07:20.678: INFO: Got endpoints: latency-svc-sz6v6 [753.88579ms]
Jul  3 22:07:20.694: INFO: Created: latency-svc-mlch6
Jul  3 22:07:20.737: INFO: Got endpoints: latency-svc-2bn7n [764.672099ms]
Jul  3 22:07:20.756: INFO: Created: latency-svc-bk2g4
Jul  3 22:07:20.772: INFO: Got endpoints: latency-svc-94mxt [749.72333ms]
Jul  3 22:07:20.790: INFO: Created: latency-svc-hk8d9
Jul  3 22:07:20.821: INFO: Got endpoints: latency-svc-cjcsn [749.101854ms]
Jul  3 22:07:20.844: INFO: Created: latency-svc-tmdv4
Jul  3 22:07:20.871: INFO: Got endpoints: latency-svc-gtq2q [746.995318ms]
Jul  3 22:07:20.923: INFO: Got endpoints: latency-svc-v6m8x [751.327511ms]
Jul  3 22:07:20.974: INFO: Got endpoints: latency-svc-hzpdr [754.346639ms]
Jul  3 22:07:21.020: INFO: Got endpoints: latency-svc-9qgm9 [733.001017ms]
Jul  3 22:07:21.119: INFO: Got endpoints: latency-svc-zrbsh [798.228516ms]
Jul  3 22:07:21.126: INFO: Got endpoints: latency-svc-qcn5v [752.980154ms]
Jul  3 22:07:21.182: INFO: Got endpoints: latency-svc-4tgmt [759.510939ms]
Jul  3 22:07:21.232: INFO: Got endpoints: latency-svc-bcxdj [759.062125ms]
Jul  3 22:07:21.271: INFO: Got endpoints: latency-svc-7x8sv [750.75617ms]
Jul  3 22:07:21.320: INFO: Got endpoints: latency-svc-gt824 [748.978638ms]
Jul  3 22:07:21.371: INFO: Got endpoints: latency-svc-fvk7d [747.319474ms]
Jul  3 22:07:21.421: INFO: Got endpoints: latency-svc-mlch6 [742.553199ms]
Jul  3 22:07:21.472: INFO: Got endpoints: latency-svc-bk2g4 [734.245341ms]
Jul  3 22:07:21.523: INFO: Got endpoints: latency-svc-hk8d9 [750.703038ms]
Jul  3 22:07:21.571: INFO: Got endpoints: latency-svc-tmdv4 [750.226378ms]
Jul  3 22:07:21.573: INFO: Latencies: [29.779109ms 37.277019ms 49.471651ms 64.306106ms 68.743143ms 91.739123ms 106.526541ms 118.33778ms 130.402682ms 137.756697ms 149.38547ms 160.766447ms 169.177469ms 176.907062ms 179.031657ms 182.619234ms 183.181745ms 187.785834ms 199.3182ms 201.041778ms 201.193794ms 202.324553ms 204.744771ms 205.613532ms 206.741642ms 206.75422ms 207.853003ms 209.915651ms 213.077933ms 213.539068ms 215.488671ms 218.210164ms 219.93198ms 222.534215ms 223.844433ms 224.471672ms 228.550515ms 233.971737ms 239.561006ms 245.651375ms 249.647462ms 270.946837ms 326.375586ms 352.188206ms 379.33412ms 409.037602ms 466.638508ms 470.450709ms 519.048041ms 551.179834ms 589.67022ms 620.349653ms 671.605883ms 698.343694ms 716.523272ms 716.946872ms 718.577452ms 722.206882ms 724.130316ms 725.615085ms 725.730886ms 726.405747ms 728.349386ms 730.888794ms 731.352886ms 733.001017ms 733.074967ms 733.251069ms 734.245341ms 735.638035ms 736.096563ms 736.132246ms 737.315345ms 738.904408ms 739.193301ms 741.649581ms 741.689295ms 741.788293ms 741.887784ms 742.529667ms 742.553199ms 743.315481ms 743.807309ms 743.869327ms 743.927416ms 744.125105ms 744.489476ms 744.62228ms 744.849983ms 744.865294ms 745.245454ms 745.689833ms 745.698881ms 745.833804ms 746.112319ms 746.33678ms 746.417747ms 746.65356ms 746.731649ms 746.779858ms 746.803447ms 746.995318ms 747.038142ms 747.319474ms 747.452778ms 747.557748ms 747.898328ms 747.904278ms 747.942113ms 748.116323ms 748.153596ms 748.553025ms 748.810337ms 748.978638ms 749.003871ms 749.101854ms 749.372844ms 749.562312ms 749.595346ms 749.617596ms 749.72333ms 749.816503ms 749.977398ms 750.035512ms 750.156502ms 750.187565ms 750.226378ms 750.286505ms 750.303793ms 750.337488ms 750.545079ms 750.604951ms 750.703038ms 750.737262ms 750.750703ms 750.75617ms 750.799711ms 750.812733ms 750.908732ms 750.990973ms 750.994335ms 751.042004ms 751.056732ms 751.144996ms 751.224579ms 751.307736ms 751.327511ms 751.411867ms 751.523159ms 751.555285ms 751.663479ms 751.699233ms 751.710166ms 751.747036ms 751.955575ms 751.960906ms 752.328006ms 752.371668ms 752.515196ms 752.517112ms 752.723849ms 752.87774ms 752.980154ms 753.056404ms 753.257104ms 753.853188ms 753.88579ms 753.888341ms 753.930609ms 754.346639ms 754.401883ms 755.122474ms 755.447627ms 756.088676ms 757.006446ms 757.057578ms 757.068699ms 759.062125ms 759.510939ms 759.640593ms 760.065328ms 760.511796ms 760.745678ms 762.159058ms 762.975796ms 763.021166ms 763.655919ms 764.672099ms 764.754099ms 767.735981ms 767.988817ms 771.12535ms 771.201832ms 771.720979ms 774.462862ms 774.888495ms 777.05739ms 779.810043ms 798.228516ms 801.408236ms]
Jul  3 22:07:21.573: INFO: 50 %ile: 746.803447ms
Jul  3 22:07:21.574: INFO: 90 %ile: 760.065328ms
Jul  3 22:07:21.574: INFO: 99 %ile: 798.228516ms
Jul  3 22:07:21.574: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:07:21.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8370" for this suite.
Jul  3 22:07:37.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:07:37.781: INFO: namespace svc-latency-8370 deletion completed in 16.195449201s

• [SLOW TEST:28.124 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:07:37.782: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0703 22:08:18.003557      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 22:08:18.003: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:08:18.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9985" for this suite.
Jul  3 22:08:26.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:08:26.183: INFO: namespace gc-9985 deletion completed in 8.172878176s

• [SLOW TEST:48.401 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:08:26.184: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul  3 22:08:26.361: INFO: Pod name pod-release: Found 0 pods out of 1
Jul  3 22:08:31.367: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:08:31.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-938" for this suite.
Jul  3 22:08:37.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:08:37.585: INFO: namespace replication-controller-938 deletion completed in 6.188178797s

• [SLOW TEST:11.402 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:08:37.586: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6246
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-1b96a999-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating secret with name s-test-opt-upd-1b96a9d3-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1b96a999-9ddf-11e9-b0a2-a612d8f3003c
STEP: Updating secret s-test-opt-upd-1b96a9d3-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating secret with name s-test-opt-create-1b96a9ed-9ddf-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:08:41.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6246" for this suite.
Jul  3 22:09:03.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:09:04.107: INFO: namespace projected-6246 deletion completed in 22.179539334s

• [SLOW TEST:26.521 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:09:04.108: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul  3 22:09:06.838: INFO: Successfully updated pod "labelsupdate2b647168-9ddf-11e9-b0a2-a612d8f3003c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:09:08.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2101" for this suite.
Jul  3 22:09:30.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:09:31.047: INFO: namespace downward-api-2101 deletion completed in 22.181286886s

• [SLOW TEST:26.940 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:09:31.054: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-3b74087c-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating secret with name secret-projected-all-test-volume-3b740864-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul  3 22:09:31.249: INFO: Waiting up to 5m0s for pod "projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c" in namespace "projected-2701" to be "success or failure"
Jul  3 22:09:31.254: INFO: Pod "projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.329978ms
Jul  3 22:09:33.261: INFO: Pod "projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011741408s
Jul  3 22:09:35.267: INFO: Pod "projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017801996s
STEP: Saw pod success
Jul  3 22:09:35.267: INFO: Pod "projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:09:35.272: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c container projected-all-volume-test: <nil>
STEP: delete the pod
Jul  3 22:09:35.301: INFO: Waiting for pod projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:09:35.305: INFO: Pod projected-volume-3b740828-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:09:35.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2701" for this suite.
Jul  3 22:09:41.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:09:41.524: INFO: namespace projected-2701 deletion completed in 6.21310723s

• [SLOW TEST:10.471 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:09:41.525: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-41b127a3-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:09:41.712: INFO: Waiting up to 5m0s for pod "pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c" in namespace "secrets-8619" to be "success or failure"
Jul  3 22:09:41.716: INFO: Pod "pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.779109ms
Jul  3 22:09:43.722: INFO: Pod "pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00998613s
Jul  3 22:09:45.729: INFO: Pod "pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016505339s
STEP: Saw pod success
Jul  3 22:09:45.729: INFO: Pod "pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:09:45.737: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c container secret-env-test: <nil>
STEP: delete the pod
Jul  3 22:09:45.768: INFO: Waiting for pod pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:09:45.772: INFO: Pod pod-secrets-41b25956-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:09:45.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8619" for this suite.
Jul  3 22:09:51.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:09:51.957: INFO: namespace secrets-8619 deletion completed in 6.173276599s

• [SLOW TEST:10.432 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:09:51.957: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  3 22:09:52.134: INFO: Waiting up to 5m0s for pod "pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c" in namespace "emptydir-3610" to be "success or failure"
Jul  3 22:09:52.141: INFO: Pod "pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.98051ms
Jul  3 22:09:54.147: INFO: Pod "pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012751024s
STEP: Saw pod success
Jul  3 22:09:54.147: INFO: Pod "pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:09:54.153: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:09:54.180: INFO: Waiting for pod pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:09:54.184: INFO: Pod pod-47e8c0f5-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:09:54.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3610" for this suite.
Jul  3 22:10:00.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:10:00.373: INFO: namespace emptydir-3610 deletion completed in 6.182654105s

• [SLOW TEST:8.415 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:10:00.373: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:10:00.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c" in namespace "downward-api-791" to be "success or failure"
Jul  3 22:10:00.568: INFO: Pod "downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926775ms
Jul  3 22:10:02.574: INFO: Pod "downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011697952s
STEP: Saw pod success
Jul  3 22:10:02.575: INFO: Pod "downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:10:02.579: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:10:02.604: INFO: Waiting for pod downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:10:02.608: INFO: Pod downwardapi-volume-4cee95cd-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:10:02.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-791" for this suite.
Jul  3 22:10:08.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:10:08.790: INFO: namespace downward-api-791 deletion completed in 6.174401281s

• [SLOW TEST:8.417 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:10:08.792: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-wrd6
STEP: Creating a pod to test atomic-volume-subpath
Jul  3 22:10:08.978: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wrd6" in namespace "subpath-2395" to be "success or failure"
Jul  3 22:10:08.984: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993487ms
Jul  3 22:10:10.991: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012126865s
Jul  3 22:10:12.998: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 4.019884748s
Jul  3 22:10:15.008: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 6.029786967s
Jul  3 22:10:17.015: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 8.036859909s
Jul  3 22:10:19.023: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 10.044783925s
Jul  3 22:10:21.031: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 12.052131729s
Jul  3 22:10:23.038: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 14.059862292s
Jul  3 22:10:25.047: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 16.068137819s
Jul  3 22:10:27.052: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 18.07334796s
Jul  3 22:10:29.059: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Running", Reason="", readiness=true. Elapsed: 20.080705936s
Jul  3 22:10:31.066: INFO: Pod "pod-subpath-test-projected-wrd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.087449574s
STEP: Saw pod success
Jul  3 22:10:31.066: INFO: Pod "pod-subpath-test-projected-wrd6" satisfied condition "success or failure"
Jul  3 22:10:31.070: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-subpath-test-projected-wrd6 container test-container-subpath-projected-wrd6: <nil>
STEP: delete the pod
Jul  3 22:10:31.097: INFO: Waiting for pod pod-subpath-test-projected-wrd6 to disappear
Jul  3 22:10:31.101: INFO: Pod pod-subpath-test-projected-wrd6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-wrd6
Jul  3 22:10:31.101: INFO: Deleting pod "pod-subpath-test-projected-wrd6" in namespace "subpath-2395"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:10:31.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2395" for this suite.
Jul  3 22:10:37.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:10:37.308: INFO: namespace subpath-2395 deletion completed in 6.197778991s

• [SLOW TEST:28.517 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:10:37.309: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3826
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Jul  3 22:10:37.489: INFO: Waiting up to 5m0s for pod "pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c" in namespace "emptydir-3826" to be "success or failure"
Jul  3 22:10:37.494: INFO: Pod "pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.069309ms
Jul  3 22:10:39.503: INFO: Pod "pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014438289s
Jul  3 22:10:41.509: INFO: Pod "pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020061013s
STEP: Saw pod success
Jul  3 22:10:41.509: INFO: Pod "pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:10:41.514: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:10:41.541: INFO: Waiting for pod pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:10:41.545: INFO: Pod pod-62f13739-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:10:41.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3826" for this suite.
Jul  3 22:10:47.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:10:47.728: INFO: namespace emptydir-3826 deletion completed in 6.175160809s

• [SLOW TEST:10.420 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:10:47.729: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul  3 22:10:47.907: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11386,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul  3 22:10:47.907: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11386,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul  3 22:10:57.922: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11414,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul  3 22:10:57.923: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11414,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul  3 22:11:07.937: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11442,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul  3 22:11:07.937: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11442,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul  3 22:11:17.951: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11470,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul  3 22:11:17.951: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-a,UID:6927d050-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11470,Generation:0,CreationTimestamp:2019-07-03 22:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul  3 22:11:27.963: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-b,UID:81074581-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11498,Generation:0,CreationTimestamp:2019-07-03 22:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul  3 22:11:27.963: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-b,UID:81074581-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11498,Generation:0,CreationTimestamp:2019-07-03 22:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul  3 22:11:37.976: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-b,UID:81074581-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11526,Generation:0,CreationTimestamp:2019-07-03 22:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul  3 22:11:37.976: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5363,SelfLink:/api/v1/namespaces/watch-5363/configmaps/e2e-watch-test-configmap-b,UID:81074581-9ddf-11e9-a55c-fa163e25a4f0,ResourceVersion:11526,Generation:0,CreationTimestamp:2019-07-03 22:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:11:47.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5363" for this suite.
Jul  3 22:11:54.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:11:54.172: INFO: namespace watch-5363 deletion completed in 6.185602953s

• [SLOW TEST:66.443 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:11:54.173: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:11:54.337: INFO: Creating ReplicaSet my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c
Jul  3 22:11:54.349: INFO: Pod name my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c: Found 0 pods out of 1
Jul  3 22:11:59.357: INFO: Pod name my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c: Found 1 pods out of 1
Jul  3 22:11:59.357: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c" is running
Jul  3 22:11:59.361: INFO: Pod "my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c-nrxvm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 22:11:54 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 22:11:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 22:11:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 22:11:54 +0000 UTC Reason: Message:}])
Jul  3 22:11:59.362: INFO: Trying to dial the pod
Jul  3 22:12:04.386: INFO: Controller my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c: Got expected result from replica 1 [my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c-nrxvm]: "my-hostname-basic-90c1689c-9ddf-11e9-b0a2-a612d8f3003c-nrxvm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:12:04.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8101" for this suite.
Jul  3 22:12:10.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:12:10.593: INFO: namespace replicaset-8101 deletion completed in 6.197958866s

• [SLOW TEST:16.420 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:12:10.594: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  3 22:12:10.767: INFO: Waiting up to 5m0s for pod "pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c" in namespace "emptydir-7246" to be "success or failure"
Jul  3 22:12:10.775: INFO: Pod "pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.18323ms
Jul  3 22:12:12.781: INFO: Pod "pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013781947s
Jul  3 22:12:14.788: INFO: Pod "pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020680502s
STEP: Saw pod success
Jul  3 22:12:14.788: INFO: Pod "pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:12:14.794: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:12:14.827: INFO: Waiting for pod pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:12:14.831: INFO: Pod pod-9a8abd70-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:12:14.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7246" for this suite.
Jul  3 22:12:20.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:12:21.029: INFO: namespace emptydir-7246 deletion completed in 6.19058861s

• [SLOW TEST:10.436 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:12:21.030: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-8xtl
STEP: Creating a pod to test atomic-volume-subpath
Jul  3 22:12:21.221: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-8xtl" in namespace "subpath-7752" to be "success or failure"
Jul  3 22:12:21.225: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57892ms
Jul  3 22:12:23.232: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 2.011713236s
Jul  3 22:12:25.242: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 4.021051162s
Jul  3 22:12:27.248: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 6.027536529s
Jul  3 22:12:29.255: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 8.034383037s
Jul  3 22:12:31.263: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 10.042204995s
Jul  3 22:12:33.270: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 12.048984199s
Jul  3 22:12:35.278: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 14.056840312s
Jul  3 22:12:37.286: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 16.065006176s
Jul  3 22:12:39.293: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 18.072250435s
Jul  3 22:12:41.300: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Running", Reason="", readiness=true. Elapsed: 20.079555384s
Jul  3 22:12:43.307: INFO: Pod "pod-subpath-test-secret-8xtl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.086044526s
STEP: Saw pod success
Jul  3 22:12:43.307: INFO: Pod "pod-subpath-test-secret-8xtl" satisfied condition "success or failure"
Jul  3 22:12:43.312: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-subpath-test-secret-8xtl container test-container-subpath-secret-8xtl: <nil>
STEP: delete the pod
Jul  3 22:12:43.345: INFO: Waiting for pod pod-subpath-test-secret-8xtl to disappear
Jul  3 22:12:43.351: INFO: Pod pod-subpath-test-secret-8xtl no longer exists
STEP: Deleting pod pod-subpath-test-secret-8xtl
Jul  3 22:12:43.351: INFO: Deleting pod "pod-subpath-test-secret-8xtl" in namespace "subpath-7752"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:12:43.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7752" for this suite.
Jul  3 22:12:49.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:12:49.553: INFO: namespace subpath-7752 deletion completed in 6.192055834s

• [SLOW TEST:28.524 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:12:49.554: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Jul  3 22:12:49.727: INFO: Waiting up to 5m0s for pod "client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c" in namespace "containers-9780" to be "success or failure"
Jul  3 22:12:49.732: INFO: Pod "client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.934279ms
Jul  3 22:12:51.741: INFO: Pod "client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014155032s
Jul  3 22:12:53.748: INFO: Pod "client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020961807s
STEP: Saw pod success
Jul  3 22:12:53.748: INFO: Pod "client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:12:53.752: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:12:53.785: INFO: Waiting for pod client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:12:53.789: INFO: Pod client-containers-b1c35e4d-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:12:53.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9780" for this suite.
Jul  3 22:12:59.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:13:00.000: INFO: namespace containers-9780 deletion completed in 6.202376719s

• [SLOW TEST:10.446 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:13:00.001: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b7fffb80-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:13:00.200: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c" in namespace "projected-4255" to be "success or failure"
Jul  3 22:13:00.212: INFO: Pod "pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.450263ms
Jul  3 22:13:02.219: INFO: Pod "pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018838414s
STEP: Saw pod success
Jul  3 22:13:02.219: INFO: Pod "pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:13:02.223: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:13:02.253: INFO: Waiting for pod pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:13:02.257: INFO: Pod pod-projected-secrets-b80128e4-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:13:02.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4255" for this suite.
Jul  3 22:13:08.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:13:08.453: INFO: namespace projected-4255 deletion completed in 6.187346692s

• [SLOW TEST:8.452 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:13:08.453: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3720
Jul  3 22:13:12.642: INFO: Started pod liveness-http in namespace container-probe-3720
STEP: checking the pod's current state and verifying that restartCount is present
Jul  3 22:13:12.648: INFO: Initial restart count of pod liveness-http is 0
Jul  3 22:13:30.712: INFO: Restart count of pod container-probe-3720/liveness-http is now 1 (18.064633747s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:13:30.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3720" for this suite.
Jul  3 22:13:36.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:13:36.922: INFO: namespace container-probe-3720 deletion completed in 6.184746119s

• [SLOW TEST:28.469 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:13:36.922: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-cdffc215-9ddf-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:13:37.112: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c" in namespace "projected-875" to be "success or failure"
Jul  3 22:13:37.116: INFO: Pod "pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.818502ms
Jul  3 22:13:39.123: INFO: Pod "pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011293729s
Jul  3 22:13:41.130: INFO: Pod "pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017810324s
STEP: Saw pod success
Jul  3 22:13:41.130: INFO: Pod "pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:13:41.134: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:13:41.160: INFO: Waiting for pod pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:13:41.164: INFO: Pod pod-projected-secrets-ce00bfea-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:13:41.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-875" for this suite.
Jul  3 22:13:47.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:13:47.338: INFO: namespace projected-875 deletion completed in 6.166820896s

• [SLOW TEST:10.416 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:13:47.341: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:12.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9337" for this suite.
Jul  3 22:14:18.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:14:19.042: INFO: namespace container-runtime-9337 deletion completed in 6.182793672s

• [SLOW TEST:31.702 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:14:19.045: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:14:19.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c" in namespace "projected-362" to be "success or failure"
Jul  3 22:14:19.220: INFO: Pod "downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11156ms
Jul  3 22:14:21.225: INFO: Pod "downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008730101s
STEP: Saw pod success
Jul  3 22:14:21.225: INFO: Pod "downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:14:21.229: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:14:21.260: INFO: Waiting for pod downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:14:21.266: INFO: Pod downwardapi-volume-e71ab0c5-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:21.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-362" for this suite.
Jul  3 22:14:27.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:14:27.492: INFO: namespace projected-362 deletion completed in 6.21893746s

• [SLOW TEST:8.447 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:14:27.492: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Jul  3 22:14:30.209: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9136 pod-service-account-ec745988-9ddf-11e9-b0a2-a612d8f3003c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul  3 22:14:30.465: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9136 pod-service-account-ec745988-9ddf-11e9-b0a2-a612d8f3003c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul  3 22:14:30.699: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9136 pod-service-account-ec745988-9ddf-11e9-b0a2-a612d8f3003c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:30.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9136" for this suite.
Jul  3 22:14:36.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:14:37.119: INFO: namespace svcaccounts-9136 deletion completed in 6.182534406s

• [SLOW TEST:9.627 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:14:37.119: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Jul  3 22:14:37.289: INFO: Waiting up to 5m0s for pod "client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c" in namespace "containers-1478" to be "success or failure"
Jul  3 22:14:37.294: INFO: Pod "client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.668714ms
Jul  3 22:14:39.300: INFO: Pod "client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010280194s
STEP: Saw pod success
Jul  3 22:14:39.300: INFO: Pod "client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:14:39.304: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:14:39.330: INFO: Waiting for pod client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:14:39.334: INFO: Pod client-containers-f1e056cb-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:39.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1478" for this suite.
Jul  3 22:14:45.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:14:45.517: INFO: namespace containers-1478 deletion completed in 6.176395405s

• [SLOW TEST:8.398 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:14:45.518: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  3 22:14:45.698: INFO: Waiting up to 5m0s for pod "pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c" in namespace "emptydir-5792" to be "success or failure"
Jul  3 22:14:45.702: INFO: Pod "pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.660572ms
Jul  3 22:14:47.709: INFO: Pod "pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011143693s
STEP: Saw pod success
Jul  3 22:14:47.709: INFO: Pod "pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:14:47.714: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:14:47.743: INFO: Waiting for pod pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:14:47.748: INFO: Pod pod-f6e313c0-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:47.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5792" for this suite.
Jul  3 22:14:53.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:14:53.931: INFO: namespace emptydir-5792 deletion completed in 6.177326435s

• [SLOW TEST:8.413 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:14:53.932: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  3 22:14:54.113: INFO: Waiting up to 5m0s for pod "pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c" in namespace "emptydir-1787" to be "success or failure"
Jul  3 22:14:54.119: INFO: Pod "pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93383ms
Jul  3 22:14:56.126: INFO: Pod "pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012887867s
Jul  3 22:14:58.132: INFO: Pod "pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018987155s
STEP: Saw pod success
Jul  3 22:14:58.132: INFO: Pod "pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:14:58.138: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:14:58.164: INFO: Waiting for pod pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:14:58.167: INFO: Pod pod-fbe6810f-9ddf-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:14:58.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1787" for this suite.
Jul  3 22:15:04.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:15:04.350: INFO: namespace emptydir-1787 deletion completed in 6.177454231s

• [SLOW TEST:10.419 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:15:04.352: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:15:04.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9099" for this suite.
Jul  3 22:15:26.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:15:26.716: INFO: namespace pods-9099 deletion completed in 22.175299901s

• [SLOW TEST:22.364 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:15:26.717: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7058
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Jul  3 22:15:30.923: INFO: Pod pod-hostip-0f716b07-9de0-11e9-b0a2-a612d8f3003c has hostIP: 10.0.0.9
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:15:30.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7058" for this suite.
Jul  3 22:15:52.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:15:53.117: INFO: namespace pods-7058 deletion completed in 22.187028359s

• [SLOW TEST:26.401 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:15:53.120: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:15:53.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c" in namespace "downward-api-3934" to be "success or failure"
Jul  3 22:15:53.346: INFO: Pod "downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.929902ms
Jul  3 22:15:55.356: INFO: Pod "downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015447404s
STEP: Saw pod success
Jul  3 22:15:55.356: INFO: Pod "downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:15:55.362: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:15:55.415: INFO: Waiting for pod downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:15:55.418: INFO: Pod downwardapi-volume-1f34c699-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:15:55.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3934" for this suite.
Jul  3 22:16:01.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:16:01.609: INFO: namespace downward-api-3934 deletion completed in 6.184520709s

• [SLOW TEST:8.489 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:16:01.610: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4335
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  3 22:16:01.774: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul  3 22:16:27.944: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.97.16:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:16:27.944: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:16:28.110: INFO: Found all expected endpoints: [netserver-0]
Jul  3 22:16:28.116: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.17.10:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:16:28.116: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:16:28.276: INFO: Found all expected endpoints: [netserver-1]
Jul  3 22:16:28.284: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.5.5:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:16:28.284: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:16:28.421: INFO: Found all expected endpoints: [netserver-2]
Jul  3 22:16:28.428: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.248.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:16:28.428: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:16:28.591: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:16:28.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4335" for this suite.
Jul  3 22:16:52.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:16:52.784: INFO: namespace pod-network-test-4335 deletion completed in 24.184831447s

• [SLOW TEST:51.174 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:16:52.785: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2948
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul  3 22:16:52.978: INFO: Found 0 stateful pods, waiting for 3
Jul  3 22:17:02.987: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:17:02.987: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:17:02.987: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul  3 22:17:03.033: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul  3 22:17:13.090: INFO: Updating stateful set ss2
Jul  3 22:17:13.110: INFO: Waiting for Pod statefulset-2948/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jul  3 22:17:23.177: INFO: Found 2 stateful pods, waiting for 3
Jul  3 22:17:33.184: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:17:33.184: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:17:33.184: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul  3 22:17:33.224: INFO: Updating stateful set ss2
Jul  3 22:17:33.238: INFO: Waiting for Pod statefulset-2948/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul  3 22:17:43.274: INFO: Updating stateful set ss2
Jul  3 22:17:43.290: INFO: Waiting for StatefulSet statefulset-2948/ss2 to complete update
Jul  3 22:17:43.290: INFO: Waiting for Pod statefulset-2948/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul  3 22:17:53.305: INFO: Deleting all statefulset in ns statefulset-2948
Jul  3 22:17:53.311: INFO: Scaling statefulset ss2 to 0
Jul  3 22:18:13.342: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:18:13.351: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:18:13.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2948" for this suite.
Jul  3 22:18:19.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:18:19.580: INFO: namespace statefulset-2948 deletion completed in 6.189180391s

• [SLOW TEST:86.796 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:18:19.586: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:18:19.759: INFO: Waiting up to 5m0s for pod "downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c" in namespace "projected-1617" to be "success or failure"
Jul  3 22:18:19.763: INFO: Pod "downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142721ms
Jul  3 22:18:21.771: INFO: Pod "downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011640749s
STEP: Saw pod success
Jul  3 22:18:21.771: INFO: Pod "downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:18:21.783: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:18:21.811: INFO: Waiting for pod downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:18:21.814: INFO: Pod downwardapi-volume-767a692d-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:18:21.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1617" for this suite.
Jul  3 22:18:27.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:18:28.003: INFO: namespace projected-1617 deletion completed in 6.181443857s

• [SLOW TEST:8.417 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:18:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul  3 22:18:28.188: INFO: Waiting up to 5m0s for pod "downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c" in namespace "downward-api-2777" to be "success or failure"
Jul  3 22:18:28.193: INFO: Pod "downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.859593ms
Jul  3 22:18:30.198: INFO: Pod "downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010627764s
STEP: Saw pod success
Jul  3 22:18:30.198: INFO: Pod "downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:18:30.203: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:18:30.229: INFO: Waiting for pod downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:18:30.232: INFO: Pod downward-api-7b805656-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:18:30.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2777" for this suite.
Jul  3 22:18:36.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:18:36.434: INFO: namespace downward-api-2777 deletion completed in 6.196102542s

• [SLOW TEST:8.427 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:18:36.435: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Jul  3 22:18:36.624: INFO: Waiting up to 5m0s for pod "client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c" in namespace "containers-7009" to be "success or failure"
Jul  3 22:18:36.629: INFO: Pod "client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.586899ms
Jul  3 22:18:38.636: INFO: Pod "client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011925048s
Jul  3 22:18:40.643: INFO: Pod "client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018769148s
STEP: Saw pod success
Jul  3 22:18:40.643: INFO: Pod "client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:18:40.650: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:18:40.683: INFO: Waiting for pod client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:18:40.687: INFO: Pod client-containers-8087d3b4-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:18:40.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7009" for this suite.
Jul  3 22:18:46.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:18:46.897: INFO: namespace containers-7009 deletion completed in 6.202025158s

• [SLOW TEST:10.462 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:18:46.897: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6959
Jul  3 22:18:53.089: INFO: Started pod liveness-http in namespace container-probe-6959
STEP: checking the pod's current state and verifying that restartCount is present
Jul  3 22:18:53.095: INFO: Initial restart count of pod liveness-http is 0
Jul  3 22:19:05.139: INFO: Restart count of pod container-probe-6959/liveness-http is now 1 (12.044634112s elapsed)
Jul  3 22:19:25.213: INFO: Restart count of pod container-probe-6959/liveness-http is now 2 (32.118313094s elapsed)
Jul  3 22:19:43.274: INFO: Restart count of pod container-probe-6959/liveness-http is now 3 (50.179076152s elapsed)
Jul  3 22:20:03.341: INFO: Restart count of pod container-probe-6959/liveness-http is now 4 (1m10.246940896s elapsed)
Jul  3 22:21:13.595: INFO: Restart count of pod container-probe-6959/liveness-http is now 5 (2m20.500780833s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:21:13.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6959" for this suite.
Jul  3 22:21:19.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:21:19.815: INFO: namespace container-probe-6959 deletion completed in 6.193411332s

• [SLOW TEST:152.918 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:21:19.815: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-864
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:21:19.999: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c" in namespace "projected-864" to be "success or failure"
Jul  3 22:21:20.004: INFO: Pod "downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.343314ms
Jul  3 22:21:22.011: INFO: Pod "downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012441298s
Jul  3 22:21:24.018: INFO: Pod "downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018895834s
STEP: Saw pod success
Jul  3 22:21:24.018: INFO: Pod "downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:21:24.023: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:21:24.058: INFO: Waiting for pod downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:21:24.062: INFO: Pod downwardapi-volume-e1e89686-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:21:24.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-864" for this suite.
Jul  3 22:21:30.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:21:30.248: INFO: namespace projected-864 deletion completed in 6.177109387s

• [SLOW TEST:10.433 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:21:30.254: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul  3 22:21:30.430: INFO: Waiting up to 5m0s for pod "downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c" in namespace "downward-api-2695" to be "success or failure"
Jul  3 22:21:30.436: INFO: Pod "downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.451203ms
Jul  3 22:21:32.445: INFO: Pod "downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014309527s
Jul  3 22:21:34.452: INFO: Pod "downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021627978s
STEP: Saw pod success
Jul  3 22:21:34.452: INFO: Pod "downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:21:34.457: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:21:34.485: INFO: Waiting for pod downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:21:34.489: INFO: Pod downward-api-e820366f-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:21:34.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2695" for this suite.
Jul  3 22:21:40.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:21:40.694: INFO: namespace downward-api-2695 deletion completed in 6.197502198s

• [SLOW TEST:10.441 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:21:40.695: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7v27z in namespace proxy-9630
I0703 22:21:40.887027      21 runners.go:184] Created replication controller with name: proxy-service-7v27z, namespace: proxy-9630, replica count: 1
I0703 22:21:41.940193      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0703 22:21:42.940684      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0703 22:21:43.940935      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0703 22:21:44.941285      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:45.941535      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:46.942070      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:47.942402      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:48.942659      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:49.942847      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:50.943092      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:51.943251      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0703 22:21:52.943434      21 runners.go:184] proxy-service-7v27z Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  3 22:21:52.951: INFO: setup took 12.092857654s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul  3 22:21:52.970: INFO: (0) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 18.128745ms)
Jul  3 22:21:52.970: INFO: (0) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 18.12933ms)
Jul  3 22:21:52.970: INFO: (0) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 18.26508ms)
Jul  3 22:21:52.971: INFO: (0) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 19.1955ms)
Jul  3 22:21:52.971: INFO: (0) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 19.226669ms)
Jul  3 22:21:52.972: INFO: (0) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 20.289896ms)
Jul  3 22:21:52.973: INFO: (0) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 20.93102ms)
Jul  3 22:21:52.973: INFO: (0) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 21.502073ms)
Jul  3 22:21:52.973: INFO: (0) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 21.441949ms)
Jul  3 22:21:52.974: INFO: (0) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 22.175268ms)
Jul  3 22:21:52.974: INFO: (0) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 22.176568ms)
Jul  3 22:21:52.982: INFO: (0) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 30.126253ms)
Jul  3 22:21:52.982: INFO: (0) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 30.621596ms)
Jul  3 22:21:52.982: INFO: (0) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 30.827458ms)
Jul  3 22:21:52.982: INFO: (0) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 30.594738ms)
Jul  3 22:21:52.982: INFO: (0) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 30.715917ms)
Jul  3 22:21:52.991: INFO: (1) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 8.863919ms)
Jul  3 22:21:52.992: INFO: (1) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 8.908595ms)
Jul  3 22:21:52.992: INFO: (1) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 8.17304ms)
Jul  3 22:21:52.996: INFO: (1) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 13.031728ms)
Jul  3 22:21:52.996: INFO: (1) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 12.543751ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 14.001547ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 13.30076ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.318798ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.299467ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 13.379348ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 14.29175ms)
Jul  3 22:21:52.997: INFO: (1) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 13.801763ms)
Jul  3 22:21:52.998: INFO: (1) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 14.254968ms)
Jul  3 22:21:52.999: INFO: (1) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 15.157995ms)
Jul  3 22:21:52.999: INFO: (1) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 16.260213ms)
Jul  3 22:21:53.000: INFO: (1) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 16.770462ms)
Jul  3 22:21:53.011: INFO: (2) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 10.56513ms)
Jul  3 22:21:53.011: INFO: (2) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 10.171631ms)
Jul  3 22:21:53.012: INFO: (2) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 11.382335ms)
Jul  3 22:21:53.012: INFO: (2) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 11.599056ms)
Jul  3 22:21:53.014: INFO: (2) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.613139ms)
Jul  3 22:21:53.014: INFO: (2) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 13.071643ms)
Jul  3 22:21:53.014: INFO: (2) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.462235ms)
Jul  3 22:21:53.014: INFO: (2) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 13.096977ms)
Jul  3 22:21:53.015: INFO: (2) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 13.51395ms)
Jul  3 22:21:53.015: INFO: (2) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 13.439668ms)
Jul  3 22:21:53.018: INFO: (2) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 16.015535ms)
Jul  3 22:21:53.019: INFO: (2) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 17.238095ms)
Jul  3 22:21:53.020: INFO: (2) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 19.282653ms)
Jul  3 22:21:53.021: INFO: (2) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 19.804919ms)
Jul  3 22:21:53.021: INFO: (2) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 19.184276ms)
Jul  3 22:21:53.021: INFO: (2) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 19.919017ms)
Jul  3 22:21:53.030: INFO: (3) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 8.58104ms)
Jul  3 22:21:53.032: INFO: (3) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 10.646809ms)
Jul  3 22:21:53.034: INFO: (3) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.469705ms)
Jul  3 22:21:53.034: INFO: (3) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 12.907151ms)
Jul  3 22:21:53.035: INFO: (3) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 13.408372ms)
Jul  3 22:21:53.036: INFO: (3) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 14.91135ms)
Jul  3 22:21:53.036: INFO: (3) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 15.256104ms)
Jul  3 22:21:53.037: INFO: (3) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 15.548877ms)
Jul  3 22:21:53.037: INFO: (3) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 15.74973ms)
Jul  3 22:21:53.037: INFO: (3) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 15.819565ms)
Jul  3 22:21:53.037: INFO: (3) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 16.119209ms)
Jul  3 22:21:53.038: INFO: (3) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 16.326526ms)
Jul  3 22:21:53.038: INFO: (3) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 16.545601ms)
Jul  3 22:21:53.038: INFO: (3) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 16.637368ms)
Jul  3 22:21:53.039: INFO: (3) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 17.9717ms)
Jul  3 22:21:53.040: INFO: (3) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 17.963905ms)
Jul  3 22:21:53.046: INFO: (4) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 6.490686ms)
Jul  3 22:21:53.046: INFO: (4) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 6.556953ms)
Jul  3 22:21:53.047: INFO: (4) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 6.874626ms)
Jul  3 22:21:53.049: INFO: (4) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 9.043414ms)
Jul  3 22:21:53.049: INFO: (4) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 9.235363ms)
Jul  3 22:21:53.049: INFO: (4) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.370928ms)
Jul  3 22:21:53.050: INFO: (4) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 10.043172ms)
Jul  3 22:21:53.050: INFO: (4) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.000945ms)
Jul  3 22:21:53.050: INFO: (4) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 10.108867ms)
Jul  3 22:21:53.050: INFO: (4) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.478415ms)
Jul  3 22:21:53.051: INFO: (4) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 10.914486ms)
Jul  3 22:21:53.053: INFO: (4) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 13.001711ms)
Jul  3 22:21:53.053: INFO: (4) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 13.568797ms)
Jul  3 22:21:53.055: INFO: (4) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 14.686961ms)
Jul  3 22:21:53.055: INFO: (4) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 15.282753ms)
Jul  3 22:21:53.055: INFO: (4) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 15.534705ms)
Jul  3 22:21:53.064: INFO: (5) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 8.679986ms)
Jul  3 22:21:53.064: INFO: (5) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 8.956267ms)
Jul  3 22:21:53.065: INFO: (5) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 9.500674ms)
Jul  3 22:21:53.067: INFO: (5) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 10.919661ms)
Jul  3 22:21:53.068: INFO: (5) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.958156ms)
Jul  3 22:21:53.068: INFO: (5) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 12.958411ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 13.302443ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 13.271093ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.754908ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 13.65525ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 13.856824ms)
Jul  3 22:21:53.069: INFO: (5) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 13.962465ms)
Jul  3 22:21:53.071: INFO: (5) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 15.038136ms)
Jul  3 22:21:53.071: INFO: (5) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 15.450354ms)
Jul  3 22:21:53.072: INFO: (5) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 16.680862ms)
Jul  3 22:21:53.073: INFO: (5) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 17.322914ms)
Jul  3 22:21:53.081: INFO: (6) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 8.211654ms)
Jul  3 22:21:53.084: INFO: (6) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 10.748637ms)
Jul  3 22:21:53.084: INFO: (6) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.683057ms)
Jul  3 22:21:53.084: INFO: (6) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.640003ms)
Jul  3 22:21:53.084: INFO: (6) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 11.182107ms)
Jul  3 22:21:53.085: INFO: (6) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 11.188084ms)
Jul  3 22:21:53.085: INFO: (6) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 11.255547ms)
Jul  3 22:21:53.085: INFO: (6) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 11.500421ms)
Jul  3 22:21:53.085: INFO: (6) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 11.349113ms)
Jul  3 22:21:53.085: INFO: (6) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 11.633236ms)
Jul  3 22:21:53.086: INFO: (6) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 13.034083ms)
Jul  3 22:21:53.090: INFO: (6) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 16.830539ms)
Jul  3 22:21:53.091: INFO: (6) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 17.343612ms)
Jul  3 22:21:53.091: INFO: (6) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 17.439127ms)
Jul  3 22:21:53.091: INFO: (6) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 17.660637ms)
Jul  3 22:21:53.091: INFO: (6) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 18.141809ms)
Jul  3 22:21:53.098: INFO: (7) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 6.760016ms)
Jul  3 22:21:53.099: INFO: (7) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 7.599508ms)
Jul  3 22:21:53.100: INFO: (7) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 8.529116ms)
Jul  3 22:21:53.100: INFO: (7) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 8.625131ms)
Jul  3 22:21:53.100: INFO: (7) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 9.058952ms)
Jul  3 22:21:53.101: INFO: (7) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.368721ms)
Jul  3 22:21:53.102: INFO: (7) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 10.045667ms)
Jul  3 22:21:53.102: INFO: (7) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 10.31131ms)
Jul  3 22:21:53.102: INFO: (7) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.491304ms)
Jul  3 22:21:53.102: INFO: (7) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.754322ms)
Jul  3 22:21:53.102: INFO: (7) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 10.584322ms)
Jul  3 22:21:53.103: INFO: (7) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 10.991597ms)
Jul  3 22:21:53.103: INFO: (7) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 11.682991ms)
Jul  3 22:21:53.104: INFO: (7) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 12.101582ms)
Jul  3 22:21:53.112: INFO: (7) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 20.085643ms)
Jul  3 22:21:53.112: INFO: (7) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 20.126266ms)
Jul  3 22:21:53.121: INFO: (8) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 9.020475ms)
Jul  3 22:21:53.126: INFO: (8) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 13.48396ms)
Jul  3 22:21:53.126: INFO: (8) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 13.599282ms)
Jul  3 22:21:53.127: INFO: (8) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 13.83854ms)
Jul  3 22:21:53.127: INFO: (8) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 14.051397ms)
Jul  3 22:21:53.127: INFO: (8) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 14.401046ms)
Jul  3 22:21:53.127: INFO: (8) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 14.377269ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 14.490386ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 14.943405ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 16.049517ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 15.975153ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 15.78024ms)
Jul  3 22:21:53.128: INFO: (8) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 16.255619ms)
Jul  3 22:21:53.131: INFO: (8) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 17.544727ms)
Jul  3 22:21:53.132: INFO: (8) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 19.217842ms)
Jul  3 22:21:53.132: INFO: (8) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 19.545388ms)
Jul  3 22:21:53.139: INFO: (9) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 6.616543ms)
Jul  3 22:21:53.139: INFO: (9) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 7.233167ms)
Jul  3 22:21:53.139: INFO: (9) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 6.957066ms)
Jul  3 22:21:53.140: INFO: (9) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 7.035772ms)
Jul  3 22:21:53.140: INFO: (9) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 6.927154ms)
Jul  3 22:21:53.142: INFO: (9) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 8.824979ms)
Jul  3 22:21:53.142: INFO: (9) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 9.083885ms)
Jul  3 22:21:53.143: INFO: (9) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 9.920406ms)
Jul  3 22:21:53.143: INFO: (9) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.04398ms)
Jul  3 22:21:53.143: INFO: (9) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 9.783746ms)
Jul  3 22:21:53.144: INFO: (9) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 10.682996ms)
Jul  3 22:21:53.144: INFO: (9) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 10.808004ms)
Jul  3 22:21:53.145: INFO: (9) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 12.465976ms)
Jul  3 22:21:53.147: INFO: (9) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 13.412963ms)
Jul  3 22:21:53.147: INFO: (9) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 13.580253ms)
Jul  3 22:21:53.147: INFO: (9) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 14.357896ms)
Jul  3 22:21:53.158: INFO: (10) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 9.876564ms)
Jul  3 22:21:53.160: INFO: (10) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 12.081687ms)
Jul  3 22:21:53.160: INFO: (10) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.423898ms)
Jul  3 22:21:53.160: INFO: (10) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.518389ms)
Jul  3 22:21:53.161: INFO: (10) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 12.332123ms)
Jul  3 22:21:53.161: INFO: (10) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 12.971799ms)
Jul  3 22:21:53.161: INFO: (10) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.53437ms)
Jul  3 22:21:53.161: INFO: (10) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 12.910658ms)
Jul  3 22:21:53.162: INFO: (10) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 13.313872ms)
Jul  3 22:21:53.162: INFO: (10) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 14.203896ms)
Jul  3 22:21:53.166: INFO: (10) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 18.949874ms)
Jul  3 22:21:53.169: INFO: (10) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 21.0935ms)
Jul  3 22:21:53.170: INFO: (10) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 21.80486ms)
Jul  3 22:21:53.170: INFO: (10) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 21.969031ms)
Jul  3 22:21:53.170: INFO: (10) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 21.372866ms)
Jul  3 22:21:53.170: INFO: (10) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 21.286235ms)
Jul  3 22:21:53.181: INFO: (11) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.807465ms)
Jul  3 22:21:53.181: INFO: (11) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 11.025365ms)
Jul  3 22:21:53.183: INFO: (11) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 12.968404ms)
Jul  3 22:21:53.184: INFO: (11) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 13.288296ms)
Jul  3 22:21:53.184: INFO: (11) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 13.628147ms)
Jul  3 22:21:53.185: INFO: (11) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 14.661953ms)
Jul  3 22:21:53.186: INFO: (11) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 15.096589ms)
Jul  3 22:21:53.186: INFO: (11) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 15.187629ms)
Jul  3 22:21:53.187: INFO: (11) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 16.386679ms)
Jul  3 22:21:53.187: INFO: (11) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 16.911906ms)
Jul  3 22:21:53.187: INFO: (11) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 16.963254ms)
Jul  3 22:21:53.188: INFO: (11) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 17.531095ms)
Jul  3 22:21:53.189: INFO: (11) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 18.770119ms)
Jul  3 22:21:53.189: INFO: (11) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 18.866466ms)
Jul  3 22:21:53.190: INFO: (11) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 19.321737ms)
Jul  3 22:21:53.191: INFO: (11) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 20.502778ms)
Jul  3 22:21:53.198: INFO: (12) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 7.122065ms)
Jul  3 22:21:53.201: INFO: (12) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 9.405081ms)
Jul  3 22:21:53.203: INFO: (12) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 11.850418ms)
Jul  3 22:21:53.204: INFO: (12) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 11.94306ms)
Jul  3 22:21:53.204: INFO: (12) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.379449ms)
Jul  3 22:21:53.204: INFO: (12) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 12.446636ms)
Jul  3 22:21:53.204: INFO: (12) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 12.704373ms)
Jul  3 22:21:53.204: INFO: (12) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 13.172217ms)
Jul  3 22:21:53.205: INFO: (12) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.661071ms)
Jul  3 22:21:53.205: INFO: (12) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 13.656974ms)
Jul  3 22:21:53.205: INFO: (12) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 14.160243ms)
Jul  3 22:21:53.206: INFO: (12) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 13.885675ms)
Jul  3 22:21:53.216: INFO: (12) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 24.758137ms)
Jul  3 22:21:53.216: INFO: (12) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 24.661993ms)
Jul  3 22:21:53.216: INFO: (12) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 24.867076ms)
Jul  3 22:21:53.217: INFO: (12) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 25.184186ms)
Jul  3 22:21:53.225: INFO: (13) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 7.888463ms)
Jul  3 22:21:53.228: INFO: (13) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 10.769934ms)
Jul  3 22:21:53.229: INFO: (13) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.373782ms)
Jul  3 22:21:53.230: INFO: (13) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 12.520334ms)
Jul  3 22:21:53.230: INFO: (13) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 13.041044ms)
Jul  3 22:21:53.230: INFO: (13) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 12.818905ms)
Jul  3 22:21:53.230: INFO: (13) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.819114ms)
Jul  3 22:21:53.231: INFO: (13) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 14.241601ms)
Jul  3 22:21:53.231: INFO: (13) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 14.475569ms)
Jul  3 22:21:53.232: INFO: (13) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 14.565791ms)
Jul  3 22:21:53.232: INFO: (13) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 14.985128ms)
Jul  3 22:21:53.234: INFO: (13) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 17.243693ms)
Jul  3 22:21:53.236: INFO: (13) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 19.127408ms)
Jul  3 22:21:53.236: INFO: (13) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 19.051338ms)
Jul  3 22:21:53.236: INFO: (13) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 19.024336ms)
Jul  3 22:21:53.236: INFO: (13) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 19.12358ms)
Jul  3 22:21:53.247: INFO: (14) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 10.149888ms)
Jul  3 22:21:53.247: INFO: (14) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 10.182559ms)
Jul  3 22:21:53.247: INFO: (14) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.506721ms)
Jul  3 22:21:53.247: INFO: (14) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.567157ms)
Jul  3 22:21:53.247: INFO: (14) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 10.756217ms)
Jul  3 22:21:53.249: INFO: (14) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 11.934148ms)
Jul  3 22:21:53.249: INFO: (14) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 12.421293ms)
Jul  3 22:21:53.249: INFO: (14) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.479723ms)
Jul  3 22:21:53.249: INFO: (14) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.693198ms)
Jul  3 22:21:53.251: INFO: (14) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 14.45273ms)
Jul  3 22:21:53.253: INFO: (14) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 16.792469ms)
Jul  3 22:21:53.255: INFO: (14) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 18.562818ms)
Jul  3 22:21:53.255: INFO: (14) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 18.727544ms)
Jul  3 22:21:53.255: INFO: (14) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 18.517701ms)
Jul  3 22:21:53.255: INFO: (14) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 18.646577ms)
Jul  3 22:21:53.256: INFO: (14) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 18.727142ms)
Jul  3 22:21:53.265: INFO: (15) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 9.666989ms)
Jul  3 22:21:53.266: INFO: (15) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.772826ms)
Jul  3 22:21:53.266: INFO: (15) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 9.924191ms)
Jul  3 22:21:53.266: INFO: (15) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.947339ms)
Jul  3 22:21:53.267: INFO: (15) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 10.717435ms)
Jul  3 22:21:53.267: INFO: (15) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.725633ms)
Jul  3 22:21:53.267: INFO: (15) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 11.229028ms)
Jul  3 22:21:53.268: INFO: (15) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 11.649058ms)
Jul  3 22:21:53.269: INFO: (15) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 12.770343ms)
Jul  3 22:21:53.271: INFO: (15) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 14.396029ms)
Jul  3 22:21:53.271: INFO: (15) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 14.518738ms)
Jul  3 22:21:53.271: INFO: (15) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 15.335754ms)
Jul  3 22:21:53.272: INFO: (15) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 16.04076ms)
Jul  3 22:21:53.272: INFO: (15) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 16.303886ms)
Jul  3 22:21:53.272: INFO: (15) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 16.067312ms)
Jul  3 22:21:53.272: INFO: (15) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 16.369981ms)
Jul  3 22:21:53.277: INFO: (16) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 4.890205ms)
Jul  3 22:21:53.278: INFO: (16) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 5.096883ms)
Jul  3 22:21:53.279: INFO: (16) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 5.781082ms)
Jul  3 22:21:53.280: INFO: (16) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 6.470682ms)
Jul  3 22:21:53.280: INFO: (16) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 6.799503ms)
Jul  3 22:21:53.280: INFO: (16) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 7.025396ms)
Jul  3 22:21:53.280: INFO: (16) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 7.068694ms)
Jul  3 22:21:53.281: INFO: (16) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 7.01605ms)
Jul  3 22:21:53.281: INFO: (16) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 7.791635ms)
Jul  3 22:21:53.283: INFO: (16) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 10.082761ms)
Jul  3 22:21:53.283: INFO: (16) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.269094ms)
Jul  3 22:21:53.284: INFO: (16) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 11.528443ms)
Jul  3 22:21:53.285: INFO: (16) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 12.202524ms)
Jul  3 22:21:53.287: INFO: (16) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 13.660291ms)
Jul  3 22:21:53.287: INFO: (16) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 13.801261ms)
Jul  3 22:21:53.287: INFO: (16) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 13.370091ms)
Jul  3 22:21:53.297: INFO: (17) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 9.960271ms)
Jul  3 22:21:53.297: INFO: (17) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 9.384227ms)
Jul  3 22:21:53.298: INFO: (17) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.780151ms)
Jul  3 22:21:53.298: INFO: (17) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 10.628709ms)
Jul  3 22:21:53.298: INFO: (17) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.48771ms)
Jul  3 22:21:53.299: INFO: (17) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 11.296596ms)
Jul  3 22:21:53.300: INFO: (17) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 11.652523ms)
Jul  3 22:21:53.302: INFO: (17) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 13.264412ms)
Jul  3 22:21:53.302: INFO: (17) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.15019ms)
Jul  3 22:21:53.303: INFO: (17) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 14.470503ms)
Jul  3 22:21:53.303: INFO: (17) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 14.011652ms)
Jul  3 22:21:53.303: INFO: (17) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 15.360501ms)
Jul  3 22:21:53.303: INFO: (17) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 14.958888ms)
Jul  3 22:21:53.304: INFO: (17) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 15.878182ms)
Jul  3 22:21:53.305: INFO: (17) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 16.530597ms)
Jul  3 22:21:53.305: INFO: (17) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 16.467888ms)
Jul  3 22:21:53.314: INFO: (18) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 8.957547ms)
Jul  3 22:21:53.315: INFO: (18) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 9.130327ms)
Jul  3 22:21:53.315: INFO: (18) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 9.310497ms)
Jul  3 22:21:53.316: INFO: (18) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 10.390781ms)
Jul  3 22:21:53.316: INFO: (18) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 9.958919ms)
Jul  3 22:21:53.318: INFO: (18) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 11.34943ms)
Jul  3 22:21:53.318: INFO: (18) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 11.674661ms)
Jul  3 22:21:53.319: INFO: (18) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.416385ms)
Jul  3 22:21:53.319: INFO: (18) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 12.705838ms)
Jul  3 22:21:53.319: INFO: (18) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 13.028209ms)
Jul  3 22:21:53.321: INFO: (18) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 15.007985ms)
Jul  3 22:21:53.321: INFO: (18) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 15.602016ms)
Jul  3 22:21:53.322: INFO: (18) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 15.240925ms)
Jul  3 22:21:53.322: INFO: (18) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 16.091292ms)
Jul  3 22:21:53.322: INFO: (18) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 15.736396ms)
Jul  3 22:21:53.323: INFO: (18) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 16.228871ms)
Jul  3 22:21:53.330: INFO: (19) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">... (200; 6.605171ms)
Jul  3 22:21:53.331: INFO: (19) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:462/proxy/: tls qux (200; 7.922397ms)
Jul  3 22:21:53.336: INFO: (19) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2/proxy/rewriteme">test</a> (200; 12.576169ms)
Jul  3 22:21:53.336: INFO: (19) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:443/proxy/tlsrewritem... (200; 12.631363ms)
Jul  3 22:21:53.336: INFO: (19) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 12.76849ms)
Jul  3 22:21:53.336: INFO: (19) /api/v1/namespaces/proxy-9630/pods/http:proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 12.887271ms)
Jul  3 22:21:53.336: INFO: (19) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:162/proxy/: bar (200; 13.081431ms)
Jul  3 22:21:53.339: INFO: (19) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:160/proxy/: foo (200; 15.545762ms)
Jul  3 22:21:53.339: INFO: (19) /api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/: <a href="/api/v1/namespaces/proxy-9630/pods/proxy-service-7v27z-kbcr2:1080/proxy/rewriteme">test<... (200; 15.650822ms)
Jul  3 22:21:53.339: INFO: (19) /api/v1/namespaces/proxy-9630/pods/https:proxy-service-7v27z-kbcr2:460/proxy/: tls baz (200; 15.475147ms)
Jul  3 22:21:53.339: INFO: (19) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname2/proxy/: bar (200; 15.709064ms)
Jul  3 22:21:53.339: INFO: (19) /api/v1/namespaces/proxy-9630/services/http:proxy-service-7v27z:portname1/proxy/: foo (200; 15.554362ms)
Jul  3 22:21:53.341: INFO: (19) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname2/proxy/: bar (200; 18.10727ms)
Jul  3 22:21:53.341: INFO: (19) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname2/proxy/: tls qux (200; 18.114248ms)
Jul  3 22:21:53.342: INFO: (19) /api/v1/namespaces/proxy-9630/services/https:proxy-service-7v27z:tlsportname1/proxy/: tls baz (200; 18.324584ms)
Jul  3 22:21:53.342: INFO: (19) /api/v1/namespaces/proxy-9630/services/proxy-service-7v27z:portname1/proxy/: foo (200; 18.720259ms)
STEP: deleting ReplicationController proxy-service-7v27z in namespace proxy-9630, will wait for the garbage collector to delete the pods
Jul  3 22:21:53.415: INFO: Deleting ReplicationController proxy-service-7v27z took: 14.004949ms
Jul  3 22:21:53.715: INFO: Terminating ReplicationController proxy-service-7v27z pods took: 300.280413ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:21:56.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9630" for this suite.
Jul  3 22:22:02.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:22:02.317: INFO: namespace proxy-9630 deletion completed in 6.19296698s

• [SLOW TEST:21.622 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:22:02.319: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8268
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul  3 22:22:02.499: INFO: Waiting up to 5m0s for pod "pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c" in namespace "emptydir-8268" to be "success or failure"
Jul  3 22:22:02.505: INFO: Pod "pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.761182ms
Jul  3 22:22:04.513: INFO: Pod "pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013421424s
STEP: Saw pod success
Jul  3 22:22:04.513: INFO: Pod "pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:22:04.517: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:22:04.546: INFO: Waiting for pod pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:22:04.550: INFO: Pod pod-fb3dcf9c-9de0-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:22:04.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8268" for this suite.
Jul  3 22:22:10.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:22:10.757: INFO: namespace emptydir-8268 deletion completed in 6.199804077s

• [SLOW TEST:8.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:22:10.757: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  3 22:22:10.946: INFO: Waiting up to 5m0s for pod "pod-004642a5-9de1-11e9-b0a2-a612d8f3003c" in namespace "emptydir-8516" to be "success or failure"
Jul  3 22:22:10.952: INFO: Pod "pod-004642a5-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788976ms
Jul  3 22:22:12.963: INFO: Pod "pod-004642a5-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016850089s
STEP: Saw pod success
Jul  3 22:22:12.964: INFO: Pod "pod-004642a5-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:22:12.969: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-004642a5-9de1-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:22:13.000: INFO: Waiting for pod pod-004642a5-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:22:13.009: INFO: Pod pod-004642a5-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:22:13.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8516" for this suite.
Jul  3 22:22:19.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:22:19.209: INFO: namespace emptydir-8516 deletion completed in 6.192794822s

• [SLOW TEST:8.451 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:22:19.211: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-054f0e37-9de1-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:22:19.394: INFO: Waiting up to 5m0s for pod "pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c" in namespace "configmap-8598" to be "success or failure"
Jul  3 22:22:19.399: INFO: Pod "pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.77407ms
Jul  3 22:22:21.405: INFO: Pod "pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011073825s
STEP: Saw pod success
Jul  3 22:22:21.405: INFO: Pod "pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:22:21.412: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:22:21.445: INFO: Waiting for pod pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:22:21.450: INFO: Pod pod-configmaps-055001f2-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:22:21.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8598" for this suite.
Jul  3 22:22:27.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:22:27.632: INFO: namespace configmap-8598 deletion completed in 6.172376867s

• [SLOW TEST:8.422 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:22:27.635: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:22:27.797: INFO: Creating deployment "nginx-deployment"
Jul  3 22:22:27.805: INFO: Waiting for observed generation 1
Jul  3 22:22:29.815: INFO: Waiting for all required pods to come up
Jul  3 22:22:29.822: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul  3 22:22:31.841: INFO: Waiting for deployment "nginx-deployment" to complete
Jul  3 22:22:31.850: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul  3 22:22:31.860: INFO: Updating deployment nginx-deployment
Jul  3 22:22:31.860: INFO: Waiting for observed generation 2
Jul  3 22:22:33.870: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul  3 22:22:33.877: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul  3 22:22:33.882: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul  3 22:22:33.901: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul  3 22:22:33.901: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul  3 22:22:33.908: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul  3 22:22:33.920: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul  3 22:22:33.920: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul  3 22:22:33.933: INFO: Updating deployment nginx-deployment
Jul  3 22:22:33.933: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul  3 22:22:33.942: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul  3 22:22:33.947: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul  3 22:22:33.984: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2873,SelfLink:/apis/apps/v1/namespaces/deployment-2873/deployments/nginx-deployment,UID:0a53e394-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15181,Generation:3,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-07-03 22:22:30 +0000 UTC 2019-07-03 22:22:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-03 22:22:31 +0000 UTC 2019-07-03 22:22:27 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul  3 22:22:34.000: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-2873,SelfLink:/apis/apps/v1/namespaces/deployment-2873/replicasets/nginx-deployment-5f9595f595,UID:0cc038ed-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15185,Generation:3,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0a53e394-9de1-11e9-a55c-fa163e25a4f0 0xc0028e51f7 0xc0028e51f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:22:34.000: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul  3 22:22:34.000: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-2873,SelfLink:/apis/apps/v1/namespaces/deployment-2873/replicasets/nginx-deployment-6f478d8d8,UID:0a557c89-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15182,Generation:3,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0a53e394-9de1-11e9-a55c-fa163e25a4f0 0xc0028e52c7 0xc0028e52c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul  3 22:22:34.015: INFO: Pod "nginx-deployment-5f9595f595-6rkb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6rkb4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-6rkb4,UID:0cc1c4af-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15171,Generation:0,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc003269ec7 0xc003269ec8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003269f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003269f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:10.2.248.20,StartTime:2019-07-03 22:22:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.016: INFO: Pod "nginx-deployment-5f9595f595-7r6hc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7r6hc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-7r6hc,UID:0cce8a9b-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15196,Generation:0,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8040 0xc0029d8041}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d80b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d80d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:10.2.17.24,StartTime:2019-07-03 22:22:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.016: INFO: Pod "nginx-deployment-5f9595f595-8ldst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8ldst,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-8ldst,UID:0cc3d9d8-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15178,Generation:0,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc0029d81c0 0xc0029d81c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.2.97.26,StartTime:2019-07-03 22:22:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.016: INFO: Pod "nginx-deployment-5f9595f595-92v2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-92v2h,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-92v2h,UID:0cccdab7-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15125,Generation:0,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8340 0xc0029d8341}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d83b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d83d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-07-03 22:22:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.016: INFO: Pod "nginx-deployment-5f9595f595-shqbw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-shqbw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-shqbw,UID:0cc36e51-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15191,Generation:0,CreationTimestamp:2019-07-03 22:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc0029d84a0 0xc0029d84a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:,StartTime:2019-07-03 22:22:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.016: INFO: Pod "nginx-deployment-5f9595f595-zl5jx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zl5jx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-5f9595f595-zl5jx,UID:0e041995-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15202,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 0cc038ed-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8610 0xc0029d8611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d86a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-2l72z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2l72z,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-2l72z,UID:0e0331e5-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15199,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8707 0xc0029d8708}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-79s2n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-79s2n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-79s2n,UID:0e037d20-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15200,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d87f7 0xc0029d87f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-9x842" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9x842,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-9x842,UID:0a5ce3bc-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15048,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d88e7 0xc0029d88e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:10.2.17.22,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://78b153684a8e4643808c8efae559610a5cb9f54c87f945f08b2f57e63c73ba37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-bxcbf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bxcbf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-bxcbf,UID:0a5c3a8b-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15056,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8a40 0xc0029d8a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.2.97.24,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a0c75b5fdf504bfbec2e8bba209e37abef281440a3abc89220edd183e00bdf3c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-fstw8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fstw8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-fstw8,UID:0a602fdc-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15065,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8b90 0xc0029d8b91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.2.97.25,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b48cc844759de814b67a8092cff30182f104242bea179c53a77e14226692eb5e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-jzrxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jzrxt,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-jzrxt,UID:0dfd9bcf-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15206,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8ce0 0xc0029d8ce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:,StartTime:2019-07-03 22:22:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-kfgwz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kfgwz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-kfgwz,UID:0a5ba03b-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15054,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8e20 0xc0029d8e21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:10.2.5.6,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8d66223749324b30f143867dfa7b17b2a8fc3557eaace8d573e33b5a33d014ff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.017: INFO: Pod "nginx-deployment-6f478d8d8-mclmk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mclmk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-mclmk,UID:0dff5e41-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15207,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d8f70 0xc0029d8f71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d8fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d8ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:,StartTime:2019-07-03 22:22:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-mv8fr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mv8fr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-mv8fr,UID:0a5f5b29-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15069,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d90b0 0xc0029d90b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:10.2.248.19,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2882f56bebecb68d30d6c3ecb45f71bfca40944f8741044695c5bc48f6ba73a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-nqcpf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nqcpf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-nqcpf,UID:0a5cc8cd-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15051,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d9200 0xc0029d9201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:10.2.5.7,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://261e1b782e5d8bbbf4de982dcbe7218f2352e17968dc76e1e39609c4c7417e47}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-qfmz6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qfmz6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-qfmz6,UID:0a5fec63-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15057,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d9350 0xc0029d9351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d93b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d93d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:10.2.5.8,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://80ccb090502c0cbb336ed38068869dd7e7d33f1efab99d42d891dae76c25ffdb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-qjjs5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qjjs5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-qjjs5,UID:0a59ad3f-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15045,Generation:0,CreationTimestamp:2019-07-03 22:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d94a0 0xc0029d94a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:10.2.17.21,StartTime:2019-07-03 22:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:22:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8b2f65e8c5242ec113ccea8d10c063288b1908efa10251c479597f8c6805ea30}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-rld6m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rld6m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-rld6m,UID:0e03c28d-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15201,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d95f0 0xc0029d95f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-srs9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-srs9n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-srs9n,UID:0e02ca4d-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15198,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d96d7 0xc0029d96d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:22:34.018: INFO: Pod "nginx-deployment-6f478d8d8-stq9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-stq9x,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2873,SelfLink:/api/v1/namespaces/deployment-2873/pods/nginx-deployment-6f478d8d8-stq9x,UID:0dff0e94-9de1-11e9-a55c-fa163e25a4f0,ResourceVersion:15193,Generation:0,CreationTimestamp:2019-07-03 22:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0a557c89-9de1-11e9-a55c-fa163e25a4f0 0xc0029d97c7 0xc0029d97c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swbnm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swbnm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-swbnm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d9830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d9850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:22:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:22:34.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2873" for this suite.
Jul  3 22:22:42.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:22:42.242: INFO: namespace deployment-2873 deletion completed in 8.192904942s

• [SLOW TEST:14.607 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:22:42.245: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3324
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3324
Jul  3 22:22:44.430: INFO: Started pod liveness-exec in namespace container-probe-3324
STEP: checking the pod's current state and verifying that restartCount is present
Jul  3 22:22:44.435: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:26:45.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3324" for this suite.
Jul  3 22:26:51.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:26:51.511: INFO: namespace container-probe-3324 deletion completed in 6.209458775s

• [SLOW TEST:249.266 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:26:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  3 22:26:51.687: INFO: Waiting up to 5m0s for pod "pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c" in namespace "emptydir-9492" to be "success or failure"
Jul  3 22:26:51.694: INFO: Pod "pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.750837ms
Jul  3 22:26:53.700: INFO: Pod "pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012916108s
Jul  3 22:26:55.707: INFO: Pod "pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019837377s
STEP: Saw pod success
Jul  3 22:26:55.707: INFO: Pod "pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:26:55.712: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:26:55.744: INFO: Waiting for pod pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:26:55.748: INFO: Pod pod-a79c4644-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:26:55.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9492" for this suite.
Jul  3 22:27:01.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:27:01.940: INFO: namespace emptydir-9492 deletion completed in 6.186710465s

• [SLOW TEST:10.429 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:27:01.941: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-add4e566-9de1-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:27:02.132: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c" in namespace "projected-2931" to be "success or failure"
Jul  3 22:27:02.138: INFO: Pod "pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.73827ms
Jul  3 22:27:04.146: INFO: Pod "pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013814745s
Jul  3 22:27:06.155: INFO: Pod "pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022470345s
STEP: Saw pod success
Jul  3 22:27:06.155: INFO: Pod "pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:27:06.160: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:27:06.196: INFO: Waiting for pod pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:27:06.202: INFO: Pod pod-projected-configmaps-add5f6de-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:27:06.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2931" for this suite.
Jul  3 22:27:12.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:27:12.406: INFO: namespace projected-2931 deletion completed in 6.194886444s

• [SLOW TEST:10.465 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:27:12.407: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul  3 22:27:15.129: INFO: Successfully updated pod "labelsupdateb4108c3b-9de1-11e9-b0a2-a612d8f3003c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:27:17.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4422" for this suite.
Jul  3 22:27:39.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:27:39.334: INFO: namespace projected-4422 deletion completed in 22.172404634s

• [SLOW TEST:26.927 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:27:39.336: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-c41e37df-9de1-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:27:39.521: INFO: Waiting up to 5m0s for pod "pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c" in namespace "secrets-7152" to be "success or failure"
Jul  3 22:27:39.525: INFO: Pod "pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978841ms
Jul  3 22:27:41.530: INFO: Pod "pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009302472s
STEP: Saw pod success
Jul  3 22:27:41.530: INFO: Pod "pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:27:41.535: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:27:41.570: INFO: Waiting for pod pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:27:41.573: INFO: Pod pod-secrets-c41f5751-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:27:41.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7152" for this suite.
Jul  3 22:27:47.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:27:47.770: INFO: namespace secrets-7152 deletion completed in 6.190423698s

• [SLOW TEST:8.434 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:27:47.772: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:27:47.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c" in namespace "downward-api-5768" to be "success or failure"
Jul  3 22:27:47.963: INFO: Pod "downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.78466ms
Jul  3 22:27:49.971: INFO: Pod "downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014304577s
STEP: Saw pod success
Jul  3 22:27:49.971: INFO: Pod "downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:27:49.977: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:27:50.005: INFO: Waiting for pod downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:27:50.010: INFO: Pod downwardapi-volume-c9261a8b-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:27:50.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5768" for this suite.
Jul  3 22:27:56.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:27:56.195: INFO: namespace downward-api-5768 deletion completed in 6.176927778s

• [SLOW TEST:8.423 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:27:56.195: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5202
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:27:56.371: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c" in namespace "projected-5202" to be "success or failure"
Jul  3 22:27:56.376: INFO: Pod "downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.607514ms
Jul  3 22:27:58.382: INFO: Pod "downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0114004s
STEP: Saw pod success
Jul  3 22:27:58.382: INFO: Pod "downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:27:58.389: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:27:58.415: INFO: Waiting for pod downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:27:58.419: INFO: Pod downwardapi-volume-ce2a4e2b-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:27:58.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5202" for this suite.
Jul  3 22:28:04.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:28:04.611: INFO: namespace projected-5202 deletion completed in 6.186512523s

• [SLOW TEST:8.416 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:28:04.612: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2593
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d32ed77f-9de1-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:28:04.796: INFO: Waiting up to 5m0s for pod "pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c" in namespace "secrets-2593" to be "success or failure"
Jul  3 22:28:04.800: INFO: Pod "pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116765ms
Jul  3 22:28:06.806: INFO: Pod "pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010426493s
Jul  3 22:28:08.811: INFO: Pod "pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015495413s
STEP: Saw pod success
Jul  3 22:28:08.812: INFO: Pod "pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:28:08.817: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:28:08.844: INFO: Waiting for pod pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:28:08.848: INFO: Pod pod-secrets-d32fe06e-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:28:08.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2593" for this suite.
Jul  3 22:28:14.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:28:15.057: INFO: namespace secrets-2593 deletion completed in 6.200004765s

• [SLOW TEST:10.445 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:28:15.058: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-d9686f9a-9de1-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:28:15.241: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c" in namespace "projected-5007" to be "success or failure"
Jul  3 22:28:15.248: INFO: Pod "pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865614ms
Jul  3 22:28:17.255: INFO: Pod "pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013782147s
STEP: Saw pod success
Jul  3 22:28:17.255: INFO: Pod "pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:28:17.260: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:28:17.289: INFO: Waiting for pod pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:28:17.292: INFO: Pod pod-projected-configmaps-d969709e-9de1-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:28:17.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5007" for this suite.
Jul  3 22:28:23.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:28:23.484: INFO: namespace projected-5007 deletion completed in 6.184180774s

• [SLOW TEST:8.425 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:28:23.485: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5841
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:28:23.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5841" for this suite.
Jul  3 22:28:29.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:28:29.847: INFO: namespace services-5841 deletion completed in 6.180630291s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.362 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:28:29.849: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Jul  3 22:28:30.550: INFO: created pod pod-service-account-defaultsa
Jul  3 22:28:30.550: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul  3 22:28:30.558: INFO: created pod pod-service-account-mountsa
Jul  3 22:28:30.558: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul  3 22:28:30.566: INFO: created pod pod-service-account-nomountsa
Jul  3 22:28:30.566: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul  3 22:28:30.575: INFO: created pod pod-service-account-defaultsa-mountspec
Jul  3 22:28:30.575: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul  3 22:28:30.582: INFO: created pod pod-service-account-mountsa-mountspec
Jul  3 22:28:30.582: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul  3 22:28:30.591: INFO: created pod pod-service-account-nomountsa-mountspec
Jul  3 22:28:30.591: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul  3 22:28:30.597: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul  3 22:28:30.597: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul  3 22:28:30.610: INFO: created pod pod-service-account-mountsa-nomountspec
Jul  3 22:28:30.610: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul  3 22:28:30.621: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul  3 22:28:30.621: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:28:30.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7199" for this suite.
Jul  3 22:28:36.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:28:36.824: INFO: namespace svcaccounts-7199 deletion completed in 6.194505672s

• [SLOW TEST:6.975 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:28:36.825: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4252
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4252 to expose endpoints map[]
Jul  3 22:28:37.015: INFO: Get endpoints failed (6.91416ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jul  3 22:28:38.022: INFO: successfully validated that service multi-endpoint-test in namespace services-4252 exposes endpoints map[] (1.013844812s elapsed)
STEP: Creating pod pod1 in namespace services-4252
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4252 to expose endpoints map[pod1:[100]]
Jul  3 22:28:41.081: INFO: successfully validated that service multi-endpoint-test in namespace services-4252 exposes endpoints map[pod1:[100]] (3.046640271s elapsed)
STEP: Creating pod pod2 in namespace services-4252
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4252 to expose endpoints map[pod1:[100] pod2:[101]]
Jul  3 22:28:44.163: INFO: successfully validated that service multi-endpoint-test in namespace services-4252 exposes endpoints map[pod1:[100] pod2:[101]] (3.072691463s elapsed)
STEP: Deleting pod pod1 in namespace services-4252
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4252 to expose endpoints map[pod2:[101]]
Jul  3 22:28:45.197: INFO: successfully validated that service multi-endpoint-test in namespace services-4252 exposes endpoints map[pod2:[101]] (1.023490132s elapsed)
STEP: Deleting pod pod2 in namespace services-4252
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4252 to expose endpoints map[]
Jul  3 22:28:46.219: INFO: successfully validated that service multi-endpoint-test in namespace services-4252 exposes endpoints map[] (1.012285425s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:28:46.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4252" for this suite.
Jul  3 22:29:08.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:29:08.427: INFO: namespace services-4252 deletion completed in 22.167441848s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:31.602 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:29:08.428: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7238
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:29:08.598: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:29:12.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7238" for this suite.
Jul  3 22:30:00.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:30:00.959: INFO: namespace pods-7238 deletion completed in 48.172214854s

• [SLOW TEST:52.532 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:30:00.960: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:30:01.180: INFO: Create a RollingUpdate DaemonSet
Jul  3 22:30:01.189: INFO: Check that daemon pods launch on every node of the cluster
Jul  3 22:30:01.195: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:01.195: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:01.195: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:01.200: INFO: Number of nodes with available pods: 0
Jul  3 22:30:01.200: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:30:02.214: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:02.214: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:02.214: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:02.219: INFO: Number of nodes with available pods: 0
Jul  3 22:30:02.219: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:30:03.208: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:03.208: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:03.208: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:03.214: INFO: Number of nodes with available pods: 2
Jul  3 22:30:03.214: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:30:04.211: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:04.212: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:04.212: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:04.217: INFO: Number of nodes with available pods: 4
Jul  3 22:30:04.217: INFO: Number of running nodes: 4, number of available pods: 4
Jul  3 22:30:04.217: INFO: Update the DaemonSet to trigger a rollout
Jul  3 22:30:04.231: INFO: Updating DaemonSet daemon-set
Jul  3 22:30:18.250: INFO: Roll back the DaemonSet before rollout is complete
Jul  3 22:30:18.264: INFO: Updating DaemonSet daemon-set
Jul  3 22:30:18.264: INFO: Make sure DaemonSet rollback is complete
Jul  3 22:30:18.269: INFO: Wrong image for pod: daemon-set-m65h9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul  3 22:30:18.269: INFO: Pod daemon-set-m65h9 is not available
Jul  3 22:30:18.275: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:18.275: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:18.275: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:19.282: INFO: Wrong image for pod: daemon-set-m65h9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul  3 22:30:19.282: INFO: Pod daemon-set-m65h9 is not available
Jul  3 22:30:19.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:19.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:19.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:20.282: INFO: Wrong image for pod: daemon-set-m65h9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul  3 22:30:20.282: INFO: Pod daemon-set-m65h9 is not available
Jul  3 22:30:20.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:20.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:20.290: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:21.283: INFO: Pod daemon-set-mz4hb is not available
Jul  3 22:30:21.292: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:21.292: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:30:21.292: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6406, will wait for the garbage collector to delete the pods
Jul  3 22:30:21.379: INFO: Deleting DaemonSet.extensions daemon-set took: 16.954469ms
Jul  3 22:30:21.680: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.467681ms
Jul  3 22:31:47.988: INFO: Number of nodes with available pods: 0
Jul  3 22:31:47.988: INFO: Number of running nodes: 0, number of available pods: 0
Jul  3 22:31:47.997: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6406/daemonsets","resourceVersion":"17943"},"items":null}

Jul  3 22:31:48.002: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6406/pods","resourceVersion":"17943"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:31:48.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6406" for this suite.
Jul  3 22:31:54.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:31:54.240: INFO: namespace daemonsets-6406 deletion completed in 6.19899618s

• [SLOW TEST:113.281 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:31:54.240: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-5c0dcf3b-9de2-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:31:54.426: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c" in namespace "projected-8348" to be "success or failure"
Jul  3 22:31:54.432: INFO: Pod "pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.119968ms
Jul  3 22:31:56.437: INFO: Pod "pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010391115s
STEP: Saw pod success
Jul  3 22:31:56.437: INFO: Pod "pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:31:56.442: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:31:56.469: INFO: Waiting for pod pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:31:56.473: INFO: Pod pod-projected-configmaps-5c0ea613-9de2-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:31:56.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8348" for this suite.
Jul  3 22:32:02.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:32:02.683: INFO: namespace projected-8348 deletion completed in 6.202753322s

• [SLOW TEST:8.443 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:32:02.684: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul  3 22:32:02.860: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:32:17.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4750" for this suite.
Jul  3 22:32:23.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:32:23.732: INFO: namespace pods-4750 deletion completed in 6.173009775s

• [SLOW TEST:21.048 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:32:23.733: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0703 22:32:33.948445      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 22:32:33.948: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:32:33.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7944" for this suite.
Jul  3 22:32:39.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:32:40.146: INFO: namespace gc-7944 deletion completed in 6.190599266s

• [SLOW TEST:16.414 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:32:40.149: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul  3 22:32:40.328: INFO: Waiting up to 5m0s for pod "downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c" in namespace "downward-api-8446" to be "success or failure"
Jul  3 22:32:40.333: INFO: Pod "downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.667712ms
Jul  3 22:32:42.339: INFO: Pod "downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010416533s
STEP: Saw pod success
Jul  3 22:32:42.339: INFO: Pod "downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:32:42.343: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:32:42.382: INFO: Waiting for pod downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:32:42.386: INFO: Pod downward-api-776ab459-9de2-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:32:42.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8446" for this suite.
Jul  3 22:32:48.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:32:48.597: INFO: namespace downward-api-8446 deletion completed in 6.20245252s

• [SLOW TEST:8.448 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:32:48.598: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5025
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:32:50.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5025" for this suite.
Jul  3 22:33:30.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:33:30.990: INFO: namespace kubelet-test-5025 deletion completed in 40.171204511s

• [SLOW TEST:42.392 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:33:30.991: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6898
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul  3 22:33:31.188: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6898,SelfLink:/api/v1/namespaces/watch-6898/configmaps/e2e-watch-test-resource-version,UID:95b8458a-9de2-11e9-a55c-fa163e25a4f0,ResourceVersion:18497,Generation:0,CreationTimestamp:2019-07-03 22:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul  3 22:33:31.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6898,SelfLink:/api/v1/namespaces/watch-6898/configmaps/e2e-watch-test-resource-version,UID:95b8458a-9de2-11e9-a55c-fa163e25a4f0,ResourceVersion:18498,Generation:0,CreationTimestamp:2019-07-03 22:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:33:31.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6898" for this suite.
Jul  3 22:33:37.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:33:37.370: INFO: namespace watch-6898 deletion completed in 6.175411191s

• [SLOW TEST:6.380 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:33:37.370: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-99854b8c-9de2-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:33:37.552: INFO: Waiting up to 5m0s for pod "pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c" in namespace "configmap-8908" to be "success or failure"
Jul  3 22:33:37.556: INFO: Pod "pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027025ms
Jul  3 22:33:39.562: INFO: Pod "pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009811914s
STEP: Saw pod success
Jul  3 22:33:39.562: INFO: Pod "pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:33:39.567: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:33:39.602: INFO: Waiting for pod pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:33:39.606: INFO: Pod pod-configmaps-9986320e-9de2-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:33:39.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8908" for this suite.
Jul  3 22:33:45.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:33:45.786: INFO: namespace configmap-8908 deletion completed in 6.174453504s

• [SLOW TEST:8.416 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:33:45.787: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-391
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul  3 22:33:45.985: INFO: Found 0 stateful pods, waiting for 3
Jul  3 22:33:55.994: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:33:55.994: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:33:55.994: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:33:56.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-391 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:33:56.274: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:33:56.274: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:33:56.274: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul  3 22:34:06.324: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul  3 22:34:16.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-391 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:34:16.592: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:34:16.593: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:34:16.593: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:34:26.631: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:34:26.631: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul  3 22:34:26.631: INFO: Waiting for Pod statefulset-391/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul  3 22:34:26.631: INFO: Waiting for Pod statefulset-391/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul  3 22:34:36.644: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:34:36.644: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul  3 22:34:46.643: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:34:46.643: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jul  3 22:34:56.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-391 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:34:56.915: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:34:56.915: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:34:56.915: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 22:35:06.969: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul  3 22:35:16.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-391 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:35:17.242: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:35:17.242: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:35:17.242: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:35:27.280: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:35:27.280: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul  3 22:35:27.280: INFO: Waiting for Pod statefulset-391/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul  3 22:35:27.280: INFO: Waiting for Pod statefulset-391/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul  3 22:35:37.294: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:35:37.294: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul  3 22:35:47.294: INFO: Waiting for StatefulSet statefulset-391/ss2 to complete update
Jul  3 22:35:47.294: INFO: Waiting for Pod statefulset-391/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul  3 22:35:57.293: INFO: Deleting all statefulset in ns statefulset-391
Jul  3 22:35:57.298: INFO: Scaling statefulset ss2 to 0
Jul  3 22:36:27.334: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:36:27.341: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:36:27.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-391" for this suite.
Jul  3 22:36:33.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:36:33.585: INFO: namespace statefulset-391 deletion completed in 6.202592886s

• [SLOW TEST:167.798 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:36:33.586: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0703 22:37:04.307875      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 22:37:04.307: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:37:04.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2689" for this suite.
Jul  3 22:37:10.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:37:10.481: INFO: namespace gc-2689 deletion completed in 6.168052117s

• [SLOW TEST:36.896 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:37:10.482: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Jul  3 22:37:10.669: INFO: Waiting up to 5m0s for pod "var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c" in namespace "var-expansion-3937" to be "success or failure"
Jul  3 22:37:10.673: INFO: Pod "var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.115363ms
Jul  3 22:37:12.681: INFO: Pod "var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011261955s
STEP: Saw pod success
Jul  3 22:37:12.681: INFO: Pod "var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:37:12.685: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:37:12.711: INFO: Waiting for pod var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:37:12.715: INFO: Pod var-expansion-188d828b-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:37:12.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3937" for this suite.
Jul  3 22:37:18.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:37:18.901: INFO: namespace var-expansion-3937 deletion completed in 6.177511644s

• [SLOW TEST:8.419 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:37:18.903: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:37:21.128: INFO: Waiting up to 5m0s for pod "client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c" in namespace "pods-7905" to be "success or failure"
Jul  3 22:37:21.133: INFO: Pod "client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.829874ms
Jul  3 22:37:23.139: INFO: Pod "client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010522716s
Jul  3 22:37:25.147: INFO: Pod "client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019100167s
STEP: Saw pod success
Jul  3 22:37:25.148: INFO: Pod "client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:37:25.153: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c container env3cont: <nil>
STEP: delete the pod
Jul  3 22:37:25.190: INFO: Waiting for pod client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:37:25.195: INFO: Pod client-envvars-1ec913e6-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:37:25.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7905" for this suite.
Jul  3 22:38:09.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:38:09.387: INFO: namespace pods-7905 deletion completed in 44.184420016s

• [SLOW TEST:50.485 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:38:09.388: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  3 22:38:09.568: INFO: Waiting up to 5m0s for pod "pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c" in namespace "emptydir-4639" to be "success or failure"
Jul  3 22:38:09.574: INFO: Pod "pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.127665ms
Jul  3 22:38:11.581: INFO: Pod "pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01246384s
Jul  3 22:38:13.587: INFO: Pod "pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018882959s
STEP: Saw pod success
Jul  3 22:38:13.588: INFO: Pod "pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:38:13.593: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:38:13.621: INFO: Waiting for pod pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:38:13.624: INFO: Pod pod-3ba8dac4-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:38:13.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4639" for this suite.
Jul  3 22:38:19.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:38:19.823: INFO: namespace emptydir-4639 deletion completed in 6.191843889s

• [SLOW TEST:10.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:38:19.825: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-218
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-41e2ed44-9de3-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:38:20.021: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c" in namespace "projected-218" to be "success or failure"
Jul  3 22:38:20.027: INFO: Pod "pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.09321ms
Jul  3 22:38:22.034: INFO: Pod "pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012357002s
STEP: Saw pod success
Jul  3 22:38:22.034: INFO: Pod "pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:38:22.038: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:38:22.066: INFO: Waiting for pod pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:38:22.070: INFO: Pod pod-projected-configmaps-41e3df76-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:38:22.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-218" for this suite.
Jul  3 22:38:28.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:38:28.256: INFO: namespace projected-218 deletion completed in 6.18067087s

• [SLOW TEST:8.432 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:38:28.261: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  3 22:38:28.441: INFO: Waiting up to 5m0s for pod "pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c" in namespace "emptydir-3097" to be "success or failure"
Jul  3 22:38:28.446: INFO: Pod "pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.577362ms
Jul  3 22:38:30.454: INFO: Pod "pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012372109s
STEP: Saw pod success
Jul  3 22:38:30.454: INFO: Pod "pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:38:30.459: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:38:30.494: INFO: Waiting for pod pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:38:30.499: INFO: Pod pod-46e89c2e-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:38:30.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3097" for this suite.
Jul  3 22:38:36.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:38:36.703: INFO: namespace emptydir-3097 deletion completed in 6.197277203s

• [SLOW TEST:8.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:38:36.703: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:38:38.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9571" for this suite.
Jul  3 22:39:20.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:39:21.106: INFO: namespace kubelet-test-9571 deletion completed in 42.1842627s

• [SLOW TEST:44.403 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:39:21.106: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4349
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul  3 22:39:25.856: INFO: Successfully updated pod "annotationupdate6667114d-9de3-11e9-b0a2-a612d8f3003c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:39:27.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4349" for this suite.
Jul  3 22:39:49.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:39:50.094: INFO: namespace downward-api-4349 deletion completed in 22.201123018s

• [SLOW TEST:28.988 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:39:50.095: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-5xp5
STEP: Creating a pod to test atomic-volume-subpath
Jul  3 22:39:50.284: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5xp5" in namespace "subpath-6522" to be "success or failure"
Jul  3 22:39:50.288: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.990337ms
Jul  3 22:39:52.295: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010589954s
Jul  3 22:39:54.302: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 4.017636501s
Jul  3 22:39:56.310: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 6.025518416s
Jul  3 22:39:58.318: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 8.03394496s
Jul  3 22:40:00.325: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 10.041057186s
Jul  3 22:40:02.332: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 12.048175044s
Jul  3 22:40:04.338: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 14.054185446s
Jul  3 22:40:06.345: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 16.060793155s
Jul  3 22:40:08.351: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 18.066776988s
Jul  3 22:40:10.357: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 20.073373469s
Jul  3 22:40:12.364: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Running", Reason="", readiness=true. Elapsed: 22.079767914s
Jul  3 22:40:14.371: INFO: Pod "pod-subpath-test-configmap-5xp5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.086912034s
STEP: Saw pod success
Jul  3 22:40:14.371: INFO: Pod "pod-subpath-test-configmap-5xp5" satisfied condition "success or failure"
Jul  3 22:40:14.376: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-subpath-test-configmap-5xp5 container test-container-subpath-configmap-5xp5: <nil>
STEP: delete the pod
Jul  3 22:40:14.408: INFO: Waiting for pod pod-subpath-test-configmap-5xp5 to disappear
Jul  3 22:40:14.412: INFO: Pod pod-subpath-test-configmap-5xp5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5xp5
Jul  3 22:40:14.412: INFO: Deleting pod "pod-subpath-test-configmap-5xp5" in namespace "subpath-6522"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:40:14.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6522" for this suite.
Jul  3 22:40:20.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:40:20.611: INFO: namespace subpath-6522 deletion completed in 6.187243607s

• [SLOW TEST:30.516 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:40:20.611: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  3 22:40:20.842: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:20.842: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:20.842: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:20.846: INFO: Number of nodes with available pods: 0
Jul  3 22:40:20.846: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:40:21.853: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:21.853: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:21.853: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:21.857: INFO: Number of nodes with available pods: 0
Jul  3 22:40:21.858: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:40:22.854: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.855: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.855: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.860: INFO: Number of nodes with available pods: 4
Jul  3 22:40:22.860: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul  3 22:40:22.887: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.887: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.887: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:22.893: INFO: Number of nodes with available pods: 3
Jul  3 22:40:22.893: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:23.902: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:23.902: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:23.902: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:23.908: INFO: Number of nodes with available pods: 3
Jul  3 22:40:23.908: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:24.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:24.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:24.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:24.909: INFO: Number of nodes with available pods: 3
Jul  3 22:40:24.909: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:25.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:25.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:25.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:25.909: INFO: Number of nodes with available pods: 3
Jul  3 22:40:25.909: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:26.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:26.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:26.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:26.911: INFO: Number of nodes with available pods: 3
Jul  3 22:40:26.911: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:27.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:27.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:27.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:27.908: INFO: Number of nodes with available pods: 3
Jul  3 22:40:27.908: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:40:28.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:28.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:28.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:40:28.910: INFO: Number of nodes with available pods: 4
Jul  3 22:40:28.910: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2003, will wait for the garbage collector to delete the pods
Jul  3 22:40:28.992: INFO: Deleting DaemonSet.extensions daemon-set took: 15.057042ms
Jul  3 22:40:29.293: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.492159ms
Jul  3 22:40:38.000: INFO: Number of nodes with available pods: 0
Jul  3 22:40:38.000: INFO: Number of running nodes: 0, number of available pods: 0
Jul  3 22:40:38.005: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2003/daemonsets","resourceVersion":"20697"},"items":null}

Jul  3 22:40:38.009: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2003/pods","resourceVersion":"20697"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:40:38.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2003" for this suite.
Jul  3 22:40:44.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:40:44.232: INFO: namespace daemonsets-2003 deletion completed in 6.180646656s

• [SLOW TEST:23.621 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:40:44.234: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-97f405fc-9de3-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:40:44.417: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c" in namespace "projected-9215" to be "success or failure"
Jul  3 22:40:44.421: INFO: Pod "pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.514914ms
Jul  3 22:40:46.427: INFO: Pod "pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009922466s
STEP: Saw pod success
Jul  3 22:40:46.427: INFO: Pod "pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:40:46.432: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:40:46.461: INFO: Waiting for pod pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:40:46.465: INFO: Pod pod-projected-secrets-97f4daf3-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:40:46.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9215" for this suite.
Jul  3 22:40:52.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:40:52.716: INFO: namespace projected-9215 deletion completed in 6.242294615s

• [SLOW TEST:8.483 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:40:52.718: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul  3 22:40:52.885: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:40:55.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-332" for this suite.
Jul  3 22:41:01.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:41:02.004: INFO: namespace init-container-332 deletion completed in 6.181248186s

• [SLOW TEST:9.287 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:41:02.006: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a28b80ea-9de3-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:41:02.189: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c" in namespace "projected-9992" to be "success or failure"
Jul  3 22:41:02.194: INFO: Pod "pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.027585ms
Jul  3 22:41:04.201: INFO: Pod "pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c": Phase="Running", Reason="", readiness=true. Elapsed: 2.012126656s
Jul  3 22:41:06.208: INFO: Pod "pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018919044s
STEP: Saw pod success
Jul  3 22:41:06.208: INFO: Pod "pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:41:06.213: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:41:06.245: INFO: Waiting for pod pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:41:06.249: INFO: Pod pod-projected-configmaps-a28ca824-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:41:06.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9992" for this suite.
Jul  3 22:41:12.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:41:12.444: INFO: namespace projected-9992 deletion completed in 6.189251019s

• [SLOW TEST:10.438 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:41:12.445: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9801
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:41:12.623: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul  3 22:41:17.629: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  3 22:41:17.629: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul  3 22:41:19.636: INFO: Creating deployment "test-rollover-deployment"
Jul  3 22:41:19.649: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul  3 22:41:21.660: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul  3 22:41:21.670: INFO: Ensure that both replica sets have 1 created replica
Jul  3 22:41:21.682: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul  3 22:41:21.694: INFO: Updating deployment test-rollover-deployment
Jul  3 22:41:21.694: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul  3 22:41:23.707: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul  3 22:41:23.719: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul  3 22:41:23.728: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:23.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790481, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:25.742: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:25.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790481, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:27.740: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:27.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790485, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:29.741: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:29.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790485, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:31.741: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:31.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790485, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:33.742: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:33.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790485, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:35.741: INFO: all replica sets need to contain the pod-template-hash label
Jul  3 22:41:35.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790485, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697790479, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:41:37.742: INFO: 
Jul  3 22:41:37.742: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul  3 22:41:37.762: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9801,SelfLink:/apis/apps/v1/namespaces/deployment-9801/deployments/test-rollover-deployment,UID:acf51b66-9de3-11e9-a55c-fa163e25a4f0,ResourceVersion:21107,Generation:2,CreationTimestamp:2019-07-03 22:41:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-03 22:41:19 +0000 UTC 2019-07-03 22:41:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-03 22:41:35 +0000 UTC 2019-07-03 22:41:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul  3 22:41:37.770: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-9801,SelfLink:/apis/apps/v1/namespaces/deployment-9801/replicasets/test-rollover-deployment-766b4d6c9d,UID:ae2f663e-9de3-11e9-a55c-fa163e25a4f0,ResourceVersion:21096,Generation:2,CreationTimestamp:2019-07-03 22:41:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment acf51b66-9de3-11e9-a55c-fa163e25a4f0 0xc000bb6e37 0xc000bb6e38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul  3 22:41:37.771: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul  3 22:41:37.771: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9801,SelfLink:/apis/apps/v1/namespaces/deployment-9801/replicasets/test-rollover-controller,UID:a8c4a6cd-9de3-11e9-a55c-fa163e25a4f0,ResourceVersion:21106,Generation:2,CreationTimestamp:2019-07-03 22:41:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment acf51b66-9de3-11e9-a55c-fa163e25a4f0 0xc000bb6a37 0xc000bb6a38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:41:37.771: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-9801,SelfLink:/apis/apps/v1/namespaces/deployment-9801/replicasets/test-rollover-deployment-6455657675,UID:acf8e78a-9de3-11e9-a55c-fa163e25a4f0,ResourceVersion:21041,Generation:2,CreationTimestamp:2019-07-03 22:41:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment acf51b66-9de3-11e9-a55c-fa163e25a4f0 0xc000bb6c07 0xc000bb6c08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:41:37.780: INFO: Pod "test-rollover-deployment-766b4d6c9d-9hr4c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-9hr4c,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-9801,SelfLink:/api/v1/namespaces/deployment-9801/pods/test-rollover-deployment-766b4d6c9d-9hr4c,UID:ae36373d-9de3-11e9-a55c-fa163e25a4f0,ResourceVersion:21066,Generation:0,CreationTimestamp:2019-07-03 22:41:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d ae2f663e-9de3-11e9-a55c-fa163e25a4f0 0xc0022f83d7 0xc0022f83d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l2fgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l2fgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-l2fgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f8480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f84a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:41:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:41:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:41:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:41:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:10.2.17.47,StartTime:2019-07-03 22:41:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-03 22:41:24 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1300152e547f29f47d4d9945fa9d50ff060695020e30b197ecce4ece257f1c90}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:41:37.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9801" for this suite.
Jul  3 22:41:43.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:41:43.988: INFO: namespace deployment-9801 deletion completed in 6.19924169s

• [SLOW TEST:31.544 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:41:43.990: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul  3 22:41:48.219: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  3 22:41:48.226: INFO: Pod pod-with-prestop-http-hook still exists
Jul  3 22:41:50.226: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  3 22:41:50.233: INFO: Pod pod-with-prestop-http-hook still exists
Jul  3 22:41:52.226: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  3 22:41:52.232: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:41:52.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9870" for this suite.
Jul  3 22:42:14.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:42:14.428: INFO: namespace container-lifecycle-hook-9870 deletion completed in 22.175971159s

• [SLOW TEST:30.439 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:42:14.431: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-989
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5335
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:42:20.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6405" for this suite.
Jul  3 22:42:26.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:42:27.159: INFO: namespace namespaces-6405 deletion completed in 6.197175036s
STEP: Destroying namespace "nsdeletetest-989" for this suite.
Jul  3 22:42:27.165: INFO: Namespace nsdeletetest-989 was already deleted
STEP: Destroying namespace "nsdeletetest-5335" for this suite.
Jul  3 22:42:33.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:42:33.350: INFO: namespace nsdeletetest-5335 deletion completed in 6.184850816s

• [SLOW TEST:18.919 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:42:33.352: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:42:33.540: INFO: (0) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.031411ms)
Jul  3 22:42:33.547: INFO: (1) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.821596ms)
Jul  3 22:42:33.553: INFO: (2) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.929767ms)
Jul  3 22:42:33.558: INFO: (3) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.875414ms)
Jul  3 22:42:33.563: INFO: (4) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.057238ms)
Jul  3 22:42:33.569: INFO: (5) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.088925ms)
Jul  3 22:42:33.581: INFO: (6) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.103789ms)
Jul  3 22:42:33.590: INFO: (7) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.944939ms)
Jul  3 22:42:33.597: INFO: (8) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.864961ms)
Jul  3 22:42:33.604: INFO: (9) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.024167ms)
Jul  3 22:42:33.611: INFO: (10) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.379659ms)
Jul  3 22:42:33.617: INFO: (11) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.995572ms)
Jul  3 22:42:33.622: INFO: (12) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.065438ms)
Jul  3 22:42:33.629: INFO: (13) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.124738ms)
Jul  3 22:42:33.635: INFO: (14) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.627145ms)
Jul  3 22:42:33.641: INFO: (15) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.445612ms)
Jul  3 22:42:33.646: INFO: (16) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.81694ms)
Jul  3 22:42:33.653: INFO: (17) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.832389ms)
Jul  3 22:42:33.660: INFO: (18) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.11302ms)
Jul  3 22:42:33.667: INFO: (19) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.222332ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:42:33.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7627" for this suite.
Jul  3 22:42:39.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:42:39.848: INFO: namespace proxy-7627 deletion completed in 6.174489651s

• [SLOW TEST:6.495 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:42:39.850: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9162
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9162/configmap-test-dcdcac69-9de3-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:42:40.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c" in namespace "configmap-9162" to be "success or failure"
Jul  3 22:42:40.031: INFO: Pod "pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.237465ms
Jul  3 22:42:42.037: INFO: Pod "pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010422646s
STEP: Saw pod success
Jul  3 22:42:42.038: INFO: Pod "pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:42:42.044: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c container env-test: <nil>
STEP: delete the pod
Jul  3 22:42:42.071: INFO: Waiting for pod pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:42:42.075: INFO: Pod pod-configmaps-dcdd9eca-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:42:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9162" for this suite.
Jul  3 22:42:48.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:42:48.266: INFO: namespace configmap-9162 deletion completed in 6.184801174s

• [SLOW TEST:8.417 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:42:48.267: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:42:48.446: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:42:50.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7190" for this suite.
Jul  3 22:43:30.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:43:30.713: INFO: namespace pods-7190 deletion completed in 40.188155744s

• [SLOW TEST:42.446 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:43:30.713: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Jul  3 22:43:30.891: INFO: Waiting up to 5m0s for pod "var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c" in namespace "var-expansion-2109" to be "success or failure"
Jul  3 22:43:30.895: INFO: Pod "var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.245026ms
Jul  3 22:43:32.902: INFO: Pod "var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011519997s
STEP: Saw pod success
Jul  3 22:43:32.902: INFO: Pod "var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:43:32.907: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:43:32.944: INFO: Waiting for pod var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:43:32.950: INFO: Pod var-expansion-fb2ebf29-9de3-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:43:32.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2109" for this suite.
Jul  3 22:43:38.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:43:39.148: INFO: namespace var-expansion-2109 deletion completed in 6.190847213s

• [SLOW TEST:8.435 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:43:39.150: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0703 22:43:49.429937      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 22:43:49.429: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:43:49.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6313" for this suite.
Jul  3 22:43:55.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:43:55.626: INFO: namespace gc-6313 deletion completed in 6.183491095s

• [SLOW TEST:16.476 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:43:55.628: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3312
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  3 22:43:55.791: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul  3 22:44:19.941: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.97.57 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:44:19.941: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:44:21.088: INFO: Found all expected endpoints: [netserver-0]
Jul  3 22:44:21.093: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.17.51 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:44:21.093: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:44:22.220: INFO: Found all expected endpoints: [netserver-1]
Jul  3 22:44:22.225: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.248.48 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:44:22.225: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:44:23.360: INFO: Found all expected endpoints: [netserver-2]
Jul  3 22:44:23.366: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.5.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3312 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 22:44:23.366: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 22:44:24.494: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:44:24.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3312" for this suite.
Jul  3 22:44:46.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:44:46.689: INFO: namespace pod-network-test-3312 deletion completed in 22.184924628s

• [SLOW TEST:51.061 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:44:46.693: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  3 22:44:46.868: INFO: Waiting up to 5m0s for pod "pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c" in namespace "emptydir-2676" to be "success or failure"
Jul  3 22:44:46.873: INFO: Pod "pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.179801ms
Jul  3 22:44:48.880: INFO: Pod "pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012154722s
STEP: Saw pod success
Jul  3 22:44:48.880: INFO: Pod "pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:44:48.885: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:44:48.916: INFO: Waiting for pod pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:44:48.920: INFO: Pod pod-2877ead8-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:44:48.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2676" for this suite.
Jul  3 22:44:54.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:44:55.133: INFO: namespace emptydir-2676 deletion completed in 6.206194141s

• [SLOW TEST:8.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:44:55.134: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul  3 22:44:58.357: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:44:59.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4956" for this suite.
Jul  3 22:45:21.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:45:21.660: INFO: namespace replicaset-4956 deletion completed in 22.270280187s

• [SLOW TEST:26.525 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:45:21.660: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-3d559028-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:45:21.884: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c" in namespace "projected-8254" to be "success or failure"
Jul  3 22:45:21.889: INFO: Pod "pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.503624ms
Jul  3 22:45:23.896: INFO: Pod "pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012142916s
Jul  3 22:45:25.902: INFO: Pod "pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018689636s
STEP: Saw pod success
Jul  3 22:45:25.903: INFO: Pod "pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:45:25.908: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:45:25.935: INFO: Waiting for pod pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:45:25.939: INFO: Pod pod-projected-secrets-3d56b3dc-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:45:25.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8254" for this suite.
Jul  3 22:45:31.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:45:32.132: INFO: namespace projected-8254 deletion completed in 6.185330267s

• [SLOW TEST:10.472 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:45:32.133: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-438e8e94-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:45:32.329: INFO: Waiting up to 5m0s for pod "pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c" in namespace "secrets-5958" to be "success or failure"
Jul  3 22:45:32.336: INFO: Pod "pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.344349ms
Jul  3 22:45:34.343: INFO: Pod "pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013463184s
STEP: Saw pod success
Jul  3 22:45:34.343: INFO: Pod "pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:45:34.348: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:45:34.377: INFO: Waiting for pod pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:45:34.381: INFO: Pod pod-secrets-438f91c5-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:45:34.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5958" for this suite.
Jul  3 22:45:40.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:45:40.548: INFO: namespace secrets-5958 deletion completed in 6.160391035s

• [SLOW TEST:8.414 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:45:40.551: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-7206
Jul  3 22:45:42.744: INFO: Started pod liveness-exec in namespace container-probe-7206
STEP: checking the pod's current state and verifying that restartCount is present
Jul  3 22:45:42.750: INFO: Initial restart count of pod liveness-exec is 0
Jul  3 22:46:34.937: INFO: Restart count of pod container-probe-7206/liveness-exec is now 1 (52.187124069s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:46:34.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7206" for this suite.
Jul  3 22:46:40.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:46:41.151: INFO: namespace container-probe-7206 deletion completed in 6.190823741s

• [SLOW TEST:60.601 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:46:41.157: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:46:41.337: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c" in namespace "downward-api-6936" to be "success or failure"
Jul  3 22:46:41.343: INFO: Pod "downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.885511ms
Jul  3 22:46:43.351: INFO: Pod "downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013844245s
STEP: Saw pod success
Jul  3 22:46:43.351: INFO: Pod "downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:46:43.357: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:46:43.383: INFO: Waiting for pod downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:46:43.386: INFO: Pod downwardapi-volume-6cb2313f-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:46:43.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6936" for this suite.
Jul  3 22:46:49.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:46:49.598: INFO: namespace downward-api-6936 deletion completed in 6.205983926s

• [SLOW TEST:8.441 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:46:49.598: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:46:49.798: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul  3 22:46:49.811: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:49.811: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:49.811: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:49.815: INFO: Number of nodes with available pods: 0
Jul  3 22:46:49.815: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:46:50.822: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:50.822: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:50.822: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:50.828: INFO: Number of nodes with available pods: 0
Jul  3 22:46:50.828: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:46:51.824: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:51.824: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:51.824: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:51.830: INFO: Number of nodes with available pods: 3
Jul  3 22:46:51.830: INFO: Node jrpk8s114fixed-k8s-node-nf-3 is running more than one daemon pod
Jul  3 22:46:52.825: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:52.825: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:52.825: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:52.831: INFO: Number of nodes with available pods: 4
Jul  3 22:46:52.831: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul  3 22:46:52.884: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:52.884: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:52.884: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:52.884: INFO: Wrong image for pod: daemon-set-zhvd9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:52.891: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:52.891: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:52.891: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:53.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:53.900: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:53.900: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:53.900: INFO: Wrong image for pod: daemon-set-zhvd9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:53.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:53.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:53.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:54.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:54.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:54.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:54.898: INFO: Wrong image for pod: daemon-set-zhvd9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:54.898: INFO: Pod daemon-set-zhvd9 is not available
Jul  3 22:46:54.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:54.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:54.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:55.900: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:55.900: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:55.900: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:55.900: INFO: Wrong image for pod: daemon-set-zhvd9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:55.900: INFO: Pod daemon-set-zhvd9 is not available
Jul  3 22:46:55.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:55.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:55.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:56.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:56.900: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:56.900: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:56.900: INFO: Wrong image for pod: daemon-set-zhvd9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:56.900: INFO: Pod daemon-set-zhvd9 is not available
Jul  3 22:46:56.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:56.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:56.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:57.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:57.899: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:57.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:57.899: INFO: Pod daemon-set-qg455 is not available
Jul  3 22:46:57.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:57.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:57.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:58.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:58.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:58.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:58.898: INFO: Pod daemon-set-qg455 is not available
Jul  3 22:46:58.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:58.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:58.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:59.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:59.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:59.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:46:59.898: INFO: Pod daemon-set-qg455 is not available
Jul  3 22:46:59.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:59.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:46:59.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:00.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:00.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:00.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:00.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:00.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:00.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:01.900: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:01.900: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:01.900: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:01.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:01.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:01.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:02.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:02.899: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:02.899: INFO: Pod daemon-set-h4qxq is not available
Jul  3 22:47:02.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:02.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:02.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:02.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:03.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:03.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:03.898: INFO: Pod daemon-set-h4qxq is not available
Jul  3 22:47:03.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:03.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:03.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:03.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:04.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:04.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:04.898: INFO: Pod daemon-set-h4qxq is not available
Jul  3 22:47:04.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:04.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:04.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:04.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:05.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:05.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:05.898: INFO: Pod daemon-set-h4qxq is not available
Jul  3 22:47:05.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:05.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:05.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:05.903: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:06.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:06.898: INFO: Wrong image for pod: daemon-set-h4qxq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:06.898: INFO: Pod daemon-set-h4qxq is not available
Jul  3 22:47:06.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:06.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:06.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:06.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:07.897: INFO: Pod daemon-set-45hfm is not available
Jul  3 22:47:07.897: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:07.897: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:07.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:07.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:07.904: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:08.898: INFO: Pod daemon-set-45hfm is not available
Jul  3 22:47:08.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:08.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:08.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:08.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:08.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:09.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:09.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:09.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:09.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:09.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:10.898: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:10.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:10.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:10.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:10.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:11.899: INFO: Wrong image for pod: daemon-set-8wntq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:11.899: INFO: Pod daemon-set-8wntq is not available
Jul  3 22:47:11.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:11.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:11.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:11.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:12.900: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:12.900: INFO: Pod daemon-set-q9p9w is not available
Jul  3 22:47:12.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:12.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:12.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:13.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:13.898: INFO: Pod daemon-set-q9p9w is not available
Jul  3 22:47:13.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:13.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:13.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:14.898: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:14.898: INFO: Pod daemon-set-q9p9w is not available
Jul  3 22:47:14.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:14.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:14.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:15.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:15.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:15.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:15.906: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:16.899: INFO: Wrong image for pod: daemon-set-l9lkv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul  3 22:47:16.899: INFO: Pod daemon-set-l9lkv is not available
Jul  3 22:47:16.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:16.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:16.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.899: INFO: Pod daemon-set-z8h57 is not available
Jul  3 22:47:17.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.905: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jul  3 22:47:17.912: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.912: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.912: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:17.919: INFO: Number of nodes with available pods: 3
Jul  3 22:47:17.919: INFO: Node jrpk8s114fixed-k8s-node-nf-4 is running more than one daemon pod
Jul  3 22:47:18.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:18.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:18.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:18.932: INFO: Number of nodes with available pods: 3
Jul  3 22:47:18.932: INFO: Node jrpk8s114fixed-k8s-node-nf-4 is running more than one daemon pod
Jul  3 22:47:19.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:19.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:19.927: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:19.932: INFO: Number of nodes with available pods: 3
Jul  3 22:47:19.932: INFO: Node jrpk8s114fixed-k8s-node-nf-4 is running more than one daemon pod
Jul  3 22:47:20.928: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:20.928: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:20.928: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:47:20.932: INFO: Number of nodes with available pods: 4
Jul  3 22:47:20.932: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2668, will wait for the garbage collector to delete the pods
Jul  3 22:47:21.042: INFO: Deleting DaemonSet.extensions daemon-set took: 18.194242ms
Jul  3 22:47:21.343: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.505225ms
Jul  3 22:47:28.949: INFO: Number of nodes with available pods: 0
Jul  3 22:47:28.949: INFO: Number of running nodes: 0, number of available pods: 0
Jul  3 22:47:28.955: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2668/daemonsets","resourceVersion":"23266"},"items":null}

Jul  3 22:47:28.960: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2668/pods","resourceVersion":"23266"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:47:28.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2668" for this suite.
Jul  3 22:47:35.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:47:35.165: INFO: namespace daemonsets-2668 deletion completed in 6.171484166s

• [SLOW TEST:45.567 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:47:35.167: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul  3 22:47:35.347: INFO: Waiting up to 5m0s for pod "downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c" in namespace "downward-api-5174" to be "success or failure"
Jul  3 22:47:35.353: INFO: Pod "downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.218496ms
Jul  3 22:47:37.360: INFO: Pod "downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012563318s
STEP: Saw pod success
Jul  3 22:47:37.360: INFO: Pod "downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:47:37.368: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:47:37.401: INFO: Waiting for pod downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:47:37.405: INFO: Pod downward-api-8ce3f4a7-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:47:37.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5174" for this suite.
Jul  3 22:47:43.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:47:43.583: INFO: namespace downward-api-5174 deletion completed in 6.171760157s

• [SLOW TEST:8.416 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:47:43.583: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul  3 22:47:43.750: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  3 22:47:43.764: INFO: Waiting for terminating namespaces to be deleted...
Jul  3 22:47:43.769: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-1 before test
Jul  3 22:47:43.783: INFO: busybox from default started at 2019-07-03 21:33:54 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container busybox ready: true, restart count 1
Jul  3 22:47:43.783: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-ffrws from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:47:43.783: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:47:43.783: INFO: kube-proxy-v859f from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:47:43.783: INFO: calico-kube-controllers-75c555d7c-t9r98 from kube-system started at 2019-07-03 21:28:26 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  3 22:47:43.783: INFO: nodelocaldns-vxmbw from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:47:43.783: INFO: calico-node-nrmmw from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.783: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:47:43.783: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-2 before test
Jul  3 22:47:43.792: INFO: kube-proxy-9w5nv from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.792: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:47:43.793: INFO: calico-node-cbplv from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.793: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:47:43.793: INFO: nodelocaldns-s4f5b from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.793: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:47:43.793: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-h77pm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:47:43.793: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:47:43.793: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:47:43.793: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-3 before test
Jul  3 22:47:43.819: INFO: calico-node-tzhzr from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.819: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:47:43.819: INFO: nodelocaldns-qn4sv from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.819: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:47:43.819: INFO: sonobuoy-e2e-job-eb3c12b284664f3e from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:47:43.819: INFO: 	Container e2e ready: true, restart count 0
Jul  3 22:47:43.819: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:47:43.819: INFO: kube-proxy-wsfnv from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.819: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:47:43.819: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-03 22:05:29 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.820: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  3 22:47:43.820: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-stktm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:47:43.820: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:47:43.820: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:47:43.820: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-4 before test
Jul  3 22:47:43.829: INFO: calico-node-g5xlp from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.829: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:47:43.829: INFO: nodelocaldns-jn5p5 from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.830: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:47:43.830: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-pgpmv from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:47:43.830: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:47:43.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:47:43.830: INFO: kube-proxy-qqrrz from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:47:43.830: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node jrpk8s114fixed-k8s-node-nf-1
STEP: verifying the node has the label node jrpk8s114fixed-k8s-node-nf-2
STEP: verifying the node has the label node jrpk8s114fixed-k8s-node-nf-3
STEP: verifying the node has the label node jrpk8s114fixed-k8s-node-nf-4
Jul  3 22:47:43.942: INFO: Pod busybox requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-1
Jul  3 22:47:43.942: INFO: Pod sonobuoy requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod sonobuoy-e2e-job-eb3c12b284664f3e requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-ffrws requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-1
Jul  3 22:47:43.942: INFO: Pod sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-h77pm requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-2
Jul  3 22:47:43.942: INFO: Pod sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-pgpmv requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-4
Jul  3 22:47:43.942: INFO: Pod sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-stktm requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod calico-kube-controllers-75c555d7c-t9r98 requesting resource cpu=30m on Node jrpk8s114fixed-k8s-node-nf-1
Jul  3 22:47:43.942: INFO: Pod calico-node-cbplv requesting resource cpu=150m on Node jrpk8s114fixed-k8s-node-nf-2
Jul  3 22:47:43.942: INFO: Pod calico-node-g5xlp requesting resource cpu=150m on Node jrpk8s114fixed-k8s-node-nf-4
Jul  3 22:47:43.942: INFO: Pod calico-node-nrmmw requesting resource cpu=150m on Node jrpk8s114fixed-k8s-node-nf-1
Jul  3 22:47:43.942: INFO: Pod calico-node-tzhzr requesting resource cpu=150m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod kube-proxy-9w5nv requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-2
Jul  3 22:47:43.942: INFO: Pod kube-proxy-qqrrz requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-4
Jul  3 22:47:43.942: INFO: Pod kube-proxy-v859f requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-1
Jul  3 22:47:43.942: INFO: Pod kube-proxy-wsfnv requesting resource cpu=0m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod nodelocaldns-jn5p5 requesting resource cpu=100m on Node jrpk8s114fixed-k8s-node-nf-4
Jul  3 22:47:43.942: INFO: Pod nodelocaldns-qn4sv requesting resource cpu=100m on Node jrpk8s114fixed-k8s-node-nf-3
Jul  3 22:47:43.942: INFO: Pod nodelocaldns-s4f5b requesting resource cpu=100m on Node jrpk8s114fixed-k8s-node-nf-2
Jul  3 22:47:43.942: INFO: Pod nodelocaldns-vxmbw requesting resource cpu=100m on Node jrpk8s114fixed-k8s-node-nf-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c.15ae07396cd5b747], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9485/filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c to jrpk8s114fixed-k8s-node-nf-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c.15ae0739a7b3dc82], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c.15ae0739ab66fd09], Reason = [Created], Message = [Created container filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c.15ae0739ba28ddc5], Reason = [Started], Message = [Started container filler-pod-9205319f-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c.15ae07396dd7aac7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9485/filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c to jrpk8s114fixed-k8s-node-nf-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c.15ae0739ac1ee32a], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c.15ae0739dcc8638c], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c.15ae0739e0388ed7], Reason = [Created], Message = [Created container filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c.15ae0739ee0ea930], Reason = [Started], Message = [Started container filler-pod-92077be8-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c.15ae07396dfaa920], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9485/filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c to jrpk8s114fixed-k8s-node-nf-4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c.15ae0739ad9894a1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c.15ae0739b0ca3ebe], Reason = [Created], Message = [Created container filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c.15ae0739b8f02f2e], Reason = [Started], Message = [Started container filler-pod-9208b236-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c.15ae07396ea1d298], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9485/filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c to jrpk8s114fixed-k8s-node-nf-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c.15ae0739b05d2498], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c.15ae0739b40f109d], Reason = [Created], Message = [Created container filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c.15ae0739bf00c213], Reason = [Started], Message = [Started container filler-pod-9209e64a-9de4-11e9-b0a2-a612d8f3003c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15ae073a5f3a6805], Reason = [FailedScheduling], Message = [0/7 nodes are available: 7 Insufficient cpu.]
STEP: removing the label node off the node jrpk8s114fixed-k8s-node-nf-4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node jrpk8s114fixed-k8s-node-nf-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node jrpk8s114fixed-k8s-node-nf-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node jrpk8s114fixed-k8s-node-nf-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:47:49.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9485" for this suite.
Jul  3 22:47:55.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:47:55.336: INFO: namespace sched-pred-9485 deletion completed in 6.196423388s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.753 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:47:55.336: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:47:55.536: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"98ec9150-9de4-11e9-a55c-fa163e25a4f0", Controller:(*bool)(0xc00265c606), BlockOwnerDeletion:(*bool)(0xc00265c607)}}
Jul  3 22:47:55.548: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"98ea1427-9de4-11e9-a55c-fa163e25a4f0", Controller:(*bool)(0xc002d1a6c6), BlockOwnerDeletion:(*bool)(0xc002d1a6c7)}}
Jul  3 22:47:55.564: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"98eb1cae-9de4-11e9-a55c-fa163e25a4f0", Controller:(*bool)(0xc002d1a866), BlockOwnerDeletion:(*bool)(0xc002d1a867)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:00.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5773" for this suite.
Jul  3 22:48:06.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:06.778: INFO: namespace gc-5773 deletion completed in 6.189702339s

• [SLOW TEST:11.441 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:06.779: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-9fbad700-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:48:06.962: INFO: Waiting up to 5m0s for pod "pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c" in namespace "configmap-3521" to be "success or failure"
Jul  3 22:48:06.966: INFO: Pod "pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.989322ms
Jul  3 22:48:08.972: INFO: Pod "pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010615833s
STEP: Saw pod success
Jul  3 22:48:08.972: INFO: Pod "pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:48:08.977: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:48:09.005: INFO: Waiting for pod pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:48:09.009: INFO: Pod pod-configmaps-9fbbb9d0-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:09.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3521" for this suite.
Jul  3 22:48:15.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:15.210: INFO: namespace configmap-3521 deletion completed in 6.194127256s

• [SLOW TEST:8.431 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:15.211: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:48:15.385: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c" in namespace "downward-api-8890" to be "success or failure"
Jul  3 22:48:15.391: INFO: Pod "downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106246ms
Jul  3 22:48:17.398: INFO: Pod "downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013004425s
Jul  3 22:48:19.405: INFO: Pod "downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020315747s
STEP: Saw pod success
Jul  3 22:48:19.405: INFO: Pod "downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:48:19.410: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:48:19.441: INFO: Waiting for pod downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:48:19.446: INFO: Pod downwardapi-volume-a4c0f7d1-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:19.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8890" for this suite.
Jul  3 22:48:25.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:25.652: INFO: namespace downward-api-8890 deletion completed in 6.195196818s

• [SLOW TEST:10.441 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:25.653: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-601
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Jul  3 22:48:25.843: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-601" to be "success or failure"
Jul  3 22:48:25.848: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.918885ms
Jul  3 22:48:27.853: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010594931s
STEP: Saw pod success
Jul  3 22:48:27.853: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul  3 22:48:27.858: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul  3 22:48:27.890: INFO: Waiting for pod pod-host-path-test to disappear
Jul  3 22:48:27.894: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:27.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-601" for this suite.
Jul  3 22:48:33.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:34.083: INFO: namespace hostpath-601 deletion completed in 6.181320373s

• [SLOW TEST:8.431 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:34.084: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:48:34.261: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c" in namespace "projected-8873" to be "success or failure"
Jul  3 22:48:34.267: INFO: Pod "downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.4098ms
Jul  3 22:48:36.273: INFO: Pod "downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012315662s
STEP: Saw pod success
Jul  3 22:48:36.273: INFO: Pod "downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:48:36.278: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:48:36.307: INFO: Waiting for pod downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:48:36.312: INFO: Pod downwardapi-volume-b0015699-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:36.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8873" for this suite.
Jul  3 22:48:42.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:42.492: INFO: namespace projected-8873 deletion completed in 6.172550238s

• [SLOW TEST:8.408 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:42.497: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul  3 22:48:42.673: INFO: Waiting up to 5m0s for pod "downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c" in namespace "downward-api-6687" to be "success or failure"
Jul  3 22:48:42.678: INFO: Pod "downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.736409ms
Jul  3 22:48:44.684: INFO: Pod "downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011245806s
Jul  3 22:48:46.693: INFO: Pod "downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019704524s
STEP: Saw pod success
Jul  3 22:48:46.693: INFO: Pod "downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:48:46.700: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 22:48:46.732: INFO: Waiting for pod downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:48:46.737: INFO: Pod downward-api-b504ec51-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:46.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6687" for this suite.
Jul  3 22:48:52.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:48:52.924: INFO: namespace downward-api-6687 deletion completed in 6.179603746s

• [SLOW TEST:10.427 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:48:52.927: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-bb3ca61a-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:48:53.117: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c" in namespace "projected-8263" to be "success or failure"
Jul  3 22:48:53.122: INFO: Pod "pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764171ms
Jul  3 22:48:55.129: INFO: Pod "pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011548686s
STEP: Saw pod success
Jul  3 22:48:55.129: INFO: Pod "pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:48:55.133: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:48:55.159: INFO: Waiting for pod pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:48:55.163: INFO: Pod pod-projected-configmaps-bb3d8b68-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:48:55.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8263" for this suite.
Jul  3 22:49:01.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:01.350: INFO: namespace projected-8263 deletion completed in 6.180592998s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:01.350: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c0423e77-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:49:01.538: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c" in namespace "projected-8928" to be "success or failure"
Jul  3 22:49:01.544: INFO: Pod "pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.284733ms
Jul  3 22:49:03.550: INFO: Pod "pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012177449s
STEP: Saw pod success
Jul  3 22:49:03.550: INFO: Pod "pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:49:03.555: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:49:03.582: INFO: Waiting for pod pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:49:03.587: INFO: Pod pod-projected-secrets-c04354f2-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:03.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8928" for this suite.
Jul  3 22:49:09.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:09.773: INFO: namespace projected-8928 deletion completed in 6.178216838s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:09.773: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:09.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9102" for this suite.
Jul  3 22:49:15.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:16.156: INFO: namespace kubelet-test-9102 deletion completed in 6.182597201s

• [SLOW TEST:6.384 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:16.158: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8635
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:49:16.322: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:22.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8635" for this suite.
Jul  3 22:49:28.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:28.709: INFO: namespace custom-resource-definition-8635 deletion completed in 6.267946515s

• [SLOW TEST:12.552 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:28.712: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d094c2e8-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:49:28.922: INFO: Waiting up to 5m0s for pod "pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c" in namespace "secrets-8247" to be "success or failure"
Jul  3 22:49:28.928: INFO: Pod "pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.33127ms
Jul  3 22:49:30.935: INFO: Pod "pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01270786s
STEP: Saw pod success
Jul  3 22:49:30.935: INFO: Pod "pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:49:30.939: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:49:30.966: INFO: Waiting for pod pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:49:30.970: INFO: Pod pod-secrets-d095eefd-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:30.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8247" for this suite.
Jul  3 22:49:36.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:37.145: INFO: namespace secrets-8247 deletion completed in 6.167909735s

• [SLOW TEST:8.434 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:37.147: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-d599f8a8-9de4-11e9-b0a2-a612d8f3003c
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:37.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6577" for this suite.
Jul  3 22:49:43.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:49:43.519: INFO: namespace configmap-6577 deletion completed in 6.18437218s

• [SLOW TEST:6.372 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:49:43.519: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:49:48.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2809" for this suite.
Jul  3 22:50:10.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:50:10.919: INFO: namespace replication-controller-2809 deletion completed in 22.180993946s

• [SLOW TEST:27.400 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:50:10.920: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e9b9e17b-9de4-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:50:11.109: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c" in namespace "configmap-7829" to be "success or failure"
Jul  3 22:50:11.114: INFO: Pod "pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.763451ms
Jul  3 22:50:13.119: INFO: Pod "pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01061336s
STEP: Saw pod success
Jul  3 22:50:13.120: INFO: Pod "pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:50:13.129: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:50:13.158: INFO: Waiting for pod pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:50:13.162: INFO: Pod pod-configmaps-e9bb030a-9de4-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:50:13.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7829" for this suite.
Jul  3 22:50:19.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:50:19.350: INFO: namespace configmap-7829 deletion completed in 6.182267008s

• [SLOW TEST:8.430 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:50:19.351: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4816
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  3 22:50:22.062: INFO: Successfully updated pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c"
Jul  3 22:50:22.062: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c" in namespace "pods-4816" to be "terminated due to deadline exceeded"
Jul  3 22:50:22.066: INFO: Pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c": Phase="Running", Reason="", readiness=true. Elapsed: 4.248072ms
Jul  3 22:50:24.073: INFO: Pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010932232s
Jul  3 22:50:26.079: INFO: Pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01730509s
Jul  3 22:50:26.079: INFO: Pod "pod-update-activedeadlineseconds-eebf8a72-9de4-11e9-b0a2-a612d8f3003c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:50:26.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4816" for this suite.
Jul  3 22:50:32.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:50:32.261: INFO: namespace pods-4816 deletion completed in 6.173437818s

• [SLOW TEST:12.910 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:50:32.262: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7544
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9849
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:50:58.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1104" for this suite.
Jul  3 22:51:04.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:51:05.040: INFO: namespace namespaces-1104 deletion completed in 6.244769245s
STEP: Destroying namespace "nsdeletetest-7544" for this suite.
Jul  3 22:51:05.046: INFO: Namespace nsdeletetest-7544 was already deleted
STEP: Destroying namespace "nsdeletetest-9849" for this suite.
Jul  3 22:51:11.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:51:11.222: INFO: namespace nsdeletetest-9849 deletion completed in 6.176445501s

• [SLOW TEST:38.960 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:51:11.224: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-0daa8a1e-9de5-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:51:11.403: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c" in namespace "projected-1604" to be "success or failure"
Jul  3 22:51:11.410: INFO: Pod "pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.389091ms
Jul  3 22:51:13.416: INFO: Pod "pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013819441s
Jul  3 22:51:15.424: INFO: Pod "pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021624186s
STEP: Saw pod success
Jul  3 22:51:15.424: INFO: Pod "pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:51:15.429: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:51:15.463: INFO: Waiting for pod pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:51:15.468: INFO: Pod pod-projected-secrets-0dab9700-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:51:15.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1604" for this suite.
Jul  3 22:51:21.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:51:21.664: INFO: namespace projected-1604 deletion completed in 6.19004008s

• [SLOW TEST:10.440 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:51:21.664: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  3 22:51:21.896: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:21.896: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:21.897: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:21.900: INFO: Number of nodes with available pods: 0
Jul  3 22:51:21.900: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:51:22.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:22.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:22.907: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:22.912: INFO: Number of nodes with available pods: 0
Jul  3 22:51:22.912: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:51:23.908: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:23.909: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:23.909: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:23.913: INFO: Number of nodes with available pods: 2
Jul  3 22:51:23.913: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 22:51:24.909: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.909: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.909: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.915: INFO: Number of nodes with available pods: 4
Jul  3 22:51:24.915: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul  3 22:51:24.955: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.955: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.955: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:24.962: INFO: Number of nodes with available pods: 3
Jul  3 22:51:24.962: INFO: Node jrpk8s114fixed-k8s-node-nf-2 is running more than one daemon pod
Jul  3 22:51:25.970: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:25.970: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:25.970: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:25.975: INFO: Number of nodes with available pods: 3
Jul  3 22:51:25.975: INFO: Node jrpk8s114fixed-k8s-node-nf-2 is running more than one daemon pod
Jul  3 22:51:26.971: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:26.972: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:26.972: INFO: DaemonSet pods can't tolerate node jrpk8s114fixed-k8s-master-ne-nf-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  3 22:51:26.977: INFO: Number of nodes with available pods: 4
Jul  3 22:51:26.977: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7622, will wait for the garbage collector to delete the pods
Jul  3 22:51:27.054: INFO: Deleting DaemonSet.extensions daemon-set took: 12.167204ms
Jul  3 22:51:27.355: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.43797ms
Jul  3 22:51:38.062: INFO: Number of nodes with available pods: 0
Jul  3 22:51:38.062: INFO: Number of running nodes: 0, number of available pods: 0
Jul  3 22:51:38.067: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7622/daemonsets","resourceVersion":"24951"},"items":null}

Jul  3 22:51:38.072: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7622/pods","resourceVersion":"24951"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:51:38.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7622" for this suite.
Jul  3 22:51:44.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:51:44.296: INFO: namespace daemonsets-7622 deletion completed in 6.185831235s

• [SLOW TEST:22.632 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:51:44.296: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:51:48.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4060" for this suite.
Jul  3 22:51:54.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:51:54.694: INFO: namespace kubelet-test-4060 deletion completed in 6.192718299s

• [SLOW TEST:10.398 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:51:54.695: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul  3 22:51:55.145: INFO: Pod name wrapped-volume-race-27bbfea1-9de5-11e9-b0a2-a612d8f3003c: Found 0 pods out of 5
Jul  3 22:52:00.156: INFO: Pod name wrapped-volume-race-27bbfea1-9de5-11e9-b0a2-a612d8f3003c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-27bbfea1-9de5-11e9-b0a2-a612d8f3003c in namespace emptydir-wrapper-1977, will wait for the garbage collector to delete the pods
Jul  3 22:52:10.273: INFO: Deleting ReplicationController wrapped-volume-race-27bbfea1-9de5-11e9-b0a2-a612d8f3003c took: 17.37002ms
Jul  3 22:52:10.573: INFO: Terminating ReplicationController wrapped-volume-race-27bbfea1-9de5-11e9-b0a2-a612d8f3003c pods took: 300.265242ms
STEP: Creating RC which spawns configmap-volume pods
Jul  3 22:52:48.602: INFO: Pod name wrapped-volume-race-47982499-9de5-11e9-b0a2-a612d8f3003c: Found 0 pods out of 5
Jul  3 22:52:53.613: INFO: Pod name wrapped-volume-race-47982499-9de5-11e9-b0a2-a612d8f3003c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-47982499-9de5-11e9-b0a2-a612d8f3003c in namespace emptydir-wrapper-1977, will wait for the garbage collector to delete the pods
Jul  3 22:53:03.726: INFO: Deleting ReplicationController wrapped-volume-race-47982499-9de5-11e9-b0a2-a612d8f3003c took: 13.928672ms
Jul  3 22:53:04.027: INFO: Terminating ReplicationController wrapped-volume-race-47982499-9de5-11e9-b0a2-a612d8f3003c pods took: 300.299298ms
STEP: Creating RC which spawns configmap-volume pods
Jul  3 22:53:47.657: INFO: Pod name wrapped-volume-race-6acb170e-9de5-11e9-b0a2-a612d8f3003c: Found 0 pods out of 5
Jul  3 22:53:52.669: INFO: Pod name wrapped-volume-race-6acb170e-9de5-11e9-b0a2-a612d8f3003c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6acb170e-9de5-11e9-b0a2-a612d8f3003c in namespace emptydir-wrapper-1977, will wait for the garbage collector to delete the pods
Jul  3 22:54:02.785: INFO: Deleting ReplicationController wrapped-volume-race-6acb170e-9de5-11e9-b0a2-a612d8f3003c took: 16.565513ms
Jul  3 22:54:03.085: INFO: Terminating ReplicationController wrapped-volume-race-6acb170e-9de5-11e9-b0a2-a612d8f3003c pods took: 300.33533ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:54:48.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1977" for this suite.
Jul  3 22:54:56.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:54:56.646: INFO: namespace emptydir-wrapper-1977 deletion completed in 8.191823134s

• [SLOW TEST:181.951 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:54:56.646: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul  3 22:54:56.815: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  3 22:54:56.830: INFO: Waiting for terminating namespaces to be deleted...
Jul  3 22:54:56.835: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-1 before test
Jul  3 22:54:56.848: INFO: calico-node-nrmmw from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:54:56.848: INFO: calico-kube-controllers-75c555d7c-t9r98 from kube-system started at 2019-07-03 21:28:26 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  3 22:54:56.848: INFO: nodelocaldns-vxmbw from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:54:56.848: INFO: kube-proxy-v859f from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:54:56.848: INFO: busybox from default started at 2019-07-03 21:33:54 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container busybox ready: true, restart count 1
Jul  3 22:54:56.848: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-ffrws from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:54:56.848: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:54:56.848: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:54:56.848: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-2 before test
Jul  3 22:54:56.862: INFO: nodelocaldns-s4f5b from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.862: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:54:56.862: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-h77pm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:54:56.862: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:54:56.862: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:54:56.862: INFO: kube-proxy-9w5nv from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.862: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:54:56.862: INFO: calico-node-cbplv from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.862: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:54:56.862: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-3 before test
Jul  3 22:54:56.877: INFO: nodelocaldns-qn4sv from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:54:56.877: INFO: sonobuoy-e2e-job-eb3c12b284664f3e from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container e2e ready: true, restart count 0
Jul  3 22:54:56.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:54:56.877: INFO: calico-node-tzhzr from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:54:56.877: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-03 22:05:29 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  3 22:54:56.877: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-stktm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:54:56.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:54:56.877: INFO: kube-proxy-wsfnv from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.877: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:54:56.877: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-4 before test
Jul  3 22:54:56.891: INFO: calico-node-g5xlp from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.891: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:54:56.891: INFO: nodelocaldns-jn5p5 from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.891: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:54:56.891: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-pgpmv from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:54:56.891: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:54:56.891: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:54:56.891: INFO: kube-proxy-qqrrz from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:54:56.891: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ae079e3ba648ec], Reason = [FailedScheduling], Message = [0/7 nodes are available: 7 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:54:57.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7882" for this suite.
Jul  3 22:55:03.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:55:04.124: INFO: namespace sched-pred-7882 deletion completed in 6.183650723s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.478 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:55:04.124: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:55:04.300: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul  3 22:55:09.306: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  3 22:55:09.306: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul  3 22:55:09.336: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9083,SelfLink:/apis/apps/v1/namespaces/deployment-9083/deployments/test-cleanup-deployment,UID:9b7bb20c-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:26628,Generation:1,CreationTimestamp:2019-07-03 22:55:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jul  3 22:55:09.341: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-9083,SelfLink:/apis/apps/v1/namespaces/deployment-9083/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:9b7ed8af-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:26630,Generation:1,CreationTimestamp:2019-07-03 22:55:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9b7bb20c-9de5-11e9-a55c-fa163e25a4f0 0xc00265d587 0xc00265d588}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:55:09.341: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jul  3 22:55:09.342: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-9083,SelfLink:/apis/apps/v1/namespaces/deployment-9083/replicasets/test-cleanup-controller,UID:987cdd01-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:26629,Generation:1,CreationTimestamp:2019-07-03 22:55:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9b7bb20c-9de5-11e9-a55c-fa163e25a4f0 0xc00265d4b7 0xc00265d4b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul  3 22:55:09.349: INFO: Pod "test-cleanup-controller-865sc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-865sc,GenerateName:test-cleanup-controller-,Namespace:deployment-9083,SelfLink:/api/v1/namespaces/deployment-9083/pods/test-cleanup-controller-865sc,UID:987f2855-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:26616,Generation:0,CreationTimestamp:2019-07-03 22:55:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 987cdd01-9de5-11e9-a55c-fa163e25a4f0 0xc00265dde7 0xc00265dde8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8plrc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8plrc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8plrc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00265de50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00265de70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:55:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:55:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:55:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:55:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:10.2.248.74,StartTime:2019-07-03 22:55:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-03 22:55:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6b607693be69164ea469dd8a7798c255d80629c296faa1fb04d28d09913c69c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul  3 22:55:09.349: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-h4bxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-h4bxn,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-9083,SelfLink:/api/v1/namespaces/deployment-9083/pods/test-cleanup-deployment-55cbfbc8f5-h4bxn,UID:9b801e9e-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:26631,Generation:0,CreationTimestamp:2019-07-03 22:55:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 9b7ed8af-9de5-11e9-a55c-fa163e25a4f0 0xc00265df57 0xc00265df58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8plrc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8plrc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8plrc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00265dfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00265dfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:55:09.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9083" for this suite.
Jul  3 22:55:15.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:55:15.573: INFO: namespace deployment-9083 deletion completed in 6.213760821s

• [SLOW TEST:11.449 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:55:15.574: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-mlrb
STEP: Creating a pod to test atomic-volume-subpath
Jul  3 22:55:15.773: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mlrb" in namespace "subpath-399" to be "success or failure"
Jul  3 22:55:15.780: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.539043ms
Jul  3 22:55:17.787: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013399505s
Jul  3 22:55:19.794: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 4.020902942s
Jul  3 22:55:21.802: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 6.02803564s
Jul  3 22:55:23.809: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 8.035625522s
Jul  3 22:55:25.816: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 10.041963197s
Jul  3 22:55:27.824: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 12.050208215s
Jul  3 22:55:29.830: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 14.056870953s
Jul  3 22:55:31.838: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 16.064460291s
Jul  3 22:55:33.844: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 18.069946426s
Jul  3 22:55:35.851: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Running", Reason="", readiness=true. Elapsed: 20.07693529s
Jul  3 22:55:37.857: INFO: Pod "pod-subpath-test-downwardapi-mlrb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.083527063s
STEP: Saw pod success
Jul  3 22:55:37.857: INFO: Pod "pod-subpath-test-downwardapi-mlrb" satisfied condition "success or failure"
Jul  3 22:55:37.863: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-subpath-test-downwardapi-mlrb container test-container-subpath-downwardapi-mlrb: <nil>
STEP: delete the pod
Jul  3 22:55:37.892: INFO: Waiting for pod pod-subpath-test-downwardapi-mlrb to disappear
Jul  3 22:55:37.897: INFO: Pod pod-subpath-test-downwardapi-mlrb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mlrb
Jul  3 22:55:37.897: INFO: Deleting pod "pod-subpath-test-downwardapi-mlrb" in namespace "subpath-399"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:55:37.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-399" for this suite.
Jul  3 22:55:43.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:55:44.120: INFO: namespace subpath-399 deletion completed in 6.204392673s

• [SLOW TEST:28.547 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:55:44.121: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1413
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0703 22:55:50.340986      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 22:55:50.341: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:55:50.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1413" for this suite.
Jul  3 22:55:56.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:55:56.513: INFO: namespace gc-1413 deletion completed in 6.165083043s

• [SLOW TEST:12.392 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:55:56.513: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-b7b6dcba-9de5-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 22:55:56.699: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c" in namespace "projected-3424" to be "success or failure"
Jul  3 22:55:56.703: INFO: Pod "pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263714ms
Jul  3 22:55:58.709: INFO: Pod "pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010648559s
STEP: Saw pod success
Jul  3 22:55:58.710: INFO: Pod "pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:55:58.714: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 22:55:58.741: INFO: Waiting for pod pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:55:58.746: INFO: Pod pod-projected-configmaps-b7b7dd25-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:55:58.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3424" for this suite.
Jul  3 22:56:04.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:56:04.930: INFO: namespace projected-3424 deletion completed in 6.177470859s

• [SLOW TEST:8.417 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:56:04.937: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4191
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Jul  3 22:56:05.140: INFO: Waiting up to 5m0s for pod "client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c" in namespace "containers-4191" to be "success or failure"
Jul  3 22:56:05.145: INFO: Pod "client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.012727ms
Jul  3 22:56:07.151: INFO: Pod "client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011320541s
Jul  3 22:56:09.158: INFO: Pod "client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018301399s
STEP: Saw pod success
Jul  3 22:56:09.158: INFO: Pod "client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:56:09.163: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 22:56:09.192: INFO: Waiting for pod client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:56:09.203: INFO: Pod client-containers-bcbdda36-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:56:09.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4191" for this suite.
Jul  3 22:56:15.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:56:15.415: INFO: namespace containers-4191 deletion completed in 6.20419069s

• [SLOW TEST:10.478 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:56:15.416: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1144
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:56:15.605: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c" in namespace "downward-api-1144" to be "success or failure"
Jul  3 22:56:15.610: INFO: Pod "downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.885101ms
Jul  3 22:56:17.617: INFO: Pod "downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012096122s
STEP: Saw pod success
Jul  3 22:56:17.617: INFO: Pod "downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:56:17.623: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:56:17.664: INFO: Waiting for pod downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:56:17.668: INFO: Pod downwardapi-volume-c2fcb777-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:56:17.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1144" for this suite.
Jul  3 22:56:23.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:56:23.860: INFO: namespace downward-api-1144 deletion completed in 6.183566488s

• [SLOW TEST:8.444 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:56:23.860: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul  3 22:56:24.048: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27328,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul  3 22:56:24.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27329,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul  3 22:56:24.048: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27330,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul  3 22:56:34.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27359,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul  3 22:56:34.095: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27360,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul  3 22:56:34.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9950,SelfLink:/api/v1/namespaces/watch-9950/configmaps/e2e-watch-test-label-changed,UID:c803eb37-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27361,Generation:0,CreationTimestamp:2019-07-03 22:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:56:34.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9950" for this suite.
Jul  3 22:56:40.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:56:40.300: INFO: namespace watch-9950 deletion completed in 6.198498149s

• [SLOW TEST:16.440 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:56:40.302: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:56:40.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c" in namespace "projected-8703" to be "success or failure"
Jul  3 22:56:40.488: INFO: Pod "downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.121921ms
Jul  3 22:56:42.494: INFO: Pod "downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012042145s
STEP: Saw pod success
Jul  3 22:56:42.494: INFO: Pod "downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:56:42.498: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:56:42.527: INFO: Waiting for pod downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:56:42.530: INFO: Pod downwardapi-volume-d1d0afbe-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:56:42.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8703" for this suite.
Jul  3 22:56:48.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:56:48.706: INFO: namespace projected-8703 deletion completed in 6.170224212s

• [SLOW TEST:8.404 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:56:48.709: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9500
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul  3 22:56:48.878: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  3 22:56:48.891: INFO: Waiting for terminating namespaces to be deleted...
Jul  3 22:56:48.900: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-1 before test
Jul  3 22:56:48.912: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-ffrws from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:56:48.912: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:56:48.912: INFO: kube-proxy-v859f from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:56:48.912: INFO: busybox from default started at 2019-07-03 21:33:54 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container busybox ready: true, restart count 1
Jul  3 22:56:48.912: INFO: nodelocaldns-vxmbw from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:56:48.912: INFO: calico-node-nrmmw from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:56:48.912: INFO: calico-kube-controllers-75c555d7c-t9r98 from kube-system started at 2019-07-03 21:28:26 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.912: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  3 22:56:48.912: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-2 before test
Jul  3 22:56:48.920: INFO: nodelocaldns-s4f5b from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.920: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:56:48.920: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-h77pm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:56:48.920: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:56:48.920: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:56:48.921: INFO: kube-proxy-9w5nv from kube-system started at 2019-07-03 21:25:30 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.921: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:56:48.921: INFO: calico-node-cbplv from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.921: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:56:48.921: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-3 before test
Jul  3 22:56:48.929: INFO: calico-node-tzhzr from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:56:48.929: INFO: nodelocaldns-qn4sv from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container node-cache ready: true, restart count 0
Jul  3 22:56:48.929: INFO: sonobuoy-e2e-job-eb3c12b284664f3e from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container e2e ready: true, restart count 0
Jul  3 22:56:48.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:56:48.929: INFO: kube-proxy-wsfnv from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:56:48.929: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-03 22:05:29 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  3 22:56:48.929: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-stktm from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:56:48.929: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:56:48.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:56:48.929: INFO: 
Logging pods the kubelet thinks is on node jrpk8s114fixed-k8s-node-nf-4 before test
Jul  3 22:56:48.937: INFO: kube-proxy-qqrrz from kube-system started at 2019-07-03 21:25:31 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.938: INFO: 	Container kube-proxy ready: true, restart count 0
Jul  3 22:56:48.938: INFO: sonobuoy-systemd-logs-daemon-set-71b5c2b5af6344c5-pgpmv from heptio-sonobuoy started at 2019-07-03 22:05:36 +0000 UTC (2 container statuses recorded)
Jul  3 22:56:48.938: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul  3 22:56:48.938: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  3 22:56:48.938: INFO: calico-node-g5xlp from kube-system started at 2019-07-03 21:27:53 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.938: INFO: 	Container calico-node ready: true, restart count 0
Jul  3 22:56:48.938: INFO: nodelocaldns-jn5p5 from kube-system started at 2019-07-03 21:30:25 +0000 UTC (1 container statuses recorded)
Jul  3 22:56:48.938: INFO: 	Container node-cache ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d8142579-9de5-11e9-b0a2-a612d8f3003c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-d8142579-9de5-11e9-b0a2-a612d8f3003c off the node jrpk8s114fixed-k8s-node-nf-4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d8142579-9de5-11e9-b0a2-a612d8f3003c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:56:53.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9500" for this suite.
Jul  3 22:57:03.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:57:03.227: INFO: namespace sched-pred-9500 deletion completed in 10.182648401s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.518 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:57:03.229: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 22:57:03.412: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c" in namespace "downward-api-4069" to be "success or failure"
Jul  3 22:57:03.417: INFO: Pod "downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.297124ms
Jul  3 22:57:05.425: INFO: Pod "downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01264809s
Jul  3 22:57:07.431: INFO: Pod "downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018894446s
STEP: Saw pod success
Jul  3 22:57:07.431: INFO: Pod "downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:57:07.435: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 22:57:07.485: INFO: Waiting for pod downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:57:07.490: INFO: Pod downwardapi-volume-df7b48cb-9de5-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:57:07.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4069" for this suite.
Jul  3 22:57:13.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:57:13.692: INFO: namespace downward-api-4069 deletion completed in 6.190263158s

• [SLOW TEST:10.463 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:57:13.693: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8313
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-e5b8eb2e-9de5-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:57:17.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8313" for this suite.
Jul  3 22:57:39.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:57:40.121: INFO: namespace configmap-8313 deletion completed in 22.175841866s

• [SLOW TEST:26.429 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:57:40.123: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2916
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 22:57:40.285: INFO: Creating deployment "test-recreate-deployment"
Jul  3 22:57:40.294: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul  3 22:57:40.309: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul  3 22:57:42.321: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul  3 22:57:42.326: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697791460, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697791460, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697791460, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697791460, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 22:57:44.333: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul  3 22:57:44.346: INFO: Updating deployment test-recreate-deployment
Jul  3 22:57:44.346: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul  3 22:57:44.452: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2916,SelfLink:/apis/apps/v1/namespaces/deployment-2916/deployments/test-recreate-deployment,UID:f5786633-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27790,Generation:2,CreationTimestamp:2019-07-03 22:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-03 22:57:44 +0000 UTC 2019-07-03 22:57:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-03 22:57:44 +0000 UTC 2019-07-03 22:57:40 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul  3 22:57:44.459: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-2916,SelfLink:/apis/apps/v1/namespaces/deployment-2916/replicasets/test-recreate-deployment-c9cbd8684,UID:f7eb1fdf-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27786,Generation:1,CreationTimestamp:2019-07-03 22:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f5786633-9de5-11e9-a55c-fa163e25a4f0 0xc0025cd3c0 0xc0025cd3c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:57:44.459: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul  3 22:57:44.459: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-2916,SelfLink:/apis/apps/v1/namespaces/deployment-2916/replicasets/test-recreate-deployment-7d57d5ff7c,UID:f579b2f1-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27778,Generation:2,CreationTimestamp:2019-07-03 22:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f5786633-9de5-11e9-a55c-fa163e25a4f0 0xc0025cd2f7 0xc0025cd2f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 22:57:44.466: INFO: Pod "test-recreate-deployment-c9cbd8684-jcb9b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-jcb9b,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-2916,SelfLink:/api/v1/namespaces/deployment-2916/pods/test-recreate-deployment-c9cbd8684-jcb9b,UID:f7ec5e6f-9de5-11e9-a55c-fa163e25a4f0,ResourceVersion:27789,Generation:0,CreationTimestamp:2019-07-03 22:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 f7eb1fdf-9de5-11e9-a55c-fa163e25a4f0 0xc0023ca580 0xc0023ca581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8lr2f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8lr2f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8lr2f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023ca5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023ca600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 22:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:,StartTime:2019-07-03 22:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:57:44.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2916" for this suite.
Jul  3 22:57:50.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:57:50.658: INFO: namespace deployment-2916 deletion completed in 6.184549681s

• [SLOW TEST:10.535 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:57:50.658: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3542
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3542
STEP: Creating statefulset with conflicting port in namespace statefulset-3542
STEP: Waiting until pod test-pod will start running in namespace statefulset-3542
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3542
Jul  3 22:57:54.929: INFO: Observed stateful pod in namespace: statefulset-3542, name: ss-0, uid: fdf68d7a-9de5-11e9-a55c-fa163e25a4f0, status phase: Pending. Waiting for statefulset controller to delete.
Jul  3 22:57:55.116: INFO: Observed stateful pod in namespace: statefulset-3542, name: ss-0, uid: fdf68d7a-9de5-11e9-a55c-fa163e25a4f0, status phase: Failed. Waiting for statefulset controller to delete.
Jul  3 22:57:55.124: INFO: Observed stateful pod in namespace: statefulset-3542, name: ss-0, uid: fdf68d7a-9de5-11e9-a55c-fa163e25a4f0, status phase: Failed. Waiting for statefulset controller to delete.
Jul  3 22:57:55.128: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3542
STEP: Removing pod with conflicting port in namespace statefulset-3542
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3542 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul  3 22:57:59.161: INFO: Deleting all statefulset in ns statefulset-3542
Jul  3 22:57:59.165: INFO: Scaling statefulset ss to 0
Jul  3 22:58:09.189: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:58:09.195: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:58:09.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3542" for this suite.
Jul  3 22:58:15.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:58:15.441: INFO: namespace statefulset-3542 deletion completed in 6.208655939s

• [SLOW TEST:24.783 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:58:15.445: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3733
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3733
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3733
Jul  3 22:58:15.634: INFO: Found 0 stateful pods, waiting for 1
Jul  3 22:58:25.642: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul  3 22:58:25.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:58:25.933: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:58:25.933: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:58:25.933: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 22:58:25.939: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  3 22:58:35.949: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 22:58:35.949: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:58:35.975: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999367s
Jul  3 22:58:36.982: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993376388s
Jul  3 22:58:37.988: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.986131599s
Jul  3 22:58:38.995: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979746072s
Jul  3 22:58:40.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.973443534s
Jul  3 22:58:41.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.967177378s
Jul  3 22:58:42.013: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.96134377s
Jul  3 22:58:43.021: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.954886903s
Jul  3 22:58:44.029: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.946990331s
Jul  3 22:58:45.037: INFO: Verifying statefulset ss doesn't scale past 1 for another 939.272009ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3733
Jul  3 22:58:46.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:58:46.286: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:58:46.286: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:58:46.286: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:58:46.293: INFO: Found 1 stateful pods, waiting for 3
Jul  3 22:58:56.302: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:58:56.302: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 22:58:56.302: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul  3 22:58:56.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:58:56.575: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:58:56.575: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:58:56.575: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 22:58:56.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:58:56.836: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:58:56.836: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:58:56.836: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 22:58:56.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 22:58:57.087: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 22:58:57.087: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 22:58:57.087: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 22:58:57.087: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:58:57.093: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul  3 22:59:07.105: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 22:59:07.105: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 22:59:07.105: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 22:59:07.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999566s
Jul  3 22:59:08.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991509596s
Jul  3 22:59:09.146: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984069547s
Jul  3 22:59:10.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97657051s
Jul  3 22:59:11.158: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.970801762s
Jul  3 22:59:12.166: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964503179s
Jul  3 22:59:13.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956684547s
Jul  3 22:59:14.181: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949698523s
Jul  3 22:59:15.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941149415s
Jul  3 22:59:16.197: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.028982ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3733
Jul  3 22:59:17.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:59:17.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:59:17.476: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:59:17.476: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:59:17.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:59:17.719: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:59:17.719: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:59:17.719: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:59:17.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-3733 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 22:59:17.955: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 22:59:17.955: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 22:59:17.955: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 22:59:17.955: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul  3 22:59:47.983: INFO: Deleting all statefulset in ns statefulset-3733
Jul  3 22:59:47.988: INFO: Scaling statefulset ss to 0
Jul  3 22:59:48.008: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 22:59:48.014: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:59:48.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3733" for this suite.
Jul  3 22:59:54.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 22:59:54.251: INFO: namespace statefulset-3733 deletion completed in 6.204075066s

• [SLOW TEST:98.806 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 22:59:54.259: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-456bdd5f-9de6-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 22:59:54.444: INFO: Waiting up to 5m0s for pod "pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c" in namespace "secrets-6259" to be "success or failure"
Jul  3 22:59:54.449: INFO: Pod "pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393489ms
Jul  3 22:59:56.454: INFO: Pod "pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010013662s
STEP: Saw pod success
Jul  3 22:59:56.454: INFO: Pod "pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 22:59:56.459: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 22:59:56.488: INFO: Waiting for pod pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c to disappear
Jul  3 22:59:56.491: INFO: Pod pod-secrets-456d12cb-9de6-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 22:59:56.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6259" for this suite.
Jul  3 23:00:02.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:00:02.695: INFO: namespace secrets-6259 deletion completed in 6.196168104s

• [SLOW TEST:8.437 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:00:02.697: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-4a744dae-9de6-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 23:00:02.888: INFO: Waiting up to 5m0s for pod "pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c" in namespace "secrets-2215" to be "success or failure"
Jul  3 23:00:02.893: INFO: Pod "pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.417446ms
Jul  3 23:00:04.901: INFO: Pod "pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012863865s
Jul  3 23:00:06.907: INFO: Pod "pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019156266s
STEP: Saw pod success
Jul  3 23:00:06.907: INFO: Pod "pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:00:06.912: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 23:00:06.944: INFO: Waiting for pod pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:00:06.948: INFO: Pod pod-secrets-4a7555ce-9de6-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:00:06.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2215" for this suite.
Jul  3 23:00:12.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:00:13.137: INFO: namespace secrets-2215 deletion completed in 6.181146356s

• [SLOW TEST:10.441 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:00:13.138: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:01:13.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4337" for this suite.
Jul  3 23:01:35.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:01:35.517: INFO: namespace container-probe-4337 deletion completed in 22.18777681s

• [SLOW TEST:82.379 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:01:35.517: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul  3 23:01:39.720: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-81c6c4b0-9de6-11e9-b0a2-a612d8f3003c,GenerateName:,Namespace:events-6009,SelfLink:/api/v1/namespaces/events-6009/pods/send-events-81c6c4b0-9de6-11e9-b0a2-a612d8f3003c,UID:81c7feff-9de6-11e9-a55c-fa163e25a4f0,ResourceVersion:29025,Generation:0,CreationTimestamp:2019-07-03 23:01:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 683709224,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fqtxc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fqtxc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-fqtxc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ef9ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ef9f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:01:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:01:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:01:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:01:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:10.2.17.72,StartTime:2019-07-03 23:01:35 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-03 23:01:38 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ed7003ef055bc71bcd0df4b5fc39f1dccf284f70f13f67475024a410063eeefa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul  3 23:01:41.728: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul  3 23:01:43.736: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:01:43.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6009" for this suite.
Jul  3 23:02:23.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:02:23.951: INFO: namespace events-6009 deletion completed in 40.194129147s

• [SLOW TEST:48.434 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:02:23.953: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0703 23:02:24.719824      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul  3 23:02:24.720: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:02:24.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7710" for this suite.
Jul  3 23:02:30.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:02:30.904: INFO: namespace gc-7710 deletion completed in 6.177174676s

• [SLOW TEST:6.952 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:02:30.905: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5299/secret-test-a2caa86c-9de6-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 23:02:31.098: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c" in namespace "secrets-5299" to be "success or failure"
Jul  3 23:02:31.105: INFO: Pod "pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.052378ms
Jul  3 23:02:33.112: INFO: Pod "pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014403118s
Jul  3 23:02:35.119: INFO: Pod "pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021376309s
STEP: Saw pod success
Jul  3 23:02:35.119: INFO: Pod "pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:02:35.125: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c container env-test: <nil>
STEP: delete the pod
Jul  3 23:02:35.157: INFO: Waiting for pod pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:02:35.160: INFO: Pod pod-configmaps-a2cc4fd5-9de6-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:02:35.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5299" for this suite.
Jul  3 23:02:41.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:02:41.376: INFO: namespace secrets-5299 deletion completed in 6.208397296s

• [SLOW TEST:10.471 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:02:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7730
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  3 23:02:41.559: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul  3 23:03:03.723: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.83:8080/dial?request=hostName&protocol=http&host=10.2.97.82&port=8080&tries=1'] Namespace:pod-network-test-7730 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:03:03.723: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:03:03.893: INFO: Waiting for endpoints: map[]
Jul  3 23:03:03.898: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.83:8080/dial?request=hostName&protocol=http&host=10.2.5.29&port=8080&tries=1'] Namespace:pod-network-test-7730 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:03:03.898: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:03:04.039: INFO: Waiting for endpoints: map[]
Jul  3 23:03:04.045: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.83:8080/dial?request=hostName&protocol=http&host=10.2.17.74&port=8080&tries=1'] Namespace:pod-network-test-7730 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:03:04.045: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:03:04.195: INFO: Waiting for endpoints: map[]
Jul  3 23:03:04.202: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.83:8080/dial?request=hostName&protocol=http&host=10.2.248.85&port=8080&tries=1'] Namespace:pod-network-test-7730 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:03:04.202: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:03:04.340: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:03:04.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7730" for this suite.
Jul  3 23:03:28.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:03:28.553: INFO: namespace pod-network-test-7730 deletion completed in 24.203591428s

• [SLOW TEST:47.176 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:03:28.554: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  3 23:03:28.732: INFO: Waiting up to 5m0s for pod "pod-c5270407-9de6-11e9-b0a2-a612d8f3003c" in namespace "emptydir-380" to be "success or failure"
Jul  3 23:03:28.736: INFO: Pod "pod-c5270407-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.689414ms
Jul  3 23:03:30.743: INFO: Pod "pod-c5270407-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010459137s
Jul  3 23:03:32.750: INFO: Pod "pod-c5270407-9de6-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017965878s
STEP: Saw pod success
Jul  3 23:03:32.750: INFO: Pod "pod-c5270407-9de6-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:03:32.755: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-c5270407-9de6-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 23:03:32.781: INFO: Waiting for pod pod-c5270407-9de6-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:03:32.785: INFO: Pod pod-c5270407-9de6-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:03:32.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-380" for this suite.
Jul  3 23:03:38.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:03:38.966: INFO: namespace emptydir-380 deletion completed in 6.174404811s

• [SLOW TEST:10.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:03:38.966: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8748
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1507
STEP: Creating secret with name secret-test-cb5bb0e0-9de6-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume secrets
Jul  3 23:03:39.315: INFO: Waiting up to 5m0s for pod "pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c" in namespace "secrets-8748" to be "success or failure"
Jul  3 23:03:39.324: INFO: Pod "pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.44659ms
Jul  3 23:03:41.330: INFO: Pod "pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015077693s
STEP: Saw pod success
Jul  3 23:03:41.331: INFO: Pod "pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:03:41.337: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c container secret-volume-test: <nil>
STEP: delete the pod
Jul  3 23:03:41.364: INFO: Waiting for pod pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:03:41.368: INFO: Pod pod-secrets-cb75cbc1-9de6-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:03:41.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8748" for this suite.
Jul  3 23:03:47.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:03:47.559: INFO: namespace secrets-8748 deletion completed in 6.184395768s
STEP: Destroying namespace "secret-namespace-1507" for this suite.
Jul  3 23:03:53.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:03:53.740: INFO: namespace secret-namespace-1507 deletion completed in 6.18064316s

• [SLOW TEST:14.774 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:03:53.740: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9965
Jul  3 23:03:55.957: INFO: Started pod liveness-http in namespace container-probe-9965
STEP: checking the pod's current state and verifying that restartCount is present
Jul  3 23:03:55.962: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:07:56.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9965" for this suite.
Jul  3 23:08:02.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:08:03.042: INFO: namespace container-probe-9965 deletion completed in 6.181733981s

• [SLOW TEST:249.302 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:08:03.043: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  3 23:08:11.296: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  3 23:08:11.301: INFO: Pod pod-with-poststart-http-hook still exists
Jul  3 23:08:13.302: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  3 23:08:13.309: INFO: Pod pod-with-poststart-http-hook still exists
Jul  3 23:08:15.301: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  3 23:08:15.309: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:08:15.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5699" for this suite.
Jul  3 23:08:37.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:08:37.513: INFO: namespace container-lifecycle-hook-5699 deletion completed in 22.197539524s

• [SLOW TEST:34.470 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:08:37.516: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3675
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 23:08:37.699: INFO: (0) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.535043ms)
Jul  3 23:08:37.704: INFO: (1) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.256018ms)
Jul  3 23:08:37.709: INFO: (2) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.220969ms)
Jul  3 23:08:37.715: INFO: (3) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.206745ms)
Jul  3 23:08:37.721: INFO: (4) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.140299ms)
Jul  3 23:08:37.728: INFO: (5) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.051692ms)
Jul  3 23:08:37.733: INFO: (6) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.731398ms)
Jul  3 23:08:37.739: INFO: (7) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.870617ms)
Jul  3 23:08:37.744: INFO: (8) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.484053ms)
Jul  3 23:08:37.750: INFO: (9) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.906163ms)
Jul  3 23:08:37.756: INFO: (10) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.760284ms)
Jul  3 23:08:37.761: INFO: (11) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.87968ms)
Jul  3 23:08:37.767: INFO: (12) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.457119ms)
Jul  3 23:08:37.772: INFO: (13) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.027041ms)
Jul  3 23:08:37.781: INFO: (14) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.761502ms)
Jul  3 23:08:37.787: INFO: (15) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.808203ms)
Jul  3 23:08:37.793: INFO: (16) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.789164ms)
Jul  3 23:08:37.799: INFO: (17) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.724558ms)
Jul  3 23:08:37.804: INFO: (18) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.816191ms)
Jul  3 23:08:37.811: INFO: (19) /api/v1/nodes/jrpk8s114fixed-k8s-node-nf-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.39298ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:08:37.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3675" for this suite.
Jul  3 23:08:43.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:08:43.994: INFO: namespace proxy-3675 deletion completed in 6.176793182s

• [SLOW TEST:6.478 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:08:43.996: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 23:08:44.178: INFO: Waiting up to 5m0s for pod "downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c" in namespace "projected-7582" to be "success or failure"
Jul  3 23:08:44.183: INFO: Pod "downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.84596ms
Jul  3 23:08:46.189: INFO: Pod "downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011652904s
STEP: Saw pod success
Jul  3 23:08:46.189: INFO: Pod "downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:08:46.195: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 23:08:46.229: INFO: Waiting for pod downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:08:46.232: INFO: Pod downwardapi-volume-812b7758-9de7-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:08:46.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7582" for this suite.
Jul  3 23:08:52.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:08:52.417: INFO: namespace projected-7582 deletion completed in 6.178244839s

• [SLOW TEST:8.421 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:08:52.419: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2210
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2210.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2210.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  3 23:08:54.665: INFO: DNS probes using dns-2210/dns-test-86309310-9de7-11e9-b0a2-a612d8f3003c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:08:54.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2210" for this suite.
Jul  3 23:09:00.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:09:00.867: INFO: namespace dns-2210 deletion completed in 6.182264333s

• [SLOW TEST:8.448 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:09:00.868: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c
Jul  3 23:09:01.058: INFO: Pod name my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c: Found 0 pods out of 1
Jul  3 23:09:06.065: INFO: Pod name my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c: Found 1 pods out of 1
Jul  3 23:09:06.065: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c" are running
Jul  3 23:09:06.071: INFO: Pod "my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c-hmp2z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 23:09:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 23:09:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 23:09:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-03 23:09:01 +0000 UTC Reason: Message:}])
Jul  3 23:09:06.071: INFO: Trying to dial the pod
Jul  3 23:09:11.091: INFO: Controller my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c: Got expected result from replica 1 [my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c-hmp2z]: "my-hostname-basic-8b3b5136-9de7-11e9-b0a2-a612d8f3003c-hmp2z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:09:11.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5793" for this suite.
Jul  3 23:09:17.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:09:17.291: INFO: namespace replication-controller-5793 deletion completed in 6.190556177s

• [SLOW TEST:16.423 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:09:17.293: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul  3 23:09:20.026: INFO: Successfully updated pod "annotationupdate95043795-9de7-11e9-b0a2-a612d8f3003c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:09:22.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5478" for this suite.
Jul  3 23:09:44.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:09:44.272: INFO: namespace projected-5478 deletion completed in 22.208719157s

• [SLOW TEST:26.979 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:09:44.274: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Jul  3 23:09:46.006: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul  3 23:09:48.141: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 23:09:50.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 23:09:52.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697792186, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  3 23:09:55.495: INFO: Waited 1.335874414s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:09:55.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4739" for this suite.
Jul  3 23:10:02.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:10:02.192: INFO: namespace aggregator-4739 deletion completed in 6.254696979s

• [SLOW TEST:17.918 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:10:02.193: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul  3 23:10:02.381: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8108,SelfLink:/api/v1/namespaces/watch-8108/configmaps/e2e-watch-test-watch-closed,UID:afc8147c-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31260,Generation:0,CreationTimestamp:2019-07-03 23:10:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul  3 23:10:02.381: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8108,SelfLink:/api/v1/namespaces/watch-8108/configmaps/e2e-watch-test-watch-closed,UID:afc8147c-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31261,Generation:0,CreationTimestamp:2019-07-03 23:10:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul  3 23:10:02.409: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8108,SelfLink:/api/v1/namespaces/watch-8108/configmaps/e2e-watch-test-watch-closed,UID:afc8147c-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31263,Generation:0,CreationTimestamp:2019-07-03 23:10:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul  3 23:10:02.409: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8108,SelfLink:/api/v1/namespaces/watch-8108/configmaps/e2e-watch-test-watch-closed,UID:afc8147c-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31265,Generation:0,CreationTimestamp:2019-07-03 23:10:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:10:02.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8108" for this suite.
Jul  3 23:10:08.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:10:08.617: INFO: namespace watch-8108 deletion completed in 6.200436416s

• [SLOW TEST:6.424 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:10:08.617: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  3 23:10:11.355: INFO: Successfully updated pod "pod-update-b39efc23-9de7-11e9-b0a2-a612d8f3003c"
STEP: verifying the updated pod is in kubernetes
Jul  3 23:10:11.364: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:10:11.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3923" for this suite.
Jul  3 23:10:33.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:10:33.568: INFO: namespace pods-3923 deletion completed in 22.194079808s

• [SLOW TEST:24.951 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:10:33.571: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  3 23:10:33.761: INFO: Waiting up to 5m0s for pod "pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c" in namespace "emptydir-7251" to be "success or failure"
Jul  3 23:10:33.765: INFO: Pod "pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.663335ms
Jul  3 23:10:35.774: INFO: Pod "pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013316458s
Jul  3 23:10:37.781: INFO: Pod "pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019789819s
STEP: Saw pod success
Jul  3 23:10:37.781: INFO: Pod "pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:10:37.786: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 23:10:37.816: INFO: Waiting for pod pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:10:37.820: INFO: Pod pod-c27ce4bf-9de7-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:10:37.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7251" for this suite.
Jul  3 23:10:43.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:10:44.006: INFO: namespace emptydir-7251 deletion completed in 6.179693922s

• [SLOW TEST:10.436 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:10:44.007: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:10:48.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8287" for this suite.
Jul  3 23:10:54.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:10:54.451: INFO: namespace emptydir-wrapper-8287 deletion completed in 6.197964679s

• [SLOW TEST:10.445 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:10:54.454: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 23:10:54.618: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul  3 23:10:54.629: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  3 23:10:59.636: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  3 23:10:59.636: INFO: Creating deployment "test-rolling-update-deployment"
Jul  3 23:10:59.645: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul  3 23:10:59.658: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul  3 23:11:01.670: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul  3 23:11:01.679: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul  3 23:11:01.694: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/deployments/test-rolling-update-deployment,UID:d1eb7bdc-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31605,Generation:1,CreationTimestamp:2019-07-03 23:10:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-03 23:10:59 +0000 UTC 2019-07-03 23:10:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-03 23:11:01 +0000 UTC 2019-07-03 23:10:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul  3 23:11:01.701: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/replicasets/test-rolling-update-deployment-67599b4d9,UID:d1ef67fd-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31594,Generation:1,CreationTimestamp:2019-07-03 23:10:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d1eb7bdc-9de7-11e9-a55c-fa163e25a4f0 0xc001ec9ed0 0xc001ec9ed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul  3 23:11:01.701: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul  3 23:11:01.701: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/replicasets/test-rolling-update-controller,UID:ceeda006-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31603,Generation:2,CreationTimestamp:2019-07-03 23:10:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d1eb7bdc-9de7-11e9-a55c-fa163e25a4f0 0xc001ec9e07 0xc001ec9e08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul  3 23:11:01.707: INFO: Pod "test-rolling-update-deployment-67599b4d9-47879" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-47879,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-8918,SelfLink:/api/v1/namespaces/deployment-8918/pods/test-rolling-update-deployment-67599b4d9-47879,UID:d1f08b68-9de7-11e9-a55c-fa163e25a4f0,ResourceVersion:31593,Generation:0,CreationTimestamp:2019-07-03 23:10:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 d1ef67fd-9de7-11e9-a55c-fa163e25a4f0 0xc00216e780 0xc00216e781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vwc84 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vwc84,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vwc84 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jrpk8s114fixed-k8s-node-nf-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00216e7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00216e800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:10:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:10:59 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.15,PodIP:10.2.248.89,StartTime:2019-07-03 23:10:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-03 23:11:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c00c0390cdb151b41ee4c2e6941f8823b2bffef4dc924f2285273433c293190c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:11:01.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8918" for this suite.
Jul  3 23:11:07.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:11:07.922: INFO: namespace deployment-8918 deletion completed in 6.206757503s

• [SLOW TEST:13.468 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:11:07.923: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul  3 23:11:08.090: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:11:12.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4620" for this suite.
Jul  3 23:11:34.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:11:34.902: INFO: namespace init-container-4620 deletion completed in 22.193711007s

• [SLOW TEST:26.979 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:11:34.903: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1786
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-1786
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1786
Jul  3 23:11:35.103: INFO: Found 0 stateful pods, waiting for 1
Jul  3 23:11:45.116: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul  3 23:11:45.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 23:11:45.390: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 23:11:45.390: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 23:11:45.390: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 23:11:45.396: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  3 23:11:55.403: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 23:11:55.403: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 23:11:55.429: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:11:55.430: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:11:55.430: INFO: 
Jul  3 23:11:55.430: INFO: StatefulSet ss has not reached scale 3, at 1
Jul  3 23:11:56.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991993537s
Jul  3 23:11:57.466: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985298334s
Jul  3 23:11:58.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.955817795s
Jul  3 23:11:59.479: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950256416s
Jul  3 23:12:00.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.942738104s
Jul  3 23:12:01.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.93753021s
Jul  3 23:12:02.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929481161s
Jul  3 23:12:03.508: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.920542738s
Jul  3 23:12:04.516: INFO: Verifying statefulset ss doesn't scale past 3 for another 913.472995ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1786
Jul  3 23:12:05.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:05.768: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul  3 23:12:05.768: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 23:12:05.768: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 23:12:05.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:06.029: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  3 23:12:06.029: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 23:12:06.029: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 23:12:06.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:06.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  3 23:12:06.311: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul  3 23:12:06.311: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul  3 23:12:06.318: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 23:12:06.318: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  3 23:12:06.318: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul  3 23:12:06.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 23:12:06.559: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 23:12:06.559: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 23:12:06.559: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 23:12:06.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 23:12:06.806: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 23:12:06.806: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 23:12:06.806: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 23:12:06.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul  3 23:12:07.072: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul  3 23:12:07.072: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul  3 23:12:07.072: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul  3 23:12:07.072: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 23:12:07.080: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jul  3 23:12:17.095: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 23:12:17.095: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 23:12:17.095: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  3 23:12:17.125: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:17.125: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:17.126: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:17.126: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:17.126: INFO: 
Jul  3 23:12:17.126: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:18.134: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:18.135: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:18.135: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:18.135: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:18.135: INFO: 
Jul  3 23:12:18.135: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:19.142: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:19.142: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:19.142: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:19.142: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:19.142: INFO: 
Jul  3 23:12:19.142: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:20.149: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:20.149: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:20.149: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:20.149: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:20.149: INFO: 
Jul  3 23:12:20.149: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:21.157: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:21.157: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:21.157: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:21.157: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:21.157: INFO: 
Jul  3 23:12:21.157: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:22.164: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:22.164: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:22.164: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:22.164: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:22.164: INFO: 
Jul  3 23:12:22.164: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:23.172: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:23.172: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:23.172: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:23.172: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:23.172: INFO: 
Jul  3 23:12:23.172: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:24.180: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:24.180: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:24.180: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:24.180: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:24.180: INFO: 
Jul  3 23:12:24.180: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:25.188: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:25.188: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:25.188: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:25.188: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:25.188: INFO: 
Jul  3 23:12:25.189: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  3 23:12:26.199: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jul  3 23:12:26.199: INFO: ss-0  jrpk8s114fixed-k8s-node-nf-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:35 +0000 UTC  }]
Jul  3 23:12:26.199: INFO: ss-1  jrpk8s114fixed-k8s-node-nf-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:26.199: INFO: ss-2  jrpk8s114fixed-k8s-node-nf-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:12:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-03 23:11:55 +0000 UTC  }]
Jul  3 23:12:26.199: INFO: 
Jul  3 23:12:26.199: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1786
Jul  3 23:12:27.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:27.362: INFO: rc: 1
Jul  3 23:12:27.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc00376e2d0 exit status 1 <nil> <nil> true [0xc001a9d880 0xc001a9d898 0xc001a9d8b0] [0xc001a9d880 0xc001a9d898 0xc001a9d8b0] [0xc001a9d890 0xc001a9d8a8] [0x9bf9f0 0x9bf9f0] 0xc0024f0ae0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jul  3 23:12:37.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:37.456: INFO: rc: 1
Jul  3 23:12:37.456: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14330 exit status 1 <nil> <nil> true [0xc000010448 0xc000010798 0xc0000108c8] [0xc000010448 0xc000010798 0xc0000108c8] [0xc000010740 0xc0000108a8] [0x9bf9f0 0x9bf9f0] 0xc0018a2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:12:47.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:47.569: INFO: rc: 1
Jul  3 23:12:47.569: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002838330 exit status 1 <nil> <nil> true [0xc0004c6230 0xc0004c6398 0xc0004c6608] [0xc0004c6230 0xc0004c6398 0xc0004c6608] [0xc0004c62f8 0xc0004c65a0] [0x9bf9f0 0x9bf9f0] 0xc002325080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:12:57.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:12:57.671: INFO: rc: 1
Jul  3 23:12:57.671: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002838690 exit status 1 <nil> <nil> true [0xc0004c6710 0xc0004c67e0 0xc0004c69d8] [0xc0004c6710 0xc0004c67e0 0xc0004c69d8] [0xc0004c6788 0xc0004c6998] [0x9bf9f0 0x9bf9f0] 0xc002325c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:07.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:07.776: INFO: rc: 1
Jul  3 23:13:07.776: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002838cc0 exit status 1 <nil> <nil> true [0xc0004c6b60 0xc0004c6d60 0xc0004c6e10] [0xc0004c6b60 0xc0004c6d60 0xc0004c6e10] [0xc0004c6bf0 0xc0004c6db0] [0x9bf9f0 0x9bf9f0] 0xc0032f44e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:17.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:17.868: INFO: rc: 1
Jul  3 23:13:17.868: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978330 exit status 1 <nil> <nil> true [0xc000166000 0xc000b9a3c8 0xc000b9aa98] [0xc000166000 0xc000b9a3c8 0xc000b9aa98] [0xc000b9a360 0xc000b9a780] [0x9bf9f0 0x9bf9f0] 0xc0032a65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:27.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:27.978: INFO: rc: 1
Jul  3 23:13:27.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000fda360 exit status 1 <nil> <nil> true [0xc000727798 0xc000727cc0 0xc000adc030] [0xc000727798 0xc000727cc0 0xc000adc030] [0xc000727870 0xc000adc018] [0x9bf9f0 0x9bf9f0] 0xc001844540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:37.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:38.071: INFO: rc: 1
Jul  3 23:13:38.071: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029786c0 exit status 1 <nil> <nil> true [0xc000b9acd8 0xc000b9b388 0xc000b9b530] [0xc000b9acd8 0xc000b9b388 0xc000b9b530] [0xc000b9b0f8 0xc000b9b4d8] [0x9bf9f0 0x9bf9f0] 0xc0032a7440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:48.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:48.173: INFO: rc: 1
Jul  3 23:13:48.173: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978a50 exit status 1 <nil> <nil> true [0xc000b9b620 0xc000b9b7e0 0xc000b9b918] [0xc000b9b620 0xc000b9b7e0 0xc000b9b918] [0xc000b9b6e0 0xc000b9b8e8] [0x9bf9f0 0x9bf9f0] 0xc002201b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:13:58.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:13:58.279: INFO: rc: 1
Jul  3 23:13:58.279: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d148a0 exit status 1 <nil> <nil> true [0xc0000108e0 0xc0000109d8 0xc000010af0] [0xc0000108e0 0xc0000109d8 0xc000010af0] [0xc0000109c0 0xc000010aa8] [0x9bf9f0 0x9bf9f0] 0xc0018a26c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:08.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:08.373: INFO: rc: 1
Jul  3 23:14:08.374: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978db0 exit status 1 <nil> <nil> true [0xc000b9b948 0xc000b9bac8 0xc000b9bb60] [0xc000b9b948 0xc000b9bac8 0xc000b9bb60] [0xc000b9ba30 0xc000b9bb10] [0x9bf9f0 0x9bf9f0] 0xc002354300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:18.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:18.470: INFO: rc: 1
Jul  3 23:14:18.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14c00 exit status 1 <nil> <nil> true [0xc000010b20 0xc000010bd0 0xc000010c00] [0xc000010b20 0xc000010bd0 0xc000010c00] [0xc000010b98 0xc000010bf0] [0x9bf9f0 0x9bf9f0] 0xc0018a2c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:28.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:28.560: INFO: rc: 1
Jul  3 23:14:28.560: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14f60 exit status 1 <nil> <nil> true [0xc000010c28 0xc000010c90 0xc000010d10] [0xc000010c28 0xc000010c90 0xc000010d10] [0xc000010c80 0xc000010d00] [0x9bf9f0 0x9bf9f0] 0xc0018a31a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:38.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:38.650: INFO: rc: 1
Jul  3 23:14:38.650: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14480 exit status 1 <nil> <nil> true [0xc0007277d0 0xc000166000 0xc000010448] [0xc0007277d0 0xc000166000 0xc000010448] [0xc000727cc0 0xc000010080] [0x9bf9f0 0x9bf9f0] 0xc002201da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:48.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:48.742: INFO: rc: 1
Jul  3 23:14:48.742: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14870 exit status 1 <nil> <nil> true [0xc000010520 0xc000010810 0xc0000108e0] [0xc000010520 0xc000010810 0xc0000108e0] [0xc000010798 0xc0000108c8] [0x9bf9f0 0x9bf9f0] 0xc0032a6660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:14:58.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:14:58.834: INFO: rc: 1
Jul  3 23:14:58.834: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002838360 exit status 1 <nil> <nil> true [0xc0004c6230 0xc0004c6398 0xc0004c6608] [0xc0004c6230 0xc0004c6398 0xc0004c6608] [0xc0004c62f8 0xc0004c65a0] [0x9bf9f0 0x9bf9f0] 0xc002325080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:08.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:08.925: INFO: rc: 1
Jul  3 23:15:08.925: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978360 exit status 1 <nil> <nil> true [0xc000b9a360 0xc000b9a780 0xc000b9af68] [0xc000b9a360 0xc000b9a780 0xc000b9af68] [0xc000b9a5a0 0xc000b9acd8] [0x9bf9f0 0x9bf9f0] 0xc0018a2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:18.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:19.020: INFO: rc: 1
Jul  3 23:15:19.020: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d14c90 exit status 1 <nil> <nil> true [0xc000010940 0xc000010a70 0xc000010b20] [0xc000010940 0xc000010a70 0xc000010b20] [0xc0000109d8 0xc000010af0] [0x9bf9f0 0x9bf9f0] 0xc0032a7740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:29.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:29.136: INFO: rc: 1
Jul  3 23:15:29.136: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d15050 exit status 1 <nil> <nil> true [0xc000010b70 0xc000010be0 0xc000010c28] [0xc000010b70 0xc000010be0 0xc000010c28] [0xc000010bd0 0xc000010c00] [0x9bf9f0 0x9bf9f0] 0xc0032f4720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:39.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:39.229: INFO: rc: 1
Jul  3 23:15:39.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000fda330 exit status 1 <nil> <nil> true [0xc000adc000 0xc000adc048 0xc000adc060] [0xc000adc000 0xc000adc048 0xc000adc060] [0xc000adc030 0xc000adc058] [0x9bf9f0 0x9bf9f0] 0xc002354300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:49.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:49.327: INFO: rc: 1
Jul  3 23:15:49.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d15410 exit status 1 <nil> <nil> true [0xc000010c50 0xc000010ce8 0xc000010d30] [0xc000010c50 0xc000010ce8 0xc000010d30] [0xc000010c90 0xc000010d10] [0x9bf9f0 0x9bf9f0] 0xc0032f5020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:15:59.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:15:59.427: INFO: rc: 1
Jul  3 23:15:59.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d15770 exit status 1 <nil> <nil> true [0xc000010d40 0xc000010d68 0xc000010dc8] [0xc000010d40 0xc000010d68 0xc000010dc8] [0xc000010d58 0xc000010db8] [0x9bf9f0 0x9bf9f0] 0xc0032f58c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:09.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:16:09.529: INFO: rc: 1
Jul  3 23:16:09.530: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978720 exit status 1 <nil> <nil> true [0xc000b9b0f8 0xc000b9b4d8 0xc000b9b630] [0xc000b9b0f8 0xc000b9b4d8 0xc000b9b630] [0xc000b9b440 0xc000b9b620] [0x9bf9f0 0x9bf9f0] 0xc0018a26c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:19.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:16:19.628: INFO: rc: 1
Jul  3 23:16:19.628: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978ae0 exit status 1 <nil> <nil> true [0xc000b9b6e0 0xc000b9b8e8 0xc000b9b9b8] [0xc000b9b6e0 0xc000b9b8e8 0xc000b9b9b8] [0xc000b9b840 0xc000b9b948] [0x9bf9f0 0x9bf9f0] 0xc0018a2c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:29.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:16:29.724: INFO: rc: 1
Jul  3 23:16:29.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001fa2030 exit status 1 <nil> <nil> true [0xc000010dd0 0xc000010df8 0xc000010e30] [0xc000010dd0 0xc000010df8 0xc000010e30] [0xc000010de8 0xc000010e20] [0x9bf9f0 0x9bf9f0] 0xc0032f5ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:39.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:16:39.830: INFO: rc: 1
Jul  3 23:16:39.830: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000fda360 exit status 1 <nil> <nil> true [0xc000adc018 0xc000adc050 0xc000adc080] [0xc000adc018 0xc000adc050 0xc000adc080] [0xc000adc048 0xc000adc060] [0x9bf9f0 0x9bf9f0] 0xc002354300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:49.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:16:49.933: INFO: rc: 1
Jul  3 23:16:49.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002978330 exit status 1 <nil> <nil> true [0xc000166000 0xc0007277d0 0xc000b9a360] [0xc000166000 0xc0007277d0 0xc000b9a360] [0xc000727798 0xc000727cc0] [0x9bf9f0 0x9bf9f0] 0xc0032a65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:16:59.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:17:00.043: INFO: rc: 1
Jul  3 23:17:00.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000fda6c0 exit status 1 <nil> <nil> true [0xc000adc0a0 0xc000adc0d8 0xc000adc108] [0xc000adc0a0 0xc000adc0d8 0xc000adc108] [0xc000adc0c0 0xc000adc0e8] [0x9bf9f0 0x9bf9f0] 0xc002354720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:17:10.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:17:10.138: INFO: rc: 1
Jul  3 23:17:10.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d144b0 exit status 1 <nil> <nil> true [0xc000010080 0xc000010740 0xc0000108a8] [0xc000010080 0xc000010740 0xc0000108a8] [0xc000010520 0xc000010810] [0x9bf9f0 0x9bf9f0] 0xc002201da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:17:20.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:17:20.233: INFO: rc: 1
Jul  3 23:17:20.233: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002d148d0 exit status 1 <nil> <nil> true [0xc0000108c8 0xc0000109c0 0xc000010aa8] [0xc0000108c8 0xc0000109c0 0xc000010aa8] [0xc000010940 0xc000010a70] [0x9bf9f0 0x9bf9f0] 0xc0018a23c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jul  3 23:17:30.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-411152090 exec --namespace=statefulset-1786 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul  3 23:17:30.324: INFO: rc: 1
Jul  3 23:17:30.324: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Jul  3 23:17:30.324: INFO: Scaling statefulset ss to 0
Jul  3 23:17:30.345: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul  3 23:17:30.352: INFO: Deleting all statefulset in ns statefulset-1786
Jul  3 23:17:30.359: INFO: Scaling statefulset ss to 0
Jul  3 23:17:30.375: INFO: Waiting for statefulset status.replicas updated to 0
Jul  3 23:17:30.382: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:17:30.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1786" for this suite.
Jul  3 23:17:36.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:17:36.595: INFO: namespace statefulset-1786 deletion completed in 6.177220109s

• [SLOW TEST:361.692 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:17:36.596: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-966
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  3 23:17:36.770: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul  3 23:17:58.937: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.92:8080/dial?request=hostName&protocol=udp&host=10.2.17.81&port=8081&tries=1'] Namespace:pod-network-test-966 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:17:58.938: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:17:59.109: INFO: Waiting for endpoints: map[]
Jul  3 23:17:59.115: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.92:8080/dial?request=hostName&protocol=udp&host=10.2.248.91&port=8081&tries=1'] Namespace:pod-network-test-966 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:17:59.115: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:17:59.262: INFO: Waiting for endpoints: map[]
Jul  3 23:17:59.268: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.92:8080/dial?request=hostName&protocol=udp&host=10.2.97.91&port=8081&tries=1'] Namespace:pod-network-test-966 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:17:59.268: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:17:59.405: INFO: Waiting for endpoints: map[]
Jul  3 23:17:59.410: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.97.92:8080/dial?request=hostName&protocol=udp&host=10.2.5.31&port=8081&tries=1'] Namespace:pod-network-test-966 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:17:59.410: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:17:59.557: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:17:59.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-966" for this suite.
Jul  3 23:18:23.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:18:23.781: INFO: namespace pod-network-test-966 deletion completed in 24.216173157s

• [SLOW TEST:47.185 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:18:23.787: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2917
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-dac27179-9de8-11e9-b0a2-a612d8f3003c
STEP: Creating configMap with name cm-test-opt-upd-dac271c2-9de8-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dac27179-9de8-11e9-b0a2-a612d8f3003c
STEP: Updating configmap cm-test-opt-upd-dac271c2-9de8-11e9-b0a2-a612d8f3003c
STEP: Creating configMap with name cm-test-opt-create-dac271de-9de8-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:19:34.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2917" for this suite.
Jul  3 23:19:56.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:19:56.883: INFO: namespace projected-2917 deletion completed in 22.19899297s

• [SLOW TEST:93.096 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:19:56.885: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-9829
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9829 to expose endpoints map[]
Jul  3 23:19:57.082: INFO: Get endpoints failed (6.347515ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jul  3 23:19:58.089: INFO: successfully validated that service endpoint-test2 in namespace services-9829 exposes endpoints map[] (1.013542959s elapsed)
STEP: Creating pod pod1 in namespace services-9829
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9829 to expose endpoints map[pod1:[80]]
Jul  3 23:20:00.138: INFO: successfully validated that service endpoint-test2 in namespace services-9829 exposes endpoints map[pod1:[80]] (2.035504295s elapsed)
STEP: Creating pod pod2 in namespace services-9829
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9829 to expose endpoints map[pod1:[80] pod2:[80]]
Jul  3 23:20:02.190: INFO: successfully validated that service endpoint-test2 in namespace services-9829 exposes endpoints map[pod1:[80] pod2:[80]] (2.044174874s elapsed)
STEP: Deleting pod pod1 in namespace services-9829
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9829 to expose endpoints map[pod2:[80]]
Jul  3 23:20:03.222: INFO: successfully validated that service endpoint-test2 in namespace services-9829 exposes endpoints map[pod2:[80]] (1.022111281s elapsed)
STEP: Deleting pod pod2 in namespace services-9829
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9829 to expose endpoints map[]
Jul  3 23:20:04.243: INFO: successfully validated that service endpoint-test2 in namespace services-9829 exposes endpoints map[] (1.012670577s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:20:04.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9829" for this suite.
Jul  3 23:20:10.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:20:10.494: INFO: namespace services-9829 deletion completed in 6.200974807s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:13.610 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:20:10.496: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul  3 23:20:16.732: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:16.737: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:18.738: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:18.746: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:20.738: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:20.744: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:22.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:22.745: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:24.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:24.744: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:26.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:26.745: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:28.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:28.745: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:30.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:30.743: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:32.738: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:32.745: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:34.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:34.744: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:36.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:36.745: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  3 23:20:38.738: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  3 23:20:38.744: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:20:38.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5736" for this suite.
Jul  3 23:21:00.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:21:00.950: INFO: namespace container-lifecycle-hook-5736 deletion completed in 22.182383966s

• [SLOW TEST:50.455 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:21:00.951: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2793
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-386f8261-9de9-11e9-b0a2-a612d8f3003c
STEP: Creating configMap with name cm-test-opt-upd-386f82b9-9de9-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-386f8261-9de9-11e9-b0a2-a612d8f3003c
STEP: Updating configmap cm-test-opt-upd-386f82b9-9de9-11e9-b0a2-a612d8f3003c
STEP: Creating configMap with name cm-test-opt-create-386f82d8-9de9-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:21:09.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2793" for this suite.
Jul  3 23:21:23.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:21:23.511: INFO: namespace configmap-2793 deletion completed in 14.195295787s

• [SLOW TEST:22.560 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:21:23.511: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 23:21:23.694: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c" in namespace "projected-2656" to be "success or failure"
Jul  3 23:21:23.700: INFO: Pod "downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.690102ms
Jul  3 23:21:25.707: INFO: Pod "downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012990759s
STEP: Saw pod success
Jul  3 23:21:25.707: INFO: Pod "downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:21:25.713: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-2 pod downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 23:21:25.744: INFO: Waiting for pod downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:21:25.749: INFO: Pod downwardapi-volume-45e0993b-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:21:25.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2656" for this suite.
Jul  3 23:21:31.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:21:31.936: INFO: namespace projected-2656 deletion completed in 6.178141982s

• [SLOW TEST:8.425 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:21:31.937: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 23:21:32.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c" in namespace "downward-api-456" to be "success or failure"
Jul  3 23:21:32.125: INFO: Pod "downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419568ms
Jul  3 23:21:34.133: INFO: Pod "downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0121226s
STEP: Saw pod success
Jul  3 23:21:34.133: INFO: Pod "downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:21:34.139: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 23:21:34.174: INFO: Waiting for pod downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:21:34.179: INFO: Pod downwardapi-volume-4ae67255-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:21:34.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-456" for this suite.
Jul  3 23:21:40.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:21:40.373: INFO: namespace downward-api-456 deletion completed in 6.18719656s

• [SLOW TEST:8.436 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:21:40.377: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 23:22:06.577: INFO: Container started at 2019-07-03 23:21:41 +0000 UTC, pod became ready at 2019-07-03 23:22:05 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:22:06.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5682" for this suite.
Jul  3 23:22:28.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:22:28.769: INFO: namespace container-probe-5682 deletion completed in 22.181780702s

• [SLOW TEST:48.392 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:22:28.771: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:22:32.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3898" for this suite.
Jul  3 23:23:21.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:23:21.194: INFO: namespace kubelet-test-3898 deletion completed in 48.195915623s

• [SLOW TEST:52.424 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:23:21.195: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3465
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul  3 23:23:21.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c" in namespace "downward-api-3465" to be "success or failure"
Jul  3 23:23:21.400: INFO: Pod "downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.481386ms
Jul  3 23:23:23.407: INFO: Pod "downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015919571s
STEP: Saw pod success
Jul  3 23:23:23.407: INFO: Pod "downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:23:23.413: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c container client-container: <nil>
STEP: delete the pod
Jul  3 23:23:23.447: INFO: Waiting for pod downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:23:23.451: INFO: Pod downwardapi-volume-8c07d08c-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:23:23.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3465" for this suite.
Jul  3 23:23:29.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:23:29.660: INFO: namespace downward-api-3465 deletion completed in 6.20227s

• [SLOW TEST:8.466 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:23:29.663: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul  3 23:23:33.887: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:33.888: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.037: INFO: Exec stderr: ""
Jul  3 23:23:34.037: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.037: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.192: INFO: Exec stderr: ""
Jul  3 23:23:34.192: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.192: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.334: INFO: Exec stderr: ""
Jul  3 23:23:34.334: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.335: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.477: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul  3 23:23:34.477: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.477: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.616: INFO: Exec stderr: ""
Jul  3 23:23:34.616: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.616: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.748: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul  3 23:23:34.748: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.748: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:34.882: INFO: Exec stderr: ""
Jul  3 23:23:34.882: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:34.882: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:35.012: INFO: Exec stderr: ""
Jul  3 23:23:35.012: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:35.012: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:35.138: INFO: Exec stderr: ""
Jul  3 23:23:35.138: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6355 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul  3 23:23:35.138: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
Jul  3 23:23:35.261: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:23:35.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6355" for this suite.
Jul  3 23:24:21.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:24:21.461: INFO: namespace e2e-kubelet-etc-hosts-6355 deletion completed in 46.191947994s

• [SLOW TEST:51.798 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:24:21.461: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-366
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-366/configmap-test-aff0d9c5-9de9-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 23:24:21.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c" in namespace "configmap-366" to be "success or failure"
Jul  3 23:24:21.646: INFO: Pod "pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034059ms
Jul  3 23:24:23.652: INFO: Pod "pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009662218s
STEP: Saw pod success
Jul  3 23:24:23.652: INFO: Pod "pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:24:23.656: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c container env-test: <nil>
STEP: delete the pod
Jul  3 23:24:23.686: INFO: Waiting for pod pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:24:23.691: INFO: Pod pod-configmaps-aff1ded2-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:24:23.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-366" for this suite.
Jul  3 23:24:29.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:24:29.871: INFO: namespace configmap-366 deletion completed in 6.173129818s

• [SLOW TEST:8.410 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:24:29.872: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul  3 23:24:30.071: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul  3 23:24:30.086: INFO: Number of nodes with available pods: 0
Jul  3 23:24:30.086: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul  3 23:24:30.116: INFO: Number of nodes with available pods: 0
Jul  3 23:24:30.116: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:31.122: INFO: Number of nodes with available pods: 0
Jul  3 23:24:31.122: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:32.123: INFO: Number of nodes with available pods: 1
Jul  3 23:24:32.123: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul  3 23:24:32.149: INFO: Number of nodes with available pods: 1
Jul  3 23:24:32.149: INFO: Number of running nodes: 0, number of available pods: 1
Jul  3 23:24:33.157: INFO: Number of nodes with available pods: 0
Jul  3 23:24:33.157: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul  3 23:24:33.176: INFO: Number of nodes with available pods: 0
Jul  3 23:24:33.176: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:34.183: INFO: Number of nodes with available pods: 0
Jul  3 23:24:34.183: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:35.183: INFO: Number of nodes with available pods: 0
Jul  3 23:24:35.183: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:36.183: INFO: Number of nodes with available pods: 0
Jul  3 23:24:36.183: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:37.183: INFO: Number of nodes with available pods: 0
Jul  3 23:24:37.183: INFO: Node jrpk8s114fixed-k8s-node-nf-1 is running more than one daemon pod
Jul  3 23:24:38.182: INFO: Number of nodes with available pods: 1
Jul  3 23:24:38.183: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6811, will wait for the garbage collector to delete the pods
Jul  3 23:24:38.265: INFO: Deleting DaemonSet.extensions daemon-set took: 14.32636ms
Jul  3 23:24:38.565: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.428338ms
Jul  3 23:24:47.572: INFO: Number of nodes with available pods: 0
Jul  3 23:24:47.572: INFO: Number of running nodes: 0, number of available pods: 0
Jul  3 23:24:47.579: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6811/daemonsets","resourceVersion":"34967"},"items":null}

Jul  3 23:24:47.584: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6811/pods","resourceVersion":"34967"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:24:47.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6811" for this suite.
Jul  3 23:24:53.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:24:53.836: INFO: namespace daemonsets-6811 deletion completed in 6.199773934s

• [SLOW TEST:23.964 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:24:53.839: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  3 23:24:54.021: INFO: Waiting up to 5m0s for pod "pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c" in namespace "emptydir-1351" to be "success or failure"
Jul  3 23:24:54.027: INFO: Pod "pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.948112ms
Jul  3 23:24:56.034: INFO: Pod "pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012862313s
Jul  3 23:24:58.041: INFO: Pod "pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020299689s
STEP: Saw pod success
Jul  3 23:24:58.041: INFO: Pod "pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:24:58.047: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c container test-container: <nil>
STEP: delete the pod
Jul  3 23:24:58.082: INFO: Waiting for pod pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:24:58.087: INFO: Pod pod-c33e123a-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:24:58.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1351" for this suite.
Jul  3 23:25:04.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:25:04.276: INFO: namespace emptydir-1351 deletion completed in 6.181113449s

• [SLOW TEST:10.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:25:04.277: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul  3 23:25:04.437: INFO: PodSpec: initContainers in spec.initContainers
Jul  3 23:25:49.497: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c9758f51-9de9-11e9-b0a2-a612d8f3003c", GenerateName:"", Namespace:"init-container-6382", SelfLink:"/api/v1/namespaces/init-container-6382/pods/pod-init-c9758f51-9de9-11e9-b0a2-a612d8f3003c", UID:"c9764582-9de9-11e9-a55c-fa163e25a4f0", ResourceVersion:"35230", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63697793104, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"437652353"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-r26sm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00287c1c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r26sm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r26sm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r26sm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003060cb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"jrpk8s114fixed-k8s-node-nf-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001845260), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003060d30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003060d50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003060d58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003060d5c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697793104, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697793104, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697793104, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63697793104, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.9", PodIP:"10.2.17.86", StartTime:(*v1.Time)(0xc002edb800), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025ca0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025ca150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c7aaa7e73f0fe6802a7b2d4d8a30894dcce61afd21ee8f8b5f1bc1a33cf6bb3a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002edb840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002edb820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:25:49.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6382" for this suite.
Jul  3 23:26:11.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:26:11.691: INFO: namespace init-container-6382 deletion completed in 22.183062249s

• [SLOW TEST:67.414 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:26:11.691: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Jul  3 23:26:11.872: INFO: Waiting up to 5m0s for pod "var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c" in namespace "var-expansion-1296" to be "success or failure"
Jul  3 23:26:11.878: INFO: Pod "var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.142067ms
Jul  3 23:26:13.885: INFO: Pod "var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012529618s
Jul  3 23:26:15.891: INFO: Pod "var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019379086s
STEP: Saw pod success
Jul  3 23:26:15.891: INFO: Pod "var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:26:15.897: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c container dapi-container: <nil>
STEP: delete the pod
Jul  3 23:26:15.929: INFO: Waiting for pod var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:26:15.933: INFO: Pod var-expansion-f1a58cb0-9de9-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:26:15.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1296" for this suite.
Jul  3 23:26:21.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:26:22.134: INFO: namespace var-expansion-1296 deletion completed in 6.190564005s

• [SLOW TEST:10.442 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:26:22.134: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9123
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9123
STEP: Deleting pre-stop pod
Jul  3 23:26:35.396: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:26:35.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9123" for this suite.
Jul  3 23:27:15.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:27:15.629: INFO: namespace prestop-9123 deletion completed in 40.212699039s

• [SLOW TEST:53.495 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:27:15.630: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-17c1cbf3-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating a pod to test consume configMaps
Jul  3 23:27:15.818: INFO: Waiting up to 5m0s for pod "pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c" in namespace "configmap-4354" to be "success or failure"
Jul  3 23:27:15.823: INFO: Pod "pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.558615ms
Jul  3 23:27:17.829: INFO: Pod "pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011174038s
STEP: Saw pod success
Jul  3 23:27:17.829: INFO: Pod "pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c" satisfied condition "success or failure"
Jul  3 23:27:17.836: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-4 pod pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c container configmap-volume-test: <nil>
STEP: delete the pod
Jul  3 23:27:17.866: INFO: Waiting for pod pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c to disappear
Jul  3 23:27:17.871: INFO: Pod pod-configmaps-17c2cd57-9dea-11e9-b0a2-a612d8f3003c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:27:17.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4354" for this suite.
Jul  3 23:27:23.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:27:24.084: INFO: namespace configmap-4354 deletion completed in 6.204542338s

• [SLOW TEST:8.454 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:27:24.085: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1889
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-1ccce178-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1ccce178-9dea-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:27:28.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1889" for this suite.
Jul  3 23:27:50.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:27:50.560: INFO: namespace configmap-1889 deletion completed in 22.203023348s

• [SLOW TEST:26.476 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:27:50.562: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1636
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2c95bef4-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2c95bef4-9dea-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:29:17.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1636" for this suite.
Jul  3 23:29:39.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:29:39.671: INFO: namespace projected-1636 deletion completed in 22.189740202s

• [SLOW TEST:109.109 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:29:39.673: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1507
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1507.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1507.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1507.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1507.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  3 23:29:57.928: INFO: DNS probes using dns-1507/dns-test-6d9c56e3-9dea-11e9-b0a2-a612d8f3003c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:29:57.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1507" for this suite.
Jul  3 23:30:03.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:30:04.154: INFO: namespace dns-1507 deletion completed in 6.199845373s

• [SLOW TEST:24.481 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:30:04.155: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8303
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-7c34a824-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating secret with name s-test-opt-upd-7c34a890-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7c34a824-9dea-11e9-b0a2-a612d8f3003c
STEP: Updating secret s-test-opt-upd-7c34a890-9dea-11e9-b0a2-a612d8f3003c
STEP: Creating secret with name s-test-opt-create-7c34a8d7-9dea-11e9-b0a2-a612d8f3003c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:30:08.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8303" for this suite.
Jul  3 23:30:30.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:30:30.696: INFO: namespace secrets-8303 deletion completed in 22.195069564s

• [SLOW TEST:26.541 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:30:30.699: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  3 23:30:36.952: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:36.958: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:38.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:38.965: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:40.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:40.965: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:42.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:42.966: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:44.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:44.965: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:46.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:46.966: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:48.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:48.964: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:50.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:50.966: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:52.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:52.966: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:54.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:54.965: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:56.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:56.965: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  3 23:30:58.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  3 23:30:58.965: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:30:58.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1206" for this suite.
Jul  3 23:31:20.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:31:21.181: INFO: namespace container-lifecycle-hook-1206 deletion completed in 22.208673403s

• [SLOW TEST:50.483 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:31:21.184: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-7sbg
STEP: Creating a pod to test atomic-volume-subpath
Jul  3 23:31:21.391: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7sbg" in namespace "subpath-9040" to be "success or failure"
Jul  3 23:31:21.398: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.201303ms
Jul  3 23:31:23.404: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012392158s
Jul  3 23:31:25.410: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 4.018305673s
Jul  3 23:31:27.418: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 6.026534251s
Jul  3 23:31:29.424: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 8.032792922s
Jul  3 23:31:31.431: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 10.039773355s
Jul  3 23:31:33.441: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 12.049505456s
Jul  3 23:31:35.450: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 14.058763506s
Jul  3 23:31:37.457: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 16.065858206s
Jul  3 23:31:39.463: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 18.071426789s
Jul  3 23:31:41.471: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 20.079391083s
Jul  3 23:31:43.478: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Running", Reason="", readiness=true. Elapsed: 22.086389825s
Jul  3 23:31:45.485: INFO: Pod "pod-subpath-test-configmap-7sbg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.093680101s
STEP: Saw pod success
Jul  3 23:31:45.485: INFO: Pod "pod-subpath-test-configmap-7sbg" satisfied condition "success or failure"
Jul  3 23:31:45.490: INFO: Trying to get logs from node jrpk8s114fixed-k8s-node-nf-1 pod pod-subpath-test-configmap-7sbg container test-container-subpath-configmap-7sbg: <nil>
STEP: delete the pod
Jul  3 23:31:45.519: INFO: Waiting for pod pod-subpath-test-configmap-7sbg to disappear
Jul  3 23:31:45.524: INFO: Pod pod-subpath-test-configmap-7sbg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7sbg
Jul  3 23:31:45.524: INFO: Deleting pod "pod-subpath-test-configmap-7sbg" in namespace "subpath-9040"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:31:45.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9040" for this suite.
Jul  3 23:31:51.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:31:51.710: INFO: namespace subpath-9040 deletion completed in 6.170906461s

• [SLOW TEST:30.526 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul  3 23:31:51.712: INFO: >>> kubeConfig: /tmp/kubeconfig-411152090
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul  3 23:31:51.879: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul  3 23:31:55.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8528" for this suite.
Jul  3 23:32:01.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul  3 23:32:02.002: INFO: namespace init-container-8528 deletion completed in 6.178738181s

• [SLOW TEST:10.290 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSJul  3 23:32:02.002: INFO: Running AfterSuite actions on all nodes
Jul  3 23:32:02.002: INFO: Running AfterSuite actions on node 1
Jul  3 23:32:02.002: INFO: Skipping dumping logs from cluster

Ran 182 of 3584 Specs in 5148.418 seconds
SUCCESS! -- 182 Passed | 0 Failed | 0 Pending | 3402 Skipped PASS

Ginkgo ran 1 suite in 1h25m50.493114839s
Test Suite Passed
