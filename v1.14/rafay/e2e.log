I0721 17:28:01.548587      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-991073413
I0721 17:28:01.548692      16 e2e.go:240] Starting e2e run "e285543c-abdc-11e9-974c-16aa19c3723a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1563730078 - Will randomize all specs
Will run 204 of 3584 specs

Jul 21 17:28:01.952: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 17:28:01.954: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul 21 17:28:01.978: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 21 17:28:02.002: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul 21 17:28:02.002: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jul 21 17:28:02.002: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 21 17:28:02.012: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Jul 21 17:28:02.012: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'glusterfs' (0 seconds elapsed)
Jul 21 17:28:02.012: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jul 21 17:28:02.012: INFO: e2e test version: v1.14.1
Jul 21 17:28:02.013: INFO: kube-apiserver version: v1.14.1
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:28:02.016: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
Jul 21 17:28:02.085: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 21 17:28:02.115: INFO: Waiting up to 5m0s for pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a" in namespace "downward-api-8031" to be "success or failure"
Jul 21 17:28:02.117: INFO: Pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.487792ms
Jul 21 17:28:04.122: INFO: Pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006811898s
Jul 21 17:28:06.137: INFO: Pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021827158s
Jul 21 17:28:08.143: INFO: Pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027948172s
STEP: Saw pod success
Jul 21 17:28:08.143: INFO: Pod "downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:28:08.145: INFO: Trying to get logs from node ip-10-222-31-145 pod downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 17:28:08.172: INFO: Waiting for pod downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a to disappear
Jul 21 17:28:08.174: INFO: Pod downward-api-e42eb18b-abdc-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:28:08.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8031" for this suite.
Jul 21 17:28:14.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:28:14.770: INFO: namespace downward-api-8031 deletion completed in 6.594201287s

â€¢ [SLOW TEST:12.754 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:28:14.771: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5181
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-5181
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5181
Jul 21 17:28:14.864: INFO: Found 0 stateful pods, waiting for 1
Jul 21 17:28:24.869: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul 21 17:28:24.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:28:25.210: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:28:25.210: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:28:25.210: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 17:28:25.214: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 21 17:28:35.219: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 17:28:35.219: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 17:28:35.230: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:28:35.230: INFO: ss-0  ip-10-222-31-145  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  }]
Jul 21 17:28:35.230: INFO: 
Jul 21 17:28:35.230: INFO: StatefulSet ss has not reached scale 3, at 1
Jul 21 17:28:36.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996656371s
Jul 21 17:28:37.256: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979145788s
Jul 21 17:28:38.259: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969995155s
Jul 21 17:28:39.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967144501s
Jul 21 17:28:40.267: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.963543967s
Jul 21 17:28:41.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954748902s
Jul 21 17:28:42.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.947641881s
Jul 21 17:28:43.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944362287s
Jul 21 17:28:44.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.080877ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5181
Jul 21 17:28:45.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:28:45.544: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 17:28:45.544: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 17:28:45.544: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 17:28:45.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:28:46.223: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 21 17:28:46.223: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 17:28:46.223: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 17:28:46.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:28:46.755: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 21 17:28:46.755: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 17:28:46.755: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 17:28:46.760: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 17:28:46.760: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 17:28:46.760: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul 21 17:28:46.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:28:47.234: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:28:47.234: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:28:47.234: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 17:28:47.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:28:47.721: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:28:47.721: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:28:47.721: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 17:28:47.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:28:48.440: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:28:48.440: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:28:48.440: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 17:28:48.440: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 17:28:48.442: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jul 21 17:28:58.449: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 17:28:58.449: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 17:28:58.449: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 17:28:58.477: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:28:58.477: INFO: ss-0  ip-10-222-31-145  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  }]
Jul 21 17:28:58.477: INFO: ss-1  ip-10-222-31-145  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:28:58.477: INFO: ss-2  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:28:58.477: INFO: 
Jul 21 17:28:58.477: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 21 17:28:59.483: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:28:59.483: INFO: ss-0  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  }]
Jul 21 17:28:59.483: INFO: ss-1  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:28:59.483: INFO: ss-2  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:28:59.483: INFO: 
Jul 21 17:28:59.483: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 21 17:29:00.489: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:00.489: INFO: ss-0  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:14 +0000 UTC  }]
Jul 21 17:29:00.489: INFO: ss-1  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:00.489: INFO: ss-2  ip-10-222-31-145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:00.489: INFO: 
Jul 21 17:29:00.489: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 21 17:29:01.508: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:01.508: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:01.508: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:01.509: INFO: 
Jul 21 17:29:01.509: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:02.511: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:02.511: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:02.511: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:02.511: INFO: 
Jul 21 17:29:02.511: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:03.515: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:03.515: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:03.515: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:03.515: INFO: 
Jul 21 17:29:03.515: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:04.536: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:04.536: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:04.536: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:04.536: INFO: 
Jul 21 17:29:04.536: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:05.540: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:05.540: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:05.540: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:05.540: INFO: 
Jul 21 17:29:05.540: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:06.543: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:06.543: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:06.543: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:06.543: INFO: 
Jul 21 17:29:06.543: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 21 17:29:07.546: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul 21 17:29:07.546: INFO: ss-1  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:07.546: INFO: ss-2  ip-10-222-31-145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 17:28:35 +0000 UTC  }]
Jul 21 17:29:07.546: INFO: 
Jul 21 17:29:07.546: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5181
Jul 21 17:29:08.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:08.730: INFO: rc: 1
Jul 21 17:29:08.730: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001250540 exit status 1 <nil> <nil> true [0xc0027ac360 0xc0027ac378 0xc0027ac390] [0xc0027ac360 0xc0027ac378 0xc0027ac390] [0xc0027ac370 0xc0027ac388] [0x9bf9f0 0x9bf9f0] 0xc001c93620 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jul 21 17:29:18.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:18.801: INFO: rc: 1
Jul 21 17:29:18.801: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa9b30 exit status 1 <nil> <nil> true [0xc002299080 0xc0022990a8 0xc0022990c8] [0xc002299080 0xc0022990a8 0xc0022990c8] [0xc002299098 0xc0022990c0] [0x9bf9f0 0x9bf9f0] 0xc002722fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:29:28.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:28.864: INFO: rc: 1
Jul 21 17:29:28.864: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0012508d0 exit status 1 <nil> <nil> true [0xc0027ac398 0xc0027ac3b0 0xc0027ac3c8] [0xc0027ac398 0xc0027ac3b0 0xc0027ac3c8] [0xc0027ac3a8 0xc0027ac3c0] [0x9bf9f0 0x9bf9f0] 0xc001c93c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:29:38.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:38.946: INFO: rc: 1
Jul 21 17:29:38.946: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0011ce8a0 exit status 1 <nil> <nil> true [0xc001fda310 0xc001fda368 0xc001fda390] [0xc001fda310 0xc001fda368 0xc001fda390] [0xc001fda350 0xc001fda388] [0x9bf9f0 0x9bf9f0] 0xc0016a5ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:29:48.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:49.060: INFO: rc: 1
Jul 21 17:29:49.060: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa9e90 exit status 1 <nil> <nil> true [0xc0022990d0 0xc002299100 0xc002299118] [0xc0022990d0 0xc002299100 0xc002299118] [0xc0022990f0 0xc002299110] [0x9bf9f0 0x9bf9f0] 0xc002723680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:29:59.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:29:59.234: INFO: rc: 1
Jul 21 17:29:59.234: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001250c00 exit status 1 <nil> <nil> true [0xc0027ac3d0 0xc0027ac3e8 0xc0027ac400] [0xc0027ac3d0 0xc0027ac3e8 0xc0027ac400] [0xc0027ac3e0 0xc0027ac3f8] [0x9bf9f0 0x9bf9f0] 0xc00285a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:30:09.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:30:09.626: INFO: rc: 1
Jul 21 17:30:09.626: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288210 exit status 1 <nil> <nil> true [0xc002299128 0xc002299150 0xc002299170] [0xc002299128 0xc002299150 0xc002299170] [0xc002299148 0xc002299160] [0x9bf9f0 0x9bf9f0] 0xc002723ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:30:19.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:30:19.803: INFO: rc: 1
Jul 21 17:30:19.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288330 exit status 1 <nil> <nil> true [0xc002298018 0xc002298050 0xc0022980b8] [0xc002298018 0xc002298050 0xc0022980b8] [0xc002298038 0xc0022980a0] [0x9bf9f0 0x9bf9f0] 0xc0027225a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:30:29.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:30:29.939: INFO: rc: 1
Jul 21 17:30:29.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b7e300 exit status 1 <nil> <nil> true [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418108 0xc001418580] [0x9bf9f0 0x9bf9f0] 0xc002c9a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:30:39.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:30:40.099: INFO: rc: 1
Jul 21 17:30:40.099: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288660 exit status 1 <nil> <nil> true [0xc0022980d0 0xc002298108 0xc002298148] [0xc0022980d0 0xc002298108 0xc002298148] [0xc0022980f8 0xc002298140] [0x9bf9f0 0x9bf9f0] 0xc002722c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:30:50.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:30:50.171: INFO: rc: 1
Jul 21 17:30:50.171: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12330 exit status 1 <nil> <nil> true [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc000010460 0xc000010568] [0x9bf9f0 0x9bf9f0] 0xc001c924e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:00.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:00.261: INFO: rc: 1
Jul 21 17:31:00.261: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12690 exit status 1 <nil> <nil> true [0xc000010680 0xc000010f10 0xc00018f8d8] [0xc000010680 0xc000010f10 0xc00018f8d8] [0xc000010e38 0xc00018f8a8] [0x9bf9f0 0x9bf9f0] 0xc001c92ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:10.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:10.575: INFO: rc: 1
Jul 21 17:31:10.575: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0012889c0 exit status 1 <nil> <nil> true [0xc002298158 0xc002298180 0xc0022981c8] [0xc002298158 0xc002298180 0xc0022981c8] [0xc002298178 0xc0022981b8] [0x9bf9f0 0x9bf9f0] 0xc002723260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:20.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:20.758: INFO: rc: 1
Jul 21 17:31:20.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b129f0 exit status 1 <nil> <nil> true [0xc00018f928 0xc00018faa8 0xc00018fc60] [0xc00018f928 0xc00018faa8 0xc00018fc60] [0xc00018f978 0xc00018fb80] [0x9bf9f0 0x9bf9f0] 0xc001c932c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:30.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:30.904: INFO: rc: 1
Jul 21 17:31:30.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288d20 exit status 1 <nil> <nil> true [0xc0022981d8 0xc002298200 0xc002298238] [0xc0022981d8 0xc002298200 0xc002298238] [0xc0022981f8 0xc002298218] [0x9bf9f0 0x9bf9f0] 0xc002723920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:40.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:41.081: INFO: rc: 1
Jul 21 17:31:41.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001289080 exit status 1 <nil> <nil> true [0xc002298248 0xc002298270 0xc002298298] [0xc002298248 0xc002298270 0xc002298298] [0xc002298268 0xc002298288] [0x9bf9f0 0x9bf9f0] 0xc001a72000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:31:51.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:31:51.306: INFO: rc: 1
Jul 21 17:31:51.306: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b7e660 exit status 1 <nil> <nil> true [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014189e0 0xc001418ae0] [0x9bf9f0 0x9bf9f0] 0xc002c9a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:01.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:01.551: INFO: rc: 1
Jul 21 17:32:01.551: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa8330 exit status 1 <nil> <nil> true [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc6e8 0xc0000cc830] [0x9bf9f0 0x9bf9f0] 0xc001e5c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:11.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:11.726: INFO: rc: 1
Jul 21 17:32:11.726: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12d80 exit status 1 <nil> <nil> true [0xc00018fd08 0xc00018fd80 0xc00018fe28] [0xc00018fd08 0xc00018fd80 0xc00018fe28] [0xc00018fd38 0xc00018fe20] [0x9bf9f0 0x9bf9f0] 0xc001c938c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:21.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:21.896: INFO: rc: 1
Jul 21 17:32:21.899: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b7e330 exit status 1 <nil> <nil> true [0xc0000102f8 0xc000010518 0xc000010680] [0xc0000102f8 0xc000010518 0xc000010680] [0xc0000104f8 0xc000010618] [0x9bf9f0 0x9bf9f0] 0xc0027225a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:31.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:31.994: INFO: rc: 1
Jul 21 17:32:31.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12300 exit status 1 <nil> <nil> true [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418108 0xc001418580] [0x9bf9f0 0x9bf9f0] 0xc002c9a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:41.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:42.097: INFO: rc: 1
Jul 21 17:32:42.097: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b126c0 exit status 1 <nil> <nil> true [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014189e0 0xc001418ae0] [0x9bf9f0 0x9bf9f0] 0xc002c9a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:32:52.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:32:52.234: INFO: rc: 1
Jul 21 17:32:52.234: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa8300 exit status 1 <nil> <nil> true [0xc00018e000 0xc00018f928 0xc00018faa8] [0xc00018e000 0xc00018f928 0xc00018faa8] [0xc00018f8d8 0xc00018f978] [0x9bf9f0 0x9bf9f0] 0xc001c924e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:02.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:02.373: INFO: rc: 1
Jul 21 17:33:02.373: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12a50 exit status 1 <nil> <nil> true [0xc001418c50 0xc001418e28 0xc001418f70] [0xc001418c50 0xc001418e28 0xc001418f70] [0xc001418d28 0xc001418ee0] [0x9bf9f0 0x9bf9f0] 0xc002c9a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:12.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:12.709: INFO: rc: 1
Jul 21 17:33:12.709: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288360 exit status 1 <nil> <nil> true [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc6e8 0xc0000cc830] [0x9bf9f0 0x9bf9f0] 0xc001e5c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:22.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:22.804: INFO: rc: 1
Jul 21 17:33:22.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa8660 exit status 1 <nil> <nil> true [0xc00018fb20 0xc00018fd08 0xc00018fd80] [0xc00018fb20 0xc00018fd08 0xc00018fd80] [0xc00018fc60 0xc00018fd38] [0x9bf9f0 0x9bf9f0] 0xc001c92ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:32.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:32.919: INFO: rc: 1
Jul 21 17:33:32.919: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aa8990 exit status 1 <nil> <nil> true [0xc00018fdc8 0xc00018fe38 0xc00018ff18] [0xc00018fdc8 0xc00018fe38 0xc00018ff18] [0xc00018fe28 0xc00018fef0] [0x9bf9f0 0x9bf9f0] 0xc001c932c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:42.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:43.012: INFO: rc: 1
Jul 21 17:33:43.013: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b12e10 exit status 1 <nil> <nil> true [0xc001418fe8 0xc001419288 0xc0014193a8] [0xc001418fe8 0xc001419288 0xc0014193a8] [0xc001419170 0xc001419398] [0x9bf9f0 0x9bf9f0] 0xc002c9ad80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:33:53.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:33:53.105: INFO: rc: 1
Jul 21 17:33:53.105: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002b13170 exit status 1 <nil> <nil> true [0xc0014193f8 0xc0014194c8 0xc001419600] [0xc0014193f8 0xc0014194c8 0xc001419600] [0xc0014194b8 0xc001419590] [0x9bf9f0 0x9bf9f0] 0xc002c9b320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:34:03.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:34:03.169: INFO: rc: 1
Jul 21 17:34:03.169: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001288750 exit status 1 <nil> <nil> true [0xc0000cc9a0 0xc0000cca80 0xc0000ccb38] [0xc0000cc9a0 0xc0000cca80 0xc0000ccb38] [0xc0000cca70 0xc0000ccad8] [0x9bf9f0 0x9bf9f0] 0xc001e5cc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 21 17:34:13.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-5181 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:34:13.389: INFO: rc: 1
Jul 21 17:34:13.389: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jul 21 17:34:13.389: INFO: Scaling statefulset ss to 0
Jul 21 17:34:13.424: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 21 17:34:13.434: INFO: Deleting all statefulset in ns statefulset-5181
Jul 21 17:34:13.443: INFO: Scaling statefulset ss to 0
Jul 21 17:34:13.472: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 17:34:13.476: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:34:13.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5181" for this suite.
Jul 21 17:34:19.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:34:20.161: INFO: namespace statefulset-5181 deletion completed in 6.622471721s

â€¢ [SLOW TEST:365.390 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:34:20.161: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 17:34:20.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a" in namespace "downward-api-7765" to be "success or failure"
Jul 21 17:34:20.203: INFO: Pod "downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.297372ms
Jul 21 17:34:22.219: INFO: Pod "downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021214607s
Jul 21 17:34:24.227: INFO: Pod "downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029786596s
STEP: Saw pod success
Jul 21 17:34:24.227: INFO: Pod "downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:34:24.231: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 17:34:24.252: INFO: Waiting for pod downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a to disappear
Jul 21 17:34:24.254: INFO: Pod downwardapi-volume-c58bafc3-abdd-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:34:24.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7765" for this suite.
Jul 21 17:34:30.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:34:30.846: INFO: namespace downward-api-7765 deletion completed in 6.588932645s

â€¢ [SLOW TEST:10.685 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:34:30.848: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 17:34:30.922: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul 21 17:34:30.942: INFO: Number of nodes with available pods: 0
Jul 21 17:34:30.942: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul 21 17:34:30.980: INFO: Number of nodes with available pods: 0
Jul 21 17:34:30.980: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:31.987: INFO: Number of nodes with available pods: 0
Jul 21 17:34:31.987: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:32.984: INFO: Number of nodes with available pods: 0
Jul 21 17:34:32.985: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:33.985: INFO: Number of nodes with available pods: 1
Jul 21 17:34:33.985: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul 21 17:34:34.004: INFO: Number of nodes with available pods: 1
Jul 21 17:34:34.004: INFO: Number of running nodes: 0, number of available pods: 1
Jul 21 17:34:35.007: INFO: Number of nodes with available pods: 0
Jul 21 17:34:35.007: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul 21 17:34:35.018: INFO: Number of nodes with available pods: 0
Jul 21 17:34:35.018: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:36.022: INFO: Number of nodes with available pods: 0
Jul 21 17:34:36.022: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:37.020: INFO: Number of nodes with available pods: 0
Jul 21 17:34:37.020: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:38.022: INFO: Number of nodes with available pods: 0
Jul 21 17:34:38.022: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:39.020: INFO: Number of nodes with available pods: 0
Jul 21 17:34:39.020: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:40.023: INFO: Number of nodes with available pods: 0
Jul 21 17:34:40.023: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:41.025: INFO: Number of nodes with available pods: 0
Jul 21 17:34:41.025: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:34:42.025: INFO: Number of nodes with available pods: 1
Jul 21 17:34:42.025: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6445, will wait for the garbage collector to delete the pods
Jul 21 17:34:42.106: INFO: Deleting DaemonSet.extensions daemon-set took: 15.890083ms
Jul 21 17:34:42.506: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.687825ms
Jul 21 17:34:52.509: INFO: Number of nodes with available pods: 0
Jul 21 17:34:52.509: INFO: Number of running nodes: 0, number of available pods: 0
Jul 21 17:34:52.512: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6445/daemonsets","resourceVersion":"8071"},"items":null}

Jul 21 17:34:52.514: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6445/pods","resourceVersion":"8071"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:34:52.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6445" for this suite.
Jul 21 17:34:58.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:34:59.102: INFO: namespace daemonsets-6445 deletion completed in 6.576446527s

â€¢ [SLOW TEST:28.254 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:34:59.102: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-dcc5e5b7-abdd-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 17:34:59.170: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a" in namespace "projected-4623" to be "success or failure"
Jul 21 17:34:59.179: INFO: Pod "pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.883225ms
Jul 21 17:35:01.196: INFO: Pod "pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026382999s
Jul 21 17:35:03.203: INFO: Pod "pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033150963s
STEP: Saw pod success
Jul 21 17:35:03.203: INFO: Pod "pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:35:03.209: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 21 17:35:03.258: INFO: Waiting for pod pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a to disappear
Jul 21 17:35:03.267: INFO: Pod pod-projected-secrets-dcc66fb6-abdd-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:35:03.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4623" for this suite.
Jul 21 17:35:09.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:35:09.887: INFO: namespace projected-4623 deletion completed in 6.615136794s

â€¢ [SLOW TEST:10.785 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:35:09.888: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 17:35:09.921: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a" in namespace "projected-5808" to be "success or failure"
Jul 21 17:35:09.926: INFO: Pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.561188ms
Jul 21 17:35:11.935: INFO: Pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014368188s
Jul 21 17:35:13.955: INFO: Pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034185454s
Jul 21 17:35:15.960: INFO: Pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039466217s
STEP: Saw pod success
Jul 21 17:35:15.960: INFO: Pod "downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:35:15.963: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 17:35:15.988: INFO: Waiting for pod downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a to disappear
Jul 21 17:35:15.991: INFO: Pod downwardapi-volume-e32f3f45-abdd-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:35:15.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5808" for this suite.
Jul 21 17:35:22.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:35:22.580: INFO: namespace projected-5808 deletion completed in 6.586412615s

â€¢ [SLOW TEST:12.692 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:35:22.580: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 21 17:35:22.627: INFO: Waiting up to 5m0s for pod "pod-eac188d1-abdd-11e9-974c-16aa19c3723a" in namespace "emptydir-9980" to be "success or failure"
Jul 21 17:35:22.637: INFO: Pod "pod-eac188d1-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.436188ms
Jul 21 17:35:24.642: INFO: Pod "pod-eac188d1-abdd-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014664067s
Jul 21 17:35:26.646: INFO: Pod "pod-eac188d1-abdd-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019137669s
STEP: Saw pod success
Jul 21 17:35:26.646: INFO: Pod "pod-eac188d1-abdd-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:35:26.654: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-eac188d1-abdd-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 17:35:26.687: INFO: Waiting for pod pod-eac188d1-abdd-11e9-974c-16aa19c3723a to disappear
Jul 21 17:35:26.689: INFO: Pod pod-eac188d1-abdd-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:35:26.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9980" for this suite.
Jul 21 17:35:32.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:35:33.273: INFO: namespace emptydir-9980 deletion completed in 6.581573876s

â€¢ [SLOW TEST:10.693 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:35:33.273: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Jul 21 17:35:37.362: INFO: Pod pod-hostip-f1239b66-abdd-11e9-974c-16aa19c3723a has hostIP: 10.222.31.145
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:35:37.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2845" for this suite.
Jul 21 17:35:59.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:35:59.941: INFO: namespace pods-2845 deletion completed in 22.576708045s

â€¢ [SLOW TEST:26.668 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:35:59.942: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0104c926-abde-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 17:35:59.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a" in namespace "projected-2341" to be "success or failure"
Jul 21 17:35:59.996: INFO: Pod "pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.163255ms
Jul 21 17:36:01.999: INFO: Pod "pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013857916s
Jul 21 17:36:04.012: INFO: Pod "pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026717353s
STEP: Saw pod success
Jul 21 17:36:04.012: INFO: Pod "pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:36:04.016: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 17:36:04.084: INFO: Waiting for pod pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a to disappear
Jul 21 17:36:04.100: INFO: Pod pod-projected-configmaps-010547f4-abde-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:36:04.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2341" for this suite.
Jul 21 17:36:12.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:36:12.743: INFO: namespace projected-2341 deletion completed in 8.625081968s

â€¢ [SLOW TEST:12.802 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:36:12.744: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-08a823f6-abde-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 17:36:12.797: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a" in namespace "projected-6251" to be "success or failure"
Jul 21 17:36:12.829: INFO: Pod "pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 32.12539ms
Jul 21 17:36:14.838: INFO: Pod "pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040861279s
Jul 21 17:36:16.841: INFO: Pod "pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043785121s
STEP: Saw pod success
Jul 21 17:36:16.841: INFO: Pod "pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:36:16.846: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 17:36:16.887: INFO: Waiting for pod pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a to disappear
Jul 21 17:36:16.893: INFO: Pod pod-projected-configmaps-08a8dcb6-abde-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:36:16.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6251" for this suite.
Jul 21 17:36:22.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:36:23.477: INFO: namespace projected-6251 deletion completed in 6.575138755s

â€¢ [SLOW TEST:10.733 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:36:23.478: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-0f0bc684-abde-11e9-974c-16aa19c3723a
STEP: Creating configMap with name cm-test-opt-upd-0f0bc6c7-abde-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0f0bc684-abde-11e9-974c-16aa19c3723a
STEP: Updating configmap cm-test-opt-upd-0f0bc6c7-abde-11e9-974c-16aa19c3723a
STEP: Creating configMap with name cm-test-opt-create-0f0bc6e5-abde-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:36:31.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4843" for this suite.
Jul 21 17:36:53.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:36:54.169: INFO: namespace configmap-4843 deletion completed in 22.581513275s

â€¢ [SLOW TEST:30.691 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:36:54.169: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 21 17:37:02.293: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 21 17:37:02.302: INFO: Pod pod-with-poststart-http-hook still exists
Jul 21 17:37:04.302: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 21 17:37:04.306: INFO: Pod pod-with-poststart-http-hook still exists
Jul 21 17:37:06.302: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 21 17:37:06.305: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:37:06.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5193" for this suite.
Jul 21 17:37:28.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:37:28.877: INFO: namespace container-lifecycle-hook-5193 deletion completed in 22.569214317s

â€¢ [SLOW TEST:34.708 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:37:28.877: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-3606f068-abde-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3606f068-abde-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:39:03.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2473" for this suite.
Jul 21 17:39:27.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:39:28.120: INFO: namespace configmap-2473 deletion completed in 24.63054765s

â€¢ [SLOW TEST:119.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:39:28.121: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 21 17:39:28.146: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 21 17:39:28.150: INFO: Waiting for terminating namespaces to be deleted...
Jul 21 17:39:28.152: INFO: 
Logging pods the kubelet thinks is on node ip-10-222-31-145 before test
Jul 21 17:39:28.170: INFO: resource-allocation-8c8cdcfd8-njc4s from rcloud-admin started at 2019-07-21 16:46:45 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.171: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.171: INFO: 	Container resource-allocation ready: true, restart count 0
Jul 21 17:39:28.171: INFO: debug-broker-0 from rcloud-infra started at 2019-07-21 16:47:27 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.171: INFO: 	Container debug-broker ready: true, restart count 0
Jul 21 17:39:28.171: INFO: debug-processor-76656764d-kh7gg from rcloud-admin started at 2019-07-21 16:47:36 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container debug-processor ready: true, restart count 0
Jul 21 17:39:28.172: INFO: config-processor-7847fd6f49-z4g58 from rcloud-admin started at 2019-07-21 16:48:12 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container config-processor ready: true, restart count 0
Jul 21 17:39:28.172: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.172: INFO: edge-sec-665bf84b5d-nr27w from rcloud-infra started at 2019-07-21 16:48:52 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container edge-sec ready: true, restart count 0
Jul 21 17:39:28.172: INFO: coredns-fb8b8dccf-wrz8f from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container coredns ready: true, restart count 0
Jul 21 17:39:28.172: INFO: istio-mixer-86bc989497-v8bvv from istio-system started at 2019-07-21 16:44:40 +0000 UTC (3 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.172: INFO: 	Container mixer ready: true, restart count 0
Jul 21 17:39:28.172: INFO: 	Container statsd-to-prometheus ready: true, restart count 0
Jul 21 17:39:28.172: INFO: istio-pilot-75c4c5dcc5-n4dxq from istio-system started at 2019-07-21 16:44:41 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.172: INFO: 	Container discovery ready: true, restart count 0
Jul 21 17:39:28.172: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.172: INFO: postgres-756f878d66-kdw48 from rcloud-admin started at 2019-07-21 16:45:23 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container postgres ready: true, restart count 0
Jul 21 17:39:28.173: INFO: admin-api-7758ff5dc6-t554w from rcloud-admin started at 2019-07-21 16:46:02 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container admin-api ready: true, restart count 0
Jul 21 17:39:28.173: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.173: INFO: frontend-opsconsole-65d75f5d69-mdz97 from rcloud-admin started at 2019-07-21 16:46:19 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container frontend-opsconsole ready: true, restart count 0
Jul 21 17:39:28.173: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.173: INFO: workload-processor-7c768567f6-zdlzm from rcloud-admin started at 2019-07-21 16:46:28 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.173: INFO: 	Container workload-processor ready: true, restart count 0
Jul 21 17:39:28.173: INFO: workload-broker-c5f8c89c-h6ssl from rcloud-infra started at 2019-07-21 16:47:04 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container workload-broker ready: true, restart count 0
Jul 21 17:39:28.173: INFO: etcd-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 17:39:28.173: INFO: kafka-core-7c75bb8ccd-zrkn5 from rcloud-infra started at 2019-07-21 16:45:19 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container kafka-core ready: true, restart count 1
Jul 21 17:39:28.173: INFO: admin-redis-599959c468-9bdcj from rcloud-admin started at 2019-07-21 16:45:22 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container admin-redis ready: true, restart count 0
Jul 21 17:39:28.173: INFO: regauth-8bd9db7c4-dmmnf from rcloud-admin started at 2019-07-21 16:47:18 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container docker-auth ready: true, restart count 0
Jul 21 17:39:28.173: INFO: salt-master-6bc4f85449-hf78n from rcloud-infra started at 2019-07-21 16:49:01 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.173: INFO: 	Container salt-master ready: true, restart count 0
Jul 21 17:39:28.173: INFO: coredns-fb8b8dccf-ggr8r from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container coredns ready: true, restart count 0
Jul 21 17:39:28.174: INFO: edge-processor-68f574bb58-7xwpb from rcloud-admin started at 2019-07-21 16:47:52 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container edge-processor ready: true, restart count 0
Jul 21 17:39:28.174: INFO: config-broker-5c85977786-rvjlb from rcloud-infra started at 2019-07-21 16:48:01 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container config-broker ready: true, restart count 0
Jul 21 17:39:28.174: INFO: nginx-ingress-controller-78dcf4d98b-nzf98 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jul 21 17:39:28.174: INFO: istio-ca-78655bf74f-jtfdj from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container istio-ca ready: true, restart count 0
Jul 21 17:39:28.174: INFO: frontend-7cc7768fc8-tmhds from rcloud-admin started at 2019-07-21 16:46:12 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container frontend ready: true, restart count 0
Jul 21 17:39:28.174: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.174: INFO: edgesrv-6459c565cb-z2898 from rcloud-admin started at 2019-07-21 16:48:40 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container edgesrv ready: true, restart count 0
Jul 21 17:39:28.174: INFO: sonobuoy-systemd-logs-daemon-set-5655e65ca0e146ed-znmf4 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 21 17:39:28.174: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 21 17:39:28.174: INFO: kube-apiserver-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 17:39:28.174: INFO: kube-controller-manager-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 17:39:28.174: INFO: canal-sztcn from kube-system started at 2019-07-21 16:40:24 +0000 UTC (3 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container calico-node ready: true, restart count 0
Jul 21 17:39:28.174: INFO: 	Container install-cni ready: true, restart count 0
Jul 21 17:39:28.174: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 21 17:39:28.174: INFO: keygensvc-86d69565-94v4f from rcloud-infra started at 2019-07-21 16:45:34 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container keygensvc ready: true, restart count 2
Jul 21 17:39:28.174: INFO: nginx-ingress-controller-admin-564f6884d8-gz2js from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.174: INFO: 	Container nginx-ingress-controller-admin ready: true, restart count 0
Jul 21 17:39:28.174: INFO: kube-scheduler-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 17:39:28.175: INFO: glusterfs-8krmv from kube-system started at 2019-07-21 16:44:02 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container glusterfs ready: true, restart count 0
Jul 21 17:39:28.175: INFO: default-http-backend-55b84578bf-lghj8 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 21 17:39:28.175: INFO: cryptosvc-d477c486-rtrnb from rcloud-infra started at 2019-07-21 16:45:44 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container cryptosvc ready: true, restart count 1
Jul 21 17:39:28.175: INFO: sonobuoy-e2e-job-9d9f8ba6e19c4dc2 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container e2e ready: true, restart count 0
Jul 21 17:39:28.175: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 21 17:39:28.175: INFO: default-http-backend-admin-656d9c9d8c-c8s9h from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container default-http-backend-admin ready: true, restart count 0
Jul 21 17:39:28.175: INFO: istio-ingress-6c8b8f96cd-dwlvc from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container istio-ingress ready: true, restart count 0
Jul 21 17:39:28.175: INFO: rafay-container-registry-6474bdcbcf-mgd9f from rcloud-admin started at 2019-07-21 16:47:23 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container registry ready: true, restart count 0
Jul 21 17:39:28.175: INFO: zookeeper-86bfd95d77-lxx59 from rcloud-infra started at 2019-07-21 16:45:33 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container zk-0 ready: true, restart count 0
Jul 21 17:39:28.175: INFO: workload-placement-746878b79f-dbd7b from rcloud-admin started at 2019-07-21 16:46:37 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.175: INFO: 	Container workload-placement ready: true, restart count 0
Jul 21 17:39:28.175: INFO: traffic-steering-547844bcf8-sj82z from rcloud-admin started at 2019-07-21 16:46:55 +0000 UTC (2 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 17:39:28.175: INFO: 	Container traffic-steering ready: true, restart count 0
Jul 21 17:39:28.175: INFO: authsrv-88696bc57-vx55z from rcloud-admin started at 2019-07-21 16:47:15 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container authsrv ready: true, restart count 0
Jul 21 17:39:28.175: INFO: edge-broker-5bf96697cf-l57cr from rcloud-infra started at 2019-07-21 16:47:45 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container edge-broker ready: true, restart count 0
Jul 21 17:39:28.175: INFO: kube-proxy-89z7m from kube-system started at 2019-07-21 16:40:24 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 21 17:39:28.175: INFO: heketi-84f9566569-55wr6 from kube-system started at 2019-07-21 16:44:03 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container heketi ready: true, restart count 0
Jul 21 17:39:28.175: INFO: tiller-deploy-85494c96cf-mtrlx from kube-system started at 2019-07-21 16:44:49 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container tiller ready: true, restart count 0
Jul 21 17:39:28.175: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-21 17:27:48 +0000 UTC (1 container statuses recorded)
Jul 21 17:39:28.175: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-222-31-145
Jul 21 17:39:28.212: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.212: INFO: Pod sonobuoy-e2e-job-9d9f8ba6e19c4dc2 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod sonobuoy-systemd-logs-daemon-set-5655e65ca0e146ed-znmf4 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod istio-ca-78655bf74f-jtfdj requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod istio-ingress-6c8b8f96cd-dwlvc requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod istio-mixer-86bc989497-v8bvv requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod istio-pilot-75c4c5dcc5-n4dxq requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod canal-sztcn requesting resource cpu=250m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod coredns-fb8b8dccf-ggr8r requesting resource cpu=100m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod coredns-fb8b8dccf-wrz8f requesting resource cpu=100m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod etcd-ip-10-222-31-145 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod glusterfs-8krmv requesting resource cpu=100m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod heketi-84f9566569-55wr6 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod kube-apiserver-ip-10-222-31-145 requesting resource cpu=250m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod kube-controller-manager-ip-10-222-31-145 requesting resource cpu=200m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod kube-proxy-89z7m requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod kube-scheduler-ip-10-222-31-145 requesting resource cpu=100m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod tiller-deploy-85494c96cf-mtrlx requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod admin-api-7758ff5dc6-t554w requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod admin-redis-599959c468-9bdcj requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.214: INFO: Pod authsrv-88696bc57-vx55z requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod config-processor-7847fd6f49-z4g58 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod debug-processor-76656764d-kh7gg requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod default-http-backend-admin-656d9c9d8c-c8s9h requesting resource cpu=10m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod edge-processor-68f574bb58-7xwpb requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod edgesrv-6459c565cb-z2898 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod frontend-7cc7768fc8-tmhds requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod frontend-opsconsole-65d75f5d69-mdz97 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod nginx-ingress-controller-admin-564f6884d8-gz2js requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod postgres-756f878d66-kdw48 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod rafay-container-registry-6474bdcbcf-mgd9f requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod regauth-8bd9db7c4-dmmnf requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod resource-allocation-8c8cdcfd8-njc4s requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod traffic-steering-547844bcf8-sj82z requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod workload-placement-746878b79f-dbd7b requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.215: INFO: Pod workload-processor-7c768567f6-zdlzm requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod config-broker-5c85977786-rvjlb requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod cryptosvc-d477c486-rtrnb requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod debug-broker-0 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod default-http-backend-55b84578bf-lghj8 requesting resource cpu=10m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod edge-broker-5bf96697cf-l57cr requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod edge-sec-665bf84b5d-nr27w requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod kafka-core-7c75bb8ccd-zrkn5 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod keygensvc-86d69565-94v4f requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod nginx-ingress-controller-78dcf4d98b-nzf98 requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod salt-master-6bc4f85449-hf78n requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod workload-broker-c5f8c89c-h6ssl requesting resource cpu=0m on Node ip-10-222-31-145
Jul 21 17:39:28.216: INFO: Pod zookeeper-86bfd95d77-lxx59 requesting resource cpu=0m on Node ip-10-222-31-145
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a.15b37cd945061fe4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7702/filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a to ip-10-222-31-145]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a.15b37cd99f7cc9ce], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a.15b37cd9a4bc6b4b], Reason = [Created], Message = [Created container filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a.15b37cd9bba66e3e], Reason = [Started], Message = [Started container filler-pod-7d24c9e0-abde-11e9-974c-16aa19c3723a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b37cda34694c8a], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node ip-10-222-31-145
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:39:33.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7702" for this suite.
Jul 21 17:39:39.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:39:39.861: INFO: namespace sched-pred-7702 deletion completed in 6.590223732s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.740 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:39:39.861: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 21 17:39:44.460: INFO: Successfully updated pod "labelsupdate841bc732-abde-11e9-974c-16aa19c3723a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:39:46.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8879" for this suite.
Jul 21 17:40:10.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:40:11.068: INFO: namespace projected-8879 deletion completed in 24.59012485s

â€¢ [SLOW TEST:31.207 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:40:11.068: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:40:11.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2090" for this suite.
Jul 21 17:40:17.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:40:17.808: INFO: namespace services-2090 deletion completed in 6.655147137s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:6.740 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:40:17.808: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9986/configmap-test-9abdb45a-abde-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 17:40:18.025: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a" in namespace "configmap-9986" to be "success or failure"
Jul 21 17:40:18.032: INFO: Pod "pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.20887ms
Jul 21 17:40:20.038: INFO: Pod "pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012949032s
Jul 21 17:40:22.042: INFO: Pod "pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017603646s
STEP: Saw pod success
Jul 21 17:40:22.042: INFO: Pod "pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:40:22.048: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a container env-test: <nil>
STEP: delete the pod
Jul 21 17:40:22.085: INFO: Waiting for pod pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a to disappear
Jul 21 17:40:22.093: INFO: Pod pod-configmaps-9ad0c592-abde-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:40:22.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9986" for this suite.
Jul 21 17:40:28.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:40:28.697: INFO: namespace configmap-9986 deletion completed in 6.601355708s

â€¢ [SLOW TEST:10.889 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:40:28.698: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 21 17:40:28.734: INFO: PodSpec: initContainers in spec.initContainers
Jul 21 17:41:21.119: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a1372d15-abde-11e9-974c-16aa19c3723a", GenerateName:"", Namespace:"init-container-8440", SelfLink:"/api/v1/namespaces/init-container-8440/pods/pod-init-a1372d15-abde-11e9-974c-16aa19c3723a", UID:"a138a20c-abde-11e9-9149-027a95377cb1", ResourceVersion:"9184", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63699327628, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"734804080"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.0.70/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-x4kwt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b91b80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x4kwt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x4kwt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x4kwt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0007a3d88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-222-31-145", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002be5980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007a3e20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007a3e40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0007a3e48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0007a3e4c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327628, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327628, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327628, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327628, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.222.31.145", PodIP:"10.244.0.70", StartTime:(*v1.Time)(0xc002454e20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000d80e70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a4dd007f4562b4fa9bbe4e18cb09e4392cfeb5a64fc6c0dc0136705fe4654676"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002454f60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002454f00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:41:21.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8440" for this suite.
Jul 21 17:41:43.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:41:43.719: INFO: namespace init-container-8440 deletion completed in 22.568655707s

â€¢ [SLOW TEST:75.022 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:41:43.719: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Jul 21 17:41:48.276: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2179 pod-service-account-ce3b2e22-abde-11e9-974c-16aa19c3723a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul 21 17:41:48.691: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2179 pod-service-account-ce3b2e22-abde-11e9-974c-16aa19c3723a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul 21 17:41:49.074: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2179 pod-service-account-ce3b2e22-abde-11e9-974c-16aa19c3723a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:41:49.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2179" for this suite.
Jul 21 17:41:55.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:41:56.150: INFO: namespace svcaccounts-2179 deletion completed in 6.571144374s

â€¢ [SLOW TEST:12.431 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:41:56.151: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Jul 21 17:41:56.182: INFO: Waiting up to 5m0s for pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a" in namespace "containers-744" to be "success or failure"
Jul 21 17:41:56.189: INFO: Pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.337802ms
Jul 21 17:41:58.199: INFO: Pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01716644s
Jul 21 17:42:00.212: INFO: Pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02986155s
Jul 21 17:42:02.215: INFO: Pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032604439s
STEP: Saw pod success
Jul 21 17:42:02.215: INFO: Pod "client-containers-d555dc35-abde-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:42:02.217: INFO: Trying to get logs from node ip-10-222-31-145 pod client-containers-d555dc35-abde-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 17:42:02.238: INFO: Waiting for pod client-containers-d555dc35-abde-11e9-974c-16aa19c3723a to disappear
Jul 21 17:42:02.247: INFO: Pod client-containers-d555dc35-abde-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:42:02.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-744" for this suite.
Jul 21 17:42:08.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:42:08.832: INFO: namespace containers-744 deletion completed in 6.581629525s

â€¢ [SLOW TEST:12.681 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:42:08.832: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 21 17:42:08.904: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:42:14.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6934" for this suite.
Jul 21 17:42:20.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:42:21.249: INFO: namespace init-container-6934 deletion completed in 6.611959624s

â€¢ [SLOW TEST:12.417 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:42:21.251: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e44f98b6-abde-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 17:42:21.327: INFO: Waiting up to 5m0s for pod "pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a" in namespace "configmap-108" to be "success or failure"
Jul 21 17:42:21.334: INFO: Pod "pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.09208ms
Jul 21 17:42:23.338: INFO: Pod "pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0106707s
Jul 21 17:42:25.341: INFO: Pod "pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013478513s
STEP: Saw pod success
Jul 21 17:42:25.341: INFO: Pod "pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:42:25.343: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 17:42:25.369: INFO: Waiting for pod pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a to disappear
Jul 21 17:42:25.376: INFO: Pod pod-configmaps-e450e6b4-abde-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:42:25.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-108" for this suite.
Jul 21 17:42:31.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:42:31.965: INFO: namespace configmap-108 deletion completed in 6.586826937s

â€¢ [SLOW TEST:10.715 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:42:31.966: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul 21 17:42:32.012: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9451,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 21 17:42:32.012: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9451,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul 21 17:42:42.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9470,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 21 17:42:42.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9470,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul 21 17:42:52.025: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9487,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 21 17:42:52.025: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9487,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul 21 17:43:02.032: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9505,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 21 17:43:02.032: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-a,UID:eab0f948-abde-11e9-9149-027a95377cb1,ResourceVersion:9505,Generation:0,CreationTimestamp:2019-07-21 17:42:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul 21 17:43:12.054: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-b,UID:028ceb5c-abdf-11e9-9149-027a95377cb1,ResourceVersion:9523,Generation:0,CreationTimestamp:2019-07-21 17:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 21 17:43:12.054: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-b,UID:028ceb5c-abdf-11e9-9149-027a95377cb1,ResourceVersion:9523,Generation:0,CreationTimestamp:2019-07-21 17:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul 21 17:43:22.060: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-b,UID:028ceb5c-abdf-11e9-9149-027a95377cb1,ResourceVersion:9541,Generation:0,CreationTimestamp:2019-07-21 17:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 21 17:43:22.060: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2438,SelfLink:/api/v1/namespaces/watch-2438/configmaps/e2e-watch-test-configmap-b,UID:028ceb5c-abdf-11e9-9149-027a95377cb1,ResourceVersion:9541,Generation:0,CreationTimestamp:2019-07-21 17:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:43:32.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2438" for this suite.
Jul 21 17:43:38.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:43:38.640: INFO: namespace watch-2438 deletion completed in 6.574563678s

â€¢ [SLOW TEST:66.675 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:43:38.640: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Jul 21 17:43:38.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-2176'
Jul 21 17:43:39.472: INFO: stderr: ""
Jul 21 17:43:39.472: INFO: stdout: "pod/pause created\n"
Jul 21 17:43:39.472: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 21 17:43:39.472: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2176" to be "running and ready"
Jul 21 17:43:39.483: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.213768ms
Jul 21 17:43:41.486: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014024551s
Jul 21 17:43:43.489: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.016701293s
Jul 21 17:43:43.489: INFO: Pod "pause" satisfied condition "running and ready"
Jul 21 17:43:43.489: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Jul 21 17:43:43.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 label pods pause testing-label=testing-label-value --namespace=kubectl-2176'
Jul 21 17:43:43.570: INFO: stderr: ""
Jul 21 17:43:43.570: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul 21 17:43:43.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pod pause -L testing-label --namespace=kubectl-2176'
Jul 21 17:43:43.677: INFO: stderr: ""
Jul 21 17:43:43.677: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul 21 17:43:43.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 label pods pause testing-label- --namespace=kubectl-2176'
Jul 21 17:43:43.766: INFO: stderr: ""
Jul 21 17:43:43.766: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul 21 17:43:43.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pod pause -L testing-label --namespace=kubectl-2176'
Jul 21 17:43:43.881: INFO: stderr: ""
Jul 21 17:43:43.881: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Jul 21 17:43:43.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-2176'
Jul 21 17:43:44.013: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 17:43:44.013: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 21 17:43:44.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get rc,svc -l name=pause --no-headers --namespace=kubectl-2176'
Jul 21 17:43:44.269: INFO: stderr: "No resources found.\n"
Jul 21 17:43:44.269: INFO: stdout: ""
Jul 21 17:43:44.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -l name=pause --namespace=kubectl-2176 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 21 17:43:44.583: INFO: stderr: ""
Jul 21 17:43:44.583: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:43:44.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2176" for this suite.
Jul 21 17:43:50.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:43:51.161: INFO: namespace kubectl-2176 deletion completed in 6.573573099s

â€¢ [SLOW TEST:12.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:43:51.161: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Jul 21 17:43:51.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-2352'
Jul 21 17:43:51.767: INFO: stderr: ""
Jul 21 17:43:51.767: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 17:43:51.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2352'
Jul 21 17:43:51.939: INFO: stderr: ""
Jul 21 17:43:51.939: INFO: stdout: "update-demo-nautilus-5887q update-demo-nautilus-nl2zw "
Jul 21 17:43:51.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-5887q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:43:52.193: INFO: stderr: ""
Jul 21 17:43:52.193: INFO: stdout: ""
Jul 21 17:43:52.193: INFO: update-demo-nautilus-5887q is created but not running
Jul 21 17:43:57.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2352'
Jul 21 17:43:57.318: INFO: stderr: ""
Jul 21 17:43:57.318: INFO: stdout: "update-demo-nautilus-5887q update-demo-nautilus-nl2zw "
Jul 21 17:43:57.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-5887q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:43:57.442: INFO: stderr: ""
Jul 21 17:43:57.442: INFO: stdout: "true"
Jul 21 17:43:57.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-5887q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:43:57.594: INFO: stderr: ""
Jul 21 17:43:57.594: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:43:57.594: INFO: validating pod update-demo-nautilus-5887q
Jul 21 17:43:57.600: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:43:57.600: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:43:57.600: INFO: update-demo-nautilus-5887q is verified up and running
Jul 21 17:43:57.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-nl2zw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:43:57.732: INFO: stderr: ""
Jul 21 17:43:57.732: INFO: stdout: "true"
Jul 21 17:43:57.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-nl2zw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:43:57.859: INFO: stderr: ""
Jul 21 17:43:57.859: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:43:57.859: INFO: validating pod update-demo-nautilus-nl2zw
Jul 21 17:43:57.871: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:43:57.871: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:43:57.871: INFO: update-demo-nautilus-nl2zw is verified up and running
STEP: rolling-update to new replication controller
Jul 21 17:43:57.873: INFO: scanned /root for discovery docs: <nil>
Jul 21 17:43:57.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2352'
Jul 21 17:44:21.547: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 21 17:44:21.548: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 17:44:21.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2352'
Jul 21 17:44:21.733: INFO: stderr: ""
Jul 21 17:44:21.733: INFO: stdout: "update-demo-kitten-8xmv5 update-demo-kitten-z46bt update-demo-nautilus-nl2zw "
STEP: Replicas for name=update-demo: expected=2 actual=3
Jul 21 17:44:26.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2352'
Jul 21 17:44:26.816: INFO: stderr: ""
Jul 21 17:44:26.816: INFO: stdout: "update-demo-kitten-8xmv5 update-demo-kitten-z46bt "
Jul 21 17:44:26.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-kitten-8xmv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:44:26.893: INFO: stderr: ""
Jul 21 17:44:26.893: INFO: stdout: "true"
Jul 21 17:44:26.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-kitten-8xmv5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:44:26.966: INFO: stderr: ""
Jul 21 17:44:26.966: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 21 17:44:26.966: INFO: validating pod update-demo-kitten-8xmv5
Jul 21 17:44:26.969: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 21 17:44:26.969: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 21 17:44:26.969: INFO: update-demo-kitten-8xmv5 is verified up and running
Jul 21 17:44:26.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-kitten-z46bt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:44:27.062: INFO: stderr: ""
Jul 21 17:44:27.062: INFO: stdout: "true"
Jul 21 17:44:27.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-kitten-z46bt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2352'
Jul 21 17:44:27.139: INFO: stderr: ""
Jul 21 17:44:27.139: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 21 17:44:27.139: INFO: validating pod update-demo-kitten-z46bt
Jul 21 17:44:27.142: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 21 17:44:27.142: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 21 17:44:27.142: INFO: update-demo-kitten-z46bt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:44:27.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2352" for this suite.
Jul 21 17:44:51.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:44:51.748: INFO: namespace kubectl-2352 deletion completed in 24.603162306s

â€¢ [SLOW TEST:60.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:44:51.751: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Jul 21 17:44:52.531: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul 21 17:44:54.584: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:44:56.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:44:58.588: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:45:00.591: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:45:02.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:45:04.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699327892, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 17:45:07.580: INFO: Waited 987.688353ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:45:08.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1571" for this suite.
Jul 21 17:45:16.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:45:17.376: INFO: namespace aggregator-1571 deletion completed in 8.615663995s

â€¢ [SLOW TEST:25.625 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:45:17.377: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-4d4dede7-abdf-11e9-974c-16aa19c3723a
STEP: Creating configMap with name cm-test-opt-upd-4d4dee3e-abdf-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4d4dede7-abdf-11e9-974c-16aa19c3723a
STEP: Updating configmap cm-test-opt-upd-4d4dee3e-abdf-11e9-974c-16aa19c3723a
STEP: Creating configMap with name cm-test-opt-create-4d4dee58-abdf-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:45:27.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3600" for this suite.
Jul 21 17:45:49.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:45:50.417: INFO: namespace projected-3600 deletion completed in 22.597937207s

â€¢ [SLOW TEST:33.041 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:45:50.417: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 21 17:45:50.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-515'
Jul 21 17:45:51.056: INFO: stderr: ""
Jul 21 17:45:51.056: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 17:45:51.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:45:51.650: INFO: stderr: ""
Jul 21 17:45:51.650: INFO: stdout: "update-demo-nautilus-ht4t8 update-demo-nautilus-rlrdb "
Jul 21 17:45:51.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:45:51.961: INFO: stderr: ""
Jul 21 17:45:51.961: INFO: stdout: ""
Jul 21 17:45:51.961: INFO: update-demo-nautilus-ht4t8 is created but not running
Jul 21 17:45:56.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:45:57.062: INFO: stderr: ""
Jul 21 17:45:57.062: INFO: stdout: "update-demo-nautilus-ht4t8 update-demo-nautilus-rlrdb "
Jul 21 17:45:57.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:45:57.167: INFO: stderr: ""
Jul 21 17:45:57.167: INFO: stdout: "true"
Jul 21 17:45:57.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:45:57.295: INFO: stderr: ""
Jul 21 17:45:57.295: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:45:57.295: INFO: validating pod update-demo-nautilus-ht4t8
Jul 21 17:45:57.298: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:45:57.298: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:45:57.298: INFO: update-demo-nautilus-ht4t8 is verified up and running
Jul 21 17:45:57.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-rlrdb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:45:57.483: INFO: stderr: ""
Jul 21 17:45:57.483: INFO: stdout: "true"
Jul 21 17:45:57.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-rlrdb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:45:57.628: INFO: stderr: ""
Jul 21 17:45:57.628: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:45:57.628: INFO: validating pod update-demo-nautilus-rlrdb
Jul 21 17:45:57.635: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:45:57.635: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:45:57.636: INFO: update-demo-nautilus-rlrdb is verified up and running
STEP: scaling down the replication controller
Jul 21 17:45:57.643: INFO: scanned /root for discovery docs: <nil>
Jul 21 17:45:57.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-515'
Jul 21 17:45:58.933: INFO: stderr: ""
Jul 21 17:45:58.933: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 17:45:58.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:45:59.332: INFO: stderr: ""
Jul 21 17:45:59.332: INFO: stdout: "update-demo-nautilus-ht4t8 update-demo-nautilus-rlrdb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 21 17:46:04.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:46:04.569: INFO: stderr: ""
Jul 21 17:46:04.569: INFO: stdout: "update-demo-nautilus-ht4t8 "
Jul 21 17:46:04.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:04.741: INFO: stderr: ""
Jul 21 17:46:04.741: INFO: stdout: "true"
Jul 21 17:46:04.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:05.027: INFO: stderr: ""
Jul 21 17:46:05.027: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:46:05.027: INFO: validating pod update-demo-nautilus-ht4t8
Jul 21 17:46:05.039: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:46:05.039: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:46:05.039: INFO: update-demo-nautilus-ht4t8 is verified up and running
STEP: scaling up the replication controller
Jul 21 17:46:05.041: INFO: scanned /root for discovery docs: <nil>
Jul 21 17:46:05.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-515'
Jul 21 17:46:06.538: INFO: stderr: ""
Jul 21 17:46:06.538: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 17:46:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:46:06.833: INFO: stderr: ""
Jul 21 17:46:06.833: INFO: stdout: "update-demo-nautilus-4hw7j update-demo-nautilus-ht4t8 "
Jul 21 17:46:06.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-4hw7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:06.941: INFO: stderr: ""
Jul 21 17:46:06.941: INFO: stdout: ""
Jul 21 17:46:06.941: INFO: update-demo-nautilus-4hw7j is created but not running
Jul 21 17:46:11.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-515'
Jul 21 17:46:12.715: INFO: stderr: ""
Jul 21 17:46:12.715: INFO: stdout: "update-demo-nautilus-4hw7j update-demo-nautilus-ht4t8 "
Jul 21 17:46:12.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-4hw7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:13.000: INFO: stderr: ""
Jul 21 17:46:13.000: INFO: stdout: "true"
Jul 21 17:46:13.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-4hw7j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:13.533: INFO: stderr: ""
Jul 21 17:46:13.533: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:46:13.533: INFO: validating pod update-demo-nautilus-4hw7j
Jul 21 17:46:13.547: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:46:13.547: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:46:13.547: INFO: update-demo-nautilus-4hw7j is verified up and running
Jul 21 17:46:13.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:13.811: INFO: stderr: ""
Jul 21 17:46:13.811: INFO: stdout: "true"
Jul 21 17:46:13.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-ht4t8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-515'
Jul 21 17:46:14.568: INFO: stderr: ""
Jul 21 17:46:14.568: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 17:46:14.568: INFO: validating pod update-demo-nautilus-ht4t8
Jul 21 17:46:14.669: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 17:46:14.669: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 17:46:14.669: INFO: update-demo-nautilus-ht4t8 is verified up and running
STEP: using delete to clean up resources
Jul 21 17:46:14.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-515'
Jul 21 17:46:15.915: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 17:46:15.915: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 21 17:46:15.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-515'
Jul 21 17:46:16.689: INFO: stderr: "No resources found.\n"
Jul 21 17:46:16.689: INFO: stdout: ""
Jul 21 17:46:16.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -l name=update-demo --namespace=kubectl-515 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 21 17:46:17.287: INFO: stderr: ""
Jul 21 17:46:17.287: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:46:17.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-515" for this suite.
Jul 21 17:46:41.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:46:41.900: INFO: namespace kubectl-515 deletion completed in 24.610212573s

â€¢ [SLOW TEST:51.482 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:46:41.903: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 21 17:46:42.002: INFO: Waiting up to 5m0s for pod "downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a" in namespace "downward-api-7833" to be "success or failure"
Jul 21 17:46:42.010: INFO: Pod "downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.358638ms
Jul 21 17:46:44.019: INFO: Pod "downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017542795s
Jul 21 17:46:46.027: INFO: Pod "downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025470964s
STEP: Saw pod success
Jul 21 17:46:46.027: INFO: Pod "downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:46:46.053: INFO: Trying to get logs from node ip-10-222-31-145 pod downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 17:46:46.135: INFO: Waiting for pod downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:46:46.147: INFO: Pod downward-api-7fb0bcc0-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:46:46.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7833" for this suite.
Jul 21 17:46:52.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:46:52.740: INFO: namespace downward-api-7833 deletion completed in 6.587259849s

â€¢ [SLOW TEST:10.837 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:46:52.741: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 21 17:46:52.826: INFO: Waiting up to 5m0s for pod "pod-86213141-abdf-11e9-974c-16aa19c3723a" in namespace "emptydir-4791" to be "success or failure"
Jul 21 17:46:52.834: INFO: Pod "pod-86213141-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021817ms
Jul 21 17:46:54.839: INFO: Pod "pod-86213141-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013252301s
Jul 21 17:46:56.843: INFO: Pod "pod-86213141-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017549747s
STEP: Saw pod success
Jul 21 17:46:56.844: INFO: Pod "pod-86213141-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:46:56.847: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-86213141-abdf-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 17:46:56.908: INFO: Waiting for pod pod-86213141-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:46:56.913: INFO: Pod pod-86213141-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:46:56.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4791" for this suite.
Jul 21 17:47:02.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:47:03.522: INFO: namespace emptydir-4791 deletion completed in 6.604325173s

â€¢ [SLOW TEST:10.781 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:47:03.523: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-8c8c7519-abdf-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 17:47:03.576: INFO: Waiting up to 5m0s for pod "pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a" in namespace "secrets-3346" to be "success or failure"
Jul 21 17:47:03.595: INFO: Pod "pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.564142ms
Jul 21 17:47:05.623: INFO: Pod "pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04690857s
Jul 21 17:47:07.632: INFO: Pod "pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056386583s
STEP: Saw pod success
Jul 21 17:47:07.632: INFO: Pod "pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:47:07.635: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 17:47:07.665: INFO: Waiting for pod pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:47:07.672: INFO: Pod pod-secrets-8c8d21b7-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:47:07.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3346" for this suite.
Jul 21 17:47:13.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:47:14.291: INFO: namespace secrets-3346 deletion completed in 6.610549497s

â€¢ [SLOW TEST:10.768 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:47:14.291: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 17:47:14.414: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9302b849-abdf-11e9-9149-027a95377cb1", Controller:(*bool)(0xc0021782e6), BlockOwnerDeletion:(*bool)(0xc0021782e7)}}
Jul 21 17:47:14.428: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"92ff5e31-abdf-11e9-9149-027a95377cb1", Controller:(*bool)(0xc0007153c6), BlockOwnerDeletion:(*bool)(0xc0007153c7)}}
Jul 21 17:47:14.440: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9300a964-abdf-11e9-9149-027a95377cb1", Controller:(*bool)(0xc0021784a6), BlockOwnerDeletion:(*bool)(0xc0021784a7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:47:19.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1414" for this suite.
Jul 21 17:47:25.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:47:26.116: INFO: namespace gc-1414 deletion completed in 6.639392634s

â€¢ [SLOW TEST:11.825 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:47:26.119: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 17:47:26.206: INFO: Conformance test suite needs a cluster with at least 2 nodes.
Jul 21 17:47:26.206: INFO: Create a RollingUpdate DaemonSet
Jul 21 17:47:26.212: INFO: Check that daemon pods launch on every node of the cluster
Jul 21 17:47:26.220: INFO: Number of nodes with available pods: 0
Jul 21 17:47:26.220: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:47:27.234: INFO: Number of nodes with available pods: 0
Jul 21 17:47:27.234: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:47:28.253: INFO: Number of nodes with available pods: 0
Jul 21 17:47:28.253: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 17:47:29.232: INFO: Number of nodes with available pods: 1
Jul 21 17:47:29.233: INFO: Number of running nodes: 1, number of available pods: 1
Jul 21 17:47:29.233: INFO: Update the DaemonSet to trigger a rollout
Jul 21 17:47:29.247: INFO: Updating DaemonSet daemon-set
Jul 21 17:47:35.297: INFO: Roll back the DaemonSet before rollout is complete
Jul 21 17:47:35.315: INFO: Updating DaemonSet daemon-set
Jul 21 17:47:35.315: INFO: Make sure DaemonSet rollback is complete
Jul 21 17:47:35.320: INFO: Wrong image for pod: daemon-set-b26kj. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 21 17:47:35.320: INFO: Pod daemon-set-b26kj is not available
Jul 21 17:47:36.346: INFO: Wrong image for pod: daemon-set-b26kj. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 21 17:47:36.346: INFO: Pod daemon-set-b26kj is not available
Jul 21 17:47:37.339: INFO: Pod daemon-set-8hcw5 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7885, will wait for the garbage collector to delete the pods
Jul 21 17:47:37.432: INFO: Deleting DaemonSet.extensions daemon-set took: 18.210368ms
Jul 21 17:47:37.432: INFO: Terminating DaemonSet.extensions daemon-set pods took: 79.694Âµs
Jul 21 17:47:38.636: INFO: Number of nodes with available pods: 0
Jul 21 17:47:38.636: INFO: Number of running nodes: 0, number of available pods: 0
Jul 21 17:47:38.643: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7885/daemonsets","resourceVersion":"10675"},"items":null}

Jul 21 17:47:38.646: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7885/pods","resourceVersion":"10675"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:47:38.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7885" for this suite.
Jul 21 17:47:44.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:47:45.237: INFO: namespace daemonsets-7885 deletion completed in 6.576742614s

â€¢ [SLOW TEST:19.118 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:47:45.239: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a56b0a57-abdf-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 17:47:45.292: INFO: Waiting up to 5m0s for pod "pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a" in namespace "secrets-7420" to be "success or failure"
Jul 21 17:47:45.294: INFO: Pod "pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.492846ms
Jul 21 17:47:47.298: INFO: Pod "pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006089814s
Jul 21 17:47:49.304: INFO: Pod "pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012519508s
STEP: Saw pod success
Jul 21 17:47:49.304: INFO: Pod "pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:47:49.310: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a container secret-env-test: <nil>
STEP: delete the pod
Jul 21 17:47:49.332: INFO: Waiting for pod pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:47:49.337: INFO: Pod pod-secrets-a56b7f30-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:47:49.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7420" for this suite.
Jul 21 17:47:55.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:47:55.937: INFO: namespace secrets-7420 deletion completed in 6.597427282s

â€¢ [SLOW TEST:10.697 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:47:55.937: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 21 17:47:56.028: INFO: Waiting up to 5m0s for pod "downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a" in namespace "downward-api-1758" to be "success or failure"
Jul 21 17:47:56.040: INFO: Pod "downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.469916ms
Jul 21 17:47:58.045: INFO: Pod "downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01746229s
Jul 21 17:48:00.053: INFO: Pod "downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024720289s
STEP: Saw pod success
Jul 21 17:48:00.055: INFO: Pod "downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:48:00.059: INFO: Trying to get logs from node ip-10-222-31-145 pod downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 17:48:00.108: INFO: Waiting for pod downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:48:00.114: INFO: Pod downward-api-abcff4be-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:48:00.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1758" for this suite.
Jul 21 17:48:06.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:48:06.701: INFO: namespace downward-api-1758 deletion completed in 6.581969809s

â€¢ [SLOW TEST:10.764 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:48:06.701: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-b236faff-abdf-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 17:48:06.767: INFO: Waiting up to 5m0s for pod "pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a" in namespace "configmap-8965" to be "success or failure"
Jul 21 17:48:06.786: INFO: Pod "pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.141944ms
Jul 21 17:48:08.789: INFO: Pod "pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02206428s
Jul 21 17:48:10.794: INFO: Pod "pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026091661s
STEP: Saw pod success
Jul 21 17:48:10.794: INFO: Pod "pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:48:10.800: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 17:48:10.838: INFO: Waiting for pod pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:48:10.849: INFO: Pod pod-configmaps-b238050f-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:48:10.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8965" for this suite.
Jul 21 17:48:16.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:48:17.468: INFO: namespace configmap-8965 deletion completed in 6.602848617s

â€¢ [SLOW TEST:10.767 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:48:17.468: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 17:48:17.502: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a" in namespace "projected-1149" to be "success or failure"
Jul 21 17:48:17.514: INFO: Pod "downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.733693ms
Jul 21 17:48:19.517: INFO: Pod "downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014962029s
Jul 21 17:48:21.522: INFO: Pod "downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019200623s
STEP: Saw pod success
Jul 21 17:48:21.522: INFO: Pod "downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:48:21.526: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 17:48:21.569: INFO: Waiting for pod downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a to disappear
Jul 21 17:48:21.579: INFO: Pod downwardapi-volume-b89dfaa7-abdf-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:48:21.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1149" for this suite.
Jul 21 17:48:27.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:48:28.185: INFO: namespace projected-1149 deletion completed in 6.581456515s

â€¢ [SLOW TEST:10.717 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:48:28.185: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-x6s8
STEP: Creating a pod to test atomic-volume-subpath
Jul 21 17:48:28.225: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x6s8" in namespace "subpath-7822" to be "success or failure"
Jul 21 17:48:28.239: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.110461ms
Jul 21 17:48:30.245: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019729615s
Jul 21 17:48:32.249: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 4.023495626s
Jul 21 17:48:34.254: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 6.02834181s
Jul 21 17:48:36.257: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 8.031572515s
Jul 21 17:48:38.260: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 10.034300303s
Jul 21 17:48:40.262: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 12.036913375s
Jul 21 17:48:42.265: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 14.039443686s
Jul 21 17:48:44.268: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 16.043036306s
Jul 21 17:48:46.272: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 18.046600696s
Jul 21 17:48:48.279: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 20.053588644s
Jul 21 17:48:50.284: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Running", Reason="", readiness=true. Elapsed: 22.058544831s
Jul 21 17:48:52.287: INFO: Pod "pod-subpath-test-configmap-x6s8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061096876s
STEP: Saw pod success
Jul 21 17:48:52.287: INFO: Pod "pod-subpath-test-configmap-x6s8" satisfied condition "success or failure"
Jul 21 17:48:52.289: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-subpath-test-configmap-x6s8 container test-container-subpath-configmap-x6s8: <nil>
STEP: delete the pod
Jul 21 17:48:52.321: INFO: Waiting for pod pod-subpath-test-configmap-x6s8 to disappear
Jul 21 17:48:52.325: INFO: Pod pod-subpath-test-configmap-x6s8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x6s8
Jul 21 17:48:52.325: INFO: Deleting pod "pod-subpath-test-configmap-x6s8" in namespace "subpath-7822"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:48:52.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7822" for this suite.
Jul 21 17:48:58.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:48:58.905: INFO: namespace subpath-7822 deletion completed in 6.572182095s

â€¢ [SLOW TEST:30.720 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:48:58.906: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2232
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 21 17:48:58.946: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 21 17:49:23.027: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.94:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2232 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 17:49:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 17:49:23.259: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:49:23.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2232" for this suite.
Jul 21 17:49:45.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:49:45.843: INFO: namespace pod-network-test-2232 deletion completed in 22.580899994s

â€¢ [SLOW TEST:46.937 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:49:45.843: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 21 17:49:45.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-7341'
Jul 21 17:49:46.394: INFO: stderr: ""
Jul 21 17:49:46.394: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 21 17:49:47.408: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:47.408: INFO: Found 0 / 1
Jul 21 17:49:48.400: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:48.400: INFO: Found 0 / 1
Jul 21 17:49:49.398: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:49.398: INFO: Found 0 / 1
Jul 21 17:49:50.411: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:50.411: INFO: Found 1 / 1
Jul 21 17:49:50.411: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul 21 17:49:50.417: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:50.417: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 21 17:49:50.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 patch pod redis-master-md6v2 --namespace=kubectl-7341 -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 21 17:49:50.695: INFO: stderr: ""
Jul 21 17:49:50.695: INFO: stdout: "pod/redis-master-md6v2 patched\n"
STEP: checking annotations
Jul 21 17:49:50.698: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 17:49:50.698: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:49:50.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7341" for this suite.
Jul 21 17:50:14.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:50:15.298: INFO: namespace kubectl-7341 deletion completed in 24.597738663s

â€¢ [SLOW TEST:29.454 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:50:15.298: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0721 17:50:25.375053      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 17:50:25.375: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:50:25.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1290" for this suite.
Jul 21 17:50:31.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:50:32.004: INFO: namespace gc-1290 deletion completed in 6.627293977s

â€¢ [SLOW TEST:16.707 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:50:32.006: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-3863
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3863
STEP: Deleting pre-stop pod
Jul 21 17:50:45.116: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:50:45.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3863" for this suite.
Jul 21 17:51:25.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:51:25.729: INFO: namespace prestop-3863 deletion completed in 40.584293816s

â€¢ [SLOW TEST:53.724 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:51:25.730: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 17:51:25.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a" in namespace "downward-api-6399" to be "success or failure"
Jul 21 17:51:25.857: INFO: Pod "downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.502948ms
Jul 21 17:51:27.878: INFO: Pod "downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045944287s
Jul 21 17:51:29.880: INFO: Pod "downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048582525s
STEP: Saw pod success
Jul 21 17:51:29.881: INFO: Pod "downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:51:29.883: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 17:51:29.900: INFO: Waiting for pod downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a to disappear
Jul 21 17:51:29.904: INFO: Pod downwardapi-volume-28dd3bd8-abe0-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:51:29.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6399" for this suite.
Jul 21 17:51:35.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:51:36.500: INFO: namespace downward-api-6399 deletion completed in 6.594050316s

â€¢ [SLOW TEST:10.770 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:51:36.500: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 17:51:36.543: INFO: (0) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.383132ms)
Jul 21 17:51:36.551: INFO: (1) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.919178ms)
Jul 21 17:51:36.560: INFO: (2) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 8.749498ms)
Jul 21 17:51:36.578: INFO: (3) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 18.531696ms)
Jul 21 17:51:36.586: INFO: (4) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.32019ms)
Jul 21 17:51:36.593: INFO: (5) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.064249ms)
Jul 21 17:51:36.599: INFO: (6) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.904805ms)
Jul 21 17:51:36.606: INFO: (7) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.920811ms)
Jul 21 17:51:36.610: INFO: (8) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.77215ms)
Jul 21 17:51:36.613: INFO: (9) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.292898ms)
Jul 21 17:51:36.617: INFO: (10) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.558638ms)
Jul 21 17:51:36.619: INFO: (11) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.665707ms)
Jul 21 17:51:36.622: INFO: (12) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.454784ms)
Jul 21 17:51:36.625: INFO: (13) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.872484ms)
Jul 21 17:51:36.630: INFO: (14) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.290262ms)
Jul 21 17:51:36.634: INFO: (15) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.362102ms)
Jul 21 17:51:36.637: INFO: (16) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.153998ms)
Jul 21 17:51:36.641: INFO: (17) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.336088ms)
Jul 21 17:51:36.645: INFO: (18) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.469684ms)
Jul 21 17:51:36.647: INFO: (19) /api/v1/nodes/ip-10-222-31-145/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.429057ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:51:36.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-376" for this suite.
Jul 21 17:51:42.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:51:42.763: INFO: namespace proxy-376 deletion completed in 6.113140784s

â€¢ [SLOW TEST:6.263 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:51:42.763: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 17:51:42.800: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a" in namespace "downward-api-1610" to be "success or failure"
Jul 21 17:51:42.804: INFO: Pod "downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012145ms
Jul 21 17:51:44.815: INFO: Pod "downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015132761s
Jul 21 17:51:46.818: INFO: Pod "downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017597679s
STEP: Saw pod success
Jul 21 17:51:46.818: INFO: Pod "downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:51:46.820: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 17:51:46.834: INFO: Waiting for pod downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a to disappear
Jul 21 17:51:46.836: INFO: Pod downwardapi-volume-32fb8713-abe0-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:51:46.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1610" for this suite.
Jul 21 17:51:52.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:51:53.418: INFO: namespace downward-api-1610 deletion completed in 6.580868218s

â€¢ [SLOW TEST:10.655 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:51:53.419: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 21 17:51:53.455: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:51:58.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-833" for this suite.
Jul 21 17:52:04.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:52:04.674: INFO: namespace init-container-833 deletion completed in 6.638936542s

â€¢ [SLOW TEST:11.255 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:52:04.675: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1191
Jul 21 17:52:08.812: INFO: Started pod liveness-http in namespace container-probe-1191
STEP: checking the pod's current state and verifying that restartCount is present
Jul 21 17:52:08.815: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:56:09.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1191" for this suite.
Jul 21 17:56:15.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:56:16.271: INFO: namespace container-probe-1191 deletion completed in 6.626677125s

â€¢ [SLOW TEST:251.596 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:56:16.271: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 17:56:16.367: INFO: (0) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.174698ms)
Jul 21 17:56:16.385: INFO: (1) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 17.931918ms)
Jul 21 17:56:16.390: INFO: (2) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.718228ms)
Jul 21 17:56:16.396: INFO: (3) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.263457ms)
Jul 21 17:56:16.402: INFO: (4) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.072674ms)
Jul 21 17:56:16.415: INFO: (5) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 12.627695ms)
Jul 21 17:56:16.423: INFO: (6) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.929379ms)
Jul 21 17:56:16.431: INFO: (7) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 8.126228ms)
Jul 21 17:56:16.444: INFO: (8) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 12.377921ms)
Jul 21 17:56:16.447: INFO: (9) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.330201ms)
Jul 21 17:56:16.454: INFO: (10) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.612521ms)
Jul 21 17:56:16.458: INFO: (11) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.802732ms)
Jul 21 17:56:16.462: INFO: (12) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.896807ms)
Jul 21 17:56:16.465: INFO: (13) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.051711ms)
Jul 21 17:56:16.468: INFO: (14) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.2917ms)
Jul 21 17:56:16.472: INFO: (15) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.29649ms)
Jul 21 17:56:16.476: INFO: (16) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.811137ms)
Jul 21 17:56:16.482: INFO: (17) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.313235ms)
Jul 21 17:56:16.489: INFO: (18) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.057686ms)
Jul 21 17:56:16.494: INFO: (19) /api/v1/nodes/ip-10-222-31-145:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.73374ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:56:16.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5954" for this suite.
Jul 21 17:56:22.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:56:22.674: INFO: namespace proxy-5954 deletion completed in 6.161458258s

â€¢ [SLOW TEST:6.402 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:56:22.674: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d9d2a151-abe0-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 17:56:22.719: INFO: Waiting up to 5m0s for pod "pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a" in namespace "secrets-2084" to be "success or failure"
Jul 21 17:56:22.722: INFO: Pod "pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.286052ms
Jul 21 17:56:24.726: INFO: Pod "pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006796483s
Jul 21 17:56:26.729: INFO: Pod "pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009578417s
STEP: Saw pod success
Jul 21 17:56:26.729: INFO: Pod "pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 17:56:26.732: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 17:56:26.756: INFO: Waiting for pod pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a to disappear
Jul 21 17:56:26.760: INFO: Pod pod-secrets-d9d3c765-abe0-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:56:26.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2084" for this suite.
Jul 21 17:56:32.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:56:33.370: INFO: namespace secrets-2084 deletion completed in 6.608200344s

â€¢ [SLOW TEST:10.696 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:56:33.370: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Jul 21 17:56:33.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 cluster-info'
Jul 21 17:56:34.168: INFO: stderr: ""
Jul 21 17:56:34.168: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:56:34.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3498" for this suite.
Jul 21 17:56:40.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:56:40.795: INFO: namespace kubectl-3498 deletion completed in 6.617985869s

â€¢ [SLOW TEST:7.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:56:40.795: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4929
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 21 17:56:40.858: INFO: Found 0 stateful pods, waiting for 3
Jul 21 17:56:50.869: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 17:56:50.869: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 17:56:50.869: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 17:56:50.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-4929 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:56:51.678: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:56:51.678: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:56:51.678: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 21 17:57:01.714: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul 21 17:57:11.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-4929 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:57:12.280: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 17:57:12.280: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 17:57:12.280: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 17:57:22.304: INFO: Waiting for StatefulSet statefulset-4929/ss2 to complete update
Jul 21 17:57:22.304: INFO: Waiting for Pod statefulset-4929/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 21 17:57:22.304: INFO: Waiting for Pod statefulset-4929/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 21 17:57:32.309: INFO: Waiting for StatefulSet statefulset-4929/ss2 to complete update
Jul 21 17:57:32.310: INFO: Waiting for Pod statefulset-4929/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 21 17:57:32.310: INFO: Waiting for Pod statefulset-4929/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 21 17:57:42.309: INFO: Waiting for StatefulSet statefulset-4929/ss2 to complete update
Jul 21 17:57:42.309: INFO: Waiting for Pod statefulset-4929/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jul 21 17:57:52.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-4929 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 17:57:52.681: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 17:57:52.681: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 17:57:52.681: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 17:58:02.711: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul 21 17:58:12.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-4929 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 17:58:13.043: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 17:58:13.043: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 17:58:13.043: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 21 17:58:43.060: INFO: Deleting all statefulset in ns statefulset-4929
Jul 21 17:58:43.061: INFO: Scaling statefulset ss2 to 0
Jul 21 17:59:03.074: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 17:59:03.076: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:59:03.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4929" for this suite.
Jul 21 17:59:09.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:59:09.671: INFO: namespace statefulset-4929 deletion completed in 6.579765132s

â€¢ [SLOW TEST:148.876 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:59:09.671: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8998
I0721 17:59:09.722740      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8998, replica count: 1
I0721 17:59:10.773267      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 17:59:11.775448      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 17:59:12.775668      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 21 17:59:12.890: INFO: Created: latency-svc-z8np7
Jul 21 17:59:12.893: INFO: Got endpoints: latency-svc-z8np7 [17.455007ms]
Jul 21 17:59:12.916: INFO: Created: latency-svc-xpj7v
Jul 21 17:59:12.918: INFO: Got endpoints: latency-svc-xpj7v [25.002696ms]
Jul 21 17:59:12.923: INFO: Created: latency-svc-dqvv5
Jul 21 17:59:12.929: INFO: Got endpoints: latency-svc-dqvv5 [35.118618ms]
Jul 21 17:59:12.937: INFO: Created: latency-svc-zdzhb
Jul 21 17:59:12.941: INFO: Got endpoints: latency-svc-zdzhb [47.012486ms]
Jul 21 17:59:12.951: INFO: Created: latency-svc-gsblc
Jul 21 17:59:12.953: INFO: Got endpoints: latency-svc-gsblc [59.565648ms]
Jul 21 17:59:12.963: INFO: Created: latency-svc-w7b4s
Jul 21 17:59:12.967: INFO: Got endpoints: latency-svc-w7b4s [72.761498ms]
Jul 21 17:59:12.992: INFO: Created: latency-svc-s4s4c
Jul 21 17:59:12.999: INFO: Got endpoints: latency-svc-s4s4c [105.175182ms]
Jul 21 17:59:13.003: INFO: Created: latency-svc-wvftb
Jul 21 17:59:13.004: INFO: Got endpoints: latency-svc-wvftb [109.822126ms]
Jul 21 17:59:13.013: INFO: Created: latency-svc-pwlq6
Jul 21 17:59:13.037: INFO: Got endpoints: latency-svc-pwlq6 [143.683204ms]
Jul 21 17:59:13.067: INFO: Created: latency-svc-nrlvx
Jul 21 17:59:13.067: INFO: Got endpoints: latency-svc-nrlvx [173.790533ms]
Jul 21 17:59:13.087: INFO: Created: latency-svc-jlbcj
Jul 21 17:59:13.090: INFO: Got endpoints: latency-svc-jlbcj [196.603042ms]
Jul 21 17:59:13.102: INFO: Created: latency-svc-5sv9x
Jul 21 17:59:13.112: INFO: Got endpoints: latency-svc-5sv9x [218.484152ms]
Jul 21 17:59:13.130: INFO: Created: latency-svc-df2sr
Jul 21 17:59:13.133: INFO: Got endpoints: latency-svc-df2sr [239.24734ms]
Jul 21 17:59:13.152: INFO: Created: latency-svc-8jm42
Jul 21 17:59:13.156: INFO: Got endpoints: latency-svc-8jm42 [261.677771ms]
Jul 21 17:59:13.206: INFO: Created: latency-svc-cwsqz
Jul 21 17:59:13.206: INFO: Got endpoints: latency-svc-cwsqz [312.225462ms]
Jul 21 17:59:13.256: INFO: Created: latency-svc-q57d6
Jul 21 17:59:13.256: INFO: Got endpoints: latency-svc-q57d6 [362.448263ms]
Jul 21 17:59:13.265: INFO: Created: latency-svc-hdx7z
Jul 21 17:59:13.275: INFO: Got endpoints: latency-svc-hdx7z [356.069412ms]
Jul 21 17:59:13.285: INFO: Created: latency-svc-4xs9p
Jul 21 17:59:13.290: INFO: Got endpoints: latency-svc-4xs9p [361.516206ms]
Jul 21 17:59:13.297: INFO: Created: latency-svc-5ntf6
Jul 21 17:59:13.305: INFO: Created: latency-svc-d8zfg
Jul 21 17:59:13.305: INFO: Got endpoints: latency-svc-5ntf6 [363.934428ms]
Jul 21 17:59:13.315: INFO: Got endpoints: latency-svc-d8zfg [360.670268ms]
Jul 21 17:59:13.329: INFO: Created: latency-svc-hgfkh
Jul 21 17:59:13.329: INFO: Got endpoints: latency-svc-hgfkh [360.116853ms]
Jul 21 17:59:13.339: INFO: Created: latency-svc-6zhc8
Jul 21 17:59:13.350: INFO: Got endpoints: latency-svc-6zhc8 [346.720316ms]
Jul 21 17:59:13.355: INFO: Created: latency-svc-77f7m
Jul 21 17:59:13.358: INFO: Got endpoints: latency-svc-77f7m [353.976914ms]
Jul 21 17:59:13.371: INFO: Created: latency-svc-d4blc
Jul 21 17:59:13.377: INFO: Got endpoints: latency-svc-d4blc [339.186092ms]
Jul 21 17:59:13.387: INFO: Created: latency-svc-ccxgx
Jul 21 17:59:13.391: INFO: Got endpoints: latency-svc-ccxgx [323.924131ms]
Jul 21 17:59:13.419: INFO: Created: latency-svc-x57zc
Jul 21 17:59:13.424: INFO: Got endpoints: latency-svc-x57zc [333.199459ms]
Jul 21 17:59:13.435: INFO: Created: latency-svc-gnkqh
Jul 21 17:59:13.439: INFO: Got endpoints: latency-svc-gnkqh [324.214182ms]
Jul 21 17:59:13.451: INFO: Created: latency-svc-mwd6s
Jul 21 17:59:13.451: INFO: Got endpoints: latency-svc-mwd6s [316.476124ms]
Jul 21 17:59:13.461: INFO: Created: latency-svc-447gk
Jul 21 17:59:13.466: INFO: Got endpoints: latency-svc-447gk [309.780204ms]
Jul 21 17:59:13.481: INFO: Created: latency-svc-sgkr7
Jul 21 17:59:13.486: INFO: Got endpoints: latency-svc-sgkr7 [280.378761ms]
Jul 21 17:59:13.510: INFO: Created: latency-svc-d8kxz
Jul 21 17:59:13.514: INFO: Got endpoints: latency-svc-d8kxz [257.433801ms]
Jul 21 17:59:13.542: INFO: Created: latency-svc-fmlrj
Jul 21 17:59:13.547: INFO: Got endpoints: latency-svc-fmlrj [267.85676ms]
Jul 21 17:59:13.561: INFO: Created: latency-svc-g6grr
Jul 21 17:59:13.561: INFO: Got endpoints: latency-svc-g6grr [270.937034ms]
Jul 21 17:59:13.616: INFO: Created: latency-svc-5scbj
Jul 21 17:59:13.616: INFO: Got endpoints: latency-svc-5scbj [311.221865ms]
Jul 21 17:59:13.631: INFO: Created: latency-svc-w52m2
Jul 21 17:59:13.631: INFO: Got endpoints: latency-svc-w52m2 [316.406462ms]
Jul 21 17:59:13.646: INFO: Created: latency-svc-vm7m9
Jul 21 17:59:13.654: INFO: Got endpoints: latency-svc-vm7m9 [325.60853ms]
Jul 21 17:59:13.680: INFO: Created: latency-svc-89lks
Jul 21 17:59:13.680: INFO: Got endpoints: latency-svc-89lks [330.20018ms]
Jul 21 17:59:13.696: INFO: Created: latency-svc-kkktk
Jul 21 17:59:13.708: INFO: Got endpoints: latency-svc-kkktk [349.867168ms]
Jul 21 17:59:13.716: INFO: Created: latency-svc-5dpzr
Jul 21 17:59:13.720: INFO: Got endpoints: latency-svc-5dpzr [342.643496ms]
Jul 21 17:59:13.742: INFO: Created: latency-svc-d7zhg
Jul 21 17:59:13.753: INFO: Got endpoints: latency-svc-d7zhg [361.036909ms]
Jul 21 17:59:13.760: INFO: Created: latency-svc-xxnrk
Jul 21 17:59:13.764: INFO: Got endpoints: latency-svc-xxnrk [340.000913ms]
Jul 21 17:59:13.784: INFO: Created: latency-svc-58pp5
Jul 21 17:59:13.784: INFO: Got endpoints: latency-svc-58pp5 [344.502023ms]
Jul 21 17:59:13.813: INFO: Created: latency-svc-5vhst
Jul 21 17:59:13.821: INFO: Got endpoints: latency-svc-5vhst [36.820684ms]
Jul 21 17:59:13.827: INFO: Created: latency-svc-b47n4
Jul 21 17:59:13.830: INFO: Got endpoints: latency-svc-b47n4 [379.088149ms]
Jul 21 17:59:13.853: INFO: Created: latency-svc-gsjq9
Jul 21 17:59:13.853: INFO: Got endpoints: latency-svc-gsjq9 [386.934229ms]
Jul 21 17:59:13.854: INFO: Created: latency-svc-q5c9r
Jul 21 17:59:13.862: INFO: Got endpoints: latency-svc-q5c9r [375.625935ms]
Jul 21 17:59:13.875: INFO: Created: latency-svc-4lgsw
Jul 21 17:59:13.878: INFO: Got endpoints: latency-svc-4lgsw [363.592739ms]
Jul 21 17:59:13.907: INFO: Created: latency-svc-7mqkr
Jul 21 17:59:13.925: INFO: Got endpoints: latency-svc-7mqkr [377.718408ms]
Jul 21 17:59:13.981: INFO: Created: latency-svc-v4qfc
Jul 21 17:59:14.000: INFO: Got endpoints: latency-svc-v4qfc [438.337461ms]
Jul 21 17:59:14.015: INFO: Created: latency-svc-7dzfj
Jul 21 17:59:14.023: INFO: Got endpoints: latency-svc-7dzfj [406.828086ms]
Jul 21 17:59:14.039: INFO: Created: latency-svc-fnswn
Jul 21 17:59:14.049: INFO: Got endpoints: latency-svc-fnswn [417.573684ms]
Jul 21 17:59:14.097: INFO: Created: latency-svc-rbbcp
Jul 21 17:59:14.105: INFO: Got endpoints: latency-svc-rbbcp [451.095375ms]
Jul 21 17:59:14.130: INFO: Created: latency-svc-k7vjr
Jul 21 17:59:14.149: INFO: Got endpoints: latency-svc-k7vjr [469.514339ms]
Jul 21 17:59:14.181: INFO: Created: latency-svc-jgh27
Jul 21 17:59:14.192: INFO: Got endpoints: latency-svc-jgh27 [484.099377ms]
Jul 21 17:59:14.206: INFO: Created: latency-svc-znqhw
Jul 21 17:59:14.213: INFO: Got endpoints: latency-svc-znqhw [492.847078ms]
Jul 21 17:59:14.262: INFO: Created: latency-svc-5znnz
Jul 21 17:59:14.273: INFO: Got endpoints: latency-svc-5znnz [520.358896ms]
Jul 21 17:59:14.327: INFO: Created: latency-svc-lxzhd
Jul 21 17:59:14.330: INFO: Got endpoints: latency-svc-lxzhd [565.074844ms]
Jul 21 17:59:14.376: INFO: Created: latency-svc-qbhs4
Jul 21 17:59:14.390: INFO: Got endpoints: latency-svc-qbhs4 [569.276923ms]
Jul 21 17:59:14.543: INFO: Created: latency-svc-rrqpt
Jul 21 17:59:14.573: INFO: Got endpoints: latency-svc-rrqpt [742.434469ms]
Jul 21 17:59:14.657: INFO: Created: latency-svc-8dppf
Jul 21 17:59:14.685: INFO: Got endpoints: latency-svc-8dppf [831.236359ms]
Jul 21 17:59:14.687: INFO: Created: latency-svc-5j2jp
Jul 21 17:59:14.693: INFO: Got endpoints: latency-svc-5j2jp [830.386956ms]
Jul 21 17:59:14.702: INFO: Created: latency-svc-qwpcp
Jul 21 17:59:14.740: INFO: Got endpoints: latency-svc-qwpcp [861.241946ms]
Jul 21 17:59:14.769: INFO: Created: latency-svc-47694
Jul 21 17:59:14.769: INFO: Got endpoints: latency-svc-47694 [844.348538ms]
Jul 21 17:59:14.802: INFO: Created: latency-svc-stkzp
Jul 21 17:59:14.805: INFO: Got endpoints: latency-svc-stkzp [804.827363ms]
Jul 21 17:59:14.830: INFO: Created: latency-svc-98tbh
Jul 21 17:59:14.830: INFO: Got endpoints: latency-svc-98tbh [806.974074ms]
Jul 21 17:59:14.848: INFO: Created: latency-svc-22rc9
Jul 21 17:59:14.959: INFO: Got endpoints: latency-svc-22rc9 [910.203017ms]
Jul 21 17:59:14.964: INFO: Created: latency-svc-kf5pv
Jul 21 17:59:14.997: INFO: Got endpoints: latency-svc-kf5pv [891.266746ms]
Jul 21 17:59:15.027: INFO: Created: latency-svc-wkk25
Jul 21 17:59:15.031: INFO: Got endpoints: latency-svc-wkk25 [881.064915ms]
Jul 21 17:59:15.050: INFO: Created: latency-svc-62mh9
Jul 21 17:59:15.054: INFO: Got endpoints: latency-svc-62mh9 [862.081585ms]
Jul 21 17:59:15.093: INFO: Created: latency-svc-mk9rh
Jul 21 17:59:15.097: INFO: Got endpoints: latency-svc-mk9rh [884.219335ms]
Jul 21 17:59:15.127: INFO: Created: latency-svc-9qb22
Jul 21 17:59:15.131: INFO: Got endpoints: latency-svc-9qb22 [857.487118ms]
Jul 21 17:59:15.156: INFO: Created: latency-svc-kcvld
Jul 21 17:59:15.177: INFO: Got endpoints: latency-svc-kcvld [847.005234ms]
Jul 21 17:59:15.191: INFO: Created: latency-svc-r6p2b
Jul 21 17:59:15.201: INFO: Got endpoints: latency-svc-r6p2b [810.698755ms]
Jul 21 17:59:15.247: INFO: Created: latency-svc-qn98n
Jul 21 17:59:15.248: INFO: Got endpoints: latency-svc-qn98n [675.106029ms]
Jul 21 17:59:15.287: INFO: Created: latency-svc-fzdqx
Jul 21 17:59:15.287: INFO: Got endpoints: latency-svc-fzdqx [602.472598ms]
Jul 21 17:59:15.302: INFO: Created: latency-svc-kwjl2
Jul 21 17:59:15.315: INFO: Got endpoints: latency-svc-kwjl2 [622.223915ms]
Jul 21 17:59:15.329: INFO: Created: latency-svc-dzf9w
Jul 21 17:59:15.330: INFO: Got endpoints: latency-svc-dzf9w [589.570621ms]
Jul 21 17:59:15.355: INFO: Created: latency-svc-c86pw
Jul 21 17:59:15.363: INFO: Got endpoints: latency-svc-c86pw [593.548277ms]
Jul 21 17:59:15.371: INFO: Created: latency-svc-lt7td
Jul 21 17:59:15.413: INFO: Got endpoints: latency-svc-lt7td [607.684289ms]
Jul 21 17:59:15.449: INFO: Created: latency-svc-6pgrl
Jul 21 17:59:15.453: INFO: Got endpoints: latency-svc-6pgrl [623.056767ms]
Jul 21 17:59:15.480: INFO: Created: latency-svc-z5l62
Jul 21 17:59:15.507: INFO: Got endpoints: latency-svc-z5l62 [547.999953ms]
Jul 21 17:59:15.516: INFO: Created: latency-svc-khnhb
Jul 21 17:59:15.536: INFO: Got endpoints: latency-svc-khnhb [539.097055ms]
Jul 21 17:59:15.572: INFO: Created: latency-svc-2r52t
Jul 21 17:59:15.573: INFO: Got endpoints: latency-svc-2r52t [540.098597ms]
Jul 21 17:59:15.610: INFO: Created: latency-svc-x9xdh
Jul 21 17:59:15.613: INFO: Got endpoints: latency-svc-x9xdh [554.284734ms]
Jul 21 17:59:15.664: INFO: Created: latency-svc-c98cp
Jul 21 17:59:15.664: INFO: Got endpoints: latency-svc-c98cp [566.345404ms]
Jul 21 17:59:15.802: INFO: Created: latency-svc-sgtvr
Jul 21 17:59:15.826: INFO: Got endpoints: latency-svc-sgtvr [693.330584ms]
Jul 21 17:59:15.898: INFO: Created: latency-svc-xhjb5
Jul 21 17:59:15.902: INFO: Got endpoints: latency-svc-xhjb5 [723.496593ms]
Jul 21 17:59:15.912: INFO: Created: latency-svc-c2cm7
Jul 21 17:59:15.944: INFO: Created: latency-svc-xssds
Jul 21 17:59:15.947: INFO: Got endpoints: latency-svc-c2cm7 [744.193634ms]
Jul 21 17:59:15.950: INFO: Got endpoints: latency-svc-xssds [701.71ms]
Jul 21 17:59:15.987: INFO: Created: latency-svc-2szp7
Jul 21 17:59:15.988: INFO: Got endpoints: latency-svc-2szp7 [700.376328ms]
Jul 21 17:59:15.998: INFO: Created: latency-svc-446tp
Jul 21 17:59:15.998: INFO: Got endpoints: latency-svc-446tp [679.506262ms]
Jul 21 17:59:16.041: INFO: Created: latency-svc-9js9w
Jul 21 17:59:16.064: INFO: Got endpoints: latency-svc-9js9w [733.75824ms]
Jul 21 17:59:16.111: INFO: Created: latency-svc-tvgsv
Jul 21 17:59:16.111: INFO: Got endpoints: latency-svc-tvgsv [747.652909ms]
Jul 21 17:59:16.128: INFO: Created: latency-svc-48jhz
Jul 21 17:59:16.132: INFO: Got endpoints: latency-svc-48jhz [715.350282ms]
Jul 21 17:59:16.158: INFO: Created: latency-svc-8mrw9
Jul 21 17:59:16.164: INFO: Got endpoints: latency-svc-8mrw9 [708.841629ms]
Jul 21 17:59:16.180: INFO: Created: latency-svc-nhtnp
Jul 21 17:59:16.201: INFO: Got endpoints: latency-svc-nhtnp [693.743409ms]
Jul 21 17:59:16.207: INFO: Created: latency-svc-5jc5z
Jul 21 17:59:16.219: INFO: Created: latency-svc-mvlzb
Jul 21 17:59:16.237: INFO: Created: latency-svc-qvbsz
Jul 21 17:59:16.265: INFO: Got endpoints: latency-svc-5jc5z [728.824692ms]
Jul 21 17:59:16.272: INFO: Created: latency-svc-sbntt
Jul 21 17:59:16.297: INFO: Got endpoints: latency-svc-mvlzb [724.156571ms]
Jul 21 17:59:16.302: INFO: Created: latency-svc-27rz4
Jul 21 17:59:16.334: INFO: Created: latency-svc-h4g2b
Jul 21 17:59:16.348: INFO: Created: latency-svc-cll4b
Jul 21 17:59:16.350: INFO: Got endpoints: latency-svc-qvbsz [736.087804ms]
Jul 21 17:59:16.387: INFO: Created: latency-svc-lnf7m
Jul 21 17:59:16.398: INFO: Got endpoints: latency-svc-sbntt [734.147969ms]
Jul 21 17:59:16.402: INFO: Created: latency-svc-5smt8
Jul 21 17:59:16.434: INFO: Created: latency-svc-t5f62
Jul 21 17:59:16.459: INFO: Got endpoints: latency-svc-27rz4 [632.491841ms]
Jul 21 17:59:16.470: INFO: Created: latency-svc-v58kh
Jul 21 17:59:16.519: INFO: Got endpoints: latency-svc-h4g2b [617.099774ms]
Jul 21 17:59:16.524: INFO: Created: latency-svc-rwzlf
Jul 21 17:59:16.547: INFO: Got endpoints: latency-svc-cll4b [600.187782ms]
Jul 21 17:59:16.561: INFO: Created: latency-svc-47gpm
Jul 21 17:59:16.567: INFO: Created: latency-svc-x9fpg
Jul 21 17:59:16.578: INFO: Created: latency-svc-m9ztn
Jul 21 17:59:16.595: INFO: Got endpoints: latency-svc-lnf7m [644.536043ms]
Jul 21 17:59:16.607: INFO: Created: latency-svc-894sb
Jul 21 17:59:16.629: INFO: Created: latency-svc-vj78m
Jul 21 17:59:16.640: INFO: Created: latency-svc-p9vb5
Jul 21 17:59:16.654: INFO: Got endpoints: latency-svc-5smt8 [666.225753ms]
Jul 21 17:59:16.668: INFO: Created: latency-svc-h5w4m
Jul 21 17:59:16.668: INFO: Created: latency-svc-fcsfq
Jul 21 17:59:16.693: INFO: Created: latency-svc-4jvwg
Jul 21 17:59:16.696: INFO: Got endpoints: latency-svc-t5f62 [697.308571ms]
Jul 21 17:59:16.702: INFO: Created: latency-svc-nwq5s
Jul 21 17:59:16.731: INFO: Created: latency-svc-kdwnk
Jul 21 17:59:16.747: INFO: Got endpoints: latency-svc-v58kh [681.592965ms]
Jul 21 17:59:16.748: INFO: Created: latency-svc-84tv9
Jul 21 17:59:16.763: INFO: Created: latency-svc-fnggt
Jul 21 17:59:16.768: INFO: Created: latency-svc-4mhb9
Jul 21 17:59:16.800: INFO: Got endpoints: latency-svc-rwzlf [689.111872ms]
Jul 21 17:59:16.827: INFO: Created: latency-svc-snfzm
Jul 21 17:59:16.860: INFO: Got endpoints: latency-svc-47gpm [728.379963ms]
Jul 21 17:59:16.879: INFO: Created: latency-svc-znldh
Jul 21 17:59:16.899: INFO: Got endpoints: latency-svc-x9fpg [735.266715ms]
Jul 21 17:59:16.923: INFO: Created: latency-svc-z2x4j
Jul 21 17:59:16.944: INFO: Got endpoints: latency-svc-m9ztn [742.615733ms]
Jul 21 17:59:16.974: INFO: Created: latency-svc-nxjmd
Jul 21 17:59:16.999: INFO: Got endpoints: latency-svc-894sb [733.711893ms]
Jul 21 17:59:17.030: INFO: Created: latency-svc-cbpw7
Jul 21 17:59:17.045: INFO: Got endpoints: latency-svc-vj78m [748.023446ms]
Jul 21 17:59:17.071: INFO: Created: latency-svc-xx4cf
Jul 21 17:59:17.123: INFO: Got endpoints: latency-svc-p9vb5 [772.912674ms]
Jul 21 17:59:17.199: INFO: Got endpoints: latency-svc-fcsfq [801.266831ms]
Jul 21 17:59:17.207: INFO: Got endpoints: latency-svc-h5w4m [748.028953ms]
Jul 21 17:59:17.246: INFO: Created: latency-svc-4hzgh
Jul 21 17:59:17.251: INFO: Got endpoints: latency-svc-nwq5s [731.454273ms]
Jul 21 17:59:17.289: INFO: Created: latency-svc-rzv27
Jul 21 17:59:17.306: INFO: Got endpoints: latency-svc-4jvwg [758.380587ms]
Jul 21 17:59:17.350: INFO: Created: latency-svc-g98qg
Jul 21 17:59:17.354: INFO: Got endpoints: latency-svc-kdwnk [759.301312ms]
Jul 21 17:59:17.394: INFO: Created: latency-svc-7bf2r
Jul 21 17:59:17.412: INFO: Got endpoints: latency-svc-84tv9 [757.589326ms]
Jul 21 17:59:17.414: INFO: Created: latency-svc-kskfl
Jul 21 17:59:17.480: INFO: Created: latency-svc-p4mdv
Jul 21 17:59:17.489: INFO: Got endpoints: latency-svc-fnggt [793.557752ms]
Jul 21 17:59:17.493: INFO: Created: latency-svc-djq4p
Jul 21 17:59:17.766: INFO: Created: latency-svc-hzzk9
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-cbpw7 [762.971041ms]
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-znldh [905.720496ms]
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-4mhb9 [1.019240097s]
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-snfzm [965.872577ms]
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-nxjmd [822.605151ms]
Jul 21 17:59:17.766: INFO: Got endpoints: latency-svc-z2x4j [867.411494ms]
Jul 21 17:59:17.839: INFO: Created: latency-svc-fckk2
Jul 21 17:59:17.839: INFO: Got endpoints: latency-svc-xx4cf [792.687097ms]
Jul 21 17:59:17.874: INFO: Got endpoints: latency-svc-4hzgh [751.507843ms]
Jul 21 17:59:17.886: INFO: Created: latency-svc-w2xmm
Jul 21 17:59:17.904: INFO: Got endpoints: latency-svc-rzv27 [704.708278ms]
Jul 21 17:59:17.914: INFO: Created: latency-svc-kmkbj
Jul 21 17:59:17.943: INFO: Created: latency-svc-kcchn
Jul 21 17:59:17.981: INFO: Got endpoints: latency-svc-g98qg [769.861315ms]
Jul 21 17:59:18.012: INFO: Created: latency-svc-cklr8
Jul 21 17:59:18.012: INFO: Got endpoints: latency-svc-7bf2r [761.150536ms]
Jul 21 17:59:18.042: INFO: Created: latency-svc-q47wt
Jul 21 17:59:18.066: INFO: Got endpoints: latency-svc-kskfl [759.824967ms]
Jul 21 17:59:18.116: INFO: Created: latency-svc-zxp4w
Jul 21 17:59:18.118: INFO: Got endpoints: latency-svc-p4mdv [763.917718ms]
Jul 21 17:59:18.149: INFO: Got endpoints: latency-svc-djq4p [737.054567ms]
Jul 21 17:59:18.155: INFO: Created: latency-svc-swjwg
Jul 21 17:59:18.165: INFO: Created: latency-svc-znnmh
Jul 21 17:59:18.174: INFO: Created: latency-svc-6bnzl
Jul 21 17:59:18.201: INFO: Created: latency-svc-qtg4k
Jul 21 17:59:18.208: INFO: Got endpoints: latency-svc-hzzk9 [718.155081ms]
Jul 21 17:59:18.233: INFO: Created: latency-svc-h9ldt
Jul 21 17:59:18.258: INFO: Got endpoints: latency-svc-fckk2 [491.809466ms]
Jul 21 17:59:18.279: INFO: Created: latency-svc-rtnh8
Jul 21 17:59:18.311: INFO: Got endpoints: latency-svc-w2xmm [544.480785ms]
Jul 21 17:59:18.333: INFO: Created: latency-svc-mkzv6
Jul 21 17:59:18.348: INFO: Got endpoints: latency-svc-kmkbj [582.222339ms]
Jul 21 17:59:18.355: INFO: Created: latency-svc-p8m98
Jul 21 17:59:18.367: INFO: Created: latency-svc-2b8mq
Jul 21 17:59:18.375: INFO: Created: latency-svc-q42jf
Jul 21 17:59:18.404: INFO: Got endpoints: latency-svc-kcchn [638.228873ms]
Jul 21 17:59:18.416: INFO: Created: latency-svc-rgxrf
Jul 21 17:59:18.437: INFO: Created: latency-svc-94cfx
Jul 21 17:59:18.444: INFO: Got endpoints: latency-svc-cklr8 [677.458172ms]
Jul 21 17:59:18.478: INFO: Created: latency-svc-sczq2
Jul 21 17:59:18.508: INFO: Got endpoints: latency-svc-q47wt [741.195368ms]
Jul 21 17:59:18.555: INFO: Created: latency-svc-v2xfv
Jul 21 17:59:18.557: INFO: Got endpoints: latency-svc-zxp4w [716.99809ms]
Jul 21 17:59:18.615: INFO: Created: latency-svc-z4qnj
Jul 21 17:59:18.615: INFO: Got endpoints: latency-svc-swjwg [740.658792ms]
Jul 21 17:59:18.640: INFO: Created: latency-svc-ml9cg
Jul 21 17:59:18.677: INFO: Got endpoints: latency-svc-znnmh [772.606695ms]
Jul 21 17:59:18.709: INFO: Got endpoints: latency-svc-6bnzl [727.705653ms]
Jul 21 17:59:18.720: INFO: Created: latency-svc-ntsfm
Jul 21 17:59:18.767: INFO: Got endpoints: latency-svc-qtg4k [754.844758ms]
Jul 21 17:59:18.773: INFO: Created: latency-svc-jkffx
Jul 21 17:59:18.825: INFO: Got endpoints: latency-svc-h9ldt [758.630863ms]
Jul 21 17:59:18.868: INFO: Created: latency-svc-dl2kx
Jul 21 17:59:18.868: INFO: Created: latency-svc-5ckjx
Jul 21 17:59:18.868: INFO: Got endpoints: latency-svc-rtnh8 [749.260265ms]
Jul 21 17:59:18.905: INFO: Got endpoints: latency-svc-mkzv6 [756.010858ms]
Jul 21 17:59:18.909: INFO: Created: latency-svc-294pc
Jul 21 17:59:18.941: INFO: Created: latency-svc-rjjgd
Jul 21 17:59:18.944: INFO: Got endpoints: latency-svc-p8m98 [736.675129ms]
Jul 21 17:59:18.979: INFO: Created: latency-svc-89zj5
Jul 21 17:59:18.997: INFO: Got endpoints: latency-svc-2b8mq [738.583222ms]
Jul 21 17:59:19.015: INFO: Created: latency-svc-tjtg7
Jul 21 17:59:19.060: INFO: Got endpoints: latency-svc-q42jf [748.829553ms]
Jul 21 17:59:19.080: INFO: Created: latency-svc-cwbcf
Jul 21 17:59:19.096: INFO: Got endpoints: latency-svc-rgxrf [747.972275ms]
Jul 21 17:59:19.123: INFO: Created: latency-svc-x26qj
Jul 21 17:59:19.146: INFO: Got endpoints: latency-svc-94cfx [741.181888ms]
Jul 21 17:59:19.175: INFO: Created: latency-svc-qcxss
Jul 21 17:59:19.206: INFO: Got endpoints: latency-svc-sczq2 [761.652886ms]
Jul 21 17:59:19.228: INFO: Created: latency-svc-4n8kx
Jul 21 17:59:19.247: INFO: Got endpoints: latency-svc-v2xfv [739.735931ms]
Jul 21 17:59:19.278: INFO: Created: latency-svc-lw44t
Jul 21 17:59:19.297: INFO: Got endpoints: latency-svc-z4qnj [740.497576ms]
Jul 21 17:59:19.356: INFO: Got endpoints: latency-svc-ml9cg [740.260963ms]
Jul 21 17:59:19.366: INFO: Created: latency-svc-f24zx
Jul 21 17:59:19.395: INFO: Created: latency-svc-k2zxq
Jul 21 17:59:19.396: INFO: Got endpoints: latency-svc-ntsfm [718.945611ms]
Jul 21 17:59:19.428: INFO: Created: latency-svc-f7l8w
Jul 21 17:59:19.459: INFO: Got endpoints: latency-svc-jkffx [750.099831ms]
Jul 21 17:59:19.518: INFO: Got endpoints: latency-svc-5ckjx [744.624445ms]
Jul 21 17:59:19.523: INFO: Created: latency-svc-4df9m
Jul 21 17:59:19.543: INFO: Created: latency-svc-rrgn2
Jul 21 17:59:19.557: INFO: Got endpoints: latency-svc-dl2kx [731.996083ms]
Jul 21 17:59:19.622: INFO: Got endpoints: latency-svc-294pc [754.214899ms]
Jul 21 17:59:19.622: INFO: Created: latency-svc-bgdb4
Jul 21 17:59:19.647: INFO: Got endpoints: latency-svc-rjjgd [742.635304ms]
Jul 21 17:59:19.707: INFO: Got endpoints: latency-svc-89zj5 [762.638031ms]
Jul 21 17:59:19.744: INFO: Got endpoints: latency-svc-tjtg7 [746.807197ms]
Jul 21 17:59:19.771: INFO: Created: latency-svc-4t9cv
Jul 21 17:59:19.790: INFO: Created: latency-svc-jvghg
Jul 21 17:59:19.827: INFO: Got endpoints: latency-svc-cwbcf [767.054137ms]
Jul 21 17:59:19.852: INFO: Got endpoints: latency-svc-x26qj [756.077498ms]
Jul 21 17:59:19.861: INFO: Created: latency-svc-qbj5d
Jul 21 17:59:19.875: INFO: Created: latency-svc-87gdb
Jul 21 17:59:19.893: INFO: Created: latency-svc-bgvr8
Jul 21 17:59:19.897: INFO: Got endpoints: latency-svc-qcxss [751.125855ms]
Jul 21 17:59:19.923: INFO: Created: latency-svc-4l2f7
Jul 21 17:59:19.932: INFO: Created: latency-svc-xnfz8
Jul 21 17:59:19.944: INFO: Got endpoints: latency-svc-4n8kx [738.541784ms]
Jul 21 17:59:19.971: INFO: Created: latency-svc-vflv5
Jul 21 17:59:19.997: INFO: Got endpoints: latency-svc-lw44t [749.356816ms]
Jul 21 17:59:20.036: INFO: Created: latency-svc-4fpjp
Jul 21 17:59:20.045: INFO: Got endpoints: latency-svc-f24zx [742.532975ms]
Jul 21 17:59:20.066: INFO: Created: latency-svc-7g7fm
Jul 21 17:59:20.097: INFO: Got endpoints: latency-svc-k2zxq [741.698984ms]
Jul 21 17:59:20.117: INFO: Created: latency-svc-c5v75
Jul 21 17:59:20.145: INFO: Got endpoints: latency-svc-f7l8w [749.424856ms]
Jul 21 17:59:20.167: INFO: Created: latency-svc-r9k5z
Jul 21 17:59:20.196: INFO: Got endpoints: latency-svc-4df9m [736.879621ms]
Jul 21 17:59:20.218: INFO: Created: latency-svc-qh74t
Jul 21 17:59:20.247: INFO: Got endpoints: latency-svc-rrgn2 [724.172907ms]
Jul 21 17:59:20.283: INFO: Created: latency-svc-f8t68
Jul 21 17:59:20.312: INFO: Got endpoints: latency-svc-bgdb4 [755.0645ms]
Jul 21 17:59:20.341: INFO: Created: latency-svc-bd22c
Jul 21 17:59:20.346: INFO: Got endpoints: latency-svc-4t9cv [716.654141ms]
Jul 21 17:59:20.398: INFO: Got endpoints: latency-svc-jvghg [750.279253ms]
Jul 21 17:59:20.428: INFO: Created: latency-svc-pznht
Jul 21 17:59:20.448: INFO: Got endpoints: latency-svc-qbj5d [739.412846ms]
Jul 21 17:59:20.460: INFO: Created: latency-svc-px5cx
Jul 21 17:59:20.485: INFO: Created: latency-svc-l7q86
Jul 21 17:59:20.500: INFO: Got endpoints: latency-svc-87gdb [755.755647ms]
Jul 21 17:59:20.545: INFO: Created: latency-svc-q687n
Jul 21 17:59:20.549: INFO: Got endpoints: latency-svc-bgvr8 [720.957216ms]
Jul 21 17:59:20.584: INFO: Created: latency-svc-fz9xd
Jul 21 17:59:20.595: INFO: Got endpoints: latency-svc-4l2f7 [741.993022ms]
Jul 21 17:59:20.609: INFO: Created: latency-svc-h88xz
Jul 21 17:59:20.658: INFO: Got endpoints: latency-svc-xnfz8 [760.971295ms]
Jul 21 17:59:20.689: INFO: Created: latency-svc-5lhw9
Jul 21 17:59:20.699: INFO: Got endpoints: latency-svc-vflv5 [754.476897ms]
Jul 21 17:59:20.748: INFO: Got endpoints: latency-svc-4fpjp [751.307085ms]
Jul 21 17:59:20.787: INFO: Created: latency-svc-sx75t
Jul 21 17:59:20.795: INFO: Got endpoints: latency-svc-7g7fm [750.059175ms]
Jul 21 17:59:20.846: INFO: Got endpoints: latency-svc-c5v75 [748.480013ms]
Jul 21 17:59:20.902: INFO: Got endpoints: latency-svc-r9k5z [756.859354ms]
Jul 21 17:59:20.948: INFO: Got endpoints: latency-svc-qh74t [752.56105ms]
Jul 21 17:59:20.996: INFO: Got endpoints: latency-svc-f8t68 [746.171209ms]
Jul 21 17:59:21.050: INFO: Got endpoints: latency-svc-bd22c [737.391222ms]
Jul 21 17:59:21.097: INFO: Got endpoints: latency-svc-pznht [751.29921ms]
Jul 21 17:59:21.165: INFO: Got endpoints: latency-svc-px5cx [767.321637ms]
Jul 21 17:59:21.196: INFO: Got endpoints: latency-svc-l7q86 [748.251364ms]
Jul 21 17:59:21.261: INFO: Got endpoints: latency-svc-q687n [760.893319ms]
Jul 21 17:59:21.311: INFO: Got endpoints: latency-svc-fz9xd [762.016045ms]
Jul 21 17:59:21.347: INFO: Got endpoints: latency-svc-h88xz [752.700869ms]
Jul 21 17:59:21.408: INFO: Got endpoints: latency-svc-5lhw9 [749.581185ms]
Jul 21 17:59:21.448: INFO: Got endpoints: latency-svc-sx75t [744.716438ms]
Jul 21 17:59:21.448: INFO: Latencies: [25.002696ms 35.118618ms 36.820684ms 47.012486ms 59.565648ms 72.761498ms 105.175182ms 109.822126ms 143.683204ms 173.790533ms 196.603042ms 218.484152ms 239.24734ms 257.433801ms 261.677771ms 267.85676ms 270.937034ms 280.378761ms 309.780204ms 311.221865ms 312.225462ms 316.406462ms 316.476124ms 323.924131ms 324.214182ms 325.60853ms 330.20018ms 333.199459ms 339.186092ms 340.000913ms 342.643496ms 344.502023ms 346.720316ms 349.867168ms 353.976914ms 356.069412ms 360.116853ms 360.670268ms 361.036909ms 361.516206ms 362.448263ms 363.592739ms 363.934428ms 375.625935ms 377.718408ms 379.088149ms 386.934229ms 406.828086ms 417.573684ms 438.337461ms 451.095375ms 469.514339ms 484.099377ms 491.809466ms 492.847078ms 520.358896ms 539.097055ms 540.098597ms 544.480785ms 547.999953ms 554.284734ms 565.074844ms 566.345404ms 569.276923ms 582.222339ms 589.570621ms 593.548277ms 600.187782ms 602.472598ms 607.684289ms 617.099774ms 622.223915ms 623.056767ms 632.491841ms 638.228873ms 644.536043ms 666.225753ms 675.106029ms 677.458172ms 679.506262ms 681.592965ms 689.111872ms 693.330584ms 693.743409ms 697.308571ms 700.376328ms 701.71ms 704.708278ms 708.841629ms 715.350282ms 716.654141ms 716.99809ms 718.155081ms 718.945611ms 720.957216ms 723.496593ms 724.156571ms 724.172907ms 727.705653ms 728.379963ms 728.824692ms 731.454273ms 731.996083ms 733.711893ms 733.75824ms 734.147969ms 735.266715ms 736.087804ms 736.675129ms 736.879621ms 737.054567ms 737.391222ms 738.541784ms 738.583222ms 739.412846ms 739.735931ms 740.260963ms 740.497576ms 740.658792ms 741.181888ms 741.195368ms 741.698984ms 741.993022ms 742.434469ms 742.532975ms 742.615733ms 742.635304ms 744.193634ms 744.624445ms 744.716438ms 746.171209ms 746.807197ms 747.652909ms 747.972275ms 748.023446ms 748.028953ms 748.251364ms 748.480013ms 748.829553ms 749.260265ms 749.356816ms 749.424856ms 749.581185ms 750.059175ms 750.099831ms 750.279253ms 751.125855ms 751.29921ms 751.307085ms 751.507843ms 752.56105ms 752.700869ms 754.214899ms 754.476897ms 754.844758ms 755.0645ms 755.755647ms 756.010858ms 756.077498ms 756.859354ms 757.589326ms 758.380587ms 758.630863ms 759.301312ms 759.824967ms 760.893319ms 760.971295ms 761.150536ms 761.652886ms 762.016045ms 762.638031ms 762.971041ms 763.917718ms 767.054137ms 767.321637ms 769.861315ms 772.606695ms 772.912674ms 792.687097ms 793.557752ms 801.266831ms 804.827363ms 806.974074ms 810.698755ms 822.605151ms 830.386956ms 831.236359ms 844.348538ms 847.005234ms 857.487118ms 861.241946ms 862.081585ms 867.411494ms 881.064915ms 884.219335ms 891.266746ms 905.720496ms 910.203017ms 965.872577ms 1.019240097s]
Jul 21 17:59:21.448: INFO: 50 %ile: 728.824692ms
Jul 21 17:59:21.448: INFO: 90 %ile: 801.266831ms
Jul 21 17:59:21.448: INFO: 99 %ile: 965.872577ms
Jul 21 17:59:21.448: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:59:21.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8998" for this suite.
Jul 21 17:59:43.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 17:59:44.250: INFO: namespace svc-latency-8998 deletion completed in 22.795281056s

â€¢ [SLOW TEST:34.578 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 17:59:44.250: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 21 17:59:48.942: INFO: Successfully updated pod "annotationupdate51ff0049-abe1-11e9-974c-16aa19c3723a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 17:59:52.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1846" for this suite.
Jul 21 18:00:19.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:00:20.131: INFO: namespace downward-api-1846 deletion completed in 27.135645338s

â€¢ [SLOW TEST:35.881 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:00:20.132: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Jul 21 18:00:20.296: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-991073413 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:00:20.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1987" for this suite.
Jul 21 18:00:26.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:00:27.867: INFO: namespace kubectl-1987 deletion completed in 6.955803477s

â€¢ [SLOW TEST:7.735 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:00:27.867: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0721 18:00:34.369047      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 18:00:34.369: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:00:34.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4432" for this suite.
Jul 21 18:00:40.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:00:41.074: INFO: namespace gc-4432 deletion completed in 6.694500404s

â€¢ [SLOW TEST:13.206 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:00:41.074: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-73dcce35-abe1-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:00:41.188: INFO: Waiting up to 5m0s for pod "pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a" in namespace "configmap-3502" to be "success or failure"
Jul 21 18:00:41.225: INFO: Pod "pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.495903ms
Jul 21 18:00:43.241: INFO: Pod "pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052711556s
Jul 21 18:00:45.247: INFO: Pod "pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058752991s
STEP: Saw pod success
Jul 21 18:00:45.247: INFO: Pod "pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:00:45.250: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:00:45.304: INFO: Waiting for pod pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:00:45.310: INFO: Pod pod-configmaps-73dda3d5-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:00:45.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3502" for this suite.
Jul 21 18:00:51.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:00:51.929: INFO: namespace configmap-3502 deletion completed in 6.614053715s

â€¢ [SLOW TEST:10.855 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:00:51.930: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:00:51.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-8493'
Jul 21 18:00:52.381: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 21 18:00:52.381: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Jul 21 18:00:54.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8493'
Jul 21 18:00:54.923: INFO: stderr: ""
Jul 21 18:00:54.923: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:00:54.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8493" for this suite.
Jul 21 18:03:00.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:01.543: INFO: namespace kubectl-8493 deletion completed in 2m6.612313561s

â€¢ [SLOW TEST:129.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:01.544: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Jul 21 18:03:01.581: INFO: Waiting up to 5m0s for pod "client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a" in namespace "containers-1348" to be "success or failure"
Jul 21 18:03:01.585: INFO: Pod "client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752905ms
Jul 21 18:03:03.588: INFO: Pod "client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006691294s
Jul 21 18:03:05.592: INFO: Pod "client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010735411s
STEP: Saw pod success
Jul 21 18:03:05.592: INFO: Pod "client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:05.594: INFO: Trying to get logs from node ip-10-222-31-145 pod client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:03:05.614: INFO: Waiting for pod client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:05.622: INFO: Pod client-containers-c791e3dd-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:05.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1348" for this suite.
Jul 21 18:03:11.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:12.212: INFO: namespace containers-1348 deletion completed in 6.577162556s

â€¢ [SLOW TEST:10.668 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:12.213: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 21 18:03:12.330: INFO: Waiting up to 5m0s for pod "pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a" in namespace "emptydir-1797" to be "success or failure"
Jul 21 18:03:12.348: INFO: Pod "pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.480567ms
Jul 21 18:03:14.352: INFO: Pod "pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022101577s
Jul 21 18:03:16.354: INFO: Pod "pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024407792s
STEP: Saw pod success
Jul 21 18:03:16.354: INFO: Pod "pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:16.359: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:03:16.385: INFO: Waiting for pod pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:16.389: INFO: Pod pod-cdf5efe9-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:16.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1797" for this suite.
Jul 21 18:03:22.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:23.005: INFO: namespace emptydir-1797 deletion completed in 6.582802116s

â€¢ [SLOW TEST:10.792 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:23.005: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Jul 21 18:03:23.033: INFO: Waiting up to 5m0s for pod "var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a" in namespace "var-expansion-9869" to be "success or failure"
Jul 21 18:03:23.045: INFO: Pod "var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.683883ms
Jul 21 18:03:25.048: INFO: Pod "var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014973133s
Jul 21 18:03:27.051: INFO: Pod "var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017659633s
STEP: Saw pod success
Jul 21 18:03:27.051: INFO: Pod "var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:27.053: INFO: Trying to get logs from node ip-10-222-31-145 pod var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 18:03:27.079: INFO: Waiting for pod var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:27.087: INFO: Pod var-expansion-d45b9bc8-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:27.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9869" for this suite.
Jul 21 18:03:33.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:33.697: INFO: namespace var-expansion-9869 deletion completed in 6.606445123s

â€¢ [SLOW TEST:10.692 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:33.697: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:03:33.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a" in namespace "downward-api-9276" to be "success or failure"
Jul 21 18:03:33.754: INFO: Pod "downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.343651ms
Jul 21 18:03:35.761: INFO: Pod "downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018829817s
Jul 21 18:03:37.764: INFO: Pod "downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021823563s
STEP: Saw pod success
Jul 21 18:03:37.764: INFO: Pod "downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:37.766: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:03:37.794: INFO: Waiting for pod downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:37.797: INFO: Pod downwardapi-volume-dabce4df-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:37.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9276" for this suite.
Jul 21 18:03:43.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:44.401: INFO: namespace downward-api-9276 deletion completed in 6.588536235s

â€¢ [SLOW TEST:10.704 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:44.401: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 21 18:03:44.447: INFO: Waiting up to 5m0s for pod "downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a" in namespace "downward-api-7370" to be "success or failure"
Jul 21 18:03:44.456: INFO: Pod "downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.846134ms
Jul 21 18:03:46.461: INFO: Pod "downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013310659s
Jul 21 18:03:48.464: INFO: Pod "downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01632908s
STEP: Saw pod success
Jul 21 18:03:48.464: INFO: Pod "downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:48.466: INFO: Trying to get logs from node ip-10-222-31-145 pod downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 18:03:48.490: INFO: Waiting for pod downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:48.494: INFO: Pod downward-api-e11e6884-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:48.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7370" for this suite.
Jul 21 18:03:54.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:03:55.066: INFO: namespace downward-api-7370 deletion completed in 6.569389544s

â€¢ [SLOW TEST:10.665 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:03:55.066: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Jul 21 18:03:55.098: INFO: Waiting up to 5m0s for pod "var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a" in namespace "var-expansion-8102" to be "success or failure"
Jul 21 18:03:55.108: INFO: Pod "var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.303258ms
Jul 21 18:03:57.110: INFO: Pod "var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01284704s
Jul 21 18:03:59.114: INFO: Pod "var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01605946s
STEP: Saw pod success
Jul 21 18:03:59.114: INFO: Pod "var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:03:59.116: INFO: Trying to get logs from node ip-10-222-31-145 pod var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 18:03:59.148: INFO: Waiting for pod var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:03:59.151: INFO: Pod var-expansion-e777e8b3-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:03:59.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8102" for this suite.
Jul 21 18:04:07.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:04:07.751: INFO: namespace var-expansion-8102 deletion completed in 8.597415654s

â€¢ [SLOW TEST:12.685 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:04:07.751: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a
Jul 21 18:04:07.850: INFO: Pod name my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a: Found 0 pods out of 1
Jul 21 18:04:12.856: INFO: Pod name my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a: Found 1 pods out of 1
Jul 21 18:04:12.856: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a" are running
Jul 21 18:04:14.865: INFO: Pod "my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a-4w4dc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:04:07 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:04:07 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:04:07 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:04:07 +0000 UTC Reason: Message:}])
Jul 21 18:04:14.865: INFO: Trying to dial the pod
Jul 21 18:04:19.873: INFO: Controller my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a: Got expected result from replica 1 [my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a-4w4dc]: "my-hostname-basic-ef0e7939-abe1-11e9-974c-16aa19c3723a-4w4dc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:04:19.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9352" for this suite.
Jul 21 18:04:25.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:04:26.468: INFO: namespace replication-controller-9352 deletion completed in 6.591944646s

â€¢ [SLOW TEST:18.717 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:04:26.468: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 21 18:04:26.503: INFO: Waiting up to 5m0s for pod "pod-fa300ece-abe1-11e9-974c-16aa19c3723a" in namespace "emptydir-8905" to be "success or failure"
Jul 21 18:04:26.509: INFO: Pod "pod-fa300ece-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.795503ms
Jul 21 18:04:28.513: INFO: Pod "pod-fa300ece-abe1-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009296868s
Jul 21 18:04:30.527: INFO: Pod "pod-fa300ece-abe1-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023693999s
STEP: Saw pod success
Jul 21 18:04:30.527: INFO: Pod "pod-fa300ece-abe1-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:04:30.544: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-fa300ece-abe1-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:04:30.577: INFO: Waiting for pod pod-fa300ece-abe1-11e9-974c-16aa19c3723a to disappear
Jul 21 18:04:30.591: INFO: Pod pod-fa300ece-abe1-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:04:30.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8905" for this suite.
Jul 21 18:04:36.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:04:37.177: INFO: namespace emptydir-8905 deletion completed in 6.580832351s

â€¢ [SLOW TEST:10.708 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:04:37.177: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0721 18:04:38.328158      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 18:04:38.328: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:04:38.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-851" for this suite.
Jul 21 18:04:44.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:04:44.915: INFO: namespace gc-851 deletion completed in 6.584394579s

â€¢ [SLOW TEST:7.738 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:04:44.916: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8447
Jul 21 18:04:50.986: INFO: Started pod liveness-http in namespace container-probe-8447
STEP: checking the pod's current state and verifying that restartCount is present
Jul 21 18:04:50.988: INFO: Initial restart count of pod liveness-http is 0
Jul 21 18:05:11.055: INFO: Restart count of pod container-probe-8447/liveness-http is now 1 (20.067018806s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:05:11.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8447" for this suite.
Jul 21 18:05:17.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:05:17.733: INFO: namespace container-probe-8447 deletion completed in 6.590802692s

â€¢ [SLOW TEST:32.817 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:05:17.733: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-18c53b0d-abe2-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:05:17.850: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a" in namespace "projected-314" to be "success or failure"
Jul 21 18:05:17.877: INFO: Pod "pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.353705ms
Jul 21 18:05:19.881: INFO: Pod "pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030017581s
Jul 21 18:05:21.884: INFO: Pod "pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033115197s
STEP: Saw pod success
Jul 21 18:05:21.884: INFO: Pod "pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:05:21.886: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:05:21.917: INFO: Waiting for pod pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:05:21.930: INFO: Pod pod-projected-configmaps-18c74536-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:05:21.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-314" for this suite.
Jul 21 18:05:27.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:05:28.526: INFO: namespace projected-314 deletion completed in 6.588392488s

â€¢ [SLOW TEST:10.793 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:05:28.526: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:05:28.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-263'
Jul 21 18:05:28.678: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 21 18:05:28.678: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jul 21 18:05:28.696: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-6jxgx]
Jul 21 18:05:28.696: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-6jxgx" in namespace "kubectl-263" to be "running and ready"
Jul 21 18:05:28.702: INFO: Pod "e2e-test-nginx-rc-6jxgx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.233878ms
Jul 21 18:05:30.710: INFO: Pod "e2e-test-nginx-rc-6jxgx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013620068s
Jul 21 18:05:32.712: INFO: Pod "e2e-test-nginx-rc-6jxgx": Phase="Running", Reason="", readiness=true. Elapsed: 4.016280417s
Jul 21 18:05:32.712: INFO: Pod "e2e-test-nginx-rc-6jxgx" satisfied condition "running and ready"
Jul 21 18:05:32.712: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-6jxgx]
Jul 21 18:05:32.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 logs rc/e2e-test-nginx-rc --namespace=kubectl-263'
Jul 21 18:05:32.819: INFO: stderr: ""
Jul 21 18:05:32.820: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Jul 21 18:05:32.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete rc e2e-test-nginx-rc --namespace=kubectl-263'
Jul 21 18:05:32.929: INFO: stderr: ""
Jul 21 18:05:32.929: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:05:32.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-263" for this suite.
Jul 21 18:05:38.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:05:39.510: INFO: namespace kubectl-263 deletion completed in 6.574394005s

â€¢ [SLOW TEST:10.984 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:05:39.511: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-25ba5f31-abe2-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:05:39.565: INFO: Waiting up to 5m0s for pod "pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a" in namespace "secrets-696" to be "success or failure"
Jul 21 18:05:39.570: INFO: Pod "pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.535531ms
Jul 21 18:05:41.573: INFO: Pod "pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007751439s
Jul 21 18:05:43.581: INFO: Pod "pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015691553s
STEP: Saw pod success
Jul 21 18:05:43.581: INFO: Pod "pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:05:43.587: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:05:43.622: INFO: Waiting for pod pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:05:43.629: INFO: Pod pod-secrets-25bb40bb-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:05:43.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-696" for this suite.
Jul 21 18:05:49.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:05:50.214: INFO: namespace secrets-696 deletion completed in 6.579857358s

â€¢ [SLOW TEST:10.704 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:05:50.215: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Jul 21 18:05:50.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 api-versions'
Jul 21 18:05:50.452: INFO: stderr: ""
Jul 21 18:05:50.452: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nconfig.istio.io/v1alpha2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:05:50.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7873" for this suite.
Jul 21 18:05:56.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:05:57.036: INFO: namespace kubectl-7873 deletion completed in 6.577103473s

â€¢ [SLOW TEST:6.821 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:05:57.042: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 21 18:06:01.687: INFO: Successfully updated pod "annotationupdate302d7705-abe2-11e9-974c-16aa19c3723a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:06:03.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-264" for this suite.
Jul 21 18:06:25.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:06:26.305: INFO: namespace projected-264 deletion completed in 22.587998249s

â€¢ [SLOW TEST:29.262 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:06:26.306: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 21 18:06:26.335: INFO: Waiting up to 5m0s for pod "pod-419d6255-abe2-11e9-974c-16aa19c3723a" in namespace "emptydir-5099" to be "success or failure"
Jul 21 18:06:26.349: INFO: Pod "pod-419d6255-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.680827ms
Jul 21 18:06:28.354: INFO: Pod "pod-419d6255-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019471063s
Jul 21 18:06:30.361: INFO: Pod "pod-419d6255-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026315343s
STEP: Saw pod success
Jul 21 18:06:30.361: INFO: Pod "pod-419d6255-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:06:30.364: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-419d6255-abe2-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:06:30.385: INFO: Waiting for pod pod-419d6255-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:06:30.387: INFO: Pod pod-419d6255-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:06:30.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5099" for this suite.
Jul 21 18:06:36.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:06:36.987: INFO: namespace emptydir-5099 deletion completed in 6.58268665s

â€¢ [SLOW TEST:10.682 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:06:36.990: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-47fd0a28-abe2-11e9-974c-16aa19c3723a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:06:37.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3750" for this suite.
Jul 21 18:06:43.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:06:43.597: INFO: namespace configmap-3750 deletion completed in 6.569331601s

â€¢ [SLOW TEST:6.607 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:06:43.598: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:06:43.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a" in namespace "downward-api-7040" to be "success or failure"
Jul 21 18:06:43.630: INFO: Pod "downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.573867ms
Jul 21 18:06:45.632: INFO: Pod "downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007077205s
Jul 21 18:06:47.636: INFO: Pod "downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011332202s
STEP: Saw pod success
Jul 21 18:06:47.636: INFO: Pod "downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:06:47.639: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:06:47.660: INFO: Waiting for pod downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:06:47.663: INFO: Pod downwardapi-volume-4beb5403-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:06:47.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7040" for this suite.
Jul 21 18:06:53.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:06:54.267: INFO: namespace downward-api-7040 deletion completed in 6.593282067s

â€¢ [SLOW TEST:10.669 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:06:54.267: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:07:18.341: INFO: Container started at 2019-07-21 18:06:57 +0000 UTC, pod became ready at 2019-07-21 18:07:16 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:07:18.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2373" for this suite.
Jul 21 18:07:42.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:07:42.916: INFO: namespace container-probe-2373 deletion completed in 24.573212187s

â€¢ [SLOW TEST:48.649 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:07:42.917: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 21 18:07:42.948: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 21 18:07:42.956: INFO: Waiting for terminating namespaces to be deleted...
Jul 21 18:07:42.960: INFO: 
Logging pods the kubelet thinks is on node ip-10-222-31-145 before test
Jul 21 18:07:42.976: INFO: edge-sec-665bf84b5d-nr27w from rcloud-infra started at 2019-07-21 16:48:52 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container edge-sec ready: true, restart count 0
Jul 21 18:07:42.976: INFO: istio-mixer-86bc989497-v8bvv from istio-system started at 2019-07-21 16:44:40 +0000 UTC (3 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container mixer ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container statsd-to-prometheus ready: true, restart count 0
Jul 21 18:07:42.976: INFO: istio-pilot-75c4c5dcc5-n4dxq from istio-system started at 2019-07-21 16:44:41 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container discovery ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: debug-processor-76656764d-kh7gg from rcloud-admin started at 2019-07-21 16:47:36 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container debug-processor ready: true, restart count 0
Jul 21 18:07:42.976: INFO: postgres-756f878d66-kdw48 from rcloud-admin started at 2019-07-21 16:45:23 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container postgres ready: true, restart count 0
Jul 21 18:07:42.976: INFO: workload-broker-c5f8c89c-h6ssl from rcloud-infra started at 2019-07-21 16:47:04 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container workload-broker ready: true, restart count 0
Jul 21 18:07:42.976: INFO: salt-master-6bc4f85449-hf78n from rcloud-infra started at 2019-07-21 16:49:01 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container salt-master ready: true, restart count 0
Jul 21 18:07:42.976: INFO: edge-processor-68f574bb58-7xwpb from rcloud-admin started at 2019-07-21 16:47:52 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container edge-processor ready: true, restart count 0
Jul 21 18:07:42.976: INFO: config-broker-5c85977786-rvjlb from rcloud-infra started at 2019-07-21 16:48:01 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container config-broker ready: true, restart count 0
Jul 21 18:07:42.976: INFO: sonobuoy-systemd-logs-daemon-set-5655e65ca0e146ed-znmf4 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 21 18:07:42.976: INFO: nginx-ingress-controller-78dcf4d98b-nzf98 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jul 21 18:07:42.976: INFO: istio-ca-78655bf74f-jtfdj from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container istio-ca ready: true, restart count 0
Jul 21 18:07:42.976: INFO: frontend-7cc7768fc8-tmhds from rcloud-admin started at 2019-07-21 16:46:12 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container frontend ready: true, restart count 1
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: nginx-ingress-controller-admin-564f6884d8-gz2js from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container nginx-ingress-controller-admin ready: true, restart count 0
Jul 21 18:07:42.976: INFO: istio-ingress-6c8b8f96cd-dwlvc from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container istio-ingress ready: true, restart count 0
Jul 21 18:07:42.976: INFO: workload-placement-746878b79f-dbd7b from rcloud-admin started at 2019-07-21 16:46:37 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container workload-placement ready: true, restart count 1
Jul 21 18:07:42.976: INFO: traffic-steering-547844bcf8-sj82z from rcloud-admin started at 2019-07-21 16:46:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container traffic-steering ready: true, restart count 0
Jul 21 18:07:42.976: INFO: kube-proxy-89z7m from kube-system started at 2019-07-21 16:40:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: tiller-deploy-85494c96cf-mtrlx from kube-system started at 2019-07-21 16:44:49 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container tiller ready: true, restart count 0
Jul 21 18:07:42.976: INFO: zookeeper-86bfd95d77-lxx59 from rcloud-infra started at 2019-07-21 16:45:33 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container zk-0 ready: true, restart count 0
Jul 21 18:07:42.976: INFO: config-processor-7847fd6f49-z4g58 from rcloud-admin started at 2019-07-21 16:48:12 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container config-processor ready: true, restart count 0
Jul 21 18:07:42.976: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.976: INFO: coredns-fb8b8dccf-wrz8f from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.976: INFO: 	Container coredns ready: true, restart count 0
Jul 21 18:07:42.976: INFO: resource-allocation-8c8cdcfd8-njc4s from rcloud-admin started at 2019-07-21 16:46:45 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.977: INFO: 	Container resource-allocation ready: true, restart count 0
Jul 21 18:07:42.977: INFO: debug-broker-0 from rcloud-infra started at 2019-07-21 16:47:27 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container debug-broker ready: true, restart count 0
Jul 21 18:07:42.977: INFO: admin-api-7758ff5dc6-t554w from rcloud-admin started at 2019-07-21 16:46:02 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container admin-api ready: true, restart count 1
Jul 21 18:07:42.977: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.977: INFO: frontend-opsconsole-65d75f5d69-mdz97 from rcloud-admin started at 2019-07-21 16:46:19 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container frontend-opsconsole ready: true, restart count 1
Jul 21 18:07:42.977: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.977: INFO: workload-processor-7c768567f6-zdlzm from rcloud-admin started at 2019-07-21 16:46:28 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:07:42.977: INFO: 	Container workload-processor ready: true, restart count 0
Jul 21 18:07:42.977: INFO: regauth-8bd9db7c4-dmmnf from rcloud-admin started at 2019-07-21 16:47:18 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container docker-auth ready: true, restart count 0
Jul 21 18:07:42.977: INFO: etcd-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:07:42.977: INFO: kafka-core-7c75bb8ccd-zrkn5 from rcloud-infra started at 2019-07-21 16:45:19 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container kafka-core ready: true, restart count 1
Jul 21 18:07:42.977: INFO: admin-redis-599959c468-9bdcj from rcloud-admin started at 2019-07-21 16:45:22 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container admin-redis ready: true, restart count 0
Jul 21 18:07:42.977: INFO: coredns-fb8b8dccf-ggr8r from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container coredns ready: true, restart count 0
Jul 21 18:07:42.977: INFO: edgesrv-6459c565cb-z2898 from rcloud-admin started at 2019-07-21 16:48:40 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container edgesrv ready: true, restart count 0
Jul 21 18:07:42.977: INFO: kube-apiserver-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:07:42.977: INFO: kube-controller-manager-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:07:42.977: INFO: canal-sztcn from kube-system started at 2019-07-21 16:40:24 +0000 UTC (3 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container calico-node ready: true, restart count 0
Jul 21 18:07:42.977: INFO: 	Container install-cni ready: true, restart count 0
Jul 21 18:07:42.977: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 21 18:07:42.977: INFO: keygensvc-86d69565-94v4f from rcloud-infra started at 2019-07-21 16:45:34 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container keygensvc ready: true, restart count 2
Jul 21 18:07:42.977: INFO: kube-scheduler-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:07:42.977: INFO: glusterfs-8krmv from kube-system started at 2019-07-21 16:44:02 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container glusterfs ready: true, restart count 0
Jul 21 18:07:42.977: INFO: default-http-backend-55b84578bf-lghj8 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 21 18:07:42.977: INFO: cryptosvc-d477c486-rtrnb from rcloud-infra started at 2019-07-21 16:45:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container cryptosvc ready: true, restart count 1
Jul 21 18:07:42.977: INFO: sonobuoy-e2e-job-9d9f8ba6e19c4dc2 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container e2e ready: true, restart count 0
Jul 21 18:07:42.977: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 21 18:07:42.977: INFO: default-http-backend-admin-656d9c9d8c-c8s9h from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container default-http-backend-admin ready: true, restart count 0
Jul 21 18:07:42.977: INFO: rafay-container-registry-6474bdcbcf-mgd9f from rcloud-admin started at 2019-07-21 16:47:23 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container registry ready: true, restart count 0
Jul 21 18:07:42.977: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-21 17:27:48 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 21 18:07:42.977: INFO: heketi-84f9566569-55wr6 from kube-system started at 2019-07-21 16:44:03 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container heketi ready: true, restart count 0
Jul 21 18:07:42.977: INFO: authsrv-88696bc57-vx55z from rcloud-admin started at 2019-07-21 16:47:15 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container authsrv ready: true, restart count 0
Jul 21 18:07:42.977: INFO: edge-broker-5bf96697cf-l57cr from rcloud-infra started at 2019-07-21 16:47:45 +0000 UTC (1 container statuses recorded)
Jul 21 18:07:42.977: INFO: 	Container edge-broker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-71b37ea3-abe2-11e9-974c-16aa19c3723a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-71b37ea3-abe2-11e9-974c-16aa19c3723a off the node ip-10-222-31-145
STEP: verifying the node doesn't have the label kubernetes.io/e2e-71b37ea3-abe2-11e9-974c-16aa19c3723a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:07:51.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5392" for this suite.
Jul 21 18:08:07.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:08:07.769: INFO: namespace sched-pred-5392 deletion completed in 16.642276771s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:24.852 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:08:07.771: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jjw6f in namespace proxy-8546
I0721 18:08:07.919937      16 runners.go:184] Created replication controller with name: proxy-service-jjw6f, namespace: proxy-8546, replica count: 1
I0721 18:08:08.991145      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 18:08:09.994517      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 18:08:10.997002      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 18:08:11.999681      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 18:08:13.003344      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0721 18:08:14.003659      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:15.003815      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:16.004913      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:17.005185      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:18.006217      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:19.006586      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:20.007004      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:21.007653      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:22.009138      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0721 18:08:23.010007      16 runners.go:184] proxy-service-jjw6f Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 21 18:08:23.016: INFO: setup took 15.183047516s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul 21 18:08:23.023: INFO: (0) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 6.847594ms)
Jul 21 18:08:23.025: INFO: (0) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 8.43515ms)
Jul 21 18:08:23.025: INFO: (0) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 6.171721ms)
Jul 21 18:08:23.026: INFO: (0) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 9.44334ms)
Jul 21 18:08:23.026: INFO: (0) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 6.658162ms)
Jul 21 18:08:23.026: INFO: (0) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 7.333569ms)
Jul 21 18:08:23.034: INFO: (0) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 14.921971ms)
Jul 21 18:08:23.035: INFO: (0) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 15.190963ms)
Jul 21 18:08:23.037: INFO: (0) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 17.723078ms)
Jul 21 18:08:23.037: INFO: (0) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 17.813392ms)
Jul 21 18:08:23.042: INFO: (0) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 22.761916ms)
Jul 21 18:08:23.042: INFO: (0) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 23.113017ms)
Jul 21 18:08:23.042: INFO: (0) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 22.715058ms)
Jul 21 18:08:23.043: INFO: (0) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 23.396279ms)
Jul 21 18:08:23.047: INFO: (0) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 27.313954ms)
Jul 21 18:08:23.047: INFO: (0) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 27.593348ms)
Jul 21 18:08:23.062: INFO: (1) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 15.266651ms)
Jul 21 18:08:23.062: INFO: (1) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 14.763001ms)
Jul 21 18:08:23.064: INFO: (1) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 16.62747ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 17.34548ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 16.94834ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 17.433092ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 17.74882ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 17.377314ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 17.294863ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 17.461923ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 17.288616ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 17.998398ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 17.61312ms)
Jul 21 18:08:23.065: INFO: (1) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 17.429834ms)
Jul 21 18:08:23.064: INFO: (1) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 16.192489ms)
Jul 21 18:08:23.067: INFO: (1) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 19.497683ms)
Jul 21 18:08:23.089: INFO: (2) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 21.421513ms)
Jul 21 18:08:23.089: INFO: (2) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 21.561893ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 22.204451ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 22.084988ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 22.417205ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 22.213039ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 22.431015ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 22.240018ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 22.230715ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 22.287154ms)
Jul 21 18:08:23.090: INFO: (2) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 22.480888ms)
Jul 21 18:08:23.091: INFO: (2) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 23.138521ms)
Jul 21 18:08:23.091: INFO: (2) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 22.977032ms)
Jul 21 18:08:23.091: INFO: (2) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 23.116805ms)
Jul 21 18:08:23.091: INFO: (2) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 22.767807ms)
Jul 21 18:08:23.091: INFO: (2) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 22.874487ms)
Jul 21 18:08:23.099: INFO: (3) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 7.853148ms)
Jul 21 18:08:23.099: INFO: (3) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 8.069032ms)
Jul 21 18:08:23.106: INFO: (3) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 11.278304ms)
Jul 21 18:08:23.109: INFO: (3) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 13.327479ms)
Jul 21 18:08:23.109: INFO: (3) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 13.171897ms)
Jul 21 18:08:23.109: INFO: (3) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 12.420306ms)
Jul 21 18:08:23.109: INFO: (3) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 12.375956ms)
Jul 21 18:08:23.111: INFO: (3) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 15.230424ms)
Jul 21 18:08:23.115: INFO: (3) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 15.739989ms)
Jul 21 18:08:23.115: INFO: (3) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 16.570803ms)
Jul 21 18:08:23.115: INFO: (3) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 18.022481ms)
Jul 21 18:08:23.115: INFO: (3) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 16.423858ms)
Jul 21 18:08:23.115: INFO: (3) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 23.733092ms)
Jul 21 18:08:23.119: INFO: (3) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 22.046056ms)
Jul 21 18:08:23.119: INFO: (3) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 22.194331ms)
Jul 21 18:08:23.119: INFO: (3) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 20.388863ms)
Jul 21 18:08:23.136: INFO: (4) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 17.465449ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 19.141056ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 19.040225ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 19.438698ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 19.570465ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 19.82012ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 19.704242ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 19.590139ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 19.418873ms)
Jul 21 18:08:23.139: INFO: (4) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 19.763574ms)
Jul 21 18:08:23.140: INFO: (4) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 20.566865ms)
Jul 21 18:08:23.140: INFO: (4) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 20.224661ms)
Jul 21 18:08:23.145: INFO: (4) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 25.767847ms)
Jul 21 18:08:23.145: INFO: (4) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 26.256897ms)
Jul 21 18:08:23.145: INFO: (4) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 26.044207ms)
Jul 21 18:08:23.145: INFO: (4) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 25.905472ms)
Jul 21 18:08:23.151: INFO: (5) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 5.296523ms)
Jul 21 18:08:23.151: INFO: (5) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 5.58917ms)
Jul 21 18:08:23.152: INFO: (5) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 6.19531ms)
Jul 21 18:08:23.152: INFO: (5) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 6.087976ms)
Jul 21 18:08:23.152: INFO: (5) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 6.330034ms)
Jul 21 18:08:23.152: INFO: (5) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 6.260727ms)
Jul 21 18:08:23.155: INFO: (5) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 8.826982ms)
Jul 21 18:08:23.155: INFO: (5) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 8.721157ms)
Jul 21 18:08:23.155: INFO: (5) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 9.459275ms)
Jul 21 18:08:23.155: INFO: (5) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 9.414612ms)
Jul 21 18:08:23.157: INFO: (5) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 11.207581ms)
Jul 21 18:08:23.157: INFO: (5) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 11.163915ms)
Jul 21 18:08:23.157: INFO: (5) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 11.477419ms)
Jul 21 18:08:23.158: INFO: (5) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 11.55223ms)
Jul 21 18:08:23.158: INFO: (5) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 11.556158ms)
Jul 21 18:08:23.158: INFO: (5) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 12.142993ms)
Jul 21 18:08:23.166: INFO: (6) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 7.790185ms)
Jul 21 18:08:23.166: INFO: (6) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 7.947013ms)
Jul 21 18:08:23.166: INFO: (6) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.868107ms)
Jul 21 18:08:23.166: INFO: (6) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 7.820763ms)
Jul 21 18:08:23.170: INFO: (6) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 12.149894ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 12.187616ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 12.255607ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 12.461786ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 12.669339ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 10.672148ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 12.543222ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 12.79763ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 12.479324ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 12.466464ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 12.917753ms)
Jul 21 18:08:23.171: INFO: (6) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 12.521616ms)
Jul 21 18:08:23.181: INFO: (7) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 9.724491ms)
Jul 21 18:08:23.181: INFO: (7) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 8.979374ms)
Jul 21 18:08:23.181: INFO: (7) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 9.488605ms)
Jul 21 18:08:23.181: INFO: (7) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 10.270435ms)
Jul 21 18:08:23.186: INFO: (7) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 14.71639ms)
Jul 21 18:08:23.187: INFO: (7) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 14.826784ms)
Jul 21 18:08:23.187: INFO: (7) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 14.813096ms)
Jul 21 18:08:23.188: INFO: (7) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 16.966279ms)
Jul 21 18:08:23.188: INFO: (7) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 17.045721ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 17.127931ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 17.28421ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 17.335018ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 17.838601ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 17.957731ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 17.943396ms)
Jul 21 18:08:23.189: INFO: (7) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 17.882998ms)
Jul 21 18:08:23.197: INFO: (8) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 6.013915ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 6.305805ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 7.407837ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.626299ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 7.593011ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 8.905987ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 8.010422ms)
Jul 21 18:08:23.199: INFO: (8) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 8.29676ms)
Jul 21 18:08:23.200: INFO: (8) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 10.47006ms)
Jul 21 18:08:23.200: INFO: (8) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 7.889693ms)
Jul 21 18:08:23.200: INFO: (8) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 10.101523ms)
Jul 21 18:08:23.202: INFO: (8) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 9.685945ms)
Jul 21 18:08:23.202: INFO: (8) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 10.821581ms)
Jul 21 18:08:23.202: INFO: (8) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 9.78853ms)
Jul 21 18:08:23.202: INFO: (8) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 10.137514ms)
Jul 21 18:08:23.203: INFO: (8) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 13.267142ms)
Jul 21 18:08:23.207: INFO: (9) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 3.96657ms)
Jul 21 18:08:23.208: INFO: (9) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 4.691752ms)
Jul 21 18:08:23.210: INFO: (9) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 6.003764ms)
Jul 21 18:08:23.211: INFO: (9) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 7.41681ms)
Jul 21 18:08:23.211: INFO: (9) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 7.555531ms)
Jul 21 18:08:23.211: INFO: (9) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 7.388798ms)
Jul 21 18:08:23.211: INFO: (9) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 7.319857ms)
Jul 21 18:08:23.213: INFO: (9) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 9.303222ms)
Jul 21 18:08:23.213: INFO: (9) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 8.980997ms)
Jul 21 18:08:23.213: INFO: (9) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 9.231819ms)
Jul 21 18:08:23.209: INFO: (9) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 5.423651ms)
Jul 21 18:08:23.214: INFO: (9) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 10.022461ms)
Jul 21 18:08:23.214: INFO: (9) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 11.149575ms)
Jul 21 18:08:23.215: INFO: (9) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 11.09868ms)
Jul 21 18:08:23.215: INFO: (9) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 11.156926ms)
Jul 21 18:08:23.216: INFO: (9) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 11.945159ms)
Jul 21 18:08:23.223: INFO: (10) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.518844ms)
Jul 21 18:08:23.223: INFO: (10) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 7.773907ms)
Jul 21 18:08:23.223: INFO: (10) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 7.690501ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.630059ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 7.639307ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 8.10536ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 7.867186ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 7.814284ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 7.962873ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 7.899041ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 7.99867ms)
Jul 21 18:08:23.224: INFO: (10) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 8.050187ms)
Jul 21 18:08:23.226: INFO: (10) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 10.524276ms)
Jul 21 18:08:23.226: INFO: (10) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 10.676791ms)
Jul 21 18:08:23.226: INFO: (10) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 10.803677ms)
Jul 21 18:08:23.226: INFO: (10) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 10.61524ms)
Jul 21 18:08:23.234: INFO: (11) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 6.641996ms)
Jul 21 18:08:23.234: INFO: (11) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 6.391752ms)
Jul 21 18:08:23.237: INFO: (11) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 9.200475ms)
Jul 21 18:08:23.237: INFO: (11) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 9.482346ms)
Jul 21 18:08:23.237: INFO: (11) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 10.566405ms)
Jul 21 18:08:23.237: INFO: (11) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 10.387152ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 11.584839ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 11.664433ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 12.153961ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 12.405513ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 12.321751ms)
Jul 21 18:08:23.239: INFO: (11) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 12.554324ms)
Jul 21 18:08:23.240: INFO: (11) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 13.850429ms)
Jul 21 18:08:23.241: INFO: (11) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 13.609504ms)
Jul 21 18:08:23.241: INFO: (11) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 14.243947ms)
Jul 21 18:08:23.242: INFO: (11) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 14.906253ms)
Jul 21 18:08:23.250: INFO: (12) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 7.895168ms)
Jul 21 18:08:23.250: INFO: (12) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 7.828504ms)
Jul 21 18:08:23.250: INFO: (12) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.787422ms)
Jul 21 18:08:23.250: INFO: (12) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 8.069265ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 16.996131ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 17.077325ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 17.019491ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 17.203602ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 17.14956ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 17.060299ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 17.319534ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 17.230163ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 17.134928ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 17.108246ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 17.151555ms)
Jul 21 18:08:23.259: INFO: (12) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 17.422981ms)
Jul 21 18:08:23.266: INFO: (13) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 6.582605ms)
Jul 21 18:08:23.266: INFO: (13) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 6.830858ms)
Jul 21 18:08:23.267: INFO: (13) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 7.207461ms)
Jul 21 18:08:23.269: INFO: (13) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 8.833269ms)
Jul 21 18:08:23.269: INFO: (13) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 9.126302ms)
Jul 21 18:08:23.270: INFO: (13) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 10.297848ms)
Jul 21 18:08:23.270: INFO: (13) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 10.440392ms)
Jul 21 18:08:23.270: INFO: (13) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 10.285348ms)
Jul 21 18:08:23.270: INFO: (13) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 10.338081ms)
Jul 21 18:08:23.270: INFO: (13) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 10.671691ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 99.859698ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 99.768952ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 100.095424ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 99.961753ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 99.868218ms)
Jul 21 18:08:23.360: INFO: (13) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 99.949613ms)
Jul 21 18:08:23.391: INFO: (14) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 29.066484ms)
Jul 21 18:08:23.391: INFO: (14) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 30.139048ms)
Jul 21 18:08:23.391: INFO: (14) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 30.394313ms)
Jul 21 18:08:23.391: INFO: (14) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 30.665261ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 31.464856ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 32.888937ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 31.649606ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 33.099489ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 31.81609ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 31.974831ms)
Jul 21 18:08:23.393: INFO: (14) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 32.191435ms)
Jul 21 18:08:23.398: INFO: (14) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 38.456262ms)
Jul 21 18:08:23.399: INFO: (14) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 38.252709ms)
Jul 21 18:08:23.399: INFO: (14) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 36.962343ms)
Jul 21 18:08:23.399: INFO: (14) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 38.150828ms)
Jul 21 18:08:23.399: INFO: (14) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 38.12177ms)
Jul 21 18:08:23.419: INFO: (15) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 13.774027ms)
Jul 21 18:08:23.419: INFO: (15) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 14.025031ms)
Jul 21 18:08:23.419: INFO: (15) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 14.68836ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 14.555025ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 21.230926ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 15.048574ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 15.390736ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 14.832363ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 15.04437ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 15.261936ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 15.432595ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 15.503921ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 15.777927ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 15.038357ms)
Jul 21 18:08:23.420: INFO: (15) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 15.281326ms)
Jul 21 18:08:23.422: INFO: (15) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 17.172286ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 13.283563ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 13.276057ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 14.138127ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 13.522929ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 13.48822ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 13.964154ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 14.327143ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 13.347723ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 14.219915ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 13.327821ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 14.118494ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 13.314003ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 13.585441ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 14.46153ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 14.277387ms)
Jul 21 18:08:23.437: INFO: (16) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 13.860076ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 9.68408ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 10.201346ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 9.511659ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 9.578508ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 9.647047ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 9.995845ms)
Jul 21 18:08:23.447: INFO: (17) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 9.37286ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 11.878523ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 11.211685ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 11.8632ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 11.347108ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 11.715188ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 11.327974ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 11.587691ms)
Jul 21 18:08:23.449: INFO: (17) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 11.826429ms)
Jul 21 18:08:23.451: INFO: (17) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 13.439414ms)
Jul 21 18:08:23.472: INFO: (18) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 20.696505ms)
Jul 21 18:08:23.475: INFO: (18) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 20.165175ms)
Jul 21 18:08:23.477: INFO: (18) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 22.192229ms)
Jul 21 18:08:23.477: INFO: (18) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 23.926723ms)
Jul 21 18:08:23.479: INFO: (18) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 24.206782ms)
Jul 21 18:08:23.499: INFO: (18) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 39.640454ms)
Jul 21 18:08:23.499: INFO: (18) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 39.853141ms)
Jul 21 18:08:23.499: INFO: (18) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 46.936579ms)
Jul 21 18:08:23.499: INFO: (18) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 40.034667ms)
Jul 21 18:08:23.500: INFO: (18) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 43.589368ms)
Jul 21 18:08:23.500: INFO: (18) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 41.265373ms)
Jul 21 18:08:23.500: INFO: (18) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 44.230157ms)
Jul 21 18:08:23.500: INFO: (18) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 43.112281ms)
Jul 21 18:08:23.502: INFO: (18) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 43.068034ms)
Jul 21 18:08:23.502: INFO: (18) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 43.276455ms)
Jul 21 18:08:23.499: INFO: (18) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 39.820202ms)
Jul 21 18:08:23.509: INFO: (19) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 4.998346ms)
Jul 21 18:08:23.511: INFO: (19) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 8.306021ms)
Jul 21 18:08:23.511: INFO: (19) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb/proxy/rewriteme">test</a> (200; 8.666351ms)
Jul 21 18:08:23.511: INFO: (19) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:443/proxy/tlsrewritem... (200; 8.480151ms)
Jul 21 18:08:23.536: INFO: (19) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname1/proxy/: foo (200; 31.238152ms)
Jul 21 18:08:23.537: INFO: (19) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname1/proxy/: foo (200; 34.902747ms)
Jul 21 18:08:23.538: INFO: (19) /api/v1/namespaces/proxy-8546/services/http:proxy-service-jjw6f:portname2/proxy/: bar (200; 32.52843ms)
Jul 21 18:08:23.541: INFO: (19) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname1/proxy/: tls baz (200; 35.222188ms)
Jul 21 18:08:23.541: INFO: (19) /api/v1/namespaces/proxy-8546/services/proxy-service-jjw6f:portname2/proxy/: bar (200; 34.967838ms)
Jul 21 18:08:23.541: INFO: (19) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:160/proxy/: foo (200; 35.329625ms)
Jul 21 18:08:23.541: INFO: (19) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:460/proxy/: tls baz (200; 35.179488ms)
Jul 21 18:08:23.541: INFO: (19) /api/v1/namespaces/proxy-8546/pods/https:proxy-service-jjw6f-dvwrb:462/proxy/: tls qux (200; 35.309269ms)
Jul 21 18:08:23.542: INFO: (19) /api/v1/namespaces/proxy-8546/services/https:proxy-service-jjw6f:tlsportname2/proxy/: tls qux (200; 35.522708ms)
Jul 21 18:08:23.542: INFO: (19) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">... (200; 35.901791ms)
Jul 21 18:08:23.542: INFO: (19) /api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8546/pods/proxy-service-jjw6f-dvwrb:1080/proxy/rewriteme">test<... (200; 35.855026ms)
Jul 21 18:08:23.542: INFO: (19) /api/v1/namespaces/proxy-8546/pods/http:proxy-service-jjw6f-dvwrb:162/proxy/: bar (200; 35.708211ms)
STEP: deleting ReplicationController proxy-service-jjw6f in namespace proxy-8546, will wait for the garbage collector to delete the pods
Jul 21 18:08:23.628: INFO: Deleting ReplicationController proxy-service-jjw6f took: 25.147728ms
Jul 21 18:08:24.029: INFO: Terminating ReplicationController proxy-service-jjw6f pods took: 400.827827ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:08:32.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8546" for this suite.
Jul 21 18:08:38.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:08:38.885: INFO: namespace proxy-8546 deletion completed in 6.325818578s

â€¢ [SLOW TEST:31.116 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:08:38.889: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul 21 18:08:39.008: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8823,SelfLink:/api/v1/namespaces/watch-8823/configmaps/e2e-watch-test-resource-version,UID:90a9e28d-abe2-11e9-9149-027a95377cb1,ResourceVersion:15899,Generation:0,CreationTimestamp:2019-07-21 18:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 21 18:08:39.008: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8823,SelfLink:/api/v1/namespaces/watch-8823/configmaps/e2e-watch-test-resource-version,UID:90a9e28d-abe2-11e9-9149-027a95377cb1,ResourceVersion:15900,Generation:0,CreationTimestamp:2019-07-21 18:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:08:39.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8823" for this suite.
Jul 21 18:08:45.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:08:45.602: INFO: namespace watch-8823 deletion completed in 6.582769389s

â€¢ [SLOW TEST:6.713 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:08:45.602: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-94a4e686-abe2-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:08:45.644: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a" in namespace "projected-8319" to be "success or failure"
Jul 21 18:08:45.660: INFO: Pod "pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.606667ms
Jul 21 18:08:47.668: INFO: Pod "pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023423654s
Jul 21 18:08:49.673: INFO: Pod "pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028394434s
STEP: Saw pod success
Jul 21 18:08:49.673: INFO: Pod "pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:08:49.675: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:08:49.712: INFO: Waiting for pod pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:08:49.713: INFO: Pod pod-projected-configmaps-94a5508c-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:08:49.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8319" for this suite.
Jul 21 18:08:55.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:08:56.296: INFO: namespace projected-8319 deletion completed in 6.580758693s

â€¢ [SLOW TEST:10.694 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:08:56.297: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-9b068cc8-abe2-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:08:56.358: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a" in namespace "configmap-638" to be "success or failure"
Jul 21 18:08:56.366: INFO: Pod "pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.551271ms
Jul 21 18:08:58.371: INFO: Pod "pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013025117s
Jul 21 18:09:00.390: INFO: Pod "pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031910131s
STEP: Saw pod success
Jul 21 18:09:00.390: INFO: Pod "pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:09:00.395: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:09:00.446: INFO: Waiting for pod pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:09:00.454: INFO: Pod pod-configmaps-9b080a3f-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:09:00.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-638" for this suite.
Jul 21 18:09:06.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:09:07.095: INFO: namespace configmap-638 deletion completed in 6.633332273s

â€¢ [SLOW TEST:10.798 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:09:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:09:07.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a" in namespace "projected-4188" to be "success or failure"
Jul 21 18:09:07.157: INFO: Pod "downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 19.266367ms
Jul 21 18:09:09.160: INFO: Pod "downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022595508s
Jul 21 18:09:11.167: INFO: Pod "downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029251629s
STEP: Saw pod success
Jul 21 18:09:11.167: INFO: Pod "downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:09:11.180: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:09:11.241: INFO: Waiting for pod downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:09:11.258: INFO: Pod downwardapi-volume-a1752bdf-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:09:11.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4188" for this suite.
Jul 21 18:09:17.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:09:17.848: INFO: namespace projected-4188 deletion completed in 6.584949801s

â€¢ [SLOW TEST:10.753 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:09:17.848: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-5136
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5136 to expose endpoints map[]
Jul 21 18:09:17.902: INFO: successfully validated that service endpoint-test2 in namespace services-5136 exposes endpoints map[] (6.114846ms elapsed)
STEP: Creating pod pod1 in namespace services-5136
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5136 to expose endpoints map[pod1:[80]]
Jul 21 18:09:20.956: INFO: successfully validated that service endpoint-test2 in namespace services-5136 exposes endpoints map[pod1:[80]] (3.045036349s elapsed)
STEP: Creating pod pod2 in namespace services-5136
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5136 to expose endpoints map[pod1:[80] pod2:[80]]
Jul 21 18:09:24.049: INFO: successfully validated that service endpoint-test2 in namespace services-5136 exposes endpoints map[pod1:[80] pod2:[80]] (3.075918436s elapsed)
STEP: Deleting pod pod1 in namespace services-5136
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5136 to expose endpoints map[pod2:[80]]
Jul 21 18:09:24.119: INFO: successfully validated that service endpoint-test2 in namespace services-5136 exposes endpoints map[pod2:[80]] (24.12207ms elapsed)
STEP: Deleting pod pod2 in namespace services-5136
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5136 to expose endpoints map[]
Jul 21 18:09:25.149: INFO: successfully validated that service endpoint-test2 in namespace services-5136 exposes endpoints map[] (1.014980479s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:09:25.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5136" for this suite.
Jul 21 18:09:47.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:09:47.759: INFO: namespace services-5136 deletion completed in 22.58745216s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:29.911 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:09:47.760: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b9b1c24d-abe2-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:09:47.858: INFO: Waiting up to 5m0s for pod "pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a" in namespace "secrets-1606" to be "success or failure"
Jul 21 18:09:47.873: INFO: Pod "pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.418253ms
Jul 21 18:09:49.881: INFO: Pod "pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023230115s
Jul 21 18:09:51.884: INFO: Pod "pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025884348s
STEP: Saw pod success
Jul 21 18:09:51.884: INFO: Pod "pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:09:51.888: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:09:51.926: INFO: Waiting for pod pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:09:51.930: INFO: Pod pod-secrets-b9bad4f8-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:09:51.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1606" for this suite.
Jul 21 18:09:57.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:09:58.531: INFO: namespace secrets-1606 deletion completed in 6.595042s
STEP: Destroying namespace "secret-namespace-5159" for this suite.
Jul 21 18:10:06.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:10:07.503: INFO: namespace secret-namespace-5159 deletion completed in 8.97229872s

â€¢ [SLOW TEST:19.743 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:10:07.504: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:10:07.567: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:10:08.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1187" for this suite.
Jul 21 18:10:16.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:10:17.538: INFO: namespace custom-resource-definition-1187 deletion completed in 8.741609724s

â€¢ [SLOW TEST:10.035 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:10:17.540: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 21 18:10:17.672: INFO: Waiting up to 5m0s for pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a" in namespace "emptydir-8127" to be "success or failure"
Jul 21 18:10:17.700: INFO: Pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 27.593447ms
Jul 21 18:10:19.737: INFO: Pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064822915s
Jul 21 18:10:21.747: INFO: Pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075291112s
Jul 21 18:10:23.757: INFO: Pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084694009s
STEP: Saw pod success
Jul 21 18:10:23.757: INFO: Pod "pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:10:23.772: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:10:23.831: INFO: Waiting for pod pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:10:23.847: INFO: Pod pod-cb7e6fc4-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:10:23.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8127" for this suite.
Jul 21 18:10:29.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:10:30.856: INFO: namespace emptydir-8127 deletion completed in 6.97398198s

â€¢ [SLOW TEST:13.316 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:10:30.859: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-7283
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7283 to expose endpoints map[]
Jul 21 18:10:31.018: INFO: successfully validated that service multi-endpoint-test in namespace services-7283 exposes endpoints map[] (32.462642ms elapsed)
STEP: Creating pod pod1 in namespace services-7283
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7283 to expose endpoints map[pod1:[100]]
Jul 21 18:10:35.158: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.114679141s elapsed, will retry)
Jul 21 18:10:37.179: INFO: successfully validated that service multi-endpoint-test in namespace services-7283 exposes endpoints map[pod1:[100]] (6.134870163s elapsed)
STEP: Creating pod pod2 in namespace services-7283
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7283 to expose endpoints map[pod1:[100] pod2:[101]]
Jul 21 18:10:40.302: INFO: successfully validated that service multi-endpoint-test in namespace services-7283 exposes endpoints map[pod1:[100] pod2:[101]] (3.116137017s elapsed)
STEP: Deleting pod pod1 in namespace services-7283
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7283 to expose endpoints map[pod2:[101]]
Jul 21 18:10:40.350: INFO: successfully validated that service multi-endpoint-test in namespace services-7283 exposes endpoints map[pod2:[101]] (36.209753ms elapsed)
STEP: Deleting pod pod2 in namespace services-7283
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7283 to expose endpoints map[]
Jul 21 18:10:40.393: INFO: successfully validated that service multi-endpoint-test in namespace services-7283 exposes endpoints map[] (9.563953ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:10:40.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7283" for this suite.
Jul 21 18:11:04.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:11:05.119: INFO: namespace services-7283 deletion completed in 24.639792613s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:34.261 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:11:05.120: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Jul 21 18:11:05.239: INFO: Waiting up to 5m0s for pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a" in namespace "containers-6170" to be "success or failure"
Jul 21 18:11:05.249: INFO: Pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.757007ms
Jul 21 18:11:07.260: INFO: Pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02000235s
Jul 21 18:11:09.287: INFO: Pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046820003s
Jul 21 18:11:11.310: INFO: Pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.070137486s
STEP: Saw pod success
Jul 21 18:11:11.310: INFO: Pod "client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:11:11.314: INFO: Trying to get logs from node ip-10-222-31-145 pod client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:11:11.380: INFO: Waiting for pod client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a to disappear
Jul 21 18:11:11.383: INFO: Pod client-containers-e7d65429-abe2-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:11:11.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6170" for this suite.
Jul 21 18:11:19.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:11:20.049: INFO: namespace containers-6170 deletion completed in 8.662836717s

â€¢ [SLOW TEST:14.929 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:11:20.050: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Jul 21 18:11:20.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-4349'
Jul 21 18:11:21.089: INFO: stderr: ""
Jul 21 18:11:21.089: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Jul 21 18:11:22.105: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:11:22.105: INFO: Found 0 / 1
Jul 21 18:11:23.098: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:11:23.098: INFO: Found 0 / 1
Jul 21 18:11:24.117: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:11:24.117: INFO: Found 1 / 1
Jul 21 18:11:24.117: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 21 18:11:24.124: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:11:24.124: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jul 21 18:11:24.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 logs redis-master-7h2cr redis-master --namespace=kubectl-4349'
Jul 21 18:11:24.473: INFO: stderr: ""
Jul 21 18:11:24.473: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jul 18:11:23.502 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jul 18:11:23.502 # Server started, Redis version 3.2.12\n1:M 21 Jul 18:11:23.502 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jul 18:11:23.502 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jul 21 18:11:24.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 log redis-master-7h2cr redis-master --namespace=kubectl-4349 --tail=1'
Jul 21 18:11:24.656: INFO: stderr: ""
Jul 21 18:11:24.656: INFO: stdout: "1:M 21 Jul 18:11:23.502 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jul 21 18:11:24.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 log redis-master-7h2cr redis-master --namespace=kubectl-4349 --limit-bytes=1'
Jul 21 18:11:24.825: INFO: stderr: ""
Jul 21 18:11:24.825: INFO: stdout: " "
STEP: exposing timestamps
Jul 21 18:11:24.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 log redis-master-7h2cr redis-master --namespace=kubectl-4349 --tail=1 --timestamps'
Jul 21 18:11:25.020: INFO: stderr: ""
Jul 21 18:11:25.020: INFO: stdout: "2019-07-21T18:11:23.50348419Z 1:M 21 Jul 18:11:23.502 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jul 21 18:11:27.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 log redis-master-7h2cr redis-master --namespace=kubectl-4349 --since=1s'
Jul 21 18:11:27.752: INFO: stderr: ""
Jul 21 18:11:27.752: INFO: stdout: ""
Jul 21 18:11:27.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 log redis-master-7h2cr redis-master --namespace=kubectl-4349 --since=24h'
Jul 21 18:11:28.171: INFO: stderr: ""
Jul 21 18:11:28.171: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jul 18:11:23.502 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jul 18:11:23.502 # Server started, Redis version 3.2.12\n1:M 21 Jul 18:11:23.502 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jul 18:11:23.502 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Jul 21 18:11:28.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-4349'
Jul 21 18:11:28.299: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:11:28.300: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jul 21 18:11:28.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4349'
Jul 21 18:11:28.491: INFO: stderr: "No resources found.\n"
Jul 21 18:11:28.491: INFO: stdout: ""
Jul 21 18:11:28.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -l name=nginx --namespace=kubectl-4349 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 21 18:11:28.695: INFO: stderr: ""
Jul 21 18:11:28.695: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:11:28.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4349" for this suite.
Jul 21 18:11:52.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:11:53.266: INFO: namespace kubectl-4349 deletion completed in 24.568944618s

â€¢ [SLOW TEST:33.217 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:11:53.267: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-0481994c-abe3-11e9-974c-16aa19c3723a
STEP: Creating secret with name s-test-opt-upd-04819997-abe3-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0481994c-abe3-11e9-974c-16aa19c3723a
STEP: Updating secret s-test-opt-upd-04819997-abe3-11e9-974c-16aa19c3723a
STEP: Creating secret with name s-test-opt-create-048199b5-abe3-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:12:01.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5516" for this suite.
Jul 21 18:12:25.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:12:26.068: INFO: namespace projected-5516 deletion completed in 24.592804166s

â€¢ [SLOW TEST:32.802 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:12:26.069: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9392
Jul 21 18:12:30.199: INFO: Started pod liveness-http in namespace container-probe-9392
STEP: checking the pod's current state and verifying that restartCount is present
Jul 21 18:12:30.204: INFO: Initial restart count of pod liveness-http is 0
Jul 21 18:12:50.293: INFO: Restart count of pod container-probe-9392/liveness-http is now 1 (20.088720243s elapsed)
Jul 21 18:13:10.357: INFO: Restart count of pod container-probe-9392/liveness-http is now 2 (40.152584675s elapsed)
Jul 21 18:13:30.441: INFO: Restart count of pod container-probe-9392/liveness-http is now 3 (1m0.23707793s elapsed)
Jul 21 18:13:50.527: INFO: Restart count of pod container-probe-9392/liveness-http is now 4 (1m20.322191866s elapsed)
Jul 21 18:14:54.904: INFO: Restart count of pod container-probe-9392/liveness-http is now 5 (2m24.69944842s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:14:54.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9392" for this suite.
Jul 21 18:15:01.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:15:01.584: INFO: namespace container-probe-9392 deletion completed in 6.604924571s

â€¢ [SLOW TEST:155.516 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:15:01.591: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-74c669f6-abe3-11e9-974c-16aa19c3723a
STEP: Creating secret with name s-test-opt-upd-74c66a44-abe3-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-74c669f6-abe3-11e9-974c-16aa19c3723a
STEP: Updating secret s-test-opt-upd-74c66a44-abe3-11e9-974c-16aa19c3723a
STEP: Creating secret with name s-test-opt-create-74c66a66-abe3-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:16:26.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1251" for this suite.
Jul 21 18:16:51.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:16:51.607: INFO: namespace secrets-1251 deletion completed in 24.616161791s

â€¢ [SLOW TEST:110.017 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:16:51.608: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:16:51.646: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a" in namespace "downward-api-7711" to be "success or failure"
Jul 21 18:16:51.661: INFO: Pod "downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.621952ms
Jul 21 18:16:53.664: INFO: Pod "downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017605591s
Jul 21 18:16:55.669: INFO: Pod "downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022472159s
STEP: Saw pod success
Jul 21 18:16:55.669: INFO: Pod "downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:16:55.673: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:16:55.717: INFO: Waiting for pod downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a to disappear
Jul 21 18:16:55.724: INFO: Pod downwardapi-volume-b6539e50-abe3-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:16:55.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7711" for this suite.
Jul 21 18:17:03.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:17:04.358: INFO: namespace downward-api-7711 deletion completed in 8.594371145s

â€¢ [SLOW TEST:12.750 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:17:04.358: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-bdf1248a-abe3-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:17:04.442: INFO: Waiting up to 5m0s for pod "pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a" in namespace "secrets-3753" to be "success or failure"
Jul 21 18:17:04.451: INFO: Pod "pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.221911ms
Jul 21 18:17:06.455: INFO: Pod "pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012221741s
Jul 21 18:17:08.457: INFO: Pod "pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014821136s
STEP: Saw pod success
Jul 21 18:17:08.457: INFO: Pod "pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:17:08.459: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:17:08.482: INFO: Waiting for pod pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a to disappear
Jul 21 18:17:08.484: INFO: Pod pod-secrets-bdf1d679-abe3-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:17:08.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3753" for this suite.
Jul 21 18:17:14.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:17:15.078: INFO: namespace secrets-3753 deletion completed in 6.590245977s

â€¢ [SLOW TEST:10.720 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:17:15.078: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:17:15.113: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 21 18:17:20.116: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 21 18:17:20.116: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 21 18:17:22.120: INFO: Creating deployment "test-rollover-deployment"
Jul 21 18:17:22.127: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 21 18:17:24.141: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 21 18:17:24.148: INFO: Ensure that both replica sets have 1 created replica
Jul 21 18:17:24.162: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 21 18:17:24.180: INFO: Updating deployment test-rollover-deployment
Jul 21 18:17:24.181: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 21 18:17:26.199: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 21 18:17:26.208: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 21 18:17:26.216: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:26.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329844, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:28.220: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:28.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329847, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:30.225: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:30.225: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329847, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:32.226: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:32.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329847, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:34.231: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:34.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329847, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:36.224: INFO: all replica sets need to contain the pod-template-hash label
Jul 21 18:17:36.225: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329847, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699329842, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 18:17:38.225: INFO: 
Jul 21 18:17:38.225: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 21 18:17:38.233: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-889,SelfLink:/apis/apps/v1/namespaces/deployment-889/deployments/test-rollover-deployment,UID:c87f1816-abe3-11e9-9149-027a95377cb1,ResourceVersion:17447,Generation:2,CreationTimestamp:2019-07-21 18:17:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-21 18:17:22 +0000 UTC 2019-07-21 18:17:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-21 18:17:37 +0000 UTC 2019-07-21 18:17:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 21 18:17:38.236: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-889,SelfLink:/apis/apps/v1/namespaces/deployment-889/replicasets/test-rollover-deployment-766b4d6c9d,UID:c9b8e155-abe3-11e9-9149-027a95377cb1,ResourceVersion:17436,Generation:2,CreationTimestamp:2019-07-21 18:17:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c87f1816-abe3-11e9-9149-027a95377cb1 0xc00124af17 0xc00124af18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 21 18:17:38.236: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 21 18:17:38.236: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-889,SelfLink:/apis/apps/v1/namespaces/deployment-889/replicasets/test-rollover-controller,UID:c4510a64-abe3-11e9-9149-027a95377cb1,ResourceVersion:17446,Generation:2,CreationTimestamp:2019-07-21 18:17:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c87f1816-abe3-11e9-9149-027a95377cb1 0xc00124ad27 0xc00124ad28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 18:17:38.236: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-889,SelfLink:/apis/apps/v1/namespaces/deployment-889/replicasets/test-rollover-deployment-6455657675,UID:c881a6ee-abe3-11e9-9149-027a95377cb1,ResourceVersion:17396,Generation:2,CreationTimestamp:2019-07-21 18:17:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c87f1816-abe3-11e9-9149-027a95377cb1 0xc00124adf7 0xc00124adf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 18:17:38.239: INFO: Pod "test-rollover-deployment-766b4d6c9d-l2tv6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-l2tv6,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-889,SelfLink:/api/v1/namespaces/deployment-889/pods/test-rollover-deployment-766b4d6c9d-l2tv6,UID:c9c18caa-abe3-11e9-9149-027a95377cb1,ResourceVersion:17415,Generation:0,CreationTimestamp:2019-07-21 18:17:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.159/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d c9b8e155-abe3-11e9-9149-027a95377cb1 0xc002160737 0xc002160738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-w99m7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w99m7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-w99m7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021607b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021607d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:17:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:17:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:17:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:17:24 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.159,StartTime:2019-07-21 18:17:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-21 18:17:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cd47150d4a22a83f049f4d930e18b2afcc32fb84eeeda33cb6da9ce3370c843e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:17:38.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-889" for this suite.
Jul 21 18:17:44.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:17:44.886: INFO: namespace deployment-889 deletion completed in 6.644184572s

â€¢ [SLOW TEST:29.808 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:17:44.886: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 21 18:17:49.499: INFO: Successfully updated pod "pod-update-d61d66c8-abe3-11e9-974c-16aa19c3723a"
STEP: verifying the updated pod is in kubernetes
Jul 21 18:17:49.518: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:17:49.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2634" for this suite.
Jul 21 18:18:11.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:18:12.588: INFO: namespace pods-2634 deletion completed in 23.067952025s

â€¢ [SLOW TEST:27.701 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:18:12.589: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:18:12.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a" in namespace "projected-9833" to be "success or failure"
Jul 21 18:18:12.843: INFO: Pod "downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 29.908588ms
Jul 21 18:18:14.884: INFO: Pod "downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071148791s
Jul 21 18:18:16.887: INFO: Pod "downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073861558s
STEP: Saw pod success
Jul 21 18:18:16.887: INFO: Pod "downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:18:16.890: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:18:16.923: INFO: Waiting for pod downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a to disappear
Jul 21 18:18:16.925: INFO: Pod downwardapi-volume-e6b3edd2-abe3-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:18:16.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9833" for this suite.
Jul 21 18:18:22.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:18:23.522: INFO: namespace projected-9833 deletion completed in 6.590877868s

â€¢ [SLOW TEST:10.933 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:18:23.522: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:18:23.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 version'
Jul 21 18:18:23.681: INFO: stderr: ""
Jul 21 18:18:23.681: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:18:23.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4297" for this suite.
Jul 21 18:18:29.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:18:30.274: INFO: namespace kubectl-4297 deletion completed in 6.585167465s

â€¢ [SLOW TEST:6.751 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:18:30.274: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f123b366-abe3-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:18:30.322: INFO: Waiting up to 5m0s for pod "pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a" in namespace "configmap-7403" to be "success or failure"
Jul 21 18:18:30.344: INFO: Pod "pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006496ms
Jul 21 18:18:32.350: INFO: Pod "pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027592961s
Jul 21 18:18:34.354: INFO: Pod "pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0316604s
STEP: Saw pod success
Jul 21 18:18:34.354: INFO: Pod "pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:18:34.358: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:18:34.407: INFO: Waiting for pod pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a to disappear
Jul 21 18:18:34.411: INFO: Pod pod-configmaps-f1242335-abe3-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:18:34.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7403" for this suite.
Jul 21 18:18:40.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:18:41.021: INFO: namespace configmap-7403 deletion completed in 6.593834934s

â€¢ [SLOW TEST:10.747 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:18:41.021: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-rvpn
STEP: Creating a pod to test atomic-volume-subpath
Jul 21 18:18:41.095: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rvpn" in namespace "subpath-1388" to be "success or failure"
Jul 21 18:18:41.103: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.560434ms
Jul 21 18:18:43.108: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013050951s
Jul 21 18:18:45.111: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 4.015943368s
Jul 21 18:18:47.118: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 6.023392855s
Jul 21 18:18:49.126: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 8.031243838s
Jul 21 18:18:51.135: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 10.040624082s
Jul 21 18:18:53.138: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 12.043291157s
Jul 21 18:18:55.140: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 14.045686908s
Jul 21 18:18:57.143: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 16.048562908s
Jul 21 18:18:59.149: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 18.05472657s
Jul 21 18:19:01.231: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 20.135911082s
Jul 21 18:19:03.239: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Running", Reason="", readiness=true. Elapsed: 22.144429728s
Jul 21 18:19:05.255: INFO: Pod "pod-subpath-test-configmap-rvpn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.16043177s
STEP: Saw pod success
Jul 21 18:19:05.255: INFO: Pod "pod-subpath-test-configmap-rvpn" satisfied condition "success or failure"
Jul 21 18:19:05.268: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-subpath-test-configmap-rvpn container test-container-subpath-configmap-rvpn: <nil>
STEP: delete the pod
Jul 21 18:19:05.302: INFO: Waiting for pod pod-subpath-test-configmap-rvpn to disappear
Jul 21 18:19:05.305: INFO: Pod pod-subpath-test-configmap-rvpn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rvpn
Jul 21 18:19:05.305: INFO: Deleting pod "pod-subpath-test-configmap-rvpn" in namespace "subpath-1388"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:19:05.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1388" for this suite.
Jul 21 18:19:11.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:19:11.943: INFO: namespace subpath-1388 deletion completed in 6.628196977s

â€¢ [SLOW TEST:30.922 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:19:11.944: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-09fd16cb-abe4-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:19:12.023: INFO: Waiting up to 5m0s for pod "pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a" in namespace "configmap-6475" to be "success or failure"
Jul 21 18:19:12.046: INFO: Pod "pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 23.42725ms
Jul 21 18:19:14.062: INFO: Pod "pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039376647s
Jul 21 18:19:16.067: INFO: Pod "pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044465683s
STEP: Saw pod success
Jul 21 18:19:16.067: INFO: Pod "pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:19:16.089: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:19:16.109: INFO: Waiting for pod pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a to disappear
Jul 21 18:19:16.112: INFO: Pod pod-configmaps-09fe7841-abe4-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:19:16.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6475" for this suite.
Jul 21 18:19:22.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:19:22.715: INFO: namespace configmap-6475 deletion completed in 6.599613939s

â€¢ [SLOW TEST:10.771 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:19:22.715: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5713
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 21 18:19:22.737: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 21 18:19:46.794: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.165 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5713 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:19:46.794: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:19:47.981: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:19:47.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5713" for this suite.
Jul 21 18:20:10.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:20:10.582: INFO: namespace pod-network-test-5713 deletion completed in 22.598859479s

â€¢ [SLOW TEST:47.867 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:20:10.584: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:20:10.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-2164'
Jul 21 18:20:11.264: INFO: stderr: ""
Jul 21 18:20:11.264: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jul 21 18:20:16.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pod e2e-test-nginx-pod --namespace=kubectl-2164 -o json'
Jul 21 18:20:16.401: INFO: stderr: ""
Jul 21 18:20:16.401: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.0.167/32\"\n        },\n        \"creationTimestamp\": \"2019-07-21T18:20:11Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-2164\",\n        \"resourceVersion\": \"17975\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2164/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2d33fd77-abe4-11e9-9149-027a95377cb1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9jqtr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-222-31-145\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9jqtr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9jqtr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-21T18:20:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-21T18:20:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-21T18:20:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-21T18:20:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2b67d6554033089b670042d159d1ebf2171c7ffcdb0c903fcf5a25bb965185aa\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-07-21T18:20:14Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.222.31.145\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.167\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-07-21T18:20:11Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul 21 18:20:16.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 replace -f - --namespace=kubectl-2164'
Jul 21 18:20:16.607: INFO: stderr: ""
Jul 21 18:20:16.608: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Jul 21 18:20:16.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete pods e2e-test-nginx-pod --namespace=kubectl-2164'
Jul 21 18:20:22.440: INFO: stderr: ""
Jul 21 18:20:22.440: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:20:22.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2164" for this suite.
Jul 21 18:20:28.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:20:29.029: INFO: namespace kubectl-2164 deletion completed in 6.584184813s

â€¢ [SLOW TEST:18.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:20:29.030: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-37ebc979-abe4-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:20:29.068: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a" in namespace "projected-7076" to be "success or failure"
Jul 21 18:20:29.074: INFO: Pod "pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.959324ms
Jul 21 18:20:31.091: INFO: Pod "pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022329472s
Jul 21 18:20:33.099: INFO: Pod "pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030375939s
STEP: Saw pod success
Jul 21 18:20:33.099: INFO: Pod "pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:20:33.103: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:20:33.129: INFO: Waiting for pod pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a to disappear
Jul 21 18:20:33.133: INFO: Pod pod-projected-secrets-37ec3870-abe4-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:20:33.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7076" for this suite.
Jul 21 18:20:39.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:20:39.739: INFO: namespace projected-7076 deletion completed in 6.58699307s

â€¢ [SLOW TEST:10.709 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:20:39.739: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul 21 18:20:40.132: INFO: Pod name wrapped-volume-race-3e82c6e2-abe4-11e9-974c-16aa19c3723a: Found 0 pods out of 5
Jul 21 18:20:45.136: INFO: Pod name wrapped-volume-race-3e82c6e2-abe4-11e9-974c-16aa19c3723a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3e82c6e2-abe4-11e9-974c-16aa19c3723a in namespace emptydir-wrapper-7761, will wait for the garbage collector to delete the pods
Jul 21 18:20:57.217: INFO: Deleting ReplicationController wrapped-volume-race-3e82c6e2-abe4-11e9-974c-16aa19c3723a took: 9.953136ms
Jul 21 18:20:57.617: INFO: Terminating ReplicationController wrapped-volume-race-3e82c6e2-abe4-11e9-974c-16aa19c3723a pods took: 400.198983ms
STEP: Creating RC which spawns configmap-volume pods
Jul 21 18:21:42.843: INFO: Pod name wrapped-volume-race-63e2f7ce-abe4-11e9-974c-16aa19c3723a: Found 0 pods out of 5
Jul 21 18:21:47.851: INFO: Pod name wrapped-volume-race-63e2f7ce-abe4-11e9-974c-16aa19c3723a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-63e2f7ce-abe4-11e9-974c-16aa19c3723a in namespace emptydir-wrapper-7761, will wait for the garbage collector to delete the pods
Jul 21 18:21:59.963: INFO: Deleting ReplicationController wrapped-volume-race-63e2f7ce-abe4-11e9-974c-16aa19c3723a took: 5.718599ms
Jul 21 18:22:00.373: INFO: Terminating ReplicationController wrapped-volume-race-63e2f7ce-abe4-11e9-974c-16aa19c3723a pods took: 409.964205ms
STEP: Creating RC which spawns configmap-volume pods
Jul 21 18:22:42.884: INFO: Pod name wrapped-volume-race-87ae171a-abe4-11e9-974c-16aa19c3723a: Found 0 pods out of 5
Jul 21 18:22:47.889: INFO: Pod name wrapped-volume-race-87ae171a-abe4-11e9-974c-16aa19c3723a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-87ae171a-abe4-11e9-974c-16aa19c3723a in namespace emptydir-wrapper-7761, will wait for the garbage collector to delete the pods
Jul 21 18:22:59.973: INFO: Deleting ReplicationController wrapped-volume-race-87ae171a-abe4-11e9-974c-16aa19c3723a took: 9.233397ms
Jul 21 18:23:00.375: INFO: Terminating ReplicationController wrapped-volume-race-87ae171a-abe4-11e9-974c-16aa19c3723a pods took: 401.547376ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:23:42.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7761" for this suite.
Jul 21 18:23:48.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:23:49.530: INFO: namespace emptydir-wrapper-7761 deletion completed in 6.568457669s

â€¢ [SLOW TEST:189.792 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:23:49.531: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-af6d365e-abe4-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:23:49.565: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a" in namespace "projected-8198" to be "success or failure"
Jul 21 18:23:49.569: INFO: Pod "pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.614666ms
Jul 21 18:23:51.579: INFO: Pod "pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013888875s
Jul 21 18:23:53.582: INFO: Pod "pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016946201s
STEP: Saw pod success
Jul 21 18:23:53.582: INFO: Pod "pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:23:53.590: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:23:53.619: INFO: Waiting for pod pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a to disappear
Jul 21 18:23:53.627: INFO: Pod pod-projected-secrets-af6d9395-abe4-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:23:53.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8198" for this suite.
Jul 21 18:23:59.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:24:00.215: INFO: namespace projected-8198 deletion completed in 6.582951454s

â€¢ [SLOW TEST:10.684 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:24:00.215: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:24:00.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9451'
Jul 21 18:24:00.867: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 21 18:24:00.867: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Jul 21 18:24:00.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete jobs e2e-test-nginx-job --namespace=kubectl-9451'
Jul 21 18:24:01.034: INFO: stderr: ""
Jul 21 18:24:01.034: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:24:01.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9451" for this suite.
Jul 21 18:24:25.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:24:25.628: INFO: namespace kubectl-9451 deletion completed in 24.589621411s

â€¢ [SLOW TEST:25.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:24:25.628: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0721 18:25:05.793661      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 18:25:05.793: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:25:05.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9873" for this suite.
Jul 21 18:25:13.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:25:14.845: INFO: namespace gc-9873 deletion completed in 9.048211971s

â€¢ [SLOW TEST:49.217 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:25:14.845: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:25:43.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4442" for this suite.
Jul 21 18:25:49.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:25:49.593: INFO: namespace namespaces-4442 deletion completed in 6.570954122s
STEP: Destroying namespace "nsdeletetest-6258" for this suite.
Jul 21 18:25:49.595: INFO: Namespace nsdeletetest-6258 was already deleted
STEP: Destroying namespace "nsdeletetest-2757" for this suite.
Jul 21 18:25:55.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:25:56.163: INFO: namespace nsdeletetest-2757 deletion completed in 6.567784919s

â€¢ [SLOW TEST:41.318 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:25:56.163: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:25:56.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8872" for this suite.
Jul 21 18:26:18.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:26:18.798: INFO: namespace pods-8872 deletion completed in 22.585089301s

â€¢ [SLOW TEST:22.635 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:26:18.798: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Jul 21 18:26:18.858: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jul 21 18:26:18.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:19.471: INFO: stderr: ""
Jul 21 18:26:19.471: INFO: stdout: "service/redis-slave created\n"
Jul 21 18:26:19.472: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jul 21 18:26:19.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:19.955: INFO: stderr: ""
Jul 21 18:26:19.955: INFO: stdout: "service/redis-master created\n"
Jul 21 18:26:19.955: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 21 18:26:19.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:20.280: INFO: stderr: ""
Jul 21 18:26:20.280: INFO: stdout: "service/frontend created\n"
Jul 21 18:26:20.280: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jul 21 18:26:20.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:20.872: INFO: stderr: ""
Jul 21 18:26:20.872: INFO: stdout: "deployment.apps/frontend created\n"
Jul 21 18:26:20.873: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 21 18:26:20.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:22.388: INFO: stderr: ""
Jul 21 18:26:22.388: INFO: stdout: "deployment.apps/redis-master created\n"
Jul 21 18:26:22.393: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jul 21 18:26:22.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5785'
Jul 21 18:26:23.288: INFO: stderr: ""
Jul 21 18:26:23.288: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jul 21 18:26:23.288: INFO: Waiting for all frontend pods to be Running.
Jul 21 18:26:43.340: INFO: Waiting for frontend to serve content.
Jul 21 18:26:48.358: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 21 18:26:53.368: INFO: Trying to add a new entry to the guestbook.
Jul 21 18:26:53.375: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul 21 18:26:53.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:53.479: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:53.479: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jul 21 18:26:53.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:53.618: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:53.618: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 21 18:26:53.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:53.723: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:53.723: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 21 18:26:53.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:53.849: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:53.849: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 21 18:26:53.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:54.019: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:54.019: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 21 18:26:54.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-5785'
Jul 21 18:26:54.392: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:26:54.392: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:26:54.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5785" for this suite.
Jul 21 18:27:34.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:27:35.044: INFO: namespace kubectl-5785 deletion completed in 40.614441214s

â€¢ [SLOW TEST:76.247 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:27:35.044: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0721 18:28:05.257033      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 18:28:05.258: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:28:05.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5952" for this suite.
Jul 21 18:28:11.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:28:11.890: INFO: namespace gc-5952 deletion completed in 6.6268604s

â€¢ [SLOW TEST:36.845 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:28:11.890: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-4bd1bebf-abe5-11e9-974c-16aa19c3723a
STEP: Creating secret with name secret-projected-all-test-volume-4bd1bea7-abe5-11e9-974c-16aa19c3723a
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul 21 18:28:12.029: INFO: Waiting up to 5m0s for pod "projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a" in namespace "projected-2314" to be "success or failure"
Jul 21 18:28:12.039: INFO: Pod "projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.61876ms
Jul 21 18:28:14.048: INFO: Pod "projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018796309s
Jul 21 18:28:16.052: INFO: Pod "projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023240919s
STEP: Saw pod success
Jul 21 18:28:16.052: INFO: Pod "projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:28:16.055: INFO: Trying to get logs from node ip-10-222-31-145 pod projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a container projected-all-volume-test: <nil>
STEP: delete the pod
Jul 21 18:28:16.090: INFO: Waiting for pod projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a to disappear
Jul 21 18:28:16.099: INFO: Pod projected-volume-4bd1be61-abe5-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:28:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2314" for this suite.
Jul 21 18:28:22.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:28:22.736: INFO: namespace projected-2314 deletion completed in 6.632898943s

â€¢ [SLOW TEST:10.846 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:28:22.736: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-1994/configmap-test-52454f21-abe5-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:28:22.780: INFO: Waiting up to 5m0s for pod "pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a" in namespace "configmap-1994" to be "success or failure"
Jul 21 18:28:22.787: INFO: Pod "pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.446579ms
Jul 21 18:28:24.799: INFO: Pod "pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01893954s
Jul 21 18:28:26.803: INFO: Pod "pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023408217s
STEP: Saw pod success
Jul 21 18:28:26.803: INFO: Pod "pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:28:26.806: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a container env-test: <nil>
STEP: delete the pod
Jul 21 18:28:26.828: INFO: Waiting for pod pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a to disappear
Jul 21 18:28:26.831: INFO: Pod pod-configmaps-52460a15-abe5-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:28:26.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1994" for this suite.
Jul 21 18:28:32.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:28:33.403: INFO: namespace configmap-1994 deletion completed in 6.569197783s

â€¢ [SLOW TEST:10.667 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:28:33.403: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:28:33.433: INFO: Creating deployment "nginx-deployment"
Jul 21 18:28:33.441: INFO: Waiting for observed generation 1
Jul 21 18:28:35.463: INFO: Waiting for all required pods to come up
Jul 21 18:28:35.491: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul 21 18:28:45.511: INFO: Waiting for deployment "nginx-deployment" to complete
Jul 21 18:28:45.516: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul 21 18:28:45.523: INFO: Updating deployment nginx-deployment
Jul 21 18:28:45.524: INFO: Waiting for observed generation 2
Jul 21 18:28:47.575: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 21 18:28:47.609: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 21 18:28:47.612: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 21 18:28:47.629: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 21 18:28:47.629: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 21 18:28:47.651: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 21 18:28:47.686: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul 21 18:28:47.686: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul 21 18:28:47.757: INFO: Updating deployment nginx-deployment
Jul 21 18:28:47.758: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul 21 18:28:47.822: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 21 18:28:49.832: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 21 18:28:49.888: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8486,SelfLink:/apis/apps/v1/namespaces/deployment-8486/deployments/nginx-deployment,UID:58a16175-abe5-11e9-9149-027a95377cb1,ResourceVersion:20682,Generation:3,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-07-21 18:28:47 +0000 UTC 2019-07-21 18:28:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-21 18:28:48 +0000 UTC 2019-07-21 18:28:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul 21 18:28:49.891: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8486,SelfLink:/apis/apps/v1/namespaces/deployment-8486/replicasets/nginx-deployment-5f9595f595,UID:5fd652c4-abe5-11e9-9149-027a95377cb1,ResourceVersion:20679,Generation:3,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 58a16175-abe5-11e9-9149-027a95377cb1 0xc000d22107 0xc000d22108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 18:28:49.891: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul 21 18:28:49.891: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-8486,SelfLink:/apis/apps/v1/namespaces/deployment-8486/replicasets/nginx-deployment-6f478d8d8,UID:58a21cb1-abe5-11e9-9149-027a95377cb1,ResourceVersion:20677,Generation:3,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 58a16175-abe5-11e9-9149-027a95377cb1 0xc000d221d7 0xc000d221d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul 21 18:28:49.951: INFO: Pod "nginx-deployment-5f9595f595-5b64f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5b64f,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-5b64f,UID:61442471-abe5-11e9-9149-027a95377cb1,ResourceVersion:20671,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001ff5c77 0xc001ff5c78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ff5cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ff5d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.956: INFO: Pod "nginx-deployment-5f9595f595-6g54j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6g54j,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-6g54j,UID:61441e2b-abe5-11e9-9149-027a95377cb1,ResourceVersion:20674,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001ff5d90 0xc001ff5d91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ff5e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ff5e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.956: INFO: Pod "nginx-deployment-5f9595f595-6xmd4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6xmd4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-6xmd4,UID:6136edd7-abe5-11e9-9149-027a95377cb1,ResourceVersion:20727,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001ff5ec0 0xc001ff5ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ff5f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ff5f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.956: INFO: Pod "nginx-deployment-5f9595f595-9f6mm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9f6mm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-9f6mm,UID:5fd7f545-abe5-11e9-9149-027a95377cb1,ResourceVersion:20604,Generation:0,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0030 0xc001db0031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db00c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db00f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.956: INFO: Pod "nginx-deployment-5f9595f595-9w5sz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9w5sz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-9w5sz,UID:61441577-abe5-11e9-9149-027a95377cb1,ResourceVersion:20673,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db01d0 0xc001db01d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.956: INFO: Pod "nginx-deployment-5f9595f595-dm2dx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dm2dx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-dm2dx,UID:614408c0-abe5-11e9-9149-027a95377cb1,ResourceVersion:20669,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db02f0 0xc001db02f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db03a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-dnzlj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dnzlj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-dnzlj,UID:5ff235d8-abe5-11e9-9149-027a95377cb1,ResourceVersion:20617,Generation:0,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0450 0xc001db0451}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db04e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-jrww9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jrww9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-jrww9,UID:6136c7cf-abe5-11e9-9149-027a95377cb1,ResourceVersion:20724,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db05d0 0xc001db05d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-r7vg4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-r7vg4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-r7vg4,UID:6131f062-abe5-11e9-9149-027a95377cb1,ResourceVersion:20691,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0740 0xc001db0741}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db07c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db07e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-x6qzf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-x6qzf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-x6qzf,UID:5fd7cc65-abe5-11e9-9149-027a95377cb1,ResourceVersion:20718,Generation:0,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.218/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db08c0 0xc001db08c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-xw2qd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xw2qd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-xw2qd,UID:5fd6cc91-abe5-11e9-9149-027a95377cb1,ResourceVersion:20723,Generation:0,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.220/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0a40 0xc001db0a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-xzjd9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xzjd9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-xzjd9,UID:6149dfdf-abe5-11e9-9149-027a95377cb1,ResourceVersion:20676,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0bb0 0xc001db0bb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.957: INFO: Pod "nginx-deployment-5f9595f595-zlczl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zlczl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-5f9595f595-zlczl,UID:5ff11f0a-abe5-11e9-9149-027a95377cb1,ResourceVersion:20722,Generation:0,CreationTimestamp:2019-07-21 18:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.219/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 5fd652c4-abe5-11e9-9149-027a95377cb1 0xc001db0ce0 0xc001db0ce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-6jrt4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6jrt4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-6jrt4,UID:58ab4123-abe5-11e9-9149-027a95377cb1,ResourceVersion:20537,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.210/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db0e80 0xc001db0e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db0f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db0f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.210,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8f4c9fe752ea636acec490b95ca11bbbe8ededba85d7a3421ef3108e1f356527}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-7rvct" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7rvct,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-7rvct,UID:58ab258d-abe5-11e9-9149-027a95377cb1,ResourceVersion:20554,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.217/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1007 0xc001db1008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db10b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.217,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0103a0814da2b52ae83030a323f1fd2bd3c4cd95c88d9bc6f3bc20e3f5b9b344}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-8fhwm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8fhwm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-8fhwm,UID:614208b6-abe5-11e9-9149-027a95377cb1,ResourceVersion:20666,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db11b7 0xc001db11b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-9b54d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9b54d,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-9b54d,UID:612fe8b8-abe5-11e9-9149-027a95377cb1,ResourceVersion:20717,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db12d0 0xc001db12d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-9dskh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9dskh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-9dskh,UID:58ab36c2-abe5-11e9-9149-027a95377cb1,ResourceVersion:20540,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.211/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db14c7 0xc001db14c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.211,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://806ec44f130c04e4fafbc3f02018e05004b0d36b42d491b66af7c4a988135965}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-bkf8k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bkf8k,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-bkf8k,UID:614206c3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20668,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1857 0xc001db1858}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db18e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-gplvk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gplvk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-gplvk,UID:613adb5c-abe5-11e9-9149-027a95377cb1,ResourceVersion:20653,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1980 0xc001db1981}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db19f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-h76r7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-h76r7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-h76r7,UID:612fd2c9-abe5-11e9-9149-027a95377cb1,ResourceVersion:20719,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1b10 0xc001db1b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-j6bld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j6bld,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-j6bld,UID:613addd8-abe5-11e9-9149-027a95377cb1,ResourceVersion:20650,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1c97 0xc001db1c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001db1d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001db1db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.958: INFO: Pod "nginx-deployment-6f478d8d8-j98qm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j98qm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-j98qm,UID:614194f1-abe5-11e9-9149-027a95377cb1,ResourceVersion:20665,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc001db1e30 0xc001db1e31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.959: INFO: Pod "nginx-deployment-6f478d8d8-jg4vn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jg4vn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-jg4vn,UID:61418429-abe5-11e9-9149-027a95377cb1,ResourceVersion:20664,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a20b0 0xc0007a20b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.959: INFO: Pod "nginx-deployment-6f478d8d8-knvx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-knvx5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-knvx5,UID:613ace6e-abe5-11e9-9149-027a95377cb1,ResourceVersion:20651,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a21d0 0xc0007a21d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.965: INFO: Pod "nginx-deployment-6f478d8d8-kt7s2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kt7s2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-kt7s2,UID:58ada970-abe5-11e9-9149-027a95377cb1,ResourceVersion:20543,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.216/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2310 0xc0007a2311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a23a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.216,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8be55b4e3dedbdd66f39b3ff5cb46bc2de90222c7b33881a969e341e4f54be7e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-n78xp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-n78xp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-n78xp,UID:58adbfd5-abe5-11e9-9149-027a95377cb1,ResourceVersion:20531,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.214/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2487 0xc0007a2488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.214,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2b1fd04b7926d8a04e7adf952c08a807a6011997352ab2106152e530a0893aa9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-nmqh8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nmqh8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-nmqh8,UID:58add1ec-abe5-11e9-9149-027a95377cb1,ResourceVersion:20551,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.215/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2607 0xc0007a2608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a26b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.215,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6c871e6a91a52c627509671211072971d677b493dfe292ba0aa83e2f5bfc09f3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-q4csr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-q4csr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-q4csr,UID:613aafe7-abe5-11e9-9149-027a95377cb1,ResourceVersion:20652,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2787 0xc0007a2788}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-qdtbl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qdtbl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-qdtbl,UID:58a4fc5e-abe5-11e9-9149-027a95377cb1,ResourceVersion:20534,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.213/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a28b0 0xc0007a28b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.213,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://698ea35c8a39bc47fbea3c98445fb735e314bdd5c2ffce769d5b86b1a1e1b058}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-t7khf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-t7khf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-t7khf,UID:61415d29-abe5-11e9-9149-027a95377cb1,ResourceVersion:20663,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2a17 0xc0007a2a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-wj5sx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wj5sx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-wj5sx,UID:612d4bb3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20646,Generation:0,CreationTimestamp:2019-07-21 18:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2b30 0xc0007a2b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:47 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 18:28:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:28:49.966: INFO: Pod "nginx-deployment-6f478d8d8-xzhcr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xzhcr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8486,SelfLink:/api/v1/namespaces/deployment-8486/pods/nginx-deployment-6f478d8d8-xzhcr,UID:58a4e1d0-abe5-11e9-9149-027a95377cb1,ResourceVersion:20522,Generation:0,CreationTimestamp:2019-07-21 18:28:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.212/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 58a21cb1-abe5-11e9-9149-027a95377cb1 0xc0007a2c97 0xc0007a2c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-98p8l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-98p8l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-98p8l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007a2d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007a2d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:28:33 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.212,StartTime:2019-07-21 18:28:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:28:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://fa7acd9ef4e7917283ec716bddd43e4c3838442ccc4eb7049901936e3c9502cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:28:49.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8486" for this suite.
Jul 21 18:29:00.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:29:00.752: INFO: namespace deployment-8486 deletion completed in 10.690300129s

â€¢ [SLOW TEST:27.348 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:29:00.752: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul 21 18:29:01.193: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20953,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 21 18:29:01.193: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20954,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 21 18:29:01.193: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20955,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul 21 18:29:11.253: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20974,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 21 18:29:11.253: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20975,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul 21 18:29:11.253: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:690f10e3-abe5-11e9-9149-027a95377cb1,ResourceVersion:20976,Generation:0,CreationTimestamp:2019-07-21 18:29:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:29:11.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5846" for this suite.
Jul 21 18:29:17.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:29:17.873: INFO: namespace watch-5846 deletion completed in 6.610396841s

â€¢ [SLOW TEST:17.121 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:29:17.873: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul 21 18:29:17.915: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 21 18:29:22.919: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:29:22.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1391" for this suite.
Jul 21 18:29:28.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:29:29.569: INFO: namespace replication-controller-1391 deletion completed in 6.618159107s

â€¢ [SLOW TEST:11.696 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:29:29.569: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 21 18:29:37.732: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:37.737: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:39.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:39.743: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:41.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:41.740: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:43.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:43.741: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:45.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:45.740: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:47.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:47.739: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:49.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:49.739: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:51.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:51.740: INFO: Pod pod-with-prestop-http-hook still exists
Jul 21 18:29:53.737: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 21 18:29:53.739: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:29:53.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3440" for this suite.
Jul 21 18:30:17.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:30:18.429: INFO: namespace container-lifecycle-hook-3440 deletion completed in 24.680612166s

â€¢ [SLOW TEST:48.860 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:30:18.429: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:30:18.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1449'
Jul 21 18:30:18.989: INFO: stderr: ""
Jul 21 18:30:18.989: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Jul 21 18:30:18.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete pods e2e-test-nginx-pod --namespace=kubectl-1449'
Jul 21 18:30:22.451: INFO: stderr: ""
Jul 21 18:30:22.451: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:30:22.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1449" for this suite.
Jul 21 18:30:28.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:30:29.035: INFO: namespace kubectl-1449 deletion completed in 6.58135593s

â€¢ [SLOW TEST:10.606 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:30:29.035: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul 21 18:30:33.097: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-9d8d4623-abe5-11e9-974c-16aa19c3723a,GenerateName:,Namespace:events-7406,SelfLink:/api/v1/namespaces/events-7406/pods/send-events-9d8d4623-abe5-11e9-974c-16aa19c3723a,UID:9d8eedb6-abe5-11e9-9149-027a95377cb1,ResourceVersion:21252,Generation:0,CreationTimestamp:2019-07-21 18:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 65276858,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.234/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hqd7z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hqd7z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-hqd7z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c8fa50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c8fa70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:30:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:30:29 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.234,StartTime:2019-07-21 18:30:29 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-21 18:30:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f0cbdac32d7936ac6628a22d0dfcebe7d25fe7ca280eecfeebf86f1239babaf9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul 21 18:30:35.100: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul 21 18:30:37.108: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:30:37.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7406" for this suite.
Jul 21 18:31:17.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:31:17.704: INFO: namespace events-7406 deletion completed in 40.57842272s

â€¢ [SLOW TEST:48.669 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:31:17.704: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:31:17.742: INFO: Creating ReplicaSet my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a
Jul 21 18:31:17.753: INFO: Pod name my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a: Found 0 pods out of 1
Jul 21 18:31:22.758: INFO: Pod name my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a: Found 1 pods out of 1
Jul 21 18:31:22.758: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a" is running
Jul 21 18:31:22.761: INFO: Pod "my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a-t2ltt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:31:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:31:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:31:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-21 18:31:17 +0000 UTC Reason: Message:}])
Jul 21 18:31:22.762: INFO: Trying to dial the pod
Jul 21 18:31:27.773: INFO: Controller my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a: Got expected result from replica 1 [my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a-t2ltt]: "my-hostname-basic-ba90dabc-abe5-11e9-974c-16aa19c3723a-t2ltt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:31:27.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-681" for this suite.
Jul 21 18:31:33.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:31:34.373: INFO: namespace replicaset-681 deletion completed in 6.597463666s

â€¢ [SLOW TEST:16.669 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:31:34.374: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8384.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8384.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8384.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8384.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 215.4.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.4.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.4.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.4.215_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8384.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8384.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8384.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8384.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8384.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8384.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 215.4.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.4.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.4.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.4.215_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 21 18:31:50.500: INFO: Unable to read wheezy_udp@dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.518: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.525: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.530: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.557: INFO: Unable to read jessie_udp@dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.560: INFO: Unable to read jessie_tcp@dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.564: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local from pod dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a: the server could not find the requested resource (get pods dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a)
Jul 21 18:31:50.599: INFO: Lookups using dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a failed for: [wheezy_udp@dns-test-service.dns-8384.svc.cluster.local wheezy_tcp@dns-test-service.dns-8384.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local jessie_udp@dns-test-service.dns-8384.svc.cluster.local jessie_tcp@dns-test-service.dns-8384.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8384.svc.cluster.local]

Jul 21 18:31:55.656: INFO: DNS probes using dns-8384/dns-test-c4868d2a-abe5-11e9-974c-16aa19c3723a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:31:55.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8384" for this suite.
Jul 21 18:32:01.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:32:02.546: INFO: namespace dns-8384 deletion completed in 6.593324364s

â€¢ [SLOW TEST:28.173 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:32:02.546: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0721 18:32:12.797691      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 21 18:32:12.797: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:32:12.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8483" for this suite.
Jul 21 18:32:20.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:32:21.420: INFO: namespace gc-8483 deletion completed in 8.61952004s

â€¢ [SLOW TEST:18.874 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:32:21.421: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 21 18:32:21.525: INFO: Waiting up to 5m0s for pod "pod-e092bd80-abe5-11e9-974c-16aa19c3723a" in namespace "emptydir-6437" to be "success or failure"
Jul 21 18:32:21.546: INFO: Pod "pod-e092bd80-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 21.860211ms
Jul 21 18:32:23.550: INFO: Pod "pod-e092bd80-abe5-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025013763s
Jul 21 18:32:25.552: INFO: Pod "pod-e092bd80-abe5-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027468754s
STEP: Saw pod success
Jul 21 18:32:25.552: INFO: Pod "pod-e092bd80-abe5-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:32:25.554: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-e092bd80-abe5-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:32:25.571: INFO: Waiting for pod pod-e092bd80-abe5-11e9-974c-16aa19c3723a to disappear
Jul 21 18:32:25.574: INFO: Pod pod-e092bd80-abe5-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:32:25.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6437" for this suite.
Jul 21 18:32:31.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:32:32.155: INFO: namespace emptydir-6437 deletion completed in 6.579475838s

â€¢ [SLOW TEST:10.734 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:32:32.156: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8384
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8384
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8384
Jul 21 18:32:32.287: INFO: Found 0 stateful pods, waiting for 1
Jul 21 18:32:42.290: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul 21 18:32:42.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 18:32:42.776: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 18:32:42.776: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 18:32:42.776: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 18:32:42.781: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 21 18:32:52.784: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 18:32:52.784: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 18:32:52.797: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999668s
Jul 21 18:32:53.800: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994674538s
Jul 21 18:32:54.803: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991788314s
Jul 21 18:32:55.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988855685s
Jul 21 18:32:56.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980741402s
Jul 21 18:32:57.822: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.973239264s
Jul 21 18:32:58.825: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970568554s
Jul 21 18:32:59.827: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967677661s
Jul 21 18:33:00.830: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.965227317s
Jul 21 18:33:01.835: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.324995ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8384
Jul 21 18:33:02.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:03.181: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 18:33:03.181: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 18:33:03.181: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 18:33:03.186: INFO: Found 1 stateful pods, waiting for 3
Jul 21 18:33:13.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 18:33:13.190: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 18:33:13.190: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul 21 18:33:13.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 18:33:13.854: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 18:33:13.854: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 18:33:13.854: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 18:33:13.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 18:33:14.637: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 18:33:14.637: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 18:33:14.637: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 18:33:14.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 21 18:33:15.261: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 21 18:33:15.261: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 21 18:33:15.261: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 21 18:33:15.261: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 18:33:15.263: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jul 21 18:33:25.282: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 18:33:25.282: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 18:33:25.282: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 21 18:33:25.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999953s
Jul 21 18:33:26.306: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990788608s
Jul 21 18:33:27.310: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98769256s
Jul 21 18:33:28.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983624717s
Jul 21 18:33:29.318: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980399463s
Jul 21 18:33:30.321: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976491299s
Jul 21 18:33:31.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973240355s
Jul 21 18:33:32.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969012592s
Jul 21 18:33:33.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.959834158s
Jul 21 18:33:34.352: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.34422ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8384
Jul 21 18:33:35.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:36.088: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 18:33:36.088: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 18:33:36.088: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 18:33:36.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:36.717: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 21 18:33:36.717: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 21 18:33:36.717: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 21 18:33:36.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:37.145: INFO: rc: 126
Jul 21 18:33:37.145: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> cannot exec in a stopped state: unknown
 command terminated with exit code 126
 [] <nil> 0xc0027324e0 exit status 126 <nil> <nil> true [0xc0027ac5b8 0xc0027ac5d8 0xc0027ac5f0] [0xc0027ac5b8 0xc0027ac5d8 0xc0027ac5f0] [0xc0027ac5d0 0xc0027ac5e8] [0x9bf9f0 0x9bf9f0] 0xc002527da0 <nil>}:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126

Jul 21 18:33:47.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:47.231: INFO: rc: 1
Jul 21 18:33:47.232: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d49230 exit status 1 <nil> <nil> true [0xc002299638 0xc002299650 0xc002299680] [0xc002299638 0xc002299650 0xc002299680] [0xc002299648 0xc002299670] [0x9bf9f0 0x9bf9f0] 0xc002294000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:33:57.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:33:57.343: INFO: rc: 1
Jul 21 18:33:57.343: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e0ba70 exit status 1 <nil> <nil> true [0xc001fdbf78 0xc001fdbfc8 0xc001fdbfe0] [0xc001fdbf78 0xc001fdbfc8 0xc001fdbfe0] [0xc001fdbfb0 0xc001fdbfd8] [0x9bf9f0 0x9bf9f0] 0xc001a73e60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:07.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:07.556: INFO: rc: 1
Jul 21 18:34:07.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d496b0 exit status 1 <nil> <nil> true [0xc002299690 0xc0022996a8 0xc0022996c0] [0xc002299690 0xc0022996a8 0xc0022996c0] [0xc0022996a0 0xc0022996b8] [0x9bf9f0 0x9bf9f0] 0xc0022943c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:17.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:17.748: INFO: rc: 1
Jul 21 18:34:17.748: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e72450 exit status 1 <nil> <nil> true [0xc000a82160 0xc000a824c8 0xc000a826b8] [0xc000a82160 0xc000a824c8 0xc000a826b8] [0xc000a82498 0xc000a82678] [0x9bf9f0 0x9bf9f0] 0xc002126600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:27.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:27.825: INFO: rc: 1
Jul 21 18:34:27.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028843c0 exit status 1 <nil> <nil> true [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418070 0xc0014181c8 0xc0014185e0] [0xc001418108 0xc001418580] [0x9bf9f0 0x9bf9f0] 0xc001c554a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:37.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:37.896: INFO: rc: 1
Jul 21 18:34:37.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002884720 exit status 1 <nil> <nil> true [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014187d8 0xc001418a18 0xc001418ba0] [0xc0014189e0 0xc001418ae0] [0x9bf9f0 0x9bf9f0] 0xc001c92180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:47.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:47.986: INFO: rc: 1
Jul 21 18:34:47.986: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002884a80 exit status 1 <nil> <nil> true [0xc001418c50 0xc001418e28 0xc001418f70] [0xc001418c50 0xc001418e28 0xc001418f70] [0xc001418d28 0xc001418ee0] [0x9bf9f0 0x9bf9f0] 0xc001c92ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:34:57.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:34:58.053: INFO: rc: 1
Jul 21 18:34:58.053: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244a4b0 exit status 1 <nil> <nil> true [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc000010460 0xc000010568] [0x9bf9f0 0x9bf9f0] 0xc002c9a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:08.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:08.173: INFO: rc: 1
Jul 21 18:35:08.173: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002884de0 exit status 1 <nil> <nil> true [0xc001418fe8 0xc001419288 0xc0014193f8] [0xc001418fe8 0xc001419288 0xc0014193f8] [0xc001419170 0xc0014193a8] [0x9bf9f0 0x9bf9f0] 0xc001c934a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:18.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:18.351: INFO: rc: 1
Jul 21 18:35:18.352: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002885260 exit status 1 <nil> <nil> true [0xc001419490 0xc001419500 0xc001419618] [0xc001419490 0xc001419500 0xc001419618] [0xc0014194c8 0xc001419600] [0x9bf9f0 0x9bf9f0] 0xc001c93e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:28.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:28.422: INFO: rc: 1
Jul 21 18:35:28.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028855f0 exit status 1 <nil> <nil> true [0xc001419628 0xc001419840 0xc001419a28] [0xc001419628 0xc001419840 0xc001419a28] [0xc0014197d0 0xc001419928] [0x9bf9f0 0x9bf9f0] 0xc001d26d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:38.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:38.518: INFO: rc: 1
Jul 21 18:35:38.518: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c52300 exit status 1 <nil> <nil> true [0xc00018e000 0xc00018f928 0xc00018faa8] [0xc00018e000 0xc00018f928 0xc00018faa8] [0xc00018f8d8 0xc00018f978] [0x9bf9f0 0x9bf9f0] 0xc0026e6660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:48.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:48.596: INFO: rc: 1
Jul 21 18:35:48.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244a840 exit status 1 <nil> <nil> true [0xc000010680 0xc000010f10 0xc0000cc6e8] [0xc000010680 0xc000010f10 0xc0000cc6e8] [0xc000010e38 0xc0000cc6c8] [0x9bf9f0 0x9bf9f0] 0xc002c9a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:35:58.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:35:58.667: INFO: rc: 1
Jul 21 18:35:58.667: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e72780 exit status 1 <nil> <nil> true [0xc000a827d0 0xc000a82880 0xc000a82940] [0xc000a827d0 0xc000a82880 0xc000a82940] [0xc000a82858 0xc000a82910] [0x9bf9f0 0x9bf9f0] 0xc002126f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:08.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:08.867: INFO: rc: 1
Jul 21 18:36:08.867: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e72c30 exit status 1 <nil> <nil> true [0xc000a82948 0xc000a829c0 0xc000a82a38] [0xc000a82948 0xc000a829c0 0xc000a82a38] [0xc000a82988 0xc000a829f8] [0x9bf9f0 0x9bf9f0] 0xc0021275c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:18.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:18.935: INFO: rc: 1
Jul 21 18:36:18.935: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244a420 exit status 1 <nil> <nil> true [0xc0000cc6c8 0xc0000cc810 0xc0000cc9a0] [0xc0000cc6c8 0xc0000cc810 0xc0000cc9a0] [0xc0000cc758 0xc0000cc908] [0x9bf9f0 0x9bf9f0] 0xc002c9a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:28.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:29.004: INFO: rc: 1
Jul 21 18:36:29.004: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244a7b0 exit status 1 <nil> <nil> true [0xc0000cca50 0xc0000cca90 0xc0000ccd10] [0xc0000cca50 0xc0000cca90 0xc0000ccd10] [0xc0000cca80 0xc0000ccb38] [0x9bf9f0 0x9bf9f0] 0xc002c9a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:39.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:39.069: INFO: rc: 1
Jul 21 18:36:39.069: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244ab40 exit status 1 <nil> <nil> true [0xc0000ccd78 0xc0000ccf60 0xc0000cd0f0] [0xc0000ccd78 0xc0000ccf60 0xc0000cd0f0] [0xc0000cceb8 0xc0000cd018] [0x9bf9f0 0x9bf9f0] 0xc002c9acc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:49.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:49.255: INFO: rc: 1
Jul 21 18:36:49.255: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244aea0 exit status 1 <nil> <nil> true [0xc0000cd220 0xc0000cd588 0xc0000cd6d0] [0xc0000cd220 0xc0000cd588 0xc0000cd6d0] [0xc0000cd3d0 0xc0000cd6a0] [0x9bf9f0 0x9bf9f0] 0xc002c9b200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:36:59.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:36:59.423: INFO: rc: 1
Jul 21 18:36:59.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e724e0 exit status 1 <nil> <nil> true [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc0000100e8 0xc0000104f8 0xc000010618] [0xc000010460 0xc000010568] [0x9bf9f0 0x9bf9f0] 0xc001c92780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:09.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:09.540: INFO: rc: 1
Jul 21 18:37:09.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e72990 exit status 1 <nil> <nil> true [0xc000010680 0xc000010f10 0xc000a82470] [0xc000010680 0xc000010f10 0xc000a82470] [0xc000010e38 0xc000a82160] [0x9bf9f0 0x9bf9f0] 0xc001c93200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:19.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:19.620: INFO: rc: 1
Jul 21 18:37:19.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e731d0 exit status 1 <nil> <nil> true [0xc000a82498 0xc000a82678 0xc000a827f8] [0xc000a82498 0xc000a82678 0xc000a827f8] [0xc000a82578 0xc000a827d0] [0x9bf9f0 0x9bf9f0] 0xc001c93a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:29.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:29.781: INFO: rc: 1
Jul 21 18:37:29.781: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e73500 exit status 1 <nil> <nil> true [0xc000a82858 0xc000a82910 0xc000a82968] [0xc000a82858 0xc000a82910 0xc000a82968] [0xc000a828e0 0xc000a82948] [0x9bf9f0 0x9bf9f0] 0xc001c54d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:39.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:39.854: INFO: rc: 1
Jul 21 18:37:39.854: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244b1d0 exit status 1 <nil> <nil> true [0xc0000cd738 0xc0000cd7f0 0xc0000cd898] [0xc0000cd738 0xc0000cd7f0 0xc0000cd898] [0xc0000cd7c0 0xc0000cd860] [0x9bf9f0 0x9bf9f0] 0xc002c9b860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:49.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:49.928: INFO: rc: 1
Jul 21 18:37:49.928: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244b710 exit status 1 <nil> <nil> true [0xc0000cd930 0xc0000cda18 0xc0000cda68] [0xc0000cd930 0xc0000cda18 0xc0000cda68] [0xc0000cd9f8 0xc0000cda60] [0x9bf9f0 0x9bf9f0] 0xc002c9bf20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:37:59.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:37:59.994: INFO: rc: 1
Jul 21 18:37:59.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244ba70 exit status 1 <nil> <nil> true [0xc0000cda70 0xc0000cdad8 0xc0000cdb08] [0xc0000cda70 0xc0000cdad8 0xc0000cdb08] [0xc0000cdac0 0xc0000cdb00] [0x9bf9f0 0x9bf9f0] 0xc002126780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:38:09.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:38:10.097: INFO: rc: 1
Jul 21 18:38:10.097: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244bda0 exit status 1 <nil> <nil> true [0xc0000cdb10 0xc0000cdbf0 0xc0000cdc38] [0xc0000cdb10 0xc0000cdbf0 0xc0000cdc38] [0xc0000cdbd0 0xc0000cdc18] [0x9bf9f0 0x9bf9f0] 0xc002126fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:38:20.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:38:20.234: INFO: rc: 1
Jul 21 18:38:20.234: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00244a450 exit status 1 <nil> <nil> true [0xc0000102f8 0xc000010518 0xc000010680] [0xc0000102f8 0xc000010518 0xc000010680] [0xc0000104f8 0xc000010618] [0x9bf9f0 0x9bf9f0] 0xc001c92780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:38:30.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:38:30.619: INFO: rc: 1
Jul 21 18:38:30.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e72450 exit status 1 <nil> <nil> true [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc658 0xc0000cc758 0xc0000cc908] [0xc0000cc6e8 0xc0000cc830] [0x9bf9f0 0x9bf9f0] 0xc002c9a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 21 18:38:40.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 exec --namespace=statefulset-8384 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 21 18:38:40.711: INFO: rc: 1
Jul 21 18:38:40.711: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jul 21 18:38:40.711: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 21 18:38:40.734: INFO: Deleting all statefulset in ns statefulset-8384
Jul 21 18:38:40.737: INFO: Scaling statefulset ss to 0
Jul 21 18:38:40.748: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 18:38:40.750: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:38:40.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8384" for this suite.
Jul 21 18:38:46.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:38:47.373: INFO: namespace statefulset-8384 deletion completed in 6.585333103s

â€¢ [SLOW TEST:375.218 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:38:47.374: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:38:47.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-562'
Jul 21 18:38:47.961: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 21 18:38:47.961: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Jul 21 18:38:47.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete deployment e2e-test-nginx-deployment --namespace=kubectl-562'
Jul 21 18:38:48.152: INFO: stderr: ""
Jul 21 18:38:48.152: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:38:48.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-562" for this suite.
Jul 21 18:38:54.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:38:54.733: INFO: namespace kubectl-562 deletion completed in 6.576767976s

â€¢ [SLOW TEST:7.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:38:54.733: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:38:54.773: INFO: Waiting up to 5m0s for pod "downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a" in namespace "downward-api-3922" to be "success or failure"
Jul 21 18:38:54.777: INFO: Pod "downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.044593ms
Jul 21 18:38:56.780: INFO: Pod "downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006814126s
Jul 21 18:38:58.783: INFO: Pod "downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009462821s
STEP: Saw pod success
Jul 21 18:38:58.783: INFO: Pod "downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:38:58.786: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:38:58.803: INFO: Waiting for pod downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a to disappear
Jul 21 18:38:58.805: INFO: Pod downwardapi-volume-caf89c59-abe6-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:38:58.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3922" for this suite.
Jul 21 18:39:06.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:39:07.389: INFO: namespace downward-api-3922 deletion completed in 8.580252492s

â€¢ [SLOW TEST:12.656 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:39:07.389: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:39:11.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7914" for this suite.
Jul 21 18:39:17.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:39:18.221: INFO: namespace emptydir-wrapper-7914 deletion completed in 6.596961337s

â€¢ [SLOW TEST:10.832 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:39:18.221: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:39:23.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6743" for this suite.
Jul 21 18:39:45.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:39:45.893: INFO: namespace replication-controller-6743 deletion completed in 22.5847352s

â€¢ [SLOW TEST:27.672 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:39:45.894: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:39:45.973: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a" in namespace "projected-6418" to be "success or failure"
Jul 21 18:39:45.982: INFO: Pod "downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.894435ms
Jul 21 18:39:47.987: INFO: Pod "downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013179942s
Jul 21 18:39:49.991: INFO: Pod "downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017996414s
STEP: Saw pod success
Jul 21 18:39:49.991: INFO: Pod "downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:39:49.999: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:39:50.027: INFO: Waiting for pod downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a to disappear
Jul 21 18:39:50.044: INFO: Pod downwardapi-volume-e97c5e86-abe6-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:39:50.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6418" for this suite.
Jul 21 18:39:56.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:39:56.624: INFO: namespace projected-6418 deletion completed in 6.57418725s

â€¢ [SLOW TEST:10.730 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:39:56.624: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-efdd02b2-abe6-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:39:56.666: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a" in namespace "projected-7126" to be "success or failure"
Jul 21 18:39:56.669: INFO: Pod "pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338168ms
Jul 21 18:39:58.673: INFO: Pod "pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007268498s
Jul 21 18:40:00.678: INFO: Pod "pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011773239s
STEP: Saw pod success
Jul 21 18:40:00.678: INFO: Pod "pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:40:00.688: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:40:00.711: INFO: Waiting for pod pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a to disappear
Jul 21 18:40:00.719: INFO: Pod pod-projected-configmaps-efdd7018-abe6-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:40:00.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7126" for this suite.
Jul 21 18:40:06.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:40:07.308: INFO: namespace projected-7126 deletion completed in 6.580597805s

â€¢ [SLOW TEST:10.684 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:40:07.308: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-24qj
STEP: Creating a pod to test atomic-volume-subpath
Jul 21 18:40:07.394: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-24qj" in namespace "subpath-2506" to be "success or failure"
Jul 21 18:40:07.406: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Pending", Reason="", readiness=false. Elapsed: 11.415434ms
Jul 21 18:40:09.421: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026385943s
Jul 21 18:40:11.447: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052841137s
Jul 21 18:40:13.454: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 6.059150259s
Jul 21 18:40:15.457: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 8.062121651s
Jul 21 18:40:17.466: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 10.071063584s
Jul 21 18:40:19.499: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 12.104422672s
Jul 21 18:40:21.502: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 14.107756599s
Jul 21 18:40:23.506: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 16.111292952s
Jul 21 18:40:25.520: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 18.125680158s
Jul 21 18:40:27.523: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 20.128343597s
Jul 21 18:40:29.532: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Running", Reason="", readiness=true. Elapsed: 22.137650215s
Jul 21 18:40:31.555: INFO: Pod "pod-subpath-test-projected-24qj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.160599903s
STEP: Saw pod success
Jul 21 18:40:31.555: INFO: Pod "pod-subpath-test-projected-24qj" satisfied condition "success or failure"
Jul 21 18:40:31.566: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-subpath-test-projected-24qj container test-container-subpath-projected-24qj: <nil>
STEP: delete the pod
Jul 21 18:40:31.636: INFO: Waiting for pod pod-subpath-test-projected-24qj to disappear
Jul 21 18:40:31.644: INFO: Pod pod-subpath-test-projected-24qj no longer exists
STEP: Deleting pod pod-subpath-test-projected-24qj
Jul 21 18:40:31.644: INFO: Deleting pod "pod-subpath-test-projected-24qj" in namespace "subpath-2506"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:40:31.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2506" for this suite.
Jul 21 18:40:37.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:40:38.280: INFO: namespace subpath-2506 deletion completed in 6.614971624s

â€¢ [SLOW TEST:30.972 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:40:38.282: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 21 18:40:38.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-2823'
Jul 21 18:40:38.651: INFO: stderr: ""
Jul 21 18:40:38.651: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 21 18:40:38.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2823'
Jul 21 18:40:38.816: INFO: stderr: ""
Jul 21 18:40:38.816: INFO: stdout: "update-demo-nautilus-8zkfs update-demo-nautilus-m4znx "
Jul 21 18:40:38.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-8zkfs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2823'
Jul 21 18:40:38.931: INFO: stderr: ""
Jul 21 18:40:38.931: INFO: stdout: ""
Jul 21 18:40:38.931: INFO: update-demo-nautilus-8zkfs is created but not running
Jul 21 18:40:43.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2823'
Jul 21 18:40:44.172: INFO: stderr: ""
Jul 21 18:40:44.172: INFO: stdout: "update-demo-nautilus-8zkfs update-demo-nautilus-m4znx "
Jul 21 18:40:44.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-8zkfs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2823'
Jul 21 18:40:44.579: INFO: stderr: ""
Jul 21 18:40:44.579: INFO: stdout: "true"
Jul 21 18:40:44.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-8zkfs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2823'
Jul 21 18:40:44.721: INFO: stderr: ""
Jul 21 18:40:44.721: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 18:40:44.721: INFO: validating pod update-demo-nautilus-8zkfs
Jul 21 18:40:44.725: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 18:40:44.725: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 18:40:44.725: INFO: update-demo-nautilus-8zkfs is verified up and running
Jul 21 18:40:44.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-m4znx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2823'
Jul 21 18:40:44.848: INFO: stderr: ""
Jul 21 18:40:44.848: INFO: stdout: "true"
Jul 21 18:40:44.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods update-demo-nautilus-m4znx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2823'
Jul 21 18:40:45.048: INFO: stderr: ""
Jul 21 18:40:45.048: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 21 18:40:45.048: INFO: validating pod update-demo-nautilus-m4znx
Jul 21 18:40:45.052: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 21 18:40:45.052: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 21 18:40:45.052: INFO: update-demo-nautilus-m4znx is verified up and running
STEP: using delete to clean up resources
Jul 21 18:40:45.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete --grace-period=0 --force -f - --namespace=kubectl-2823'
Jul 21 18:40:45.162: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 21 18:40:45.162: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 21 18:40:45.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2823'
Jul 21 18:40:45.235: INFO: stderr: "No resources found.\n"
Jul 21 18:40:45.235: INFO: stdout: ""
Jul 21 18:40:45.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -l name=update-demo --namespace=kubectl-2823 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 21 18:40:45.314: INFO: stderr: ""
Jul 21 18:40:45.314: INFO: stdout: "update-demo-nautilus-8zkfs\nupdate-demo-nautilus-m4znx\n"
Jul 21 18:40:45.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2823'
Jul 21 18:40:46.177: INFO: stderr: "No resources found.\n"
Jul 21 18:40:46.178: INFO: stdout: ""
Jul 21 18:40:46.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -l name=update-demo --namespace=kubectl-2823 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 21 18:40:46.332: INFO: stderr: ""
Jul 21 18:40:46.332: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:40:46.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2823" for this suite.
Jul 21 18:40:52.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:40:52.927: INFO: namespace kubectl-2823 deletion completed in 6.585539317s

â€¢ [SLOW TEST:14.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:40:52.927: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 21 18:40:52.987: INFO: Waiting up to 5m0s for pod "pod-116ee9e4-abe7-11e9-974c-16aa19c3723a" in namespace "emptydir-5625" to be "success or failure"
Jul 21 18:40:53.003: INFO: Pod "pod-116ee9e4-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.983629ms
Jul 21 18:40:55.008: INFO: Pod "pod-116ee9e4-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020342637s
Jul 21 18:40:57.010: INFO: Pod "pod-116ee9e4-abe7-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022970087s
STEP: Saw pod success
Jul 21 18:40:57.010: INFO: Pod "pod-116ee9e4-abe7-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:40:57.013: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-116ee9e4-abe7-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:40:57.028: INFO: Waiting for pod pod-116ee9e4-abe7-11e9-974c-16aa19c3723a to disappear
Jul 21 18:40:57.030: INFO: Pod pod-116ee9e4-abe7-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:40:57.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5625" for this suite.
Jul 21 18:41:03.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:41:03.623: INFO: namespace emptydir-5625 deletion completed in 6.587176996s

â€¢ [SLOW TEST:10.696 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:41:03.624: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-17ceddf2-abe7-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 18:41:03.687: INFO: Waiting up to 5m0s for pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a" in namespace "secrets-7824" to be "success or failure"
Jul 21 18:41:03.692: INFO: Pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.057397ms
Jul 21 18:41:05.696: INFO: Pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009190379s
Jul 21 18:41:07.719: INFO: Pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032597625s
Jul 21 18:41:09.722: INFO: Pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035528413s
STEP: Saw pod success
Jul 21 18:41:09.722: INFO: Pod "pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:41:09.726: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 18:41:09.752: INFO: Waiting for pod pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a to disappear
Jul 21 18:41:09.755: INFO: Pod pod-secrets-17cf6350-abe7-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:41:09.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7824" for this suite.
Jul 21 18:41:15.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:41:16.378: INFO: namespace secrets-7824 deletion completed in 6.619128771s

â€¢ [SLOW TEST:12.754 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:41:16.379: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-1f6a4570-abe7-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:41:16.470: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a" in namespace "projected-9822" to be "success or failure"
Jul 21 18:41:16.483: INFO: Pod "pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.122702ms
Jul 21 18:41:18.486: INFO: Pod "pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015963869s
Jul 21 18:41:20.494: INFO: Pod "pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023580501s
STEP: Saw pod success
Jul 21 18:41:20.496: INFO: Pod "pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:41:20.503: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:41:20.538: INFO: Waiting for pod pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a to disappear
Jul 21 18:41:20.553: INFO: Pod pod-projected-configmaps-1f6abee6-abe7-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:41:20.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9822" for this suite.
Jul 21 18:41:26.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:41:27.129: INFO: namespace projected-9822 deletion completed in 6.570611387s

â€¢ [SLOW TEST:10.750 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:41:27.129: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:41:27.160: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a" in namespace "downward-api-9606" to be "success or failure"
Jul 21 18:41:27.166: INFO: Pod "downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.364495ms
Jul 21 18:41:29.175: INFO: Pod "downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01432448s
Jul 21 18:41:31.190: INFO: Pod "downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029998603s
STEP: Saw pod success
Jul 21 18:41:31.191: INFO: Pod "downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:41:31.196: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:41:31.225: INFO: Waiting for pod downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a to disappear
Jul 21 18:41:31.228: INFO: Pod downwardapi-volume-25cdbb96-abe7-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:41:31.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9606" for this suite.
Jul 21 18:41:37.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:41:37.840: INFO: namespace downward-api-9606 deletion completed in 6.594919647s

â€¢ [SLOW TEST:10.711 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:41:37.840: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 21 18:41:42.466: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2c341b37-abe7-11e9-974c-16aa19c3723a"
Jul 21 18:41:42.466: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2c341b37-abe7-11e9-974c-16aa19c3723a" in namespace "pods-4340" to be "terminated due to deadline exceeded"
Jul 21 18:41:42.488: INFO: Pod "pod-update-activedeadlineseconds-2c341b37-abe7-11e9-974c-16aa19c3723a": Phase="Running", Reason="", readiness=true. Elapsed: 22.54981ms
Jul 21 18:41:44.495: INFO: Pod "pod-update-activedeadlineseconds-2c341b37-abe7-11e9-974c-16aa19c3723a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.029111924s
Jul 21 18:41:44.495: INFO: Pod "pod-update-activedeadlineseconds-2c341b37-abe7-11e9-974c-16aa19c3723a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:41:44.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4340" for this suite.
Jul 21 18:41:50.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:41:51.121: INFO: namespace pods-4340 deletion completed in 6.623406541s

â€¢ [SLOW TEST:13.281 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:41:51.122: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:41:51.227: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul 21 18:41:56.229: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 21 18:41:56.229: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 21 18:41:56.255: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9332,SelfLink:/apis/apps/v1/namespaces/deployment-9332/deployments/test-cleanup-deployment,UID:3722bc0a-abe7-11e9-9149-027a95377cb1,ResourceVersion:23387,Generation:1,CreationTimestamp:2019-07-21 18:41:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jul 21 18:41:56.266: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-9332,SelfLink:/apis/apps/v1/namespaces/deployment-9332/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:37242352-abe7-11e9-9149-027a95377cb1,ResourceVersion:23389,Generation:1,CreationTimestamp:2019-07-21 18:41:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 3722bc0a-abe7-11e9-9149-027a95377cb1 0xc002a87a17 0xc002a87a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 18:41:56.266: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jul 21 18:41:56.266: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-9332,SelfLink:/apis/apps/v1/namespaces/deployment-9332/replicasets/test-cleanup-controller,UID:342302e6-abe7-11e9-9149-027a95377cb1,ResourceVersion:23388,Generation:1,CreationTimestamp:2019-07-21 18:41:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 3722bc0a-abe7-11e9-9149-027a95377cb1 0xc002a87947 0xc002a87948}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 21 18:41:56.269: INFO: Pod "test-cleanup-controller-w29mg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-w29mg,GenerateName:test-cleanup-controller-,Namespace:deployment-9332,SelfLink:/api/v1/namespaces/deployment-9332/pods/test-cleanup-controller-w29mg,UID:3426f0a5-abe7-11e9-9149-027a95377cb1,ResourceVersion:23379,Generation:0,CreationTimestamp:2019-07-21 18:41:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.52/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 342302e6-abe7-11e9-9149-027a95377cb1 0xc00326b6c7 0xc00326b6c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pcfvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pcfvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pcfvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00326b740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00326b760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:41:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:41:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:41:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:41:51 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.52,StartTime:2019-07-21 18:41:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-21 18:41:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://47cebda990e4fa5eb54f9d2458185721258fc6ca133cfbb67dba714d6fd7ec55}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 21 18:41:56.273: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-qh2n2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-qh2n2,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-9332,SelfLink:/api/v1/namespaces/deployment-9332/pods/test-cleanup-deployment-55cbfbc8f5-qh2n2,UID:3725d9a2-abe7-11e9-9149-027a95377cb1,ResourceVersion:23394,Generation:0,CreationTimestamp:2019-07-21 18:41:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 37242352-abe7-11e9-9149-027a95377cb1 0xc00326b837 0xc00326b838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pcfvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pcfvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pcfvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00326b8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00326b8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 18:41:56 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:41:56.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9332" for this suite.
Jul 21 18:42:04.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:42:04.948: INFO: namespace deployment-9332 deletion completed in 8.670334926s

â€¢ [SLOW TEST:13.827 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:42:04.952: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8840
Jul 21 18:42:11.111: INFO: Started pod liveness-exec in namespace container-probe-8840
STEP: checking the pod's current state and verifying that restartCount is present
Jul 21 18:42:11.168: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:46:12.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8840" for this suite.
Jul 21 18:46:18.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:46:18.789: INFO: namespace container-probe-8840 deletion completed in 6.594309851s

â€¢ [SLOW TEST:253.837 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:46:18.789: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-363
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 21 18:46:18.833: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 21 18:46:38.972: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.56:8080/dial?request=hostName&protocol=http&host=10.244.0.55&port=8080&tries=1'] Namespace:pod-network-test-363 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:46:38.972: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:46:39.392: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:46:39.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-363" for this suite.
Jul 21 18:47:03.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:47:04.060: INFO: namespace pod-network-test-363 deletion completed in 24.62225261s

â€¢ [SLOW TEST:45.271 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:47:04.060: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul 21 18:47:04.168: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-117,SelfLink:/api/v1/namespaces/watch-117/configmaps/e2e-watch-test-watch-closed,UID:eea7e65f-abe7-11e9-9149-027a95377cb1,ResourceVersion:24119,Generation:0,CreationTimestamp:2019-07-21 18:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 21 18:47:04.168: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-117,SelfLink:/api/v1/namespaces/watch-117/configmaps/e2e-watch-test-watch-closed,UID:eea7e65f-abe7-11e9-9149-027a95377cb1,ResourceVersion:24120,Generation:0,CreationTimestamp:2019-07-21 18:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul 21 18:47:04.213: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-117,SelfLink:/api/v1/namespaces/watch-117/configmaps/e2e-watch-test-watch-closed,UID:eea7e65f-abe7-11e9-9149-027a95377cb1,ResourceVersion:24121,Generation:0,CreationTimestamp:2019-07-21 18:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 21 18:47:04.213: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-117,SelfLink:/api/v1/namespaces/watch-117/configmaps/e2e-watch-test-watch-closed,UID:eea7e65f-abe7-11e9-9149-027a95377cb1,ResourceVersion:24122,Generation:0,CreationTimestamp:2019-07-21 18:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:47:04.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-117" for this suite.
Jul 21 18:47:10.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:47:10.915: INFO: namespace watch-117 deletion completed in 6.691670856s

â€¢ [SLOW TEST:6.855 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:47:10.918: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:47:15.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5093" for this suite.
Jul 21 18:47:55.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:47:55.607: INFO: namespace kubelet-test-5093 deletion completed in 40.582721461s

â€¢ [SLOW TEST:44.690 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:47:55.607: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:48:21.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2061" for this suite.
Jul 21 18:48:27.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:48:27.723: INFO: namespace container-runtime-2061 deletion completed in 6.613024511s

â€¢ [SLOW TEST:32.116 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:48:27.724: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 21 18:48:27.772: INFO: Number of nodes with available pods: 0
Jul 21 18:48:27.772: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:28.778: INFO: Number of nodes with available pods: 0
Jul 21 18:48:28.778: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:29.777: INFO: Number of nodes with available pods: 0
Jul 21 18:48:29.777: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:30.777: INFO: Number of nodes with available pods: 1
Jul 21 18:48:30.777: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul 21 18:48:30.831: INFO: Number of nodes with available pods: 0
Jul 21 18:48:30.831: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:31.864: INFO: Number of nodes with available pods: 0
Jul 21 18:48:31.864: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:32.836: INFO: Number of nodes with available pods: 0
Jul 21 18:48:32.836: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:48:33.839: INFO: Number of nodes with available pods: 1
Jul 21 18:48:33.839: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3003, will wait for the garbage collector to delete the pods
Jul 21 18:48:33.902: INFO: Deleting DaemonSet.extensions daemon-set took: 6.201823ms
Jul 21 18:48:34.302: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.537334ms
Jul 21 18:48:42.426: INFO: Number of nodes with available pods: 0
Jul 21 18:48:42.426: INFO: Number of running nodes: 0, number of available pods: 0
Jul 21 18:48:42.443: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3003/daemonsets","resourceVersion":"24482"},"items":null}

Jul 21 18:48:42.448: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3003/pods","resourceVersion":"24482"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:48:42.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3003" for this suite.
Jul 21 18:48:48.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:48:49.031: INFO: namespace daemonsets-3003 deletion completed in 6.576244148s

â€¢ [SLOW TEST:21.307 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:48:49.034: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2d3647ec-abe8-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2d3647ec-abe8-11e9-974c-16aa19c3723a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:50:01.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8009" for this suite.
Jul 21 18:50:23.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:50:24.178: INFO: namespace projected-8009 deletion completed in 22.588515201s

â€¢ [SLOW TEST:95.144 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:50:24.178: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 21 18:50:24.258: INFO: Number of nodes with available pods: 0
Jul 21 18:50:24.258: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:25.267: INFO: Number of nodes with available pods: 0
Jul 21 18:50:25.267: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:26.264: INFO: Number of nodes with available pods: 0
Jul 21 18:50:26.264: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:27.268: INFO: Number of nodes with available pods: 1
Jul 21 18:50:27.268: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul 21 18:50:27.299: INFO: Number of nodes with available pods: 0
Jul 21 18:50:27.299: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:28.305: INFO: Number of nodes with available pods: 0
Jul 21 18:50:28.305: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:29.321: INFO: Number of nodes with available pods: 0
Jul 21 18:50:29.321: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:30.305: INFO: Number of nodes with available pods: 0
Jul 21 18:50:30.305: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:31.327: INFO: Number of nodes with available pods: 0
Jul 21 18:50:31.327: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:32.315: INFO: Number of nodes with available pods: 0
Jul 21 18:50:32.315: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:33.309: INFO: Number of nodes with available pods: 0
Jul 21 18:50:33.309: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 18:50:34.344: INFO: Number of nodes with available pods: 1
Jul 21 18:50:34.344: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7730, will wait for the garbage collector to delete the pods
Jul 21 18:50:34.476: INFO: Deleting DaemonSet.extensions daemon-set took: 32.815588ms
Jul 21 18:50:34.876: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.273324ms
Jul 21 18:50:42.491: INFO: Number of nodes with available pods: 0
Jul 21 18:50:42.491: INFO: Number of running nodes: 0, number of available pods: 0
Jul 21 18:50:42.496: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7730/daemonsets","resourceVersion":"24781"},"items":null}

Jul 21 18:50:42.501: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7730/pods","resourceVersion":"24781"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:50:42.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7730" for this suite.
Jul 21 18:50:48.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:50:49.105: INFO: namespace daemonsets-7730 deletion completed in 6.585568822s

â€¢ [SLOW TEST:24.927 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:50:49.105: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 21 18:50:49.157: INFO: Waiting up to 5m0s for pod "pod-74c7756c-abe8-11e9-974c-16aa19c3723a" in namespace "emptydir-7489" to be "success or failure"
Jul 21 18:50:49.165: INFO: Pod "pod-74c7756c-abe8-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.224978ms
Jul 21 18:50:51.182: INFO: Pod "pod-74c7756c-abe8-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025152721s
Jul 21 18:50:53.185: INFO: Pod "pod-74c7756c-abe8-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027940294s
STEP: Saw pod success
Jul 21 18:50:53.185: INFO: Pod "pod-74c7756c-abe8-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:50:53.187: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-74c7756c-abe8-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:50:53.212: INFO: Waiting for pod pod-74c7756c-abe8-11e9-974c-16aa19c3723a to disappear
Jul 21 18:50:53.216: INFO: Pod pod-74c7756c-abe8-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:50:53.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7489" for this suite.
Jul 21 18:50:59.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:50:59.800: INFO: namespace emptydir-7489 deletion completed in 6.580226598s

â€¢ [SLOW TEST:10.695 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:50:59.800: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul 21 18:50:59.835: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:51:12.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8244" for this suite.
Jul 21 18:51:18.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:51:19.163: INFO: namespace pods-8244 deletion completed in 6.599198031s

â€¢ [SLOW TEST:19.363 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:51:19.164: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-86b3bd7e-abe8-11e9-974c-16aa19c3723a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:51:23.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4320" for this suite.
Jul 21 18:51:45.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:51:45.865: INFO: namespace configmap-4320 deletion completed in 22.568596572s

â€¢ [SLOW TEST:26.701 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:51:45.866: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 21 18:51:45.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7625'
Jul 21 18:51:46.357: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 21 18:51:46.357: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jul 21 18:51:46.377: INFO: scanned /root for discovery docs: <nil>
Jul 21 18:51:46.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7625'
Jul 21 18:52:02.491: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 21 18:52:02.491: INFO: stdout: "Created e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668\nScaling up e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jul 21 18:52:02.491: INFO: stdout: "Created e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668\nScaling up e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jul 21 18:52:02.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7625'
Jul 21 18:52:02.628: INFO: stderr: ""
Jul 21 18:52:02.628: INFO: stdout: "e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668-wjl5j "
Jul 21 18:52:02.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668-wjl5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7625'
Jul 21 18:52:02.743: INFO: stderr: ""
Jul 21 18:52:02.743: INFO: stdout: "true"
Jul 21 18:52:02.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 get pods e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668-wjl5j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7625'
Jul 21 18:52:02.844: INFO: stderr: ""
Jul 21 18:52:02.844: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jul 21 18:52:02.844: INFO: e2e-test-nginx-rc-6b1d2918d92a407993da48ed61ba1668-wjl5j is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Jul 21 18:52:02.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 delete rc e2e-test-nginx-rc --namespace=kubectl-7625'
Jul 21 18:52:02.933: INFO: stderr: ""
Jul 21 18:52:02.933: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:52:02.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7625" for this suite.
Jul 21 18:52:08.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:52:09.534: INFO: namespace kubectl-7625 deletion completed in 6.587408193s

â€¢ [SLOW TEST:23.669 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:52:09.535: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-p8hq
STEP: Creating a pod to test atomic-volume-subpath
Jul 21 18:52:09.667: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p8hq" in namespace "subpath-4908" to be "success or failure"
Jul 21 18:52:09.691: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Pending", Reason="", readiness=false. Elapsed: 24.204981ms
Jul 21 18:52:11.703: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036691337s
Jul 21 18:52:13.707: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 4.040440896s
Jul 21 18:52:15.712: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 6.045265377s
Jul 21 18:52:17.715: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 8.048330211s
Jul 21 18:52:19.719: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 10.051765754s
Jul 21 18:52:21.722: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 12.055420941s
Jul 21 18:52:23.735: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 14.068709261s
Jul 21 18:52:25.741: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 16.074303254s
Jul 21 18:52:27.745: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 18.078489926s
Jul 21 18:52:29.748: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 20.081119137s
Jul 21 18:52:31.754: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Running", Reason="", readiness=true. Elapsed: 22.087365339s
Jul 21 18:52:33.758: INFO: Pod "pod-subpath-test-downwardapi-p8hq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.090915071s
STEP: Saw pod success
Jul 21 18:52:33.758: INFO: Pod "pod-subpath-test-downwardapi-p8hq" satisfied condition "success or failure"
Jul 21 18:52:33.760: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-subpath-test-downwardapi-p8hq container test-container-subpath-downwardapi-p8hq: <nil>
STEP: delete the pod
Jul 21 18:52:33.775: INFO: Waiting for pod pod-subpath-test-downwardapi-p8hq to disappear
Jul 21 18:52:33.777: INFO: Pod pod-subpath-test-downwardapi-p8hq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-p8hq
Jul 21 18:52:33.777: INFO: Deleting pod "pod-subpath-test-downwardapi-p8hq" in namespace "subpath-4908"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:52:33.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4908" for this suite.
Jul 21 18:52:39.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:52:40.363: INFO: namespace subpath-4908 deletion completed in 6.579152566s

â€¢ [SLOW TEST:30.829 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:52:40.364: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:52:44.530: INFO: Waiting up to 5m0s for pod "client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a" in namespace "pods-7530" to be "success or failure"
Jul 21 18:52:44.540: INFO: Pod "client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.501495ms
Jul 21 18:52:46.551: INFO: Pod "client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021613984s
Jul 21 18:52:48.558: INFO: Pod "client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028591776s
STEP: Saw pod success
Jul 21 18:52:48.558: INFO: Pod "client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:52:48.564: INFO: Trying to get logs from node ip-10-222-31-145 pod client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a container env3cont: <nil>
STEP: delete the pod
Jul 21 18:52:48.593: INFO: Waiting for pod client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a to disappear
Jul 21 18:52:48.600: INFO: Pod client-envvars-b98bf6aa-abe8-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:52:48.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7530" for this suite.
Jul 21 18:53:28.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:53:29.183: INFO: namespace pods-7530 deletion completed in 40.579675621s

â€¢ [SLOW TEST:48.819 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:53:29.183: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 21 18:53:29.253: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 21 18:53:29.262: INFO: Waiting for terminating namespaces to be deleted...
Jul 21 18:53:29.265: INFO: 
Logging pods the kubelet thinks is on node ip-10-222-31-145 before test
Jul 21 18:53:29.293: INFO: nginx-ingress-controller-78dcf4d98b-nzf98 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jul 21 18:53:29.293: INFO: istio-ca-78655bf74f-jtfdj from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-ca ready: true, restart count 0
Jul 21 18:53:29.293: INFO: frontend-7cc7768fc8-tmhds from rcloud-admin started at 2019-07-21 16:46:12 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container frontend ready: true, restart count 2
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: sonobuoy-systemd-logs-daemon-set-5655e65ca0e146ed-znmf4 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jul 21 18:53:29.293: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 21 18:53:29.293: INFO: nginx-ingress-controller-admin-564f6884d8-gz2js from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container nginx-ingress-controller-admin ready: true, restart count 0
Jul 21 18:53:29.293: INFO: istio-ingress-6c8b8f96cd-dwlvc from istio-system started at 2019-07-21 16:44:37 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-ingress ready: true, restart count 0
Jul 21 18:53:29.293: INFO: kube-proxy-89z7m from kube-system started at 2019-07-21 16:40:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: tiller-deploy-85494c96cf-mtrlx from kube-system started at 2019-07-21 16:44:49 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container tiller ready: true, restart count 0
Jul 21 18:53:29.293: INFO: zookeeper-86bfd95d77-lxx59 from rcloud-infra started at 2019-07-21 16:45:33 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container zk-0 ready: true, restart count 0
Jul 21 18:53:29.293: INFO: workload-placement-746878b79f-dbd7b from rcloud-admin started at 2019-07-21 16:46:37 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container workload-placement ready: true, restart count 2
Jul 21 18:53:29.293: INFO: traffic-steering-547844bcf8-sj82z from rcloud-admin started at 2019-07-21 16:46:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container traffic-steering ready: true, restart count 0
Jul 21 18:53:29.293: INFO: coredns-fb8b8dccf-wrz8f from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container coredns ready: true, restart count 0
Jul 21 18:53:29.293: INFO: resource-allocation-8c8cdcfd8-njc4s from rcloud-admin started at 2019-07-21 16:46:45 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container resource-allocation ready: true, restart count 0
Jul 21 18:53:29.293: INFO: debug-broker-0 from rcloud-infra started at 2019-07-21 16:47:27 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container debug-broker ready: true, restart count 0
Jul 21 18:53:29.293: INFO: config-processor-7847fd6f49-z4g58 from rcloud-admin started at 2019-07-21 16:48:12 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container config-processor ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: regauth-8bd9db7c4-dmmnf from rcloud-admin started at 2019-07-21 16:47:18 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container docker-auth ready: true, restart count 0
Jul 21 18:53:29.293: INFO: etcd-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:53:29.293: INFO: kafka-core-7c75bb8ccd-zrkn5 from rcloud-infra started at 2019-07-21 16:45:19 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container kafka-core ready: true, restart count 1
Jul 21 18:53:29.293: INFO: admin-redis-599959c468-9bdcj from rcloud-admin started at 2019-07-21 16:45:22 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container admin-redis ready: true, restart count 0
Jul 21 18:53:29.293: INFO: admin-api-7758ff5dc6-t554w from rcloud-admin started at 2019-07-21 16:46:02 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container admin-api ready: true, restart count 1
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: frontend-opsconsole-65d75f5d69-mdz97 from rcloud-admin started at 2019-07-21 16:46:19 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container frontend-opsconsole ready: true, restart count 2
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: workload-processor-7c768567f6-zdlzm from rcloud-admin started at 2019-07-21 16:46:28 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container workload-processor ready: true, restart count 0
Jul 21 18:53:29.293: INFO: coredns-fb8b8dccf-ggr8r from kube-system started at 2019-07-21 16:40:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container coredns ready: true, restart count 0
Jul 21 18:53:29.293: INFO: kube-apiserver-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:53:29.293: INFO: kube-controller-manager-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:53:29.293: INFO: canal-sztcn from kube-system started at 2019-07-21 16:40:24 +0000 UTC (3 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container calico-node ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container install-cni ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 21 18:53:29.293: INFO: edgesrv-6459c565cb-z2898 from rcloud-admin started at 2019-07-21 16:48:40 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container edgesrv ready: true, restart count 0
Jul 21 18:53:29.293: INFO: kube-scheduler-ip-10-222-31-145 from kube-system started at <nil> (0 container statuses recorded)
Jul 21 18:53:29.293: INFO: glusterfs-8krmv from kube-system started at 2019-07-21 16:44:02 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container glusterfs ready: true, restart count 0
Jul 21 18:53:29.293: INFO: default-http-backend-55b84578bf-lghj8 from rcloud-infra started at 2019-07-21 16:44:24 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 21 18:53:29.293: INFO: keygensvc-86d69565-94v4f from rcloud-infra started at 2019-07-21 16:45:34 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container keygensvc ready: true, restart count 2
Jul 21 18:53:29.293: INFO: cryptosvc-d477c486-rtrnb from rcloud-infra started at 2019-07-21 16:45:44 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container cryptosvc ready: true, restart count 1
Jul 21 18:53:29.293: INFO: sonobuoy-e2e-job-9d9f8ba6e19c4dc2 from heptio-sonobuoy started at 2019-07-21 17:27:55 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container e2e ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 21 18:53:29.293: INFO: default-http-backend-admin-656d9c9d8c-c8s9h from rcloud-admin started at 2019-07-21 16:45:56 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container default-http-backend-admin ready: true, restart count 0
Jul 21 18:53:29.293: INFO: rafay-container-registry-6474bdcbcf-mgd9f from rcloud-admin started at 2019-07-21 16:47:23 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container registry ready: true, restart count 0
Jul 21 18:53:29.293: INFO: heketi-84f9566569-55wr6 from kube-system started at 2019-07-21 16:44:03 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container heketi ready: true, restart count 0
Jul 21 18:53:29.293: INFO: authsrv-88696bc57-vx55z from rcloud-admin started at 2019-07-21 16:47:15 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container authsrv ready: true, restart count 0
Jul 21 18:53:29.293: INFO: edge-broker-5bf96697cf-l57cr from rcloud-infra started at 2019-07-21 16:47:45 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container edge-broker ready: true, restart count 0
Jul 21 18:53:29.293: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-21 17:27:48 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: istio-mixer-86bc989497-v8bvv from istio-system started at 2019-07-21 16:44:40 +0000 UTC (3 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container mixer ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container statsd-to-prometheus ready: true, restart count 0
Jul 21 18:53:29.293: INFO: istio-pilot-75c4c5dcc5-n4dxq from istio-system started at 2019-07-21 16:44:41 +0000 UTC (2 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container discovery ready: true, restart count 0
Jul 21 18:53:29.293: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 21 18:53:29.293: INFO: debug-processor-76656764d-kh7gg from rcloud-admin started at 2019-07-21 16:47:36 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container debug-processor ready: true, restart count 0
Jul 21 18:53:29.293: INFO: edge-sec-665bf84b5d-nr27w from rcloud-infra started at 2019-07-21 16:48:52 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container edge-sec ready: true, restart count 0
Jul 21 18:53:29.293: INFO: postgres-756f878d66-kdw48 from rcloud-admin started at 2019-07-21 16:45:23 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container postgres ready: true, restart count 0
Jul 21 18:53:29.293: INFO: workload-broker-c5f8c89c-h6ssl from rcloud-infra started at 2019-07-21 16:47:04 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container workload-broker ready: true, restart count 0
Jul 21 18:53:29.293: INFO: salt-master-6bc4f85449-hf78n from rcloud-infra started at 2019-07-21 16:49:01 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container salt-master ready: true, restart count 0
Jul 21 18:53:29.293: INFO: edge-processor-68f574bb58-7xwpb from rcloud-admin started at 2019-07-21 16:47:52 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container edge-processor ready: true, restart count 0
Jul 21 18:53:29.293: INFO: config-broker-5c85977786-rvjlb from rcloud-infra started at 2019-07-21 16:48:01 +0000 UTC (1 container statuses recorded)
Jul 21 18:53:29.293: INFO: 	Container config-broker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b380e34bd5bb58], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:53:30.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6636" for this suite.
Jul 21 18:53:36.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:53:36.937: INFO: namespace sched-pred-6636 deletion completed in 6.578298972s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.754 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:53:36.937: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:54:36.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8435" for this suite.
Jul 21 18:54:59.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:54:59.569: INFO: namespace container-probe-8435 deletion completed in 22.57806148s

â€¢ [SLOW TEST:82.632 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:54:59.569: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Jul 21 18:54:59.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 --namespace=kubectl-9857 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jul 21 18:55:02.653: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jul 21 18:55:02.653: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:55:04.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9857" for this suite.
Jul 21 18:55:14.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:55:15.274: INFO: namespace kubectl-9857 deletion completed in 10.602554071s

â€¢ [SLOW TEST:15.705 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:55:15.274: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 18:55:15.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 version --client'
Jul 21 18:55:15.394: INFO: stderr: ""
Jul 21 18:55:15.394: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jul 21 18:55:15.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-6282'
Jul 21 18:55:15.634: INFO: stderr: ""
Jul 21 18:55:15.634: INFO: stdout: "replicationcontroller/redis-master created\n"
Jul 21 18:55:15.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-6282'
Jul 21 18:55:16.312: INFO: stderr: ""
Jul 21 18:55:16.312: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 21 18:55:17.322: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:55:17.322: INFO: Found 0 / 1
Jul 21 18:55:18.320: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:55:18.320: INFO: Found 1 / 1
Jul 21 18:55:18.320: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 21 18:55:18.324: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 18:55:18.324: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 21 18:55:18.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 describe pod redis-master-zfzdc --namespace=kubectl-6282'
Jul 21 18:55:18.601: INFO: stderr: ""
Jul 21 18:55:18.601: INFO: stdout: "Name:               redis-master-zfzdc\nNamespace:          kubectl-6282\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-222-31-145/10.222.31.145\nStart Time:         Sun, 21 Jul 2019 18:55:15 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.244.0.76/32\nStatus:             Running\nIP:                 10.244.0.76\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f82dd2298b76f5c4af11f3740520d6868f57984b815ca154eff0848196bd7941\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 21 Jul 2019 18:55:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-s7lbp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-s7lbp:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-s7lbp\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                       Message\n  ----    ------     ----  ----                       -------\n  Normal  Scheduled  3s    default-scheduler          Successfully assigned kubectl-6282/redis-master-zfzdc to ip-10-222-31-145\n  Normal  Pulled     1s    kubelet, ip-10-222-31-145  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-222-31-145  Created container redis-master\n  Normal  Started    0s    kubelet, ip-10-222-31-145  Started container redis-master\n"
Jul 21 18:55:18.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 describe rc redis-master --namespace=kubectl-6282'
Jul 21 18:55:18.791: INFO: stderr: ""
Jul 21 18:55:18.791: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6282\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-zfzdc\n"
Jul 21 18:55:18.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 describe service redis-master --namespace=kubectl-6282'
Jul 21 18:55:18.915: INFO: stderr: ""
Jul 21 18:55:18.915: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6282\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.105.4.74\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.0.76:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 21 18:55:18.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 describe node ip-10-222-31-145'
Jul 21 18:55:19.093: INFO: stderr: ""
Jul 21 18:55:19.094: INFO: stdout: "Name:               ip-10-222-31-145\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-222-31-145\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    storagenode=glusterfs\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"aa:5e:26:10:2a:d3\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.222.31.145\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 21 Jul 2019 16:40:04 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sun, 21 Jul 2019 18:54:54 +0000   Sun, 21 Jul 2019 16:40:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sun, 21 Jul 2019 18:54:54 +0000   Sun, 21 Jul 2019 16:40:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sun, 21 Jul 2019 18:54:54 +0000   Sun, 21 Jul 2019 16:40:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sun, 21 Jul 2019 18:54:54 +0000   Sun, 21 Jul 2019 16:40:42 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.222.31.145\n  Hostname:    ip-10-222-31-145\nCapacity:\n cpu:                4\n ephemeral-storage:  10098432Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16235516Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  9306714916\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16133116Ki\n pods:               110\nSystem Info:\n Machine ID:                 ec25f72c41c94f79b3a76a57e612085c\n System UUID:                EC25F72C-41C9-4F79-B3A7-6A57E612085C\n Boot ID:                    6abe0457-ee22-4c03-90f5-903c28103e96\n Kernel Version:             4.15.0-1032-aws\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.7\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (49 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  heptio-sonobuoy            sonobuoy-e2e-job-9d9f8ba6e19c4dc2                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5655e65ca0e146ed-znmf4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  istio-system               istio-ca-78655bf74f-jtfdj                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  istio-system               istio-ingress-6c8b8f96cd-dwlvc                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  istio-system               istio-mixer-86bc989497-v8bvv                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  istio-system               istio-pilot-75c4c5dcc5-n4dxq                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  kube-system                canal-sztcn                                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         134m\n  kube-system                coredns-fb8b8dccf-ggr8r                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     134m\n  kube-system                coredns-fb8b8dccf-wrz8f                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     134m\n  kube-system                etcd-ip-10-222-31-145                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         135m\n  kube-system                glusterfs-8krmv                                            100m (2%)     0 (0%)      100Mi (0%)       0 (0%)         131m\n  kube-system                heketi-84f9566569-55wr6                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         131m\n  kube-system                kube-apiserver-ip-10-222-31-145                            250m (6%)     0 (0%)      0 (0%)           0 (0%)         135m\n  kube-system                kube-controller-manager-ip-10-222-31-145                   200m (5%)     0 (0%)      0 (0%)           0 (0%)         135m\n  kube-system                kube-proxy-89z7m                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         134m\n  kube-system                kube-scheduler-ip-10-222-31-145                            100m (2%)     0 (0%)      0 (0%)           0 (0%)         135m\n  kube-system                tiller-deploy-85494c96cf-mtrlx                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  kubectl-6282               redis-master-zfzdc                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  rcloud-admin               admin-api-7758ff5dc6-t554w                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-admin               admin-redis-599959c468-9bdcj                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  rcloud-admin               authsrv-88696bc57-vx55z                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               config-processor-7847fd6f49-z4g58                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-admin               debug-processor-76656764d-kh7gg                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-admin               default-http-backend-admin-656d9c9d8c-c8s9h                10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      129m\n  rcloud-admin               edge-processor-68f574bb58-7xwpb                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-admin               edgesrv-6459c565cb-z2898                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  rcloud-admin               frontend-7cc7768fc8-tmhds                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-admin               frontend-opsconsole-65d75f5d69-mdz97                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-admin               nginx-ingress-controller-admin-564f6884d8-gz2js            0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-admin               postgres-756f878d66-kdw48                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  rcloud-admin               rafay-container-registry-6474bdcbcf-mgd9f                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               regauth-8bd9db7c4-dmmnf                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               resource-allocation-8c8cdcfd8-njc4s                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               traffic-steering-547844bcf8-sj82z                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               workload-placement-746878b79f-dbd7b                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-admin               workload-processor-7c768567f6-zdlzm                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-infra               config-broker-5c85977786-rvjlb                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-infra               cryptosvc-d477c486-rtrnb                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-infra               debug-broker-0                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-infra               default-http-backend-55b84578bf-lghj8                      10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      130m\n  rcloud-infra               edge-broker-5bf96697cf-l57cr                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  rcloud-infra               edge-sec-665bf84b5d-nr27w                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  rcloud-infra               kafka-core-7c75bb8ccd-zrkn5                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  rcloud-infra               keygensvc-86d69565-94v4f                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  rcloud-infra               nginx-ingress-controller-78dcf4d98b-nzf98                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  rcloud-infra               salt-master-6bc4f85449-hf78n                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  rcloud-infra               workload-broker-c5f8c89c-h6ssl                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  rcloud-infra               zookeeper-86bfd95d77-lxx59                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1120m (28%)  20m (0%)\n  memory             280Mi (1%)   380Mi (2%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:              <none>\n"
Jul 21 18:55:19.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 describe namespace kubectl-6282'
Jul 21 18:55:19.328: INFO: stderr: ""
Jul 21 18:55:19.328: INFO: stdout: "Name:         kubectl-6282\nLabels:       e2e-framework=kubectl\n              e2e-run=e285543c-abdc-11e9-974c-16aa19c3723a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:55:19.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6282" for this suite.
Jul 21 18:55:43.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:55:43.913: INFO: namespace kubectl-6282 deletion completed in 24.580965914s

â€¢ [SLOW TEST:28.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:55:43.914: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-247d67df-abe9-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:55:43.952: INFO: Waiting up to 5m0s for pod "pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a" in namespace "configmap-9871" to be "success or failure"
Jul 21 18:55:43.967: INFO: Pod "pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.350302ms
Jul 21 18:55:45.974: INFO: Pod "pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02233578s
Jul 21 18:55:47.977: INFO: Pod "pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025085681s
STEP: Saw pod success
Jul 21 18:55:47.977: INFO: Pod "pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:55:47.979: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a container configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:55:48.037: INFO: Waiting for pod pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:55:48.040: INFO: Pod pod-configmaps-247de32b-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:55:48.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9871" for this suite.
Jul 21 18:55:54.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:55:54.637: INFO: namespace configmap-9871 deletion completed in 6.594360114s

â€¢ [SLOW TEST:10.723 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:55:54.637: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2041
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 21 18:55:54.667: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 21 18:56:16.813: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.79:8080/dial?request=hostName&protocol=udp&host=10.244.0.78&port=8081&tries=1'] Namespace:pod-network-test-2041 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:16.813: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:17.091: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:56:17.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2041" for this suite.
Jul 21 18:56:41.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:56:41.741: INFO: namespace pod-network-test-2041 deletion completed in 24.646762417s

â€¢ [SLOW TEST:47.103 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:56:41.741: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul 21 18:56:51.843: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:51.843: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:52.058: INFO: Exec stderr: ""
Jul 21 18:56:52.058: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:52.058: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:52.380: INFO: Exec stderr: ""
Jul 21 18:56:52.381: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:52.381: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:52.939: INFO: Exec stderr: ""
Jul 21 18:56:52.939: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:52.939: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:53.269: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul 21 18:56:53.269: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:53.269: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:53.596: INFO: Exec stderr: ""
Jul 21 18:56:53.597: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:53.597: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:53.854: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul 21 18:56:53.854: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:53.854: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:54.205: INFO: Exec stderr: ""
Jul 21 18:56:54.205: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:54.205: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:54.679: INFO: Exec stderr: ""
Jul 21 18:56:54.679: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:54.679: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:55.047: INFO: Exec stderr: ""
Jul 21 18:56:55.047: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4001 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 21 18:56:55.047: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
Jul 21 18:56:55.323: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:56:55.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4001" for this suite.
Jul 21 18:57:43.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:57:43.898: INFO: namespace e2e-kubelet-etc-hosts-4001 deletion completed in 48.570483408s

â€¢ [SLOW TEST:62.157 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:57:43.898: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul 21 18:57:49.002: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:57:49.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8270" for this suite.
Jul 21 18:58:13.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:58:13.643: INFO: namespace replicaset-8270 deletion completed in 24.61138424s

â€¢ [SLOW TEST:29.745 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:58:13.643: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 21 18:58:13.710: INFO: Waiting up to 5m0s for pod "pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a" in namespace "emptydir-9221" to be "success or failure"
Jul 21 18:58:13.762: INFO: Pod "pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 52.103973ms
Jul 21 18:58:15.770: INFO: Pod "pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059948859s
Jul 21 18:58:17.774: INFO: Pod "pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06396586s
STEP: Saw pod success
Jul 21 18:58:17.774: INFO: Pod "pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:58:17.779: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:58:17.818: INFO: Waiting for pod pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:58:17.827: INFO: Pod pod-7dc0c13f-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:58:17.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9221" for this suite.
Jul 21 18:58:23.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:58:24.419: INFO: namespace emptydir-9221 deletion completed in 6.588887036s

â€¢ [SLOW TEST:10.776 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:58:24.419: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-842dda5f-abe9-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume configMaps
Jul 21 18:58:24.524: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a" in namespace "projected-8600" to be "success or failure"
Jul 21 18:58:24.531: INFO: Pod "pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.186055ms
Jul 21 18:58:26.535: INFO: Pod "pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01053186s
Jul 21 18:58:28.538: INFO: Pod "pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013413523s
STEP: Saw pod success
Jul 21 18:58:28.538: INFO: Pod "pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:58:28.541: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 21 18:58:28.579: INFO: Waiting for pod pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:58:28.587: INFO: Pod pod-projected-configmaps-84304215-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:58:28.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8600" for this suite.
Jul 21 18:58:34.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:58:35.166: INFO: namespace projected-8600 deletion completed in 6.576018798s

â€¢ [SLOW TEST:10.747 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:58:35.166: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 21 18:58:35.193: INFO: Waiting up to 5m0s for pod "pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a" in namespace "emptydir-145" to be "success or failure"
Jul 21 18:58:35.195: INFO: Pod "pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.728675ms
Jul 21 18:58:37.197: INFO: Pod "pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004515706s
Jul 21 18:58:39.207: INFO: Pod "pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014159585s
STEP: Saw pod success
Jul 21 18:58:39.207: INFO: Pod "pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:58:39.214: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 18:58:39.256: INFO: Waiting for pod pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:58:39.259: INFO: Pod pod-8a8f33d8-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:58:39.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-145" for this suite.
Jul 21 18:58:45.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:58:45.883: INFO: namespace emptydir-145 deletion completed in 6.613437624s

â€¢ [SLOW TEST:10.717 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:58:45.883: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 21 18:58:45.963: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:58:50.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4324" for this suite.
Jul 21 18:59:14.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:59:15.255: INFO: namespace init-container-4324 deletion completed in 24.576437761s

â€¢ [SLOW TEST:29.372 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:59:15.255: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 18:59:15.310: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a" in namespace "downward-api-679" to be "success or failure"
Jul 21 18:59:15.315: INFO: Pod "downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.541847ms
Jul 21 18:59:17.325: INFO: Pod "downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014696136s
Jul 21 18:59:19.334: INFO: Pod "downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02373574s
STEP: Saw pod success
Jul 21 18:59:19.334: INFO: Pod "downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:59:19.341: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 18:59:19.374: INFO: Waiting for pod downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:59:19.388: INFO: Pod downwardapi-volume-a277b44a-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:59:19.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-679" for this suite.
Jul 21 18:59:25.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:59:25.967: INFO: namespace downward-api-679 deletion completed in 6.576950739s

â€¢ [SLOW TEST:10.712 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:59:25.967: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 21 18:59:30.570: INFO: Successfully updated pod "labelsupdatea8db08d3-abe9-11e9-974c-16aa19c3723a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:59:32.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9803" for this suite.
Jul 21 18:59:54.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 18:59:55.174: INFO: namespace downward-api-9803 deletion completed in 22.577638926s

â€¢ [SLOW TEST:29.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 18:59:55.174: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 21 18:59:55.239: INFO: Waiting up to 5m0s for pod "downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a" in namespace "downward-api-5828" to be "success or failure"
Jul 21 18:59:55.255: INFO: Pod "downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.360544ms
Jul 21 18:59:57.260: INFO: Pod "downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021851332s
Jul 21 18:59:59.267: INFO: Pod "downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028102994s
STEP: Saw pod success
Jul 21 18:59:59.267: INFO: Pod "downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 18:59:59.276: INFO: Trying to get logs from node ip-10-222-31-145 pod downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 18:59:59.327: INFO: Waiting for pod downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 18:59:59.329: INFO: Pod downward-api-ba43a3ff-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 18:59:59.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5828" for this suite.
Jul 21 19:00:05.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:00:05.960: INFO: namespace downward-api-5828 deletion completed in 6.628917097s

â€¢ [SLOW TEST:10.786 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:00:05.960: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-c0b7ea5f-abe9-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 19:00:06.087: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a" in namespace "projected-3489" to be "success or failure"
Jul 21 19:00:06.092: INFO: Pod "pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.865154ms
Jul 21 19:00:08.099: INFO: Pod "pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012071697s
Jul 21 19:00:10.124: INFO: Pod "pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037002573s
STEP: Saw pod success
Jul 21 19:00:10.124: INFO: Pod "pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:00:10.133: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 21 19:00:10.257: INFO: Waiting for pod pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 19:00:10.259: INFO: Pod pod-projected-secrets-c0ba9c58-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:00:10.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3489" for this suite.
Jul 21 19:00:16.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:00:16.869: INFO: namespace projected-3489 deletion completed in 6.599423858s

â€¢ [SLOW TEST:10.908 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:00:16.869: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 19:00:16.904: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:00:21.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4622" for this suite.
Jul 21 19:01:01.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:01:01.883: INFO: namespace pods-4622 deletion completed in 40.581672792s

â€¢ [SLOW TEST:45.014 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:01:01.884: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 19:01:01.974: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul 21 19:01:02.007: INFO: Number of nodes with available pods: 0
Jul 21 19:01:02.007: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:03.043: INFO: Number of nodes with available pods: 0
Jul 21 19:01:03.043: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:04.014: INFO: Number of nodes with available pods: 0
Jul 21 19:01:04.014: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:05.073: INFO: Number of nodes with available pods: 1
Jul 21 19:01:05.073: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul 21 19:01:05.210: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:06.233: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:07.242: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:08.245: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:09.235: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:10.250: INFO: Wrong image for pod: daemon-set-qw2pt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 21 19:01:10.250: INFO: Pod daemon-set-qw2pt is not available
Jul 21 19:01:11.239: INFO: Pod daemon-set-l48td is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jul 21 19:01:11.308: INFO: Number of nodes with available pods: 0
Jul 21 19:01:11.308: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:12.324: INFO: Number of nodes with available pods: 0
Jul 21 19:01:12.324: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:13.323: INFO: Number of nodes with available pods: 0
Jul 21 19:01:13.323: INFO: Node ip-10-222-31-145 is running more than one daemon pod
Jul 21 19:01:14.315: INFO: Number of nodes with available pods: 1
Jul 21 19:01:14.315: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2994, will wait for the garbage collector to delete the pods
Jul 21 19:01:14.431: INFO: Deleting DaemonSet.extensions daemon-set took: 16.32516ms
Jul 21 19:01:14.831: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.187575ms
Jul 21 19:01:18.738: INFO: Number of nodes with available pods: 0
Jul 21 19:01:18.738: INFO: Number of running nodes: 0, number of available pods: 0
Jul 21 19:01:18.740: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2994/daemonsets","resourceVersion":"26768"},"items":null}

Jul 21 19:01:18.744: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2994/pods","resourceVersion":"26768"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:01:18.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2994" for this suite.
Jul 21 19:01:24.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:01:25.344: INFO: namespace daemonsets-2994 deletion completed in 6.591191416s

â€¢ [SLOW TEST:23.461 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:01:25.344: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-efff0f4c-abe9-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 19:01:25.379: INFO: Waiting up to 5m0s for pod "pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a" in namespace "secrets-5166" to be "success or failure"
Jul 21 19:01:25.390: INFO: Pod "pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.010154ms
Jul 21 19:01:27.393: INFO: Pod "pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014034392s
Jul 21 19:01:29.397: INFO: Pod "pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018021982s
STEP: Saw pod success
Jul 21 19:01:29.397: INFO: Pod "pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:01:29.400: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a container secret-volume-test: <nil>
STEP: delete the pod
Jul 21 19:01:29.432: INFO: Waiting for pod pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a to disappear
Jul 21 19:01:29.438: INFO: Pod pod-secrets-efff9985-abe9-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:01:29.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5166" for this suite.
Jul 21 19:01:35.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:01:36.016: INFO: namespace secrets-5166 deletion completed in 6.575785973s

â€¢ [SLOW TEST:10.672 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:01:36.016: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5186.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5186.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 21 19:01:40.074: INFO: DNS probes using dns-5186/dns-test-f65afd93-abe9-11e9-974c-16aa19c3723a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:01:40.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5186" for this suite.
Jul 21 19:01:46.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:01:46.737: INFO: namespace dns-5186 deletion completed in 6.627981542s

â€¢ [SLOW TEST:10.720 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:01:46.737: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:01:46.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-286" for this suite.
Jul 21 19:01:52.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:01:53.386: INFO: namespace kubelet-test-286 deletion completed in 6.597364893s

â€¢ [SLOW TEST:6.649 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:01:53.386: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4812.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4812.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4812.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4812.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4812.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4812.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 21 19:01:57.473: INFO: DNS probes using dns-4812/dns-test-00b6ead9-abea-11e9-974c-16aa19c3723a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:01:57.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4812" for this suite.
Jul 21 19:02:03.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:02:04.120: INFO: namespace dns-4812 deletion completed in 6.615924492s

â€¢ [SLOW TEST:10.734 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:02:04.120: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:02:08.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5673" for this suite.
Jul 21 19:02:14.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:02:14.828: INFO: namespace kubelet-test-5673 deletion completed in 6.604637856s

â€¢ [SLOW TEST:10.708 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:02:14.828: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 19:02:14.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a" in namespace "projected-4564" to be "success or failure"
Jul 21 19:02:14.923: INFO: Pod "downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900035ms
Jul 21 19:02:16.926: INFO: Pod "downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00778027s
Jul 21 19:02:18.929: INFO: Pod "downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010403177s
STEP: Saw pod success
Jul 21 19:02:18.929: INFO: Pod "downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:02:18.931: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 19:02:18.956: INFO: Waiting for pod downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:02:18.963: INFO: Pod downwardapi-volume-0d8485a5-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:02:18.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4564" for this suite.
Jul 21 19:02:24.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:02:25.538: INFO: namespace projected-4564 deletion completed in 6.57239503s

â€¢ [SLOW TEST:10.710 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:02:25.539: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:02:29.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7940" for this suite.
Jul 21 19:03:15.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:03:16.170: INFO: namespace kubelet-test-7940 deletion completed in 46.573095179s

â€¢ [SLOW TEST:50.631 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:03:16.170: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Jul 21 19:03:16.202: INFO: Waiting up to 5m0s for pod "pod-320db34f-abea-11e9-974c-16aa19c3723a" in namespace "emptydir-8538" to be "success or failure"
Jul 21 19:03:16.217: INFO: Pod "pod-320db34f-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.662684ms
Jul 21 19:03:18.221: INFO: Pod "pod-320db34f-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019270863s
Jul 21 19:03:20.228: INFO: Pod "pod-320db34f-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026209208s
STEP: Saw pod success
Jul 21 19:03:20.228: INFO: Pod "pod-320db34f-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:03:20.230: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-320db34f-abea-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 19:03:20.255: INFO: Waiting for pod pod-320db34f-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:03:20.257: INFO: Pod pod-320db34f-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:03:20.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8538" for this suite.
Jul 21 19:03:26.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:03:26.840: INFO: namespace emptydir-8538 deletion completed in 6.578628701s

â€¢ [SLOW TEST:10.669 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:03:26.840: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 21 19:03:34.921: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:34.926: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:36.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:36.934: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:38.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:38.934: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:40.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:40.933: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:42.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:42.933: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:44.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:44.934: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:46.932: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:46.935: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:48.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:48.933: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:50.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:50.934: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:52.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:52.935: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:54.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:54.933: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:56.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:56.933: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:03:58.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:03:58.937: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:04:00.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:04:00.934: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 21 19:04:02.931: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 21 19:04:02.933: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:04:02.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9943" for this suite.
Jul 21 19:04:24.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:04:25.531: INFO: namespace container-lifecycle-hook-9943 deletion completed in 22.587719881s

â€¢ [SLOW TEST:58.691 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:04:25.531: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 19:04:25.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a" in namespace "projected-6950" to be "success or failure"
Jul 21 19:04:25.579: INFO: Pod "downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.265859ms
Jul 21 19:04:27.582: INFO: Pod "downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008044707s
Jul 21 19:04:29.587: INFO: Pod "downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013245212s
STEP: Saw pod success
Jul 21 19:04:29.587: INFO: Pod "downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:04:29.589: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 19:04:29.617: INFO: Waiting for pod downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:04:29.623: INFO: Pod downwardapi-volume-5b67083f-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:04:29.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6950" for this suite.
Jul 21 19:04:35.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:04:36.209: INFO: namespace projected-6950 deletion completed in 6.575903593s

â€¢ [SLOW TEST:10.678 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:04:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 21 19:04:36.240: INFO: Waiting up to 5m0s for pod "pod-61c296cf-abea-11e9-974c-16aa19c3723a" in namespace "emptydir-1849" to be "success or failure"
Jul 21 19:04:36.245: INFO: Pod "pod-61c296cf-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725436ms
Jul 21 19:04:38.249: INFO: Pod "pod-61c296cf-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008807894s
Jul 21 19:04:40.252: INFO: Pod "pod-61c296cf-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011750309s
STEP: Saw pod success
Jul 21 19:04:40.252: INFO: Pod "pod-61c296cf-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:04:40.256: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-61c296cf-abea-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 19:04:40.273: INFO: Waiting for pod pod-61c296cf-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:04:40.275: INFO: Pod pod-61c296cf-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:04:40.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1849" for this suite.
Jul 21 19:04:46.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:04:46.869: INFO: namespace emptydir-1849 deletion completed in 6.591517535s

â€¢ [SLOW TEST:10.659 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:04:46.869: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Jul 21 19:04:46.899: INFO: Waiting up to 5m0s for pod "var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a" in namespace "var-expansion-2790" to be "success or failure"
Jul 21 19:04:46.904: INFO: Pod "var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044001ms
Jul 21 19:04:48.906: INFO: Pod "var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006365471s
Jul 21 19:04:50.911: INFO: Pod "var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011671518s
STEP: Saw pod success
Jul 21 19:04:50.911: INFO: Pod "var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:04:50.914: INFO: Trying to get logs from node ip-10-222-31-145 pod var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a container dapi-container: <nil>
STEP: delete the pod
Jul 21 19:04:50.936: INFO: Waiting for pod var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:04:50.941: INFO: Pod var-expansion-681cfdf3-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:04:50.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2790" for this suite.
Jul 21 19:04:56.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:04:57.513: INFO: namespace var-expansion-2790 deletion completed in 6.569868273s

â€¢ [SLOW TEST:10.644 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:04:57.514: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:05:03.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9428" for this suite.
Jul 21 19:05:09.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:05:10.233: INFO: namespace namespaces-9428 deletion completed in 6.594542999s
STEP: Destroying namespace "nsdeletetest-2319" for this suite.
Jul 21 19:05:10.238: INFO: Namespace nsdeletetest-2319 was already deleted
STEP: Destroying namespace "nsdeletetest-6597" for this suite.
Jul 21 19:05:16.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:05:16.897: INFO: namespace nsdeletetest-6597 deletion completed in 6.659490506s

â€¢ [SLOW TEST:19.384 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:05:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 19:05:16.921: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:05:20.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5446" for this suite.
Jul 21 19:06:00.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:06:01.555: INFO: namespace pods-5446 deletion completed in 40.580101801s

â€¢ [SLOW TEST:44.657 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:06:01.555: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 21 19:06:01.599: INFO: namespace kubectl-5444
Jul 21 19:06:01.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 create -f - --namespace=kubectl-5444'
Jul 21 19:06:02.361: INFO: stderr: ""
Jul 21 19:06:02.361: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 21 19:06:03.376: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 19:06:03.376: INFO: Found 0 / 1
Jul 21 19:06:04.368: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 19:06:04.368: INFO: Found 0 / 1
Jul 21 19:06:05.374: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 19:06:05.374: INFO: Found 0 / 1
Jul 21 19:06:06.409: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 19:06:06.409: INFO: Found 1 / 1
Jul 21 19:06:06.409: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 21 19:06:06.415: INFO: Selector matched 1 pods for map[app:redis]
Jul 21 19:06:06.415: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 21 19:06:06.415: INFO: wait on redis-master startup in kubectl-5444 
Jul 21 19:06:06.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 logs redis-master-ql2qj redis-master --namespace=kubectl-5444'
Jul 21 19:06:06.627: INFO: stderr: ""
Jul 21 19:06:06.630: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jul 19:06:05.102 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jul 19:06:05.103 # Server started, Redis version 3.2.12\n1:M 21 Jul 19:06:05.103 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jul 19:06:05.103 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jul 21 19:06:06.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5444'
Jul 21 19:06:06.848: INFO: stderr: ""
Jul 21 19:06:06.848: INFO: stdout: "service/rm2 exposed\n"
Jul 21 19:06:06.853: INFO: Service rm2 in namespace kubectl-5444 found.
STEP: exposing service
Jul 21 19:06:08.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-991073413 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5444'
Jul 21 19:06:09.196: INFO: stderr: ""
Jul 21 19:06:09.196: INFO: stdout: "service/rm3 exposed\n"
Jul 21 19:06:09.202: INFO: Service rm3 in namespace kubectl-5444 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:06:11.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5444" for this suite.
Jul 21 19:06:35.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:06:35.786: INFO: namespace kubectl-5444 deletion completed in 24.573063191s

â€¢ [SLOW TEST:34.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:06:35.786: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:06:39.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6972" for this suite.
Jul 21 19:07:19.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:07:20.467: INFO: namespace kubelet-test-6972 deletion completed in 40.577103767s

â€¢ [SLOW TEST:44.682 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:07:20.470: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 19:07:20.544: INFO: Creating deployment "test-recreate-deployment"
Jul 21 19:07:20.554: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 21 19:07:20.596: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul 21 19:07:22.611: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 21 19:07:22.614: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332840, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332840, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332840, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332840, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 19:07:24.617: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 21 19:07:24.636: INFO: Updating deployment test-recreate-deployment
Jul 21 19:07:24.636: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 21 19:07:24.777: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7787,SelfLink:/apis/apps/v1/namespaces/deployment-7787/deployments/test-recreate-deployment,UID:c3b28bf4-abea-11e9-9149-027a95377cb1,ResourceVersion:27955,Generation:2,CreationTimestamp:2019-07-21 19:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-21 19:07:24 +0000 UTC 2019-07-21 19:07:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-21 19:07:24 +0000 UTC 2019-07-21 19:07:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul 21 19:07:24.793: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-7787,SelfLink:/apis/apps/v1/namespaces/deployment-7787/replicasets/test-recreate-deployment-c9cbd8684,UID:c62e3026-abea-11e9-9149-027a95377cb1,ResourceVersion:27953,Generation:1,CreationTimestamp:2019-07-21 19:07:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c3b28bf4-abea-11e9-9149-027a95377cb1 0xc002cd7170 0xc002cd7171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 19:07:24.793: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 21 19:07:24.794: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-7787,SelfLink:/apis/apps/v1/namespaces/deployment-7787/replicasets/test-recreate-deployment-7d57d5ff7c,UID:c3b3f686-abea-11e9-9149-027a95377cb1,ResourceVersion:27943,Generation:2,CreationTimestamp:2019-07-21 19:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c3b28bf4-abea-11e9-9149-027a95377cb1 0xc002cd7087 0xc002cd7088}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 19:07:24.798: INFO: Pod "test-recreate-deployment-c9cbd8684-vsjql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-vsjql,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-7787,SelfLink:/api/v1/namespaces/deployment-7787/pods/test-recreate-deployment-c9cbd8684-vsjql,UID:c62f802b-abea-11e9-9149-027a95377cb1,ResourceVersion:27956,Generation:0,CreationTimestamp:2019-07-21 19:07:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 c62e3026-abea-11e9-9149-027a95377cb1 0xc002cd79c0 0xc002cd79c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dwmd9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dwmd9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dwmd9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002cd7a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002cd7a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:07:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:07:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:07:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:07:24 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:,StartTime:2019-07-21 19:07:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:07:24.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7787" for this suite.
Jul 21 19:07:30.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:07:31.418: INFO: namespace deployment-7787 deletion completed in 6.613586737s

â€¢ [SLOW TEST:10.949 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:07:31.422: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 21 19:07:39.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:39.557: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:41.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:41.559: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:43.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:43.559: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:45.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:45.559: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:47.562: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:47.566: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:49.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:49.561: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:51.558: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:51.565: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:53.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:53.560: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:55.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:55.560: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 21 19:07:57.557: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 21 19:07:57.560: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:07:57.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3549" for this suite.
Jul 21 19:08:19.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:08:20.138: INFO: namespace container-lifecycle-hook-3549 deletion completed in 22.575136123s

â€¢ [SLOW TEST:48.717 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:08:20.138: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-fh2t
STEP: Creating a pod to test atomic-volume-subpath
Jul 21 19:08:20.174: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-fh2t" in namespace "subpath-5318" to be "success or failure"
Jul 21 19:08:20.178: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42955ms
Jul 21 19:08:22.183: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009613956s
Jul 21 19:08:24.188: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 4.014567508s
Jul 21 19:08:26.191: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 6.016907043s
Jul 21 19:08:28.203: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 8.029149135s
Jul 21 19:08:30.210: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 10.036083566s
Jul 21 19:08:32.227: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 12.053264596s
Jul 21 19:08:34.240: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 14.066690202s
Jul 21 19:08:36.243: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 16.069167222s
Jul 21 19:08:38.246: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 18.072354931s
Jul 21 19:08:40.249: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 20.075105889s
Jul 21 19:08:42.252: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Running", Reason="", readiness=true. Elapsed: 22.078128741s
Jul 21 19:08:44.255: INFO: Pod "pod-subpath-test-secret-fh2t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0815402s
STEP: Saw pod success
Jul 21 19:08:44.255: INFO: Pod "pod-subpath-test-secret-fh2t" satisfied condition "success or failure"
Jul 21 19:08:44.258: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-subpath-test-secret-fh2t container test-container-subpath-secret-fh2t: <nil>
STEP: delete the pod
Jul 21 19:08:44.287: INFO: Waiting for pod pod-subpath-test-secret-fh2t to disappear
Jul 21 19:08:44.289: INFO: Pod pod-subpath-test-secret-fh2t no longer exists
STEP: Deleting pod pod-subpath-test-secret-fh2t
Jul 21 19:08:44.290: INFO: Deleting pod "pod-subpath-test-secret-fh2t" in namespace "subpath-5318"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:08:44.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5318" for this suite.
Jul 21 19:08:50.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:08:50.884: INFO: namespace subpath-5318 deletion completed in 6.588453319s

â€¢ [SLOW TEST:30.746 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:08:50.885: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 19:08:50.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a" in namespace "projected-5231" to be "success or failure"
Jul 21 19:08:51.003: INFO: Pod "downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.005341ms
Jul 21 19:08:53.009: INFO: Pod "downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031909482s
Jul 21 19:08:55.012: INFO: Pod "downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034831127s
STEP: Saw pod success
Jul 21 19:08:55.012: INFO: Pod "downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:08:55.014: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 19:08:55.029: INFO: Waiting for pod downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:08:55.040: INFO: Pod downwardapi-volume-f9974bdf-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:08:55.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5231" for this suite.
Jul 21 19:09:01.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:09:01.622: INFO: namespace projected-5231 deletion completed in 6.576893734s

â€¢ [SLOW TEST:10.737 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:09:01.622: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-fff84ecd-abea-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 19:09:01.730: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a" in namespace "projected-8291" to be "success or failure"
Jul 21 19:09:01.735: INFO: Pod "pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.864868ms
Jul 21 19:09:03.746: INFO: Pod "pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015780941s
Jul 21 19:09:05.754: INFO: Pod "pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023651857s
STEP: Saw pod success
Jul 21 19:09:05.754: INFO: Pod "pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:09:05.757: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 21 19:09:05.904: INFO: Waiting for pod pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a to disappear
Jul 21 19:09:05.990: INFO: Pod pod-projected-secrets-fffeda9d-abea-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:09:05.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8291" for this suite.
Jul 21 19:09:12.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:09:12.667: INFO: namespace projected-8291 deletion completed in 6.665097749s

â€¢ [SLOW TEST:11.045 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:09:12.667: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Jul 21 19:09:13.360: INFO: created pod pod-service-account-defaultsa
Jul 21 19:09:13.360: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 21 19:09:13.372: INFO: created pod pod-service-account-mountsa
Jul 21 19:09:13.372: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 21 19:09:13.379: INFO: created pod pod-service-account-nomountsa
Jul 21 19:09:13.379: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 21 19:09:13.408: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 21 19:09:13.408: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 21 19:09:13.424: INFO: created pod pod-service-account-mountsa-mountspec
Jul 21 19:09:13.424: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 21 19:09:13.445: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 21 19:09:13.445: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 21 19:09:13.460: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 21 19:09:13.460: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 21 19:09:13.479: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 21 19:09:13.479: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 21 19:09:13.519: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 21 19:09:13.519: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:09:13.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7677" for this suite.
Jul 21 19:09:37.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:09:38.167: INFO: namespace svcaccounts-7677 deletion completed in 24.639971938s

â€¢ [SLOW TEST:25.500 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:09:38.167: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 21 19:09:38.196: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 21 19:09:38.205: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 21 19:09:43.207: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 21 19:09:43.207: INFO: Creating deployment "test-rolling-update-deployment"
Jul 21 19:09:43.211: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 21 19:09:43.219: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 21 19:09:45.224: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 21 19:09:45.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332983, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332983, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332983, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63699332983, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 21 19:09:47.230: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 21 19:09:47.239: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4156,SelfLink:/apis/apps/v1/namespaces/deployment-4156/deployments/test-rolling-update-deployment,UID:18bb0940-abeb-11e9-9149-027a95377cb1,ResourceVersion:28522,Generation:1,CreationTimestamp:2019-07-21 19:09:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-21 19:09:43 +0000 UTC 2019-07-21 19:09:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-21 19:09:45 +0000 UTC 2019-07-21 19:09:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 21 19:09:47.242: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-4156,SelfLink:/apis/apps/v1/namespaces/deployment-4156/replicasets/test-rolling-update-deployment-67599b4d9,UID:18bc600a-abeb-11e9-9149-027a95377cb1,ResourceVersion:28511,Generation:1,CreationTimestamp:2019-07-21 19:09:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 18bb0940-abeb-11e9-9149-027a95377cb1 0xc0026e0d70 0xc0026e0d71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 21 19:09:47.242: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 21 19:09:47.242: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4156,SelfLink:/apis/apps/v1/namespaces/deployment-4156/replicasets/test-rolling-update-controller,UID:15be6a8d-abeb-11e9-9149-027a95377cb1,ResourceVersion:28521,Generation:2,CreationTimestamp:2019-07-21 19:09:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 18bb0940-abeb-11e9-9149-027a95377cb1 0xc0026e0ca7 0xc0026e0ca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 21 19:09:47.244: INFO: Pod "test-rolling-update-deployment-67599b4d9-6l58d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-6l58d,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-4156,SelfLink:/api/v1/namespaces/deployment-4156/pods/test-rolling-update-deployment-67599b4d9-6l58d,UID:18bcdba8-abeb-11e9-9149-027a95377cb1,ResourceVersion:28510,Generation:0,CreationTimestamp:2019-07-21 19:09:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.0.125/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 18bc600a-abeb-11e9-9149-027a95377cb1 0xc002c8fe60 0xc002c8fe61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-s5gdv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s5gdv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s5gdv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-222-31-145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c8fed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c8fef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:09:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-21 19:09:43 +0000 UTC  }],Message:,Reason:,HostIP:10.222.31.145,PodIP:10.244.0.125,StartTime:2019-07-21 19:09:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-21 19:09:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://169c2344f3836f8a1f7d8412b046d021b59b47368c220316ea3acfbe8ae36b95}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:09:47.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4156" for this suite.
Jul 21 19:09:53.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:09:53.818: INFO: namespace deployment-4156 deletion completed in 6.570080763s

â€¢ [SLOW TEST:15.651 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:09:53.819: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4930
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4930
STEP: Creating statefulset with conflicting port in namespace statefulset-4930
STEP: Waiting until pod test-pod will start running in namespace statefulset-4930
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4930
Jul 21 19:09:57.896: INFO: Observed stateful pod in namespace: statefulset-4930, name: ss-0, uid: 21010a27-abeb-11e9-9149-027a95377cb1, status phase: Pending. Waiting for statefulset controller to delete.
Jul 21 19:09:58.075: INFO: Observed stateful pod in namespace: statefulset-4930, name: ss-0, uid: 21010a27-abeb-11e9-9149-027a95377cb1, status phase: Failed. Waiting for statefulset controller to delete.
Jul 21 19:09:58.084: INFO: Observed stateful pod in namespace: statefulset-4930, name: ss-0, uid: 21010a27-abeb-11e9-9149-027a95377cb1, status phase: Failed. Waiting for statefulset controller to delete.
Jul 21 19:09:58.094: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4930
STEP: Removing pod with conflicting port in namespace statefulset-4930
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4930 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 21 19:10:02.164: INFO: Deleting all statefulset in ns statefulset-4930
Jul 21 19:10:02.167: INFO: Scaling statefulset ss to 0
Jul 21 19:10:22.209: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 19:10:22.215: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:10:22.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4930" for this suite.
Jul 21 19:10:28.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:10:28.853: INFO: namespace statefulset-4930 deletion completed in 6.585235893s

â€¢ [SLOW TEST:35.035 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:10:28.853: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 21 19:10:28.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a" in namespace "projected-1648" to be "success or failure"
Jul 21 19:10:28.901: INFO: Pod "downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.610802ms
Jul 21 19:10:30.926: INFO: Pod "downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037878878s
Jul 21 19:10:32.930: INFO: Pod "downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041680316s
STEP: Saw pod success
Jul 21 19:10:32.930: INFO: Pod "downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:10:32.932: INFO: Trying to get logs from node ip-10-222-31-145 pod downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a container client-container: <nil>
STEP: delete the pod
Jul 21 19:10:32.957: INFO: Waiting for pod downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a to disappear
Jul 21 19:10:32.959: INFO: Pod downwardapi-volume-33f45352-abeb-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:10:32.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1648" for this suite.
Jul 21 19:10:38.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:10:39.535: INFO: namespace projected-1648 deletion completed in 6.573844345s

â€¢ [SLOW TEST:10.682 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:10:39.536: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-1948/secret-test-3a53df6e-abeb-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 19:10:39.597: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a" in namespace "secrets-1948" to be "success or failure"
Jul 21 19:10:39.613: INFO: Pod "pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.566673ms
Jul 21 19:10:41.617: INFO: Pod "pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019537668s
Jul 21 19:10:43.628: INFO: Pod "pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031229473s
STEP: Saw pod success
Jul 21 19:10:43.628: INFO: Pod "pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:10:43.631: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a container env-test: <nil>
STEP: delete the pod
Jul 21 19:10:43.694: INFO: Waiting for pod pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a to disappear
Jul 21 19:10:43.700: INFO: Pod pod-configmaps-3a550b05-abeb-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:10:43.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1948" for this suite.
Jul 21 19:10:49.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:10:50.282: INFO: namespace secrets-1948 deletion completed in 6.576394702s

â€¢ [SLOW TEST:10.746 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:10:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2261
Jul 21 19:10:54.363: INFO: Started pod liveness-exec in namespace container-probe-2261
STEP: checking the pod's current state and verifying that restartCount is present
Jul 21 19:10:54.367: INFO: Initial restart count of pod liveness-exec is 0
Jul 21 19:11:48.518: INFO: Restart count of pod container-probe-2261/liveness-exec is now 1 (54.151536093s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:11:48.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2261" for this suite.
Jul 21 19:11:54.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:11:55.123: INFO: namespace container-probe-2261 deletion completed in 6.579696961s

â€¢ [SLOW TEST:64.840 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:11:55.123: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2599
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 21 19:11:55.175: INFO: Found 0 stateful pods, waiting for 3
Jul 21 19:12:05.179: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 19:12:05.179: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 19:12:05.179: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 21 19:12:05.206: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul 21 19:12:15.243: INFO: Updating stateful set ss2
Jul 21 19:12:15.248: INFO: Waiting for Pod statefulset-2599/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jul 21 19:12:25.347: INFO: Found 2 stateful pods, waiting for 3
Jul 21 19:12:35.351: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 19:12:35.351: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 21 19:12:35.351: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul 21 19:12:35.372: INFO: Updating stateful set ss2
Jul 21 19:12:35.379: INFO: Waiting for Pod statefulset-2599/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 21 19:12:45.409: INFO: Updating stateful set ss2
Jul 21 19:12:45.457: INFO: Waiting for StatefulSet statefulset-2599/ss2 to complete update
Jul 21 19:12:45.457: INFO: Waiting for Pod statefulset-2599/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 21 19:12:55.469: INFO: Deleting all statefulset in ns statefulset-2599
Jul 21 19:12:55.473: INFO: Scaling statefulset ss2 to 0
Jul 21 19:13:15.534: INFO: Waiting for statefulset status.replicas updated to 0
Jul 21 19:13:15.537: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:13:15.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2599" for this suite.
Jul 21 19:13:21.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:13:22.144: INFO: namespace statefulset-2599 deletion completed in 6.59594093s

â€¢ [SLOW TEST:87.021 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:13:22.145: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Jul 21 19:13:22.195: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-873" to be "success or failure"
Jul 21 19:13:22.198: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.246082ms
Jul 21 19:13:24.212: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016103102s
Jul 21 19:13:26.219: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02350812s
STEP: Saw pod success
Jul 21 19:13:26.219: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul 21 19:13:26.221: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul 21 19:13:26.244: INFO: Waiting for pod pod-host-path-test to disappear
Jul 21 19:13:26.246: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:13:26.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-873" for this suite.
Jul 21 19:13:32.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:13:32.828: INFO: namespace hostpath-873 deletion completed in 6.578543482s

â€¢ [SLOW TEST:10.684 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:13:32.828: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Jul 21 19:13:32.891: INFO: Waiting up to 5m0s for pod "client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a" in namespace "containers-5300" to be "success or failure"
Jul 21 19:13:32.903: INFO: Pod "client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.515157ms
Jul 21 19:13:34.908: INFO: Pod "client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016763169s
Jul 21 19:13:36.921: INFO: Pod "client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030118975s
STEP: Saw pod success
Jul 21 19:13:36.921: INFO: Pod "client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:13:36.926: INFO: Trying to get logs from node ip-10-222-31-145 pod client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 19:13:36.948: INFO: Waiting for pod client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a to disappear
Jul 21 19:13:36.954: INFO: Pod client-containers-a19cf72d-abeb-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:13:36.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5300" for this suite.
Jul 21 19:13:42.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:13:43.534: INFO: namespace containers-5300 deletion completed in 6.576874803s

â€¢ [SLOW TEST:10.706 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:13:43.535: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul 21 19:13:43.574: INFO: Waiting up to 5m0s for pod "pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a" in namespace "emptydir-3786" to be "success or failure"
Jul 21 19:13:43.579: INFO: Pod "pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741315ms
Jul 21 19:13:45.582: INFO: Pod "pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007457036s
Jul 21 19:13:47.584: INFO: Pod "pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010113695s
STEP: Saw pod success
Jul 21 19:13:47.584: INFO: Pod "pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:13:47.587: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a container test-container: <nil>
STEP: delete the pod
Jul 21 19:13:47.611: INFO: Waiting for pod pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a to disappear
Jul 21 19:13:47.613: INFO: Pod pod-a7fdd2db-abeb-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:13:47.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3786" for this suite.
Jul 21 19:13:53.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:13:54.200: INFO: namespace emptydir-3786 deletion completed in 6.584583797s

â€¢ [SLOW TEST:10.665 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:13:54.202: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-ae5df9b6-abeb-11e9-974c-16aa19c3723a
STEP: Creating a pod to test consume secrets
Jul 21 19:13:54.288: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a" in namespace "projected-8366" to be "success or failure"
Jul 21 19:13:54.307: INFO: Pod "pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 19.485539ms
Jul 21 19:13:56.315: INFO: Pod "pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026603461s
Jul 21 19:13:58.317: INFO: Pod "pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029224444s
STEP: Saw pod success
Jul 21 19:13:58.317: INFO: Pod "pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a" satisfied condition "success or failure"
Jul 21 19:13:58.320: INFO: Trying to get logs from node ip-10-222-31-145 pod pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 21 19:13:58.339: INFO: Waiting for pod pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a to disappear
Jul 21 19:13:58.342: INFO: Pod pod-projected-secrets-ae600a27-abeb-11e9-974c-16aa19c3723a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:13:58.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8366" for this suite.
Jul 21 19:14:04.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:14:04.969: INFO: namespace projected-8366 deletion completed in 6.624518909s

â€¢ [SLOW TEST:10.767 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 21 19:14:04.969: INFO: >>> kubeConfig: /tmp/kubeconfig-991073413
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Jul 21 19:14:04.999: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-991073413 proxy --unix-socket=/tmp/kubectl-proxy-unix814865748/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 21 19:14:05.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-757" for this suite.
Jul 21 19:14:11.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 21 19:14:11.693: INFO: namespace kubectl-757 deletion completed in 6.58660093s

â€¢ [SLOW TEST:6.724 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSJul 21 19:14:11.693: INFO: Running AfterSuite actions on all nodes
Jul 21 19:14:11.693: INFO: Running AfterSuite actions on node 1
Jul 21 19:14:11.693: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 6369.743 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h46m12.848686932s
Test Suite Passed
