I0529 16:07:48.877687      18 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-762736658
I0529 16:07:48.879419      18 e2e.go:240] Starting e2e run "e6399d8d-822b-11e9-abea-da3eb1f4b18f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1559146066 - Will randomize all specs
Will run 204 of 3584 specs

May 29 16:07:49.194: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:07:49.198: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 29 16:07:49.238: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 29 16:07:49.308: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 29 16:07:49.308: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 29 16:07:49.308: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 29 16:07:49.327: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'flannel' (0 seconds elapsed)
May 29 16:07:49.327: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 29 16:07:49.327: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'nginx-ingress' (0 seconds elapsed)
May 29 16:07:49.327: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
May 29 16:07:49.328: INFO: e2e test version: v1.14.1
May 29 16:07:49.333: INFO: kube-apiserver version: v1.14.1
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:07:49.334: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename containers
May 29 16:07:49.389: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 29 16:07:49.416: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-556
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
May 29 16:07:49.560: INFO: Waiting up to 5m0s for pod "client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f" in namespace "containers-556" to be "success or failure"
May 29 16:07:49.567: INFO: Pod "client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.820089ms
May 29 16:07:51.576: INFO: Pod "client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015625823s
May 29 16:07:53.584: INFO: Pod "client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023667284s
STEP: Saw pod success
May 29 16:07:53.584: INFO: Pod "client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:07:53.591: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:07:53.666: INFO: Waiting for pod client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f to disappear
May 29 16:07:53.672: INFO: Pod client-containers-e7c9b2ee-822b-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:07:53.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-556" for this suite.
May 29 16:07:59.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:07:59.938: INFO: namespace containers-556 deletion completed in 6.258339s

• [SLOW TEST:10.604 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:07:59.939: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-ee15315e-822b-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:08:00.130: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f" in namespace "projected-5427" to be "success or failure"
May 29 16:08:00.137: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.581171ms
May 29 16:08:02.146: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015545358s
May 29 16:08:04.155: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024086789s
May 29 16:08:06.163: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03275181s
May 29 16:08:08.171: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040025722s
May 29 16:08:10.179: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.048520535s
STEP: Saw pod success
May 29 16:08:10.179: INFO: Pod "pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:08:10.187: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:08:10.245: INFO: Waiting for pod pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f to disappear
May 29 16:08:10.251: INFO: Pod pod-projected-configmaps-ee16c8ed-822b-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:08:10.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5427" for this suite.
May 29 16:08:16.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:08:16.503: INFO: namespace projected-5427 deletion completed in 6.245786193s

• [SLOW TEST:16.565 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:08:16.503: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:08:22.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-198" for this suite.
May 29 16:09:00.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:09:00.975: INFO: namespace kubelet-test-198 deletion completed in 38.253074433s

• [SLOW TEST:44.472 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:09:00.978: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 29 16:09:01.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-4360'
May 29 16:09:01.989: INFO: stderr: ""
May 29 16:09:01.989: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 29 16:09:02.998: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:02.998: INFO: Found 0 / 1
May 29 16:09:03.998: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:03.998: INFO: Found 0 / 1
May 29 16:09:04.997: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:04.997: INFO: Found 0 / 1
May 29 16:09:05.997: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:05.997: INFO: Found 0 / 1
May 29 16:09:06.997: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:06.997: INFO: Found 0 / 1
May 29 16:09:07.997: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:07.997: INFO: Found 0 / 1
May 29 16:09:09.000: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:09.000: INFO: Found 0 / 1
May 29 16:09:09.998: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:09.999: INFO: Found 0 / 1
May 29 16:09:10.999: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:10.999: INFO: Found 1 / 1
May 29 16:09:10.999: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 29 16:09:11.006: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:11.006: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 16:09:11.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 patch pod redis-master-g8x7w --namespace=kubectl-4360 -p {"metadata":{"annotations":{"x":"y"}}}'
May 29 16:09:11.157: INFO: stderr: ""
May 29 16:09:11.157: INFO: stdout: "pod/redis-master-g8x7w patched\n"
STEP: checking annotations
May 29 16:09:11.164: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:11.164: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:09:11.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4360" for this suite.
May 29 16:09:33.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:09:33.452: INFO: namespace kubectl-4360 deletion completed in 22.279666643s

• [SLOW TEST:32.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:09:33.452: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-172
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:09:33.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 version --client'
May 29 16:09:33.726: INFO: stderr: ""
May 29 16:09:33.726: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 29 16:09:33.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-172'
May 29 16:09:34.047: INFO: stderr: ""
May 29 16:09:34.047: INFO: stdout: "replicationcontroller/redis-master created\n"
May 29 16:09:34.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-172'
May 29 16:09:34.436: INFO: stderr: ""
May 29 16:09:34.436: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 29 16:09:36.244: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:36.244: INFO: Found 0 / 1
May 29 16:09:36.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:36.444: INFO: Found 0 / 1
May 29 16:09:37.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:37.445: INFO: Found 0 / 1
May 29 16:09:38.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:38.445: INFO: Found 0 / 1
May 29 16:09:39.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:39.445: INFO: Found 0 / 1
May 29 16:09:40.446: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:40.446: INFO: Found 0 / 1
May 29 16:09:41.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:41.444: INFO: Found 0 / 1
May 29 16:09:42.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:42.446: INFO: Found 0 / 1
May 29 16:09:43.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:43.446: INFO: Found 0 / 1
May 29 16:09:44.443: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:44.443: INFO: Found 0 / 1
May 29 16:09:45.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:45.445: INFO: Found 0 / 1
May 29 16:09:46.459: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:46.459: INFO: Found 0 / 1
May 29 16:09:47.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:47.445: INFO: Found 0 / 1
May 29 16:09:48.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:48.444: INFO: Found 0 / 1
May 29 16:09:49.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:49.444: INFO: Found 0 / 1
May 29 16:09:50.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:50.444: INFO: Found 0 / 1
May 29 16:09:51.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:51.445: INFO: Found 0 / 1
May 29 16:09:52.445: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:52.445: INFO: Found 0 / 1
May 29 16:09:53.444: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:53.444: INFO: Found 0 / 1
May 29 16:09:54.446: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:54.446: INFO: Found 1 / 1
May 29 16:09:54.446: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 16:09:54.455: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:09:54.455: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 16:09:54.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 describe pod redis-master-fhkjv --namespace=kubectl-172'
May 29 16:09:54.617: INFO: stderr: ""
May 29 16:09:54.617: INFO: stdout: "Name:               redis-master-fhkjv\nNamespace:          kubectl-172\nPriority:           0\nPriorityClassName:  <none>\nNode:               scw-sono14-default-174540dd770e42e2af1af25266f/10.12.138.1\nStart Time:         Wed, 29 May 2019 16:09:34 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 100.64.1.7\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://38eea7664b88102b8e8933bd2cd1e67f9d0cd89fc52f6a4debf68bb93beb6a74\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 29 May 2019 16:09:53 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8cqht (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8cqht:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8cqht\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  20s   default-scheduler                                        Successfully assigned kubectl-172/redis-master-fhkjv to scw-sono14-default-174540dd770e42e2af1af25266f\n  Normal  Pulling    18s   kubelet, scw-sono14-default-174540dd770e42e2af1af25266f  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, scw-sono14-default-174540dd770e42e2af1af25266f  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, scw-sono14-default-174540dd770e42e2af1af25266f  Created container redis-master\n  Normal  Started    1s    kubelet, scw-sono14-default-174540dd770e42e2af1af25266f  Started container redis-master\n"
May 29 16:09:54.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 describe rc redis-master --namespace=kubectl-172'
May 29 16:09:54.796: INFO: stderr: ""
May 29 16:09:54.796: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-172\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  20s   replication-controller  Created pod: redis-master-fhkjv\n"
May 29 16:09:54.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 describe service redis-master --namespace=kubectl-172'
May 29 16:09:54.926: INFO: stderr: ""
May 29 16:09:54.926: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-172\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.42.144.254\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.7:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 29 16:09:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 describe node scw-sono14-default-174540dd770e42e2af1af25266f'
May 29 16:09:55.142: INFO: stderr: ""
May 29 16:09:55.142: INFO: stdout: "Name:               scw-sono14-default-174540dd770e42e2af1af25266f\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=GP1-XS\n                    beta.kubernetes.io/os=linux\n                    cloud.scaleway.com/scw-clusterid=c86542f1-4646-45e6-a5eb-f3bc35eac61b\n                    cloud.scaleway.com/scw-clustername=sono14\n                    cloud.scaleway.com/scw-cniname=flannel\n                    cloud.scaleway.com/scw-nodeid=174540dd-770e-42e2-af1a-f25266fd1f22\n                    cloud.scaleway.com/scw-nodename=scw-sono14-default-174540dd770e42e2af1af25266f\n                    cloud.scaleway.com/scw-poolid=aad41dda-19ef-4784-9a57-4535e46a523d\n                    cloud.scaleway.com/scw-poolname=default\n                    failure-domain.beta.kubernetes.io/region=par1\n                    failure-domain.beta.kubernetes.io/zone=14-2-101\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=scw-sono14-default-174540dd770e42e2af1af25266f\n                    kubernetes.io/os=linux\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ca:c0:01:2e:32:80\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.12.138.1\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 29 May 2019 16:02:29 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  KernelDeadlock   False   Wed, 29 May 2019 16:09:44 +0000   Wed, 29 May 2019 16:03:39 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  MemoryPressure   False   Wed, 29 May 2019 16:09:30 +0000   Wed, 29 May 2019 16:02:29 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 29 May 2019 16:09:30 +0000   Wed, 29 May 2019 16:02:29 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 29 May 2019 16:09:30 +0000   Wed, 29 May 2019 16:02:29 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 29 May 2019 16:09:30 +0000   Wed, 29 May 2019 16:02:59 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    scw-sono14-default-174540dd770e42e2af1af25266f\n  InternalIP:  10.12.138.1\n  ExternalIP:  163.172.189.130\nCapacity:\n cpu:                4\n ephemeral-storage:  143957176Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16421992Ki\n pods:               110\nAllocatable:\n cpu:                3800m\n ephemeral-storage:  133471416Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15373416Ki\n pods:               110\nSystem Info:\n Machine ID:                 3e383c39c8c14c89b5522a2d2fe3b6e2\n System UUID:                3e383c39c8c14c89b5522a2d2fe3b6e2\n Boot ID:                    e1edf71a-88f0-4624-a130-94e8aeedec2d\n Kernel Version:             4.15.0-50-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     100.64.1.0/24\nProviderID:                  scaleway://3e18d44e-ee97-4385-afd5-5796ca45f95c\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         2m59s\n  heptio-sonobuoy            sonobuoy-e2e-job-f013d2ad922949b9                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         2m49s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-6jrjh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         2m49s\n  kube-system                flannel-2crp5                                              100m (2%)     100m (2%)   50Mi (0%)        50Mi (0%)      7m26s\n  kube-system                kube-proxy-9zfn6                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m26s\n  kube-system                nginx-ingress-z47rs                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m56s\n  kube-system                node-problem-detector-2zzv5                                20m (0%)      200m (5%)   20Mi (0%)        100Mi (0%)     6m56s\n  kubectl-172                redis-master-fhkjv                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         21s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                120m (3%)  300m (7%)\n  memory             70Mi (0%)  150Mi (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type    Reason                   Age    From                                                        Message\n  ----    ------                   ----   ----                                                        -------\n  Normal  Starting                 7m26s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Starting kubelet.\n  Normal  NodeHasSufficientMemory  7m26s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Node scw-sono14-default-174540dd770e42e2af1af25266f status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    7m26s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Node scw-sono14-default-174540dd770e42e2af1af25266f status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     7m26s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Node scw-sono14-default-174540dd770e42e2af1af25266f status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  7m26s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Updated Node Allocatable limit across pods\n  Normal  Starting                 7m13s  kube-proxy, scw-sono14-default-174540dd770e42e2af1af25266f  Starting kube-proxy.\n  Normal  NodeReady                6m56s  kubelet, scw-sono14-default-174540dd770e42e2af1af25266f     Node scw-sono14-default-174540dd770e42e2af1af25266f status is now: NodeReady\n"
May 29 16:09:55.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 describe namespace kubectl-172'
May 29 16:09:55.288: INFO: stderr: ""
May 29 16:09:55.288: INFO: stdout: "Name:         kubectl-172\nLabels:       e2e-framework=kubectl\n              e2e-run=e6399d8d-822b-11e9-abea-da3eb1f4b18f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:09:55.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-172" for this suite.
May 29 16:10:17.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:10:17.604: INFO: namespace kubectl-172 deletion completed in 22.3072155s

• [SLOW TEST:44.152 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:10:17.604: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4935
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 29 16:10:17.786: INFO: Waiting up to 5m0s for pod "pod-402359e8-822c-11e9-abea-da3eb1f4b18f" in namespace "emptydir-4935" to be "success or failure"
May 29 16:10:17.793: INFO: Pod "pod-402359e8-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.653891ms
May 29 16:10:19.801: INFO: Pod "pod-402359e8-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015108308s
May 29 16:10:21.810: INFO: Pod "pod-402359e8-822c-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023575222s
STEP: Saw pod success
May 29 16:10:21.810: INFO: Pod "pod-402359e8-822c-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:10:21.816: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-402359e8-822c-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:10:21.846: INFO: Waiting for pod pod-402359e8-822c-11e9-abea-da3eb1f4b18f to disappear
May 29 16:10:21.852: INFO: Pod pod-402359e8-822c-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:10:21.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4935" for this suite.
May 29 16:10:27.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:10:28.120: INFO: namespace emptydir-4935 deletion completed in 6.260511075s

• [SLOW TEST:10.516 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:10:28.120: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3538
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:10:28.307: INFO: (0) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.39765ms)
May 29 16:10:28.316: INFO: (1) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.521673ms)
May 29 16:10:28.325: INFO: (2) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.521252ms)
May 29 16:10:28.334: INFO: (3) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.815565ms)
May 29 16:10:28.343: INFO: (4) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.30163ms)
May 29 16:10:28.353: INFO: (5) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.772245ms)
May 29 16:10:28.361: INFO: (6) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.826856ms)
May 29 16:10:28.369: INFO: (7) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.395946ms)
May 29 16:10:28.377: INFO: (8) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.212791ms)
May 29 16:10:28.385: INFO: (9) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.637901ms)
May 29 16:10:28.393: INFO: (10) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.744101ms)
May 29 16:10:28.402: INFO: (11) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.967631ms)
May 29 16:10:28.411: INFO: (12) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.409502ms)
May 29 16:10:28.430: INFO: (13) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.190512ms)
May 29 16:10:28.439: INFO: (14) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.08953ms)
May 29 16:10:28.454: INFO: (15) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.168671ms)
May 29 16:10:28.478: INFO: (16) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.405327ms)
May 29 16:10:28.488: INFO: (17) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.148883ms)
May 29 16:10:28.497: INFO: (18) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.536681ms)
May 29 16:10:28.506: INFO: (19) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.410934ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:10:28.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3538" for this suite.
May 29 16:10:34.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:10:34.757: INFO: namespace proxy-3538 deletion completed in 6.242759417s

• [SLOW TEST:6.637 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:10:34.757: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6943
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6943
STEP: Creating statefulset with conflicting port in namespace statefulset-6943
STEP: Waiting until pod test-pod will start running in namespace statefulset-6943
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6943
May 29 16:10:42.987: INFO: Observed stateful pod in namespace: statefulset-6943, name: ss-0, uid: 4f0b101d-822c-11e9-85f5-12d277f6ce64, status phase: Pending. Waiting for statefulset controller to delete.
May 29 16:10:43.367: INFO: Observed stateful pod in namespace: statefulset-6943, name: ss-0, uid: 4f0b101d-822c-11e9-85f5-12d277f6ce64, status phase: Failed. Waiting for statefulset controller to delete.
May 29 16:10:43.376: INFO: Observed stateful pod in namespace: statefulset-6943, name: ss-0, uid: 4f0b101d-822c-11e9-85f5-12d277f6ce64, status phase: Failed. Waiting for statefulset controller to delete.
May 29 16:10:43.381: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6943
STEP: Removing pod with conflicting port in namespace statefulset-6943
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6943 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 16:10:49.430: INFO: Deleting all statefulset in ns statefulset-6943
May 29 16:10:49.436: INFO: Scaling statefulset ss to 0
May 29 16:10:59.468: INFO: Waiting for statefulset status.replicas updated to 0
May 29 16:10:59.475: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:10:59.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6943" for this suite.
May 29 16:11:05.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:11:05.759: INFO: namespace statefulset-6943 deletion completed in 6.253534409s

• [SLOW TEST:31.002 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:11:05.761: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-mdfd
STEP: Creating a pod to test atomic-volume-subpath
May 29 16:11:05.950: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mdfd" in namespace "subpath-5600" to be "success or failure"
May 29 16:11:05.957: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.721507ms
May 29 16:11:07.966: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016371247s
May 29 16:11:09.976: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 4.026033572s
May 29 16:11:11.985: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 6.035504248s
May 29 16:11:13.993: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 8.042984484s
May 29 16:11:16.001: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 10.051673583s
May 29 16:11:18.010: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 12.060730335s
May 29 16:11:20.019: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 14.068919898s
May 29 16:11:22.026: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 16.076721863s
May 29 16:11:24.035: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 18.085546313s
May 29 16:11:26.046: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 20.09635239s
May 29 16:11:28.055: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Running", Reason="", readiness=true. Elapsed: 22.10521365s
May 29 16:11:30.063: INFO: Pod "pod-subpath-test-configmap-mdfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.112810735s
STEP: Saw pod success
May 29 16:11:30.063: INFO: Pod "pod-subpath-test-configmap-mdfd" satisfied condition "success or failure"
May 29 16:11:30.069: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-subpath-test-configmap-mdfd container test-container-subpath-configmap-mdfd: <nil>
STEP: delete the pod
May 29 16:11:30.106: INFO: Waiting for pod pod-subpath-test-configmap-mdfd to disappear
May 29 16:11:30.112: INFO: Pod pod-subpath-test-configmap-mdfd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mdfd
May 29 16:11:30.112: INFO: Deleting pod "pod-subpath-test-configmap-mdfd" in namespace "subpath-5600"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:11:30.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5600" for this suite.
May 29 16:11:36.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:11:36.383: INFO: namespace subpath-5600 deletion completed in 6.256690276s

• [SLOW TEST:30.621 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:11:36.384: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0529 16:11:46.681363      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 16:11:46.681: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:11:46.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6797" for this suite.
May 29 16:11:52.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:11:52.934: INFO: namespace gc-6797 deletion completed in 6.245849544s

• [SLOW TEST:16.550 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:11:52.938: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 29 16:12:07.170: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.170: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:07.338: INFO: Exec stderr: ""
May 29 16:12:07.338: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.338: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:07.506: INFO: Exec stderr: ""
May 29 16:12:07.506: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.506: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:07.669: INFO: Exec stderr: ""
May 29 16:12:07.669: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.669: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:07.824: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 29 16:12:07.824: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.824: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:07.982: INFO: Exec stderr: ""
May 29 16:12:07.982: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:07.982: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:08.138: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 29 16:12:08.138: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:08.138: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:08.342: INFO: Exec stderr: ""
May 29 16:12:08.343: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:08.343: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:08.502: INFO: Exec stderr: ""
May 29 16:12:08.502: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:08.502: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:08.656: INFO: Exec stderr: ""
May 29 16:12:08.657: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2197 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:12:08.657: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:12:08.791: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:12:08.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2197" for this suite.
May 29 16:12:52.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:12:53.052: INFO: namespace e2e-kubelet-etc-hosts-2197 deletion completed in 44.252863793s

• [SLOW TEST:60.115 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:12:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9546.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9546.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9546.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9546.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9546.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9546.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 16:13:15.826: INFO: DNS probes using dns-9546/dns-test-9cca4b70-822c-11e9-abea-da3eb1f4b18f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:13:15.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9546" for this suite.
May 29 16:13:21.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:13:22.101: INFO: namespace dns-9546 deletion completed in 6.249194874s

• [SLOW TEST:29.049 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:13:22.102: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 29 16:13:30.343: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:30.350: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:32.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:32.359: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:34.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:34.359: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:36.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:36.412: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:38.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:38.358: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:40.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:40.360: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:42.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:42.360: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:44.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:44.359: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:46.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:46.360: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:48.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:48.359: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 16:13:50.351: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 16:13:50.359: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:13:50.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9303" for this suite.
May 29 16:14:12.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:14:12.728: INFO: namespace container-lifecycle-hook-9303 deletion completed in 22.339510794s

• [SLOW TEST:50.626 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:14:12.728: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 29 16:14:18.985: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:18.991: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:20.991: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:20.999: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:22.991: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:22.999: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:24.992: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:25.000: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:26.991: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:27.000: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:28.991: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:28.999: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:30.992: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:31.001: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:32.992: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:33.000: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:34.994: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:35.002: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 16:14:36.993: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 16:14:37.001: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:14:37.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2042" for this suite.
May 29 16:14:59.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:14:59.277: INFO: namespace container-lifecycle-hook-2042 deletion completed in 22.267197866s

• [SLOW TEST:46.549 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:14:59.277: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6736/configmap-test-e8067040-822c-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:14:59.463: INFO: Waiting up to 5m0s for pod "pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f" in namespace "configmap-6736" to be "success or failure"
May 29 16:14:59.471: INFO: Pod "pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.2061ms
May 29 16:15:01.480: INFO: Pod "pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017068757s
May 29 16:15:03.489: INFO: Pod "pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025708486s
STEP: Saw pod success
May 29 16:15:03.489: INFO: Pod "pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:15:03.497: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f container env-test: <nil>
STEP: delete the pod
May 29 16:15:03.530: INFO: Waiting for pod pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f to disappear
May 29 16:15:03.536: INFO: Pod pod-configmaps-e80795ef-822c-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:15:03.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6736" for this suite.
May 29 16:15:09.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:15:09.803: INFO: namespace configmap-6736 deletion completed in 6.258234606s

• [SLOW TEST:10.526 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:15:09.809: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 29 16:15:09.985: INFO: Waiting up to 5m0s for pod "pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f" in namespace "emptydir-285" to be "success or failure"
May 29 16:15:09.992: INFO: Pod "pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.796269ms
May 29 16:15:12.001: INFO: Pod "pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016132878s
May 29 16:15:14.010: INFO: Pod "pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024977501s
STEP: Saw pod success
May 29 16:15:14.010: INFO: Pod "pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:15:14.019: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:15:14.052: INFO: Waiting for pod pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f to disappear
May 29 16:15:14.058: INFO: Pod pod-ee4d4652-822c-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:15:14.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-285" for this suite.
May 29 16:15:20.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:15:20.303: INFO: namespace emptydir-285 deletion completed in 6.237098586s

• [SLOW TEST:10.494 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:15:20.304: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 29 16:15:20.478: INFO: Waiting up to 5m0s for pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f" in namespace "emptydir-2348" to be "success or failure"
May 29 16:15:20.485: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.902899ms
May 29 16:15:22.494: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015455534s
May 29 16:15:24.502: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023389676s
May 29 16:15:26.511: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031969012s
May 29 16:15:28.519: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040478386s
May 29 16:15:30.529: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.050410474s
STEP: Saw pod success
May 29 16:15:30.529: INFO: Pod "pod-f48e536c-822c-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:15:30.537: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-f48e536c-822c-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:15:30.593: INFO: Waiting for pod pod-f48e536c-822c-11e9-abea-da3eb1f4b18f to disappear
May 29 16:15:30.600: INFO: Pod pod-f48e536c-822c-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:15:30.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2348" for this suite.
May 29 16:15:36.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:15:36.880: INFO: namespace emptydir-2348 deletion completed in 6.271945037s

• [SLOW TEST:16.576 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:15:36.880: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:16:37.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9037" for this suite.
May 29 16:17:01.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:17:01.345: INFO: namespace container-probe-9037 deletion completed in 24.270388624s

• [SLOW TEST:84.466 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:17:01.346: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 29 16:17:06.091: INFO: Successfully updated pod "annotationupdate30c871df-822d-11e9-abea-da3eb1f4b18f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:17:08.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-581" for this suite.
May 29 16:17:30.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:17:30.383: INFO: namespace downward-api-581 deletion completed in 22.252239556s

• [SLOW TEST:29.037 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:17:30.384: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9015
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-4217c3cb-822d-11e9-abea-da3eb1f4b18f
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:17:30.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9015" for this suite.
May 29 16:17:36.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:17:36.822: INFO: namespace configmap-9015 deletion completed in 6.260565081s

• [SLOW TEST:6.439 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:17:36.823: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2940
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
May 29 16:17:36.993: INFO: Waiting up to 5m0s for pod "pod-45ed5671-822d-11e9-abea-da3eb1f4b18f" in namespace "emptydir-2940" to be "success or failure"
May 29 16:17:37.000: INFO: Pod "pod-45ed5671-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.058923ms
May 29 16:17:39.009: INFO: Pod "pod-45ed5671-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015718941s
May 29 16:17:41.018: INFO: Pod "pod-45ed5671-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024707075s
STEP: Saw pod success
May 29 16:17:41.018: INFO: Pod "pod-45ed5671-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:17:41.025: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-45ed5671-822d-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:17:41.060: INFO: Waiting for pod pod-45ed5671-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:17:41.066: INFO: Pod pod-45ed5671-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:17:41.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2940" for this suite.
May 29 16:17:47.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:17:47.333: INFO: namespace emptydir-2940 deletion completed in 6.258392667s

• [SLOW TEST:10.510 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:17:47.334: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:17:47.512: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f" in namespace "downward-api-3695" to be "success or failure"
May 29 16:17:47.519: INFO: Pod "downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.566387ms
May 29 16:17:49.528: INFO: Pod "downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016078086s
May 29 16:17:51.537: INFO: Pod "downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024225861s
STEP: Saw pod success
May 29 16:17:51.537: INFO: Pod "downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:17:51.544: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:17:51.576: INFO: Waiting for pod downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:17:51.582: INFO: Pod downwardapi-volume-4c31ead0-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:17:51.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3695" for this suite.
May 29 16:17:57.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:17:57.848: INFO: namespace downward-api-3695 deletion completed in 6.258654399s

• [SLOW TEST:10.515 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:17:57.848: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6034
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6034
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6034
May 29 16:17:58.040: INFO: Found 0 stateful pods, waiting for 1
May 29 16:18:08.051: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 29 16:18:08.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:18:08.406: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:18:08.406: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:18:08.406: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 16:18:08.415: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 16:18:18.424: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 16:18:18.424: INFO: Waiting for statefulset status.replicas updated to 0
May 29 16:18:18.453: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:18.453: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:18.453: INFO: ss-1                                                  Pending         []
May 29 16:18:18.453: INFO: 
May 29 16:18:18.453: INFO: StatefulSet ss has not reached scale 3, at 2
May 29 16:18:19.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992098856s
May 29 16:18:20.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981931302s
May 29 16:18:21.482: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972438525s
May 29 16:18:22.491: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963176963s
May 29 16:18:23.500: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954479794s
May 29 16:18:24.510: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.94504485s
May 29 16:18:25.519: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.935633522s
May 29 16:18:26.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.926157534s
May 29 16:18:27.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 915.688841ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6034
May 29 16:18:28.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 16:18:28.826: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 16:18:28.826: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 16:18:28.826: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 16:18:28.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 16:18:29.158: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 16:18:29.158: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 16:18:29.158: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 16:18:29.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 16:18:29.448: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 16:18:29.448: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 16:18:29.448: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 16:18:29.457: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 16:18:29.457: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 16:18:29.457: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 29 16:18:29.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:18:29.782: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:18:29.782: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:18:29.782: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 16:18:29.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:18:30.082: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:18:30.082: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:18:30.082: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 16:18:30.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6034 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:18:30.766: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:18:30.766: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:18:30.766: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 16:18:30.766: INFO: Waiting for statefulset status.replicas updated to 0
May 29 16:18:30.774: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 29 16:18:40.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 16:18:40.791: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 16:18:40.791: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 16:18:40.813: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:40.813: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:40.813: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:40.813: INFO: ss-2  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:40.813: INFO: 
May 29 16:18:40.813: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 16:18:41.823: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:41.823: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:41.823: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:41.823: INFO: ss-2  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:41.823: INFO: 
May 29 16:18:41.823: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 16:18:42.832: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:42.832: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:42.832: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:42.832: INFO: ss-2  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:42.832: INFO: 
May 29 16:18:42.832: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 16:18:43.841: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:43.844: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:43.844: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:43.844: INFO: 
May 29 16:18:43.844: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:44.852: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:44.852: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:44.852: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:44.852: INFO: 
May 29 16:18:44.852: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:45.861: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:45.861: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:45.861: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:45.861: INFO: 
May 29 16:18:45.861: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:46.871: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:46.871: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:46.871: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:46.871: INFO: 
May 29 16:18:46.871: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:47.881: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:47.881: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:47.881: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:47.881: INFO: 
May 29 16:18:47.881: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:48.890: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:48.891: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:48.891: INFO: ss-1  scw-sono14-default-174540dd770e42e2af1af25266f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:18 +0000 UTC  }]
May 29 16:18:48.891: INFO: 
May 29 16:18:48.891: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 16:18:49.899: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 16:18:49.899: INFO: ss-0  scw-sono14-default-e0a3711c5d19438ba264d7868f9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:18:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:17:58 +0000 UTC  }]
May 29 16:18:49.899: INFO: 
May 29 16:18:49.899: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6034
May 29 16:18:50.908: INFO: Scaling statefulset ss to 0
May 29 16:18:50.931: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 16:18:50.938: INFO: Deleting all statefulset in ns statefulset-6034
May 29 16:18:50.945: INFO: Scaling statefulset ss to 0
May 29 16:18:50.964: INFO: Waiting for statefulset status.replicas updated to 0
May 29 16:18:50.970: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:18:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6034" for this suite.
May 29 16:18:57.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:18:57.277: INFO: namespace statefulset-6034 deletion completed in 6.27529183s

• [SLOW TEST:59.428 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:18:57.278: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-2373
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2373 to expose endpoints map[]
May 29 16:18:57.470: INFO: successfully validated that service multi-endpoint-test in namespace services-2373 exposes endpoints map[] (6.330297ms elapsed)
STEP: Creating pod pod1 in namespace services-2373
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2373 to expose endpoints map[pod1:[100]]
May 29 16:19:00.557: INFO: successfully validated that service multi-endpoint-test in namespace services-2373 exposes endpoints map[pod1:[100]] (3.075509836s elapsed)
STEP: Creating pod pod2 in namespace services-2373
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2373 to expose endpoints map[pod1:[100] pod2:[101]]
May 29 16:19:04.675: INFO: Unexpected endpoints: found map[75e73300-822d-11e9-85f5-12d277f6ce64:[100]], expected map[pod1:[100] pod2:[101]] (4.109928761s elapsed, will retry)
May 29 16:19:09.788: INFO: Unexpected endpoints: found map[75e73300-822d-11e9-85f5-12d277f6ce64:[100]], expected map[pod1:[100] pod2:[101]] (9.222896287s elapsed, will retry)
May 29 16:19:12.858: INFO: successfully validated that service multi-endpoint-test in namespace services-2373 exposes endpoints map[pod1:[100] pod2:[101]] (12.292586115s elapsed)
STEP: Deleting pod pod1 in namespace services-2373
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2373 to expose endpoints map[pod2:[101]]
May 29 16:19:12.885: INFO: successfully validated that service multi-endpoint-test in namespace services-2373 exposes endpoints map[pod2:[101]] (13.070302ms elapsed)
STEP: Deleting pod pod2 in namespace services-2373
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2373 to expose endpoints map[]
May 29 16:19:12.901: INFO: successfully validated that service multi-endpoint-test in namespace services-2373 exposes endpoints map[] (5.759399ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:19:12.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2373" for this suite.
May 29 16:19:34.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:19:35.187: INFO: namespace services-2373 deletion completed in 22.245363389s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:37.909 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:19:35.187: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0529 16:19:45.404798      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 16:19:45.404: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:19:45.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9541" for this suite.
May 29 16:19:51.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:19:51.679: INFO: namespace gc-9541 deletion completed in 6.267355572s

• [SLOW TEST:16.492 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:19:51.679: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
May 29 16:19:51.846: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 29 16:19:51.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:52.530: INFO: stderr: ""
May 29 16:19:52.530: INFO: stdout: "service/redis-slave created\n"
May 29 16:19:52.530: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 29 16:19:52.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:52.863: INFO: stderr: ""
May 29 16:19:52.863: INFO: stdout: "service/redis-master created\n"
May 29 16:19:52.863: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 29 16:19:52.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:53.181: INFO: stderr: ""
May 29 16:19:53.181: INFO: stdout: "service/frontend created\n"
May 29 16:19:53.181: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 29 16:19:53.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:53.453: INFO: stderr: ""
May 29 16:19:53.453: INFO: stdout: "deployment.apps/frontend created\n"
May 29 16:19:53.453: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 29 16:19:53.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:54.219: INFO: stderr: ""
May 29 16:19:54.219: INFO: stdout: "deployment.apps/redis-master created\n"
May 29 16:19:54.219: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 29 16:19:54.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7319'
May 29 16:19:54.628: INFO: stderr: ""
May 29 16:19:54.628: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May 29 16:19:54.628: INFO: Waiting for all frontend pods to be Running.
May 29 16:20:19.681: INFO: Waiting for frontend to serve content.
May 29 16:20:19.780: INFO: Trying to add a new entry to the guestbook.
May 29 16:20:19.911: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 29 16:20:20.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.216: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.216: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 29 16:20:20.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.388: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.388: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 29 16:20:20.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.564: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.564: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 29 16:20:20.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.689: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.689: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 29 16:20:20.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.821: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.821: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 29 16:20:20.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7319'
May 29 16:20:20.960: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:20:20.960: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:20:20.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7319" for this suite.
May 29 16:21:01.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:21:01.261: INFO: namespace kubectl-7319 deletion completed in 40.292675511s

• [SLOW TEST:69.582 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:21:01.262: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:21:01.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f" in namespace "downward-api-1781" to be "success or failure"
May 29 16:21:01.449: INFO: Pod "downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.222395ms
May 29 16:21:03.458: INFO: Pod "downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015706196s
May 29 16:21:05.467: INFO: Pod "downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024481502s
STEP: Saw pod success
May 29 16:21:05.468: INFO: Pod "downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:21:05.476: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:21:05.519: INFO: Waiting for pod downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:21:05.526: INFO: Pod downwardapi-volume-bfc963b6-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:21:05.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1781" for this suite.
May 29 16:21:11.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:21:11.789: INFO: namespace downward-api-1781 deletion completed in 6.253263368s

• [SLOW TEST:10.528 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:21:11.792: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 16:21:11.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9413'
May 29 16:21:12.103: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 29 16:21:12.103: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
May 29 16:21:12.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete jobs e2e-test-nginx-job --namespace=kubectl-9413'
May 29 16:21:12.264: INFO: stderr: ""
May 29 16:21:12.264: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:21:12.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9413" for this suite.
May 29 16:21:34.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:21:34.558: INFO: namespace kubectl-9413 deletion completed in 22.286514692s

• [SLOW TEST:22.769 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:21:34.562: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
May 29 16:21:34.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-6730'
May 29 16:21:35.123: INFO: stderr: ""
May 29 16:21:35.123: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
May 29 16:21:36.316: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:21:36.316: INFO: Found 0 / 1
May 29 16:21:37.131: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:21:37.131: INFO: Found 0 / 1
May 29 16:21:38.131: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:21:38.131: INFO: Found 1 / 1
May 29 16:21:38.131: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 16:21:38.138: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:21:38.138: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 29 16:21:38.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 logs redis-master-sx9qq redis-master --namespace=kubectl-6730'
May 29 16:21:38.284: INFO: stderr: ""
May 29 16:21:38.284: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 May 16:21:36.925 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 May 16:21:36.925 # Server started, Redis version 3.2.12\n1:M 29 May 16:21:36.925 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 May 16:21:36.925 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 29 16:21:38.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 log redis-master-sx9qq redis-master --namespace=kubectl-6730 --tail=1'
May 29 16:21:38.452: INFO: stderr: ""
May 29 16:21:38.452: INFO: stdout: "1:M 29 May 16:21:36.925 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 29 16:21:38.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 log redis-master-sx9qq redis-master --namespace=kubectl-6730 --limit-bytes=1'
May 29 16:21:38.611: INFO: stderr: ""
May 29 16:21:38.611: INFO: stdout: " "
STEP: exposing timestamps
May 29 16:21:38.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 log redis-master-sx9qq redis-master --namespace=kubectl-6730 --tail=1 --timestamps'
May 29 16:21:38.768: INFO: stderr: ""
May 29 16:21:38.768: INFO: stdout: "2019-05-29T16:21:36.926254448Z 1:M 29 May 16:21:36.925 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 29 16:21:41.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 log redis-master-sx9qq redis-master --namespace=kubectl-6730 --since=1s'
May 29 16:21:41.417: INFO: stderr: ""
May 29 16:21:41.417: INFO: stdout: ""
May 29 16:21:41.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 log redis-master-sx9qq redis-master --namespace=kubectl-6730 --since=24h'
May 29 16:21:41.617: INFO: stderr: ""
May 29 16:21:41.617: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 May 16:21:36.925 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 May 16:21:36.925 # Server started, Redis version 3.2.12\n1:M 29 May 16:21:36.925 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 May 16:21:36.925 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
May 29 16:21:41.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-6730'
May 29 16:21:41.742: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:21:41.742: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 29 16:21:41.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6730'
May 29 16:21:41.875: INFO: stderr: "No resources found.\n"
May 29 16:21:41.875: INFO: stdout: ""
May 29 16:21:41.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=nginx --namespace=kubectl-6730 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 16:21:41.979: INFO: stderr: ""
May 29 16:21:41.979: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:21:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6730" for this suite.
May 29 16:21:48.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:21:48.251: INFO: namespace kubectl-6730 deletion completed in 6.261932713s

• [SLOW TEST:13.689 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:21:48.252: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-dbcad419-822d-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:21:48.433: INFO: Waiting up to 5m0s for pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f" in namespace "secrets-1708" to be "success or failure"
May 29 16:21:48.440: INFO: Pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.271415ms
May 29 16:21:50.448: INFO: Pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014408371s
May 29 16:21:52.456: INFO: Pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022192074s
May 29 16:21:54.464: INFO: Pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030331693s
STEP: Saw pod success
May 29 16:21:54.464: INFO: Pod "pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:21:54.471: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f container secret-env-test: <nil>
STEP: delete the pod
May 29 16:21:54.506: INFO: Waiting for pod pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:21:54.512: INFO: Pod pod-secrets-dbcbeb8a-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:21:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1708" for this suite.
May 29 16:22:00.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:00.822: INFO: namespace secrets-1708 deletion completed in 6.30243098s

• [SLOW TEST:12.570 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:00.823: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e348dc22-822d-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:22:01.007: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f" in namespace "projected-5496" to be "success or failure"
May 29 16:22:01.013: INFO: Pod "pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.374087ms
May 29 16:22:03.023: INFO: Pod "pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015745888s
May 29 16:22:05.031: INFO: Pod "pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023871958s
STEP: Saw pod success
May 29 16:22:05.031: INFO: Pod "pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:22:05.038: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 16:22:05.069: INFO: Waiting for pod pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:22:05.075: INFO: Pod pod-projected-secrets-e34a11ae-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:05.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5496" for this suite.
May 29 16:22:11.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:11.332: INFO: namespace projected-5496 deletion completed in 6.248875579s

• [SLOW TEST:10.510 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:11.333: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 29 16:22:11.509: INFO: Waiting up to 5m0s for pod "pod-e98ce866-822d-11e9-abea-da3eb1f4b18f" in namespace "emptydir-4952" to be "success or failure"
May 29 16:22:11.515: INFO: Pod "pod-e98ce866-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.287752ms
May 29 16:22:13.522: INFO: Pod "pod-e98ce866-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012219543s
May 29 16:22:15.531: INFO: Pod "pod-e98ce866-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021288983s
STEP: Saw pod success
May 29 16:22:15.531: INFO: Pod "pod-e98ce866-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:22:15.539: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-e98ce866-822d-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:22:15.572: INFO: Waiting for pod pod-e98ce866-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:22:15.579: INFO: Pod pod-e98ce866-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:15.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4952" for this suite.
May 29 16:22:21.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:21.857: INFO: namespace emptydir-4952 deletion completed in 6.269964886s

• [SLOW TEST:10.524 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:21.858: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 29 16:22:22.023: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:25.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1292" for this suite.
May 29 16:22:31.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:31.597: INFO: namespace init-container-1292 deletion completed in 6.249098476s

• [SLOW TEST:9.739 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:31.605: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:22:31.767: INFO: Creating deployment "test-recreate-deployment"
May 29 16:22:31.775: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 29 16:22:31.791: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 29 16:22:33.807: INFO: Waiting deployment "test-recreate-deployment" to complete
May 29 16:22:33.813: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694743751, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694743751, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694743751, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694743751, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:22:35.822: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 29 16:22:35.839: INFO: Updating deployment test-recreate-deployment
May 29 16:22:35.839: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 29 16:22:35.925: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1728,SelfLink:/apis/apps/v1/namespaces/deployment-1728/deployments/test-recreate-deployment,UID:f5a1d366-822d-11e9-85f5-12d277f6ce64,ResourceVersion:948157661,Generation:2,CreationTimestamp:2019-05-29 16:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-29 16:22:35 +0000 UTC 2019-05-29 16:22:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-29 16:22:35 +0000 UTC 2019-05-29 16:22:31 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 29 16:22:35.933: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-1728,SelfLink:/apis/apps/v1/namespaces/deployment-1728/replicasets/test-recreate-deployment-c9cbd8684,UID:f812feae-822d-11e9-85f5-12d277f6ce64,ResourceVersion:948157656,Generation:1,CreationTimestamp:2019-05-29 16:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f5a1d366-822d-11e9-85f5-12d277f6ce64 0xc002287aa0 0xc002287aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 16:22:35.933: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 29 16:22:35.934: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-1728,SelfLink:/apis/apps/v1/namespaces/deployment-1728/replicasets/test-recreate-deployment-7d57d5ff7c,UID:f5a2944a-822d-11e9-85f5-12d277f6ce64,ResourceVersion:948157646,Generation:2,CreationTimestamp:2019-05-29 16:22:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f5a1d366-822d-11e9-85f5-12d277f6ce64 0xc002287897 0xc002287898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 16:22:35.943: INFO: Pod "test-recreate-deployment-c9cbd8684-v6vsn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-v6vsn,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-1728,SelfLink:/api/v1/namespaces/deployment-1728/pods/test-recreate-deployment-c9cbd8684-v6vsn,UID:f813a1c7-822d-11e9-85f5-12d277f6ce64,ResourceVersion:948157662,Generation:0,CreationTimestamp:2019-05-29 16:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 f812feae-822d-11e9-85f5-12d277f6ce64 0xc0024c2b40 0xc0024c2b41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vxfjr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vxfjr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vxfjr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024c2ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024c2bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:22:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:22:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:22:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:22:35 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 16:22:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:35.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1728" for this suite.
May 29 16:22:41.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:42.209: INFO: namespace deployment-1728 deletion completed in 6.25616259s

• [SLOW TEST:10.604 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:42.210: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:22:42.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f" in namespace "downward-api-4996" to be "success or failure"
May 29 16:22:42.398: INFO: Pod "downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.305969ms
May 29 16:22:44.406: INFO: Pod "downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014454383s
May 29 16:22:46.415: INFO: Pod "downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022913471s
STEP: Saw pod success
May 29 16:22:46.415: INFO: Pod "downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:22:46.423: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:22:46.452: INFO: Waiting for pod downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f to disappear
May 29 16:22:46.458: INFO: Pod downwardapi-volume-fbf52a15-822d-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:46.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4996" for this suite.
May 29 16:22:52.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:22:52.751: INFO: namespace downward-api-4996 deletion completed in 6.283686727s

• [SLOW TEST:10.541 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:22:52.752: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
May 29 16:22:52.931: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-937" to be "success or failure"
May 29 16:22:52.938: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.680676ms
May 29 16:22:54.947: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016139275s
May 29 16:22:56.955: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024723592s
STEP: Saw pod success
May 29 16:22:56.956: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 29 16:22:56.964: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 29 16:22:56.997: INFO: Waiting for pod pod-host-path-test to disappear
May 29 16:22:57.003: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:22:57.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-937" for this suite.
May 29 16:23:03.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:23:03.266: INFO: namespace hostpath-937 deletion completed in 6.253986161s

• [SLOW TEST:10.514 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:23:03.268: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 29 16:23:03.453: INFO: Waiting up to 5m0s for pod "pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f" in namespace "emptydir-1280" to be "success or failure"
May 29 16:23:03.460: INFO: Pod "pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.608086ms
May 29 16:23:05.468: INFO: Pod "pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01483208s
May 29 16:23:07.476: INFO: Pod "pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022372379s
STEP: Saw pod success
May 29 16:23:07.476: INFO: Pod "pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:23:07.481: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:23:07.510: INFO: Waiting for pod pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f to disappear
May 29 16:23:07.515: INFO: Pod pod-0882e6ae-822e-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:23:07.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1280" for this suite.
May 29 16:23:13.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:23:13.767: INFO: namespace emptydir-1280 deletion completed in 6.243645355s

• [SLOW TEST:10.499 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:23:13.769: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:23:13.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 version'
May 29 16:23:14.050: INFO: stderr: ""
May 29 16:23:14.050: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:23:14.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7836" for this suite.
May 29 16:23:20.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:23:20.316: INFO: namespace kubectl-7836 deletion completed in 6.257707978s

• [SLOW TEST:6.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:23:20.318: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 29 16:23:20.500: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948161267,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 16:23:20.501: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948161267,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 29 16:23:30.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948162102,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 29 16:23:30.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948162102,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 29 16:23:40.612: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948162941,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 16:23:40.612: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948162941,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 29 16:23:50.627: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948163792,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 16:23:50.627: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-a,UID:12acb66c-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948163792,Generation:0,CreationTimestamp:2019-05-29 16:23:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 29 16:24:00.641: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-b,UID:2a990710-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948164631,Generation:0,CreationTimestamp:2019-05-29 16:24:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 16:24:00.641: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-b,UID:2a990710-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948164631,Generation:0,CreationTimestamp:2019-05-29 16:24:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 29 16:24:10.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-b,UID:2a990710-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948165436,Generation:0,CreationTimestamp:2019-05-29 16:24:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 16:24:10.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4266,SelfLink:/api/v1/namespaces/watch-4266/configmaps/e2e-watch-test-configmap-b,UID:2a990710-822e-11e9-85f5-12d277f6ce64,ResourceVersion:948165436,Generation:0,CreationTimestamp:2019-05-29 16:24:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:24:20.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4266" for this suite.
May 29 16:24:26.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:24:26.924: INFO: namespace watch-4266 deletion completed in 6.259221974s

• [SLOW TEST:66.607 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:24:26.925: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:24:27.126: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3a61da64-822e-11e9-85f5-12d277f6ce64", Controller:(*bool)(0xc00278b75a), BlockOwnerDeletion:(*bool)(0xc00278b75b)}}
May 29 16:24:27.144: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3a5f71f4-822e-11e9-85f5-12d277f6ce64", Controller:(*bool)(0xc0023efbaa), BlockOwnerDeletion:(*bool)(0xc0023efbab)}}
May 29 16:24:27.153: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3a60c812-822e-11e9-85f5-12d277f6ce64", Controller:(*bool)(0xc0027587d2), BlockOwnerDeletion:(*bool)(0xc0027587d3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:24:32.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2365" for this suite.
May 29 16:24:38.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:24:38.440: INFO: namespace gc-2365 deletion completed in 6.259422762s

• [SLOW TEST:11.515 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:24:38.440: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5426
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 29 16:24:43.716: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:24:43.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5426" for this suite.
May 29 16:25:05.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:25:06.001: INFO: namespace replicaset-5426 deletion completed in 22.251294949s

• [SLOW TEST:27.561 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:25:06.002: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
May 29 16:25:06.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 api-versions'
May 29 16:25:06.308: INFO: stderr: ""
May 29 16:25:06.308: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:25:06.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7210" for this suite.
May 29 16:25:12.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:25:12.554: INFO: namespace kubectl-7210 deletion completed in 6.238608124s

• [SLOW TEST:6.553 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:25:12.557: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-5591c8c7-822e-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:25:12.743: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f" in namespace "projected-361" to be "success or failure"
May 29 16:25:12.749: INFO: Pod "pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.272953ms
May 29 16:25:14.757: INFO: Pod "pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013867571s
May 29 16:25:16.766: INFO: Pod "pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023173085s
STEP: Saw pod success
May 29 16:25:16.766: INFO: Pod "pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:25:16.774: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 16:25:16.803: INFO: Waiting for pod pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f to disappear
May 29 16:25:16.810: INFO: Pod pod-projected-secrets-5592edf9-822e-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:25:16.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-361" for this suite.
May 29 16:25:22.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:25:23.082: INFO: namespace projected-361 deletion completed in 6.264318247s

• [SLOW TEST:10.525 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:25:23.082: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4062
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 29 16:25:23.276: INFO: Found 0 stateful pods, waiting for 3
May 29 16:25:33.286: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 16:25:33.286: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 16:25:33.286: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 29 16:25:33.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-4062 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:25:33.612: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:25:33.612: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:25:33.612: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 29 16:25:43.668: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 29 16:25:53.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-4062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 16:25:54.043: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 16:25:54.043: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 16:25:54.043: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 16:26:04.090: INFO: Waiting for StatefulSet statefulset-4062/ss2 to complete update
May 29 16:26:04.090: INFO: Waiting for Pod statefulset-4062/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 29 16:26:04.090: INFO: Waiting for Pod statefulset-4062/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 29 16:26:14.107: INFO: Waiting for StatefulSet statefulset-4062/ss2 to complete update
May 29 16:26:14.107: INFO: Waiting for Pod statefulset-4062/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 29 16:26:24.106: INFO: Waiting for StatefulSet statefulset-4062/ss2 to complete update
May 29 16:26:24.106: INFO: Waiting for Pod statefulset-4062/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 29 16:26:34.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-4062 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 16:26:34.426: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 16:26:34.426: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 16:26:34.426: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 16:26:44.480: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 29 16:26:54.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-4062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 16:26:54.819: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 16:26:54.819: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 16:26:54.819: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 16:27:14.860: INFO: Waiting for StatefulSet statefulset-4062/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 16:27:24.877: INFO: Deleting all statefulset in ns statefulset-4062
May 29 16:27:24.883: INFO: Scaling statefulset ss2 to 0
May 29 16:27:44.914: INFO: Waiting for statefulset status.replicas updated to 0
May 29 16:27:44.921: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:27:44.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4062" for this suite.
May 29 16:27:50.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:27:51.196: INFO: namespace statefulset-4062 deletion completed in 6.244918035s

• [SLOW TEST:148.113 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:27:51.196: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 29 16:27:51.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-4848'
May 29 16:27:51.776: INFO: stderr: ""
May 29 16:27:51.776: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 16:27:51.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4848'
May 29 16:27:51.918: INFO: stderr: ""
May 29 16:27:51.918: INFO: stdout: "update-demo-nautilus-75xr9 update-demo-nautilus-hlh5x "
May 29 16:27:51.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-75xr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:27:52.024: INFO: stderr: ""
May 29 16:27:52.024: INFO: stdout: ""
May 29 16:27:52.024: INFO: update-demo-nautilus-75xr9 is created but not running
May 29 16:27:57.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4848'
May 29 16:27:57.183: INFO: stderr: ""
May 29 16:27:57.183: INFO: stdout: "update-demo-nautilus-75xr9 update-demo-nautilus-hlh5x "
May 29 16:27:57.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-75xr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:27:57.318: INFO: stderr: ""
May 29 16:27:57.319: INFO: stdout: ""
May 29 16:27:57.319: INFO: update-demo-nautilus-75xr9 is created but not running
May 29 16:28:02.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4848'
May 29 16:28:02.461: INFO: stderr: ""
May 29 16:28:02.461: INFO: stdout: "update-demo-nautilus-75xr9 update-demo-nautilus-hlh5x "
May 29 16:28:02.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-75xr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:28:02.577: INFO: stderr: ""
May 29 16:28:02.577: INFO: stdout: "true"
May 29 16:28:02.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-75xr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:28:02.722: INFO: stderr: ""
May 29 16:28:02.722: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 16:28:02.722: INFO: validating pod update-demo-nautilus-75xr9
May 29 16:28:02.816: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 16:28:02.816: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 16:28:02.816: INFO: update-demo-nautilus-75xr9 is verified up and running
May 29 16:28:02.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-hlh5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:28:02.973: INFO: stderr: ""
May 29 16:28:02.973: INFO: stdout: "true"
May 29 16:28:02.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-hlh5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4848'
May 29 16:28:03.088: INFO: stderr: ""
May 29 16:28:03.088: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 16:28:03.088: INFO: validating pod update-demo-nautilus-hlh5x
May 29 16:28:03.180: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 16:28:03.180: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 16:28:03.180: INFO: update-demo-nautilus-hlh5x is verified up and running
STEP: using delete to clean up resources
May 29 16:28:03.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-4848'
May 29 16:28:03.332: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:28:03.332: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 16:28:03.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4848'
May 29 16:28:03.469: INFO: stderr: "No resources found.\n"
May 29 16:28:03.469: INFO: stdout: ""
May 29 16:28:03.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=update-demo --namespace=kubectl-4848 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 16:28:03.590: INFO: stderr: ""
May 29 16:28:03.590: INFO: stdout: "update-demo-nautilus-75xr9\nupdate-demo-nautilus-hlh5x\n"
May 29 16:28:04.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4848'
May 29 16:28:04.202: INFO: stderr: "No resources found.\n"
May 29 16:28:04.202: INFO: stdout: ""
May 29 16:28:04.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=update-demo --namespace=kubectl-4848 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 16:28:04.320: INFO: stderr: ""
May 29 16:28:04.320: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:28:04.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4848" for this suite.
May 29 16:28:26.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:28:26.606: INFO: namespace kubectl-4848 deletion completed in 22.276660368s

• [SLOW TEST:35.410 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:28:26.608: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8073
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 16:28:26.848: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 29 16:28:46.981: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.45:8080/dial?request=hostName&protocol=http&host=100.64.1.41&port=8080&tries=1'] Namespace:pod-network-test-8073 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:28:46.981: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:28:47.175: INFO: Waiting for endpoints: map[]
May 29 16:28:47.185: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.45:8080/dial?request=hostName&protocol=http&host=100.64.0.44&port=8080&tries=1'] Namespace:pod-network-test-8073 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 16:28:47.185: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 16:28:47.372: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:28:47.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8073" for this suite.
May 29 16:29:09.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:29:10.028: INFO: namespace pod-network-test-8073 deletion completed in 22.647780625s

• [SLOW TEST:43.420 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:29:10.029: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-9599
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9599 to expose endpoints map[]
May 29 16:29:10.221: INFO: successfully validated that service endpoint-test2 in namespace services-9599 exposes endpoints map[] (6.871806ms elapsed)
STEP: Creating pod pod1 in namespace services-9599
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9599 to expose endpoints map[pod1:[80]]
May 29 16:29:13.418: INFO: successfully validated that service endpoint-test2 in namespace services-9599 exposes endpoints map[pod1:[80]] (3.181742935s elapsed)
STEP: Creating pod pod2 in namespace services-9599
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9599 to expose endpoints map[pod1:[80] pod2:[80]]
May 29 16:29:16.509: INFO: successfully validated that service endpoint-test2 in namespace services-9599 exposes endpoints map[pod1:[80] pod2:[80]] (3.083104596s elapsed)
STEP: Deleting pod pod1 in namespace services-9599
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9599 to expose endpoints map[pod2:[80]]
May 29 16:29:16.533: INFO: successfully validated that service endpoint-test2 in namespace services-9599 exposes endpoints map[pod2:[80]] (13.18423ms elapsed)
STEP: Deleting pod pod2 in namespace services-9599
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9599 to expose endpoints map[]
May 29 16:29:16.549: INFO: successfully validated that service endpoint-test2 in namespace services-9599 exposes endpoints map[] (5.836598ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:29:16.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9599" for this suite.
May 29 16:29:22.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:29:22.846: INFO: namespace services-9599 deletion completed in 6.257380501s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:12.817 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:29:22.846: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5028
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:29:23.023: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f" in namespace "downward-api-5028" to be "success or failure"
May 29 16:29:23.030: INFO: Pod "downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.377065ms
May 29 16:29:25.039: INFO: Pod "downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015455072s
May 29 16:29:27.048: INFO: Pod "downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024555506s
STEP: Saw pod success
May 29 16:29:27.048: INFO: Pod "downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:29:27.056: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:29:27.111: INFO: Waiting for pod downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f to disappear
May 29 16:29:27.118: INFO: Pod downwardapi-volume-eac08604-822e-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:29:27.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5028" for this suite.
May 29 16:29:33.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:29:33.377: INFO: namespace downward-api-5028 deletion completed in 6.249034831s

• [SLOW TEST:10.530 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:29:33.378: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-p6vd
STEP: Creating a pod to test atomic-volume-subpath
May 29 16:29:33.573: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p6vd" in namespace "subpath-9732" to be "success or failure"
May 29 16:29:33.579: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202888ms
May 29 16:29:35.588: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01478078s
May 29 16:29:37.597: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 4.023846346s
May 29 16:29:39.605: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 6.032332619s
May 29 16:29:41.615: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 8.041886265s
May 29 16:29:43.623: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 10.049771418s
May 29 16:29:45.633: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 12.059588862s
May 29 16:29:47.641: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 14.068009945s
May 29 16:29:49.649: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 16.076220788s
May 29 16:29:51.658: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 18.084852851s
May 29 16:29:53.674: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Running", Reason="", readiness=true. Elapsed: 20.100741258s
May 29 16:29:55.688: INFO: Pod "pod-subpath-test-downwardapi-p6vd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.115200914s
STEP: Saw pod success
May 29 16:29:55.688: INFO: Pod "pod-subpath-test-downwardapi-p6vd" satisfied condition "success or failure"
May 29 16:29:55.696: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-subpath-test-downwardapi-p6vd container test-container-subpath-downwardapi-p6vd: <nil>
STEP: delete the pod
May 29 16:29:55.734: INFO: Waiting for pod pod-subpath-test-downwardapi-p6vd to disappear
May 29 16:29:55.740: INFO: Pod pod-subpath-test-downwardapi-p6vd no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-p6vd
May 29 16:29:55.740: INFO: Deleting pod "pod-subpath-test-downwardapi-p6vd" in namespace "subpath-9732"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:29:55.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9732" for this suite.
May 29 16:30:01.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:30:02.050: INFO: namespace subpath-9732 deletion completed in 6.295545886s

• [SLOW TEST:28.672 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:30:02.052: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0529 16:30:02.851066      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 16:30:02.851: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:30:02.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-424" for this suite.
May 29 16:30:08.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:30:09.086: INFO: namespace gc-424 deletion completed in 6.226992679s

• [SLOW TEST:7.034 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:30:09.087: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-065017ca-822f-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:30:09.270: INFO: Waiting up to 5m0s for pod "pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f" in namespace "secrets-807" to be "success or failure"
May 29 16:30:09.277: INFO: Pod "pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689673ms
May 29 16:30:11.285: INFO: Pod "pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015100051s
May 29 16:30:13.294: INFO: Pod "pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023964599s
STEP: Saw pod success
May 29 16:30:13.294: INFO: Pod "pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:30:13.301: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 16:30:13.330: INFO: Waiting for pod pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:30:13.335: INFO: Pod pod-secrets-06512887-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:30:13.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-807" for this suite.
May 29 16:30:19.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:30:19.594: INFO: namespace secrets-807 deletion completed in 6.250593302s

• [SLOW TEST:10.507 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:30:19.595: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6191
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-0c955875-822f-11e9-abea-da3eb1f4b18f
STEP: Creating secret with name s-test-opt-upd-0c9558f1-822f-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0c955875-822f-11e9-abea-da3eb1f4b18f
STEP: Updating secret s-test-opt-upd-0c9558f1-822f-11e9-abea-da3eb1f4b18f
STEP: Creating secret with name s-test-opt-create-0c955912-822f-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:30:27.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6191" for this suite.
May 29 16:30:50.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:30:50.265: INFO: namespace secrets-6191 deletion completed in 22.269664734s

• [SLOW TEST:30.671 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:30:50.266: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-1535/secret-test-1edbdac1-822f-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:30:50.451: INFO: Waiting up to 5m0s for pod "pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f" in namespace "secrets-1535" to be "success or failure"
May 29 16:30:50.458: INFO: Pod "pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.030625ms
May 29 16:30:52.467: INFO: Pod "pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016330044s
May 29 16:30:54.476: INFO: Pod "pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025548509s
STEP: Saw pod success
May 29 16:30:54.477: INFO: Pod "pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:30:54.484: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f container env-test: <nil>
STEP: delete the pod
May 29 16:30:54.514: INFO: Waiting for pod pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:30:54.521: INFO: Pod pod-configmaps-1edd0d35-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:30:54.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1535" for this suite.
May 29 16:31:00.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:31:00.802: INFO: namespace secrets-1535 deletion completed in 6.271679s

• [SLOW TEST:10.536 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:31:00.804: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8855
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-892
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:31:07.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-642" for this suite.
May 29 16:31:13.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:31:13.638: INFO: namespace namespaces-642 deletion completed in 6.275009304s
STEP: Destroying namespace "nsdeletetest-8855" for this suite.
May 29 16:31:13.646: INFO: Namespace nsdeletetest-8855 was already deleted
STEP: Destroying namespace "nsdeletetest-892" for this suite.
May 29 16:31:19.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:31:19.925: INFO: namespace nsdeletetest-892 deletion completed in 6.279222802s

• [SLOW TEST:19.121 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:31:19.925: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1503
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-308bd934-822f-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-308bd934-822f-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:32:55.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1503" for this suite.
May 29 16:33:17.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:33:17.495: INFO: namespace projected-1503 deletion completed in 22.266112273s

• [SLOW TEST:117.570 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:33:17.496: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2784
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 29 16:33:17.680: INFO: Waiting up to 5m0s for pod "pod-769e26a0-822f-11e9-abea-da3eb1f4b18f" in namespace "emptydir-2784" to be "success or failure"
May 29 16:33:17.686: INFO: Pod "pod-769e26a0-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.715369ms
May 29 16:33:19.694: INFO: Pod "pod-769e26a0-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014287406s
May 29 16:33:21.702: INFO: Pod "pod-769e26a0-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022606117s
STEP: Saw pod success
May 29 16:33:21.703: INFO: Pod "pod-769e26a0-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:33:21.714: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-769e26a0-822f-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:33:21.743: INFO: Waiting for pod pod-769e26a0-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:33:21.749: INFO: Pod pod-769e26a0-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:33:21.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2784" for this suite.
May 29 16:33:27.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:33:28.031: INFO: namespace emptydir-2784 deletion completed in 6.27373728s

• [SLOW TEST:10.535 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:33:28.031: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 16:33:28.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5717'
May 29 16:33:28.790: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 29 16:33:28.790: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
May 29 16:33:30.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5717'
May 29 16:33:30.939: INFO: stderr: ""
May 29 16:33:30.939: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:33:30.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5717" for this suite.
May 29 16:34:46.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:34:47.194: INFO: namespace kubectl-5717 deletion completed in 1m16.243916293s

• [SLOW TEST:79.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:34:47.194: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6230
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:34:47.370: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f" in namespace "projected-6230" to be "success or failure"
May 29 16:34:47.377: INFO: Pod "downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.774171ms
May 29 16:34:49.387: INFO: Pod "downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016667808s
May 29 16:34:51.396: INFO: Pod "downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026197119s
STEP: Saw pod success
May 29 16:34:51.397: INFO: Pod "downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:34:51.404: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:34:51.436: INFO: Waiting for pod downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:34:51.443: INFO: Pod downwardapi-volume-ac13f290-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:34:51.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6230" for this suite.
May 29 16:34:57.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:34:57.742: INFO: namespace projected-6230 deletion completed in 6.28943433s

• [SLOW TEST:10.548 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:34:57.743: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
May 29 16:35:01.960: INFO: Pod pod-hostip-b25ea79a-822f-11e9-abea-da3eb1f4b18f has hostIP: 10.12.138.1
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:35:01.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1662" for this suite.
May 29 16:35:23.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:35:24.248: INFO: namespace pods-1662 deletion completed in 22.279112577s

• [SLOW TEST:26.506 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:35:24.252: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 29 16:35:24.429: INFO: Waiting up to 5m0s for pod "pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f" in namespace "emptydir-8753" to be "success or failure"
May 29 16:35:24.436: INFO: Pod "pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.599291ms
May 29 16:35:26.445: INFO: Pod "pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015823609s
May 29 16:35:28.453: INFO: Pod "pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024103258s
STEP: Saw pod success
May 29 16:35:28.453: INFO: Pod "pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:35:28.460: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:35:28.494: INFO: Waiting for pod pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:35:28.500: INFO: Pod pod-c22ae4aa-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:35:28.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8753" for this suite.
May 29 16:35:34.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:35:34.770: INFO: namespace emptydir-8753 deletion completed in 6.261874998s

• [SLOW TEST:10.518 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:35:34.770: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c86fcc45-822f-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:35:34.955: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f" in namespace "projected-3264" to be "success or failure"
May 29 16:35:34.961: INFO: Pod "pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253276ms
May 29 16:35:36.971: INFO: Pod "pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015331248s
May 29 16:35:38.978: INFO: Pod "pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023239288s
STEP: Saw pod success
May 29 16:35:38.979: INFO: Pod "pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:35:38.986: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:35:39.022: INFO: Waiting for pod pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f to disappear
May 29 16:35:39.029: INFO: Pod pod-projected-configmaps-c8710454-822f-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:35:39.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3264" for this suite.
May 29 16:35:45.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:35:45.337: INFO: namespace projected-3264 deletion completed in 6.29987748s

• [SLOW TEST:10.566 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:35:45.337: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1053
May 29 16:35:49.531: INFO: Started pod liveness-exec in namespace container-probe-1053
STEP: checking the pod's current state and verifying that restartCount is present
May 29 16:35:49.538: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:39:50.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1053" for this suite.
May 29 16:39:56.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:39:57.111: INFO: namespace container-probe-1053 deletion completed in 6.294569653s

• [SLOW TEST:251.774 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:39:57.111: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8666
May 29 16:40:01.382: INFO: Started pod liveness-http in namespace container-probe-8666
STEP: checking the pod's current state and verifying that restartCount is present
May 29 16:40:01.390: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:44:02.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8666" for this suite.
May 29 16:44:08.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:44:08.808: INFO: namespace container-probe-8666 deletion completed in 6.262555265s

• [SLOW TEST:251.696 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:44:08.808: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:44:09.013: INFO: Create a RollingUpdate DaemonSet
May 29 16:44:09.022: INFO: Check that daemon pods launch on every node of the cluster
May 29 16:44:09.035: INFO: Number of nodes with available pods: 0
May 29 16:44:09.035: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:44:10.054: INFO: Number of nodes with available pods: 0
May 29 16:44:10.054: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:44:11.053: INFO: Number of nodes with available pods: 0
May 29 16:44:11.053: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:44:12.052: INFO: Number of nodes with available pods: 2
May 29 16:44:12.052: INFO: Number of running nodes: 2, number of available pods: 2
May 29 16:44:12.052: INFO: Update the DaemonSet to trigger a rollout
May 29 16:44:12.069: INFO: Updating DaemonSet daemon-set
May 29 16:44:16.094: INFO: Roll back the DaemonSet before rollout is complete
May 29 16:44:16.111: INFO: Updating DaemonSet daemon-set
May 29 16:44:16.111: INFO: Make sure DaemonSet rollback is complete
May 29 16:44:16.118: INFO: Wrong image for pod: daemon-set-pvkzr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 29 16:44:16.118: INFO: Pod daemon-set-pvkzr is not available
May 29 16:44:17.136: INFO: Wrong image for pod: daemon-set-pvkzr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 29 16:44:17.136: INFO: Pod daemon-set-pvkzr is not available
May 29 16:44:18.140: INFO: Wrong image for pod: daemon-set-pvkzr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 29 16:44:18.140: INFO: Pod daemon-set-pvkzr is not available
May 29 16:44:19.136: INFO: Pod daemon-set-4tgq7 is not available
May 29 16:44:20.137: INFO: Pod daemon-set-4tgq7 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6510, will wait for the garbage collector to delete the pods
May 29 16:44:20.229: INFO: Deleting DaemonSet.extensions daemon-set took: 12.595763ms
May 29 16:44:20.530: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.368534ms
May 29 16:44:30.736: INFO: Number of nodes with available pods: 0
May 29 16:44:30.736: INFO: Number of running nodes: 0, number of available pods: 0
May 29 16:44:30.745: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6510/daemonsets","resourceVersion":"948261529"},"items":null}

May 29 16:44:30.753: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6510/pods","resourceVersion":"948261530"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:44:30.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6510" for this suite.
May 29 16:44:36.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:44:37.058: INFO: namespace daemonsets-6510 deletion completed in 6.276033847s

• [SLOW TEST:28.250 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:44:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 29 16:44:37.255: INFO: Waiting up to 5m0s for pod "pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f" in namespace "emptydir-7254" to be "success or failure"
May 29 16:44:37.261: INFO: Pod "pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092103ms
May 29 16:44:39.269: INFO: Pod "pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013870895s
May 29 16:44:41.277: INFO: Pod "pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022150283s
STEP: Saw pod success
May 29 16:44:41.277: INFO: Pod "pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:44:41.284: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 16:44:41.324: INFO: Waiting for pod pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:44:41.331: INFO: Pod pod-0bad5e35-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:44:41.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7254" for this suite.
May 29 16:44:47.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:44:47.652: INFO: namespace emptydir-7254 deletion completed in 6.313003445s

• [SLOW TEST:10.591 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:44:47.655: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1595
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 29 16:44:47.956: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1595,SelfLink:/api/v1/namespaces/watch-1595/configmaps/e2e-watch-test-resource-version,UID:11ff3ba4-8231-11e9-85f5-12d277f6ce64,ResourceVersion:948262893,Generation:0,CreationTimestamp:2019-05-29 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 16:44:47.956: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1595,SelfLink:/api/v1/namespaces/watch-1595/configmaps/e2e-watch-test-resource-version,UID:11ff3ba4-8231-11e9-85f5-12d277f6ce64,ResourceVersion:948262894,Generation:0,CreationTimestamp:2019-05-29 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:44:47.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1595" for this suite.
May 29 16:44:54.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:44:54.244: INFO: namespace watch-1595 deletion completed in 6.280295147s

• [SLOW TEST:6.589 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:44:54.247: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-15e884ea-8231-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:44:54.428: INFO: Waiting up to 5m0s for pod "pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f" in namespace "configmap-8973" to be "success or failure"
May 29 16:44:54.435: INFO: Pod "pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.581966ms
May 29 16:44:56.444: INFO: Pod "pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015884244s
May 29 16:44:58.453: INFO: Pod "pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024726561s
STEP: Saw pod success
May 29 16:44:58.453: INFO: Pod "pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:44:58.461: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:44:58.498: INFO: Waiting for pod pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:44:58.504: INFO: Pod pod-configmaps-15e9a96e-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:44:58.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8973" for this suite.
May 29 16:45:04.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:45:04.798: INFO: namespace configmap-8973 deletion completed in 6.284364028s

• [SLOW TEST:10.551 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:45:04.799: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-q4tv
STEP: Creating a pod to test atomic-volume-subpath
May 29 16:45:04.990: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-q4tv" in namespace "subpath-5593" to be "success or failure"
May 29 16:45:04.997: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Pending", Reason="", readiness=false. Elapsed: 7.073901ms
May 29 16:45:07.005: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015240833s
May 29 16:45:09.014: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 4.024037874s
May 29 16:45:11.023: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 6.032925761s
May 29 16:45:13.031: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 8.041378513s
May 29 16:45:15.039: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 10.049022188s
May 29 16:45:17.048: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 12.05823036s
May 29 16:45:19.056: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 14.065818669s
May 29 16:45:21.065: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 16.074747014s
May 29 16:45:23.073: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 18.083160505s
May 29 16:45:25.083: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 20.092612233s
May 29 16:45:27.092: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Running", Reason="", readiness=true. Elapsed: 22.101963088s
May 29 16:45:29.101: INFO: Pod "pod-subpath-test-secret-q4tv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.110708025s
STEP: Saw pod success
May 29 16:45:29.101: INFO: Pod "pod-subpath-test-secret-q4tv" satisfied condition "success or failure"
May 29 16:45:29.109: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-subpath-test-secret-q4tv container test-container-subpath-secret-q4tv: <nil>
STEP: delete the pod
May 29 16:45:29.141: INFO: Waiting for pod pod-subpath-test-secret-q4tv to disappear
May 29 16:45:29.147: INFO: Pod pod-subpath-test-secret-q4tv no longer exists
STEP: Deleting pod pod-subpath-test-secret-q4tv
May 29 16:45:29.147: INFO: Deleting pod "pod-subpath-test-secret-q4tv" in namespace "subpath-5593"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:45:29.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5593" for this suite.
May 29 16:45:35.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:45:35.417: INFO: namespace subpath-5593 deletion completed in 6.254724692s

• [SLOW TEST:30.618 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:45:35.417: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 29 16:45:35.581: INFO: namespace kubectl-9701
May 29 16:45:35.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-9701'
May 29 16:45:36.265: INFO: stderr: ""
May 29 16:45:36.265: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 29 16:45:37.274: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:45:37.274: INFO: Found 0 / 1
May 29 16:45:38.274: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:45:38.274: INFO: Found 0 / 1
May 29 16:45:39.274: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:45:39.274: INFO: Found 1 / 1
May 29 16:45:39.274: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 16:45:39.282: INFO: Selector matched 1 pods for map[app:redis]
May 29 16:45:39.282: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 16:45:39.283: INFO: wait on redis-master startup in kubectl-9701 
May 29 16:45:39.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 logs redis-master-t859q redis-master --namespace=kubectl-9701'
May 29 16:45:39.448: INFO: stderr: ""
May 29 16:45:39.448: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 May 16:45:37.703 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 May 16:45:37.703 # Server started, Redis version 3.2.12\n1:M 29 May 16:45:37.703 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 May 16:45:37.703 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 29 16:45:39.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9701'
May 29 16:45:39.623: INFO: stderr: ""
May 29 16:45:39.623: INFO: stdout: "service/rm2 exposed\n"
May 29 16:45:39.629: INFO: Service rm2 in namespace kubectl-9701 found.
STEP: exposing service
May 29 16:45:41.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9701'
May 29 16:45:41.839: INFO: stderr: ""
May 29 16:45:41.839: INFO: stdout: "service/rm3 exposed\n"
May 29 16:45:41.846: INFO: Service rm3 in namespace kubectl-9701 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:45:43.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9701" for this suite.
May 29 16:46:05.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:46:06.124: INFO: namespace kubectl-9701 deletion completed in 22.25515577s

• [SLOW TEST:30.707 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:46:06.125: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
May 29 16:46:06.291: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-762736658 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:46:06.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4430" for this suite.
May 29 16:46:12.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:46:12.660: INFO: namespace kubectl-4430 deletion completed in 6.252182178s

• [SLOW TEST:6.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:46:12.663: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-44a644f7-8231-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:46:12.847: INFO: Waiting up to 5m0s for pod "pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f" in namespace "configmap-3943" to be "success or failure"
May 29 16:46:12.854: INFO: Pod "pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.166785ms
May 29 16:46:14.863: INFO: Pod "pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015524687s
May 29 16:46:16.871: INFO: Pod "pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023871823s
STEP: Saw pod success
May 29 16:46:16.871: INFO: Pod "pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:46:16.879: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:46:16.909: INFO: Waiting for pod pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:46:16.916: INFO: Pod pod-configmaps-44a791e9-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:46:16.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3943" for this suite.
May 29 16:46:22.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:46:23.206: INFO: namespace configmap-3943 deletion completed in 6.281125848s

• [SLOW TEST:10.544 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:46:23.207: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 29 16:46:23.368: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:46:27.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8073" for this suite.
May 29 16:46:33.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:46:33.919: INFO: namespace init-container-8073 deletion completed in 6.31534779s

• [SLOW TEST:10.713 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:46:33.920: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 29 16:46:34.099: INFO: Waiting up to 5m0s for pod "downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f" in namespace "downward-api-2138" to be "success or failure"
May 29 16:46:34.105: INFO: Pod "downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.299003ms
May 29 16:46:36.115: INFO: Pod "downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016534907s
May 29 16:46:38.124: INFO: Pod "downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025742621s
STEP: Saw pod success
May 29 16:46:38.124: INFO: Pod "downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:46:38.133: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 16:46:38.168: INFO: Waiting for pod downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:46:38.174: INFO: Pod downward-api-51523f3d-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:46:38.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2138" for this suite.
May 29 16:46:44.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:46:44.450: INFO: namespace downward-api-2138 deletion completed in 6.264986832s

• [SLOW TEST:10.529 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:46:44.450: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:46:48.682: INFO: Waiting up to 5m0s for pod "client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f" in namespace "pods-4033" to be "success or failure"
May 29 16:46:48.690: INFO: Pod "client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.56288ms
May 29 16:46:50.698: INFO: Pod "client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016223315s
May 29 16:46:52.708: INFO: Pod "client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025723566s
STEP: Saw pod success
May 29 16:46:52.708: INFO: Pod "client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:46:52.716: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f container env3cont: <nil>
STEP: delete the pod
May 29 16:46:52.750: INFO: Waiting for pod client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:46:52.758: INFO: Pod client-envvars-5a03fe5e-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:46:52.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4033" for this suite.
May 29 16:47:44.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:47:45.083: INFO: namespace pods-4033 deletion completed in 52.31370514s

• [SLOW TEST:60.633 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:47:45.084: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7269
May 29 16:47:49.282: INFO: Started pod liveness-http in namespace container-probe-7269
STEP: checking the pod's current state and verifying that restartCount is present
May 29 16:47:49.290: INFO: Initial restart count of pod liveness-http is 0
May 29 16:48:09.397: INFO: Restart count of pod container-probe-7269/liveness-http is now 1 (20.1068039s elapsed)
May 29 16:48:27.486: INFO: Restart count of pod container-probe-7269/liveness-http is now 2 (38.196204155s elapsed)
May 29 16:48:47.575: INFO: Restart count of pod container-probe-7269/liveness-http is now 3 (58.285497268s elapsed)
May 29 16:49:07.668: INFO: Restart count of pod container-probe-7269/liveness-http is now 4 (1m18.377861683s elapsed)
May 29 16:50:18.058: INFO: Restart count of pod container-probe-7269/liveness-http is now 5 (2m28.767965783s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:50:18.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7269" for this suite.
May 29 16:50:24.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:50:24.328: INFO: namespace container-probe-7269 deletion completed in 6.245320608s

• [SLOW TEST:159.245 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:50:24.329: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:50:24.510: INFO: Waiting up to 5m0s for pod "downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f" in namespace "downward-api-9376" to be "success or failure"
May 29 16:50:24.518: INFO: Pod "downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.314962ms
May 29 16:50:26.529: INFO: Pod "downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018132681s
May 29 16:50:28.538: INFO: Pod "downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027519715s
STEP: Saw pod success
May 29 16:50:28.538: INFO: Pod "downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:50:28.545: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:50:28.584: INFO: Waiting for pod downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:50:28.591: INFO: Pod downwardapi-volume-daa7dad7-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:50:28.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9376" for this suite.
May 29 16:50:34.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:50:34.918: INFO: namespace downward-api-9376 deletion completed in 6.316807061s

• [SLOW TEST:10.590 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:50:34.919: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e0f9b732-8231-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:50:35.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f" in namespace "projected-1401" to be "success or failure"
May 29 16:50:35.136: INFO: Pod "pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.82752ms
May 29 16:50:37.144: INFO: Pod "pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017998192s
May 29 16:50:39.153: INFO: Pod "pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026393474s
STEP: Saw pod success
May 29 16:50:39.153: INFO: Pod "pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:50:39.160: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:50:39.196: INFO: Waiting for pod pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:50:39.204: INFO: Pod pod-projected-configmaps-e0fae35e-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:50:39.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1401" for this suite.
May 29 16:50:45.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:50:45.467: INFO: namespace projected-1401 deletion completed in 6.25346964s

• [SLOW TEST:10.548 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:50:45.468: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e7414cac-8231-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:50:45.653: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f" in namespace "projected-8033" to be "success or failure"
May 29 16:50:45.660: INFO: Pod "pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.610307ms
May 29 16:50:47.670: INFO: Pod "pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017420409s
May 29 16:50:49.679: INFO: Pod "pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026097626s
STEP: Saw pod success
May 29 16:50:49.679: INFO: Pod "pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:50:49.685: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 16:50:49.716: INFO: Waiting for pod pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f to disappear
May 29 16:50:49.723: INFO: Pod pod-projected-secrets-e7426f55-8231-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:50:49.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8033" for this suite.
May 29 16:50:55.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:50:56.003: INFO: namespace projected-8033 deletion completed in 6.271990518s

• [SLOW TEST:10.536 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:50:56.006: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5573
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-ed8a1784-8231-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ed8a1784-8231-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:52:27.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5573" for this suite.
May 29 16:52:49.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:52:49.522: INFO: namespace configmap-5573 deletion completed in 22.274794641s

• [SLOW TEST:113.516 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:52:49.522: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 29 16:52:49.760: INFO: Waiting up to 5m0s for pod "downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f" in namespace "downward-api-3742" to be "success or failure"
May 29 16:52:49.767: INFO: Pod "downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.657485ms
May 29 16:52:51.783: INFO: Pod "downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022490798s
May 29 16:52:53.793: INFO: Pod "downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032777094s
STEP: Saw pod success
May 29 16:52:53.793: INFO: Pod "downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:52:53.801: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 16:52:53.836: INFO: Waiting for pod downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:52:53.843: INFO: Pod downward-api-313b320d-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:52:53.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3742" for this suite.
May 29 16:52:59.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:53:00.102: INFO: namespace downward-api-3742 deletion completed in 6.247800227s

• [SLOW TEST:10.580 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:53:00.103: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2396
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 29 16:53:00.325: INFO: Number of nodes with available pods: 0
May 29 16:53:00.325: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:01.342: INFO: Number of nodes with available pods: 0
May 29 16:53:01.342: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:02.342: INFO: Number of nodes with available pods: 0
May 29 16:53:02.342: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:03.344: INFO: Number of nodes with available pods: 2
May 29 16:53:03.344: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 29 16:53:03.384: INFO: Number of nodes with available pods: 1
May 29 16:53:03.384: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:04.399: INFO: Number of nodes with available pods: 1
May 29 16:53:04.399: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:05.401: INFO: Number of nodes with available pods: 1
May 29 16:53:05.401: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:53:06.403: INFO: Number of nodes with available pods: 2
May 29 16:53:06.403: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2396, will wait for the garbage collector to delete the pods
May 29 16:53:06.490: INFO: Deleting DaemonSet.extensions daemon-set took: 14.789643ms
May 29 16:53:06.891: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.673133ms
May 29 16:53:10.797: INFO: Number of nodes with available pods: 0
May 29 16:53:10.797: INFO: Number of running nodes: 0, number of available pods: 0
May 29 16:53:10.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2396/daemonsets","resourceVersion":"948301520"},"items":null}

May 29 16:53:10.811: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2396/pods","resourceVersion":"948301521"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:53:10.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2396" for this suite.
May 29 16:53:16.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:53:17.093: INFO: namespace daemonsets-2396 deletion completed in 6.248503552s

• [SLOW TEST:16.990 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:53:17.094: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-41a11961-8232-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 16:53:17.276: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f" in namespace "projected-8963" to be "success or failure"
May 29 16:53:17.282: INFO: Pod "pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.902896ms
May 29 16:53:19.290: INFO: Pod "pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01432202s
May 29 16:53:21.298: INFO: Pod "pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022358231s
STEP: Saw pod success
May 29 16:53:21.298: INFO: Pod "pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:53:21.306: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:53:21.338: INFO: Waiting for pod pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:53:21.343: INFO: Pod pod-projected-configmaps-41a25673-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:53:21.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8963" for this suite.
May 29 16:53:27.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:53:27.599: INFO: namespace projected-8963 deletion completed in 6.24791577s

• [SLOW TEST:10.505 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:53:27.599: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 29 16:53:35.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 16:53:35.953: INFO: Pod pod-with-poststart-http-hook still exists
May 29 16:53:37.953: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 16:53:37.961: INFO: Pod pod-with-poststart-http-hook still exists
May 29 16:53:39.953: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 16:53:39.961: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:53:39.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4392" for this suite.
May 29 16:54:01.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:54:02.254: INFO: namespace container-lifecycle-hook-4392 deletion completed in 22.282868162s

• [SLOW TEST:34.655 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:54:02.256: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 29 16:54:06.988: INFO: Successfully updated pod "labelsupdate5c8ca013-8232-11e9-abea-da3eb1f4b18f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:54:09.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8660" for this suite.
May 29 16:54:31.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:54:31.269: INFO: namespace downward-api-8660 deletion completed in 22.243468848s

• [SLOW TEST:29.013 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:54:31.269: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 29 16:54:31.448: INFO: Waiting up to 5m0s for pod "downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f" in namespace "downward-api-462" to be "success or failure"
May 29 16:54:31.455: INFO: Pod "downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.302727ms
May 29 16:54:33.464: INFO: Pod "downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015618263s
May 29 16:54:35.476: INFO: Pod "downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027929122s
STEP: Saw pod success
May 29 16:54:35.476: INFO: Pod "downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:54:35.484: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 16:54:35.515: INFO: Waiting for pod downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:54:35.521: INFO: Pod downward-api-6dd804ff-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:54:35.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-462" for this suite.
May 29 16:54:41.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:54:41.785: INFO: namespace downward-api-462 deletion completed in 6.254684445s

• [SLOW TEST:10.516 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:54:41.786: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4313
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 29 16:54:42.009: INFO: Number of nodes with available pods: 0
May 29 16:54:42.009: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:43.029: INFO: Number of nodes with available pods: 0
May 29 16:54:43.029: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:44.028: INFO: Number of nodes with available pods: 0
May 29 16:54:44.029: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:45.025: INFO: Number of nodes with available pods: 2
May 29 16:54:45.025: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 29 16:54:45.063: INFO: Number of nodes with available pods: 1
May 29 16:54:45.063: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:46.082: INFO: Number of nodes with available pods: 1
May 29 16:54:46.082: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:47.082: INFO: Number of nodes with available pods: 1
May 29 16:54:47.082: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:48.084: INFO: Number of nodes with available pods: 1
May 29 16:54:48.084: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:49.080: INFO: Number of nodes with available pods: 1
May 29 16:54:49.080: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:50.079: INFO: Number of nodes with available pods: 1
May 29 16:54:50.079: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:51.079: INFO: Number of nodes with available pods: 1
May 29 16:54:51.079: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:52.081: INFO: Number of nodes with available pods: 1
May 29 16:54:52.081: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:53.080: INFO: Number of nodes with available pods: 1
May 29 16:54:53.080: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:54.080: INFO: Number of nodes with available pods: 1
May 29 16:54:54.080: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:55.080: INFO: Number of nodes with available pods: 1
May 29 16:54:55.080: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:56.083: INFO: Number of nodes with available pods: 1
May 29 16:54:56.083: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:57.081: INFO: Number of nodes with available pods: 1
May 29 16:54:57.081: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:58.082: INFO: Number of nodes with available pods: 1
May 29 16:54:58.082: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:54:59.082: INFO: Number of nodes with available pods: 1
May 29 16:54:59.082: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:55:00.082: INFO: Number of nodes with available pods: 1
May 29 16:55:00.082: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:55:01.085: INFO: Number of nodes with available pods: 1
May 29 16:55:01.085: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 16:55:02.083: INFO: Number of nodes with available pods: 2
May 29 16:55:02.084: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4313, will wait for the garbage collector to delete the pods
May 29 16:55:02.164: INFO: Deleting DaemonSet.extensions daemon-set took: 12.378928ms
May 29 16:55:02.465: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.467412ms
May 29 16:55:10.772: INFO: Number of nodes with available pods: 0
May 29 16:55:10.772: INFO: Number of running nodes: 0, number of available pods: 0
May 29 16:55:10.779: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4313/daemonsets","resourceVersion":"948310925"},"items":null}

May 29 16:55:10.786: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4313/pods","resourceVersion":"948310927"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:10.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4313" for this suite.
May 29 16:55:16.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:55:17.053: INFO: namespace daemonsets-4313 deletion completed in 6.235040072s

• [SLOW TEST:35.267 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:55:17.053: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 29 16:55:17.226: INFO: Waiting up to 5m0s for pod "downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f" in namespace "downward-api-4284" to be "success or failure"
May 29 16:55:17.232: INFO: Pod "downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113942ms
May 29 16:55:19.240: INFO: Pod "downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014096279s
May 29 16:55:21.249: INFO: Pod "downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023764066s
STEP: Saw pod success
May 29 16:55:21.249: INFO: Pod "downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:55:21.257: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 16:55:21.290: INFO: Waiting for pod downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:55:21.296: INFO: Pod downward-api-892119a4-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:21.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4284" for this suite.
May 29 16:55:29.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:55:29.553: INFO: namespace downward-api-4284 deletion completed in 8.246556472s

• [SLOW TEST:12.500 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:55:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:55:29.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f" in namespace "projected-9829" to be "success or failure"
May 29 16:55:29.765: INFO: Pod "downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.364502ms
May 29 16:55:31.774: INFO: Pod "downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01575594s
May 29 16:55:33.783: INFO: Pod "downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024381585s
STEP: Saw pod success
May 29 16:55:33.783: INFO: Pod "downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:55:33.791: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:55:33.826: INFO: Waiting for pod downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:55:33.832: INFO: Pod downwardapi-volume-90990c82-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9829" for this suite.
May 29 16:55:39.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:55:40.137: INFO: namespace projected-9829 deletion completed in 6.295998557s

• [SLOW TEST:10.583 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:55:40.137: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:44.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8444" for this suite.
May 29 16:55:50.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:55:50.601: INFO: namespace kubelet-test-8444 deletion completed in 6.263050499s

• [SLOW TEST:10.464 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:55:50.602: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 16:55:50.778: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 29 16:55:55.786: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 16:55:55.786: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 29 16:55:59.844: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4017,SelfLink:/apis/apps/v1/namespaces/deployment-4017/deployments/test-cleanup-deployment,UID:a0204b15-8232-11e9-85f5-12d277f6ce64,ResourceVersion:948314681,Generation:1,CreationTimestamp:2019-05-29 16:55:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-29 16:55:55 +0000 UTC 2019-05-29 16:55:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-29 16:55:57 +0000 UTC 2019-05-29 16:55:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 29 16:55:59.851: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-4017,SelfLink:/apis/apps/v1/namespaces/deployment-4017/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:a0234d0a-8232-11e9-85f5-12d277f6ce64,ResourceVersion:948314668,Generation:1,CreationTimestamp:2019-05-29 16:55:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment a0204b15-8232-11e9-85f5-12d277f6ce64 0xc00287c2b7 0xc00287c2b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 29 16:55:59.859: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-qcw9w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-qcw9w,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-4017,SelfLink:/api/v1/namespaces/deployment-4017/pods/test-cleanup-deployment-55cbfbc8f5-qcw9w,UID:a02404d4-8232-11e9-85f5-12d277f6ce64,ResourceVersion:948314667,Generation:0,CreationTimestamp:2019-05-29 16:55:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 a0234d0a-8232-11e9-85f5-12d277f6ce64 0xc00287c867 0xc00287c868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9b5jv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9b5jv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9b5jv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00287c8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00287c8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:55:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:55:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:55:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:55:55 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.65,StartTime:2019-05-29 16:55:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-29 16:55:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e85640c7429268c3595473d6923a8b873a4483f72d0be5b3f80a6b36af9ba7e8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:59.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4017" for this suite.
May 29 16:56:05.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:56:06.129: INFO: namespace deployment-4017 deletion completed in 6.260276352s

• [SLOW TEST:15.527 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:56:06.129: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8767
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 29 16:56:06.308: INFO: Pod name pod-release: Found 0 pods out of 1
May 29 16:56:11.318: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:12.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8767" for this suite.
May 29 16:56:18.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:56:18.603: INFO: namespace replication-controller-8767 deletion completed in 6.242306939s

• [SLOW TEST:12.473 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:56:18.604: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-476
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:22.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-476" for this suite.
May 29 16:57:14.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:57:15.099: INFO: namespace kubelet-test-476 deletion completed in 52.261376784s

• [SLOW TEST:56.495 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:57:15.100: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-3472
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3472
STEP: Deleting pre-stop pod
May 29 16:57:28.430: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:57:28.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3472" for this suite.
May 29 16:58:06.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:58:06.683: INFO: namespace prestop-3472 deletion completed in 38.234400067s

• [SLOW TEST:51.582 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:58:06.683: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:58:06.869: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f" in namespace "downward-api-830" to be "success or failure"
May 29 16:58:06.876: INFO: Pod "downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.102893ms
May 29 16:58:08.888: INFO: Pod "downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019068059s
May 29 16:58:10.896: INFO: Pod "downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027218017s
STEP: Saw pod success
May 29 16:58:10.896: INFO: Pod "downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:58:10.904: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:58:10.938: INFO: Waiting for pod downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:58:10.947: INFO: Pod downwardapi-volume-ee3e6287-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:58:10.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-830" for this suite.
May 29 16:58:16.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:58:17.196: INFO: namespace downward-api-830 deletion completed in 6.240548199s

• [SLOW TEST:10.513 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:58:17.196: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 16:58:17.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f" in namespace "downward-api-8305" to be "success or failure"
May 29 16:58:17.374: INFO: Pod "downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983797ms
May 29 16:58:19.383: INFO: Pod "downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014181089s
May 29 16:58:21.391: INFO: Pod "downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022519727s
STEP: Saw pod success
May 29 16:58:21.391: INFO: Pod "downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:58:21.398: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 16:58:21.428: INFO: Waiting for pod downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f to disappear
May 29 16:58:21.434: INFO: Pod downwardapi-volume-f480e6a7-8232-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:58:21.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8305" for this suite.
May 29 16:58:27.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:58:27.679: INFO: namespace downward-api-8305 deletion completed in 6.237130059s

• [SLOW TEST:10.483 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:58:27.680: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-167
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-fac2252b-8232-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:58:31.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-167" for this suite.
May 29 16:58:53.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:58:54.175: INFO: namespace configmap-167 deletion completed in 22.247124731s

• [SLOW TEST:26.495 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:58:54.176: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0a8c5191-8233-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 16:58:54.362: INFO: Waiting up to 5m0s for pod "pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f" in namespace "secrets-2421" to be "success or failure"
May 29 16:58:54.368: INFO: Pod "pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.078424ms
May 29 16:58:56.376: INFO: Pod "pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014454081s
May 29 16:58:58.385: INFO: Pod "pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023012089s
STEP: Saw pod success
May 29 16:58:58.385: INFO: Pod "pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 16:58:58.392: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 16:58:58.422: INFO: Waiting for pod pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 16:58:58.428: INFO: Pod pod-secrets-0a8d81c4-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:58:58.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2421" for this suite.
May 29 16:59:04.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:59:04.676: INFO: namespace secrets-2421 deletion completed in 6.238776972s

• [SLOW TEST:10.500 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:59:04.677: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-9951
May 29 16:59:08.872: INFO: Started pod liveness-exec in namespace container-probe-9951
STEP: checking the pod's current state and verifying that restartCount is present
May 29 16:59:08.880: INFO: Initial restart count of pod liveness-exec is 0
May 29 16:59:53.080: INFO: Restart count of pod container-probe-9951/liveness-exec is now 1 (44.200121917s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:59:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9951" for this suite.
May 29 16:59:59.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:59:59.351: INFO: namespace container-probe-9951 deletion completed in 6.245182864s

• [SLOW TEST:54.674 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 16:59:59.352: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:59:59.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1445" for this suite.
May 29 17:00:05.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:00:05.788: INFO: namespace services-1445 deletion completed in 6.248415634s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.436 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:00:05.790: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:00:05.962: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:00:10.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3824" for this suite.
May 29 17:00:48.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:00:48.401: INFO: namespace pods-3824 deletion completed in 38.356643079s

• [SLOW TEST:42.611 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:00:48.401: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4ea23da1-8233-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:00:48.593: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f" in namespace "projected-956" to be "success or failure"
May 29 17:00:48.600: INFO: Pod "pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883859ms
May 29 17:00:50.610: INFO: Pod "pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016306879s
May 29 17:00:52.620: INFO: Pod "pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026742993s
STEP: Saw pod success
May 29 17:00:52.620: INFO: Pod "pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:00:52.628: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:00:52.658: INFO: Waiting for pod pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 17:00:52.667: INFO: Pod pod-projected-configmaps-4ea37be9-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:00:52.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-956" for this suite.
May 29 17:00:58.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:00:58.923: INFO: namespace projected-956 deletion completed in 6.24597631s

• [SLOW TEST:10.522 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:00:58.925: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2988
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 29 17:00:59.108: INFO: Found 0 stateful pods, waiting for 3
May 29 17:01:09.119: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:09.119: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:09.119: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 29 17:01:09.166: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 29 17:01:19.227: INFO: Updating stateful set ss2
May 29 17:01:19.244: INFO: Waiting for Pod statefulset-2988/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 29 17:01:29.309: INFO: Found 2 stateful pods, waiting for 3
May 29 17:01:39.318: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:39.318: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:39.318: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 29 17:01:39.361: INFO: Updating stateful set ss2
May 29 17:01:39.375: INFO: Waiting for Pod statefulset-2988/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 29 17:01:49.390: INFO: Waiting for Pod statefulset-2988/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 29 17:01:59.420: INFO: Updating stateful set ss2
May 29 17:01:59.439: INFO: Waiting for StatefulSet statefulset-2988/ss2 to complete update
May 29 17:01:59.439: INFO: Waiting for Pod statefulset-2988/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 17:02:09.456: INFO: Deleting all statefulset in ns statefulset-2988
May 29 17:02:09.463: INFO: Scaling statefulset ss2 to 0
May 29 17:02:39.493: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:02:39.499: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:02:39.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2988" for this suite.
May 29 17:02:45.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:02:45.807: INFO: namespace statefulset-2988 deletion completed in 6.272455457s

• [SLOW TEST:106.882 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:02:45.808: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7589.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7589.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:03:00.602: INFO: DNS probes using dns-7589/dns-test-949c4705-8233-11e9-abea-da3eb1f4b18f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:00.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7589" for this suite.
May 29 17:03:06.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:03:06.879: INFO: namespace dns-7589 deletion completed in 6.247197401s

• [SLOW TEST:21.071 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:03:06.879: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6620
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9495
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:33.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2712" for this suite.
May 29 17:03:39.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:03:39.674: INFO: namespace namespaces-2712 deletion completed in 6.253814595s
STEP: Destroying namespace "nsdeletetest-6620" for this suite.
May 29 17:03:39.680: INFO: Namespace nsdeletetest-6620 was already deleted
STEP: Destroying namespace "nsdeletetest-9495" for this suite.
May 29 17:03:45.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:03:45.924: INFO: namespace nsdeletetest-9495 deletion completed in 6.243596879s

• [SLOW TEST:39.045 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:03:45.925: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:03:46.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f" in namespace "projected-3836" to be "success or failure"
May 29 17:03:46.105: INFO: Pod "downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.374101ms
May 29 17:03:48.113: INFO: Pod "downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014918891s
May 29 17:03:50.122: INFO: Pod "downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023447972s
STEP: Saw pod success
May 29 17:03:50.122: INFO: Pod "downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:03:50.129: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:03:50.168: INFO: Waiting for pod downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 17:03:50.175: INFO: Pod downwardapi-volume-b8710df4-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:50.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3836" for this suite.
May 29 17:03:56.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:03:56.427: INFO: namespace projected-3836 deletion completed in 6.241410906s

• [SLOW TEST:10.502 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:03:56.427: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6468
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-bebbc63e-8233-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:03:56.664: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f" in namespace "projected-6468" to be "success or failure"
May 29 17:03:56.684: INFO: Pod "pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.952702ms
May 29 17:03:58.692: INFO: Pod "pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028413361s
May 29 17:04:00.702: INFO: Pod "pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037981703s
STEP: Saw pod success
May 29 17:04:00.702: INFO: Pod "pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:04:00.710: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:04:00.745: INFO: Waiting for pod pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 17:04:00.752: INFO: Pod pod-projected-configmaps-bebd0161-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:00.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6468" for this suite.
May 29 17:04:06.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:07.006: INFO: namespace projected-6468 deletion completed in 6.245873661s

• [SLOW TEST:10.579 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:04:07.006: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-c502183a-8233-11e9-abea-da3eb1f4b18f
STEP: Creating secret with name secret-projected-all-test-volume-c5021807-8233-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test Check all projections for projected volume plugin
May 29 17:04:07.198: INFO: Waiting up to 5m0s for pod "projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f" in namespace "projected-4730" to be "success or failure"
May 29 17:04:07.205: INFO: Pod "projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.772329ms
May 29 17:04:09.215: INFO: Pod "projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016234399s
May 29 17:04:11.223: INFO: Pod "projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02510188s
STEP: Saw pod success
May 29 17:04:11.224: INFO: Pod "projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:04:11.231: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f container projected-all-volume-test: <nil>
STEP: delete the pod
May 29 17:04:11.261: INFO: Waiting for pod projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 17:04:11.267: INFO: Pod projected-volume-c502179e-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:11.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4730" for this suite.
May 29 17:04:17.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:17.537: INFO: namespace projected-4730 deletion completed in 6.261647403s

• [SLOW TEST:10.530 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:04:17.537: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
May 29 17:04:17.711: INFO: Waiting up to 5m0s for pod "client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f" in namespace "containers-154" to be "success or failure"
May 29 17:04:17.718: INFO: Pod "client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.171862ms
May 29 17:04:19.727: INFO: Pod "client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015500727s
May 29 17:04:21.736: INFO: Pod "client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024405123s
STEP: Saw pod success
May 29 17:04:21.736: INFO: Pod "client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:04:21.742: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:04:21.773: INFO: Waiting for pod client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f to disappear
May 29 17:04:21.779: INFO: Pod client-containers-cb48adc9-8233-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:21.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-154" for this suite.
May 29 17:04:27.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:28.036: INFO: namespace containers-154 deletion completed in 6.248126039s

• [SLOW TEST:10.499 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:04:28.039: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4046
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:04:28.213: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:29.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4046" for this suite.
May 29 17:04:35.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:35.711: INFO: namespace custom-resource-definition-4046 deletion completed in 6.318063327s

• [SLOW TEST:7.672 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:04:35.713: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:39.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8944" for this suite.
May 29 17:04:45.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:46.229: INFO: namespace emptydir-wrapper-8944 deletion completed in 6.253572137s

• [SLOW TEST:10.516 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:04:46.231: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6940
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6940
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6940
May 29 17:04:46.443: INFO: Found 0 stateful pods, waiting for 1
May 29 17:04:56.454: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 29 17:04:56.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 17:04:56.878: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 17:04:56.878: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 17:04:56.878: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 17:04:56.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 17:05:06.899: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 17:05:06.900: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:05:06.930: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999439s
May 29 17:05:07.938: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992765149s
May 29 17:05:08.945: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984664008s
May 29 17:05:09.954: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977314141s
May 29 17:05:10.963: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968535647s
May 29 17:05:11.971: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960044963s
May 29 17:05:12.979: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.951155891s
May 29 17:05:13.989: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.943617189s
May 29 17:05:14.997: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.934143578s
May 29 17:05:16.006: INFO: Verifying statefulset ss doesn't scale past 1 for another 925.707498ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6940
May 29 17:05:17.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 17:05:17.339: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 17:05:17.339: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 17:05:17.339: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 17:05:17.347: INFO: Found 1 stateful pods, waiting for 3
May 29 17:05:27.355: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:05:27.355: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:05:27.355: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 29 17:05:27.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 17:05:27.635: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 17:05:27.635: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 17:05:27.635: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 17:05:27.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 17:05:27.917: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 17:05:27.917: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 17:05:27.917: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 17:05:27.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 17:05:28.206: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 17:05:28.206: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 17:05:28.206: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 17:05:28.206: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:05:28.213: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 29 17:05:38.230: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 17:05:38.230: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 17:05:38.230: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 17:05:38.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999419s
May 29 17:05:39.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989436922s
May 29 17:05:40.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980809335s
May 29 17:05:41.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971520254s
May 29 17:05:42.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.962575301s
May 29 17:05:43.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.952436982s
May 29 17:05:44.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.941135926s
May 29 17:05:45.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9325026s
May 29 17:05:46.329: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924232496s
May 29 17:05:47.339: INFO: Verifying statefulset ss doesn't scale past 3 for another 915.635828ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6940
May 29 17:05:48.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 17:05:48.633: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 17:05:48.633: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 17:05:48.633: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 17:05:48.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 17:05:48.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 17:05:48.956: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 17:05:48.956: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 17:05:48.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 exec --namespace=statefulset-6940 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 17:05:49.247: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 17:05:49.247: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 17:05:49.247: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 17:05:49.247: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 17:06:19.284: INFO: Deleting all statefulset in ns statefulset-6940
May 29 17:06:19.289: INFO: Scaling statefulset ss to 0
May 29 17:06:19.311: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:06:19.318: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:06:19.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6940" for this suite.
May 29 17:06:25.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:06:25.616: INFO: namespace statefulset-6940 deletion completed in 6.263945479s

• [SLOW TEST:99.386 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:06:25.617: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9202
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:06:43.816: INFO: Container started at 2019-05-29 17:06:27 +0000 UTC, pod became ready at 2019-05-29 17:06:42 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:06:43.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9202" for this suite.
May 29 17:07:05.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:07:06.104: INFO: namespace container-probe-9202 deletion completed in 22.278703494s

• [SLOW TEST:40.487 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:07:06.104: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 29 17:07:06.270: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:07:06.285: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:07:06.291: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-174540dd770e42e2af1af25266f before test
May 29 17:07:06.306: INFO: kube-proxy-9zfn6 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:07:06.306: INFO: flannel-2crp5 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:07:06.306: INFO: nginx-ingress-z47rs from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:07:06.306: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-29 16:06:56 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:07:06.306: INFO: sonobuoy-e2e-job-f013d2ad922949b9 from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container e2e ready: true, restart count 0
May 29 17:07:06.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:07:06.306: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-6jrjh from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:07:06.306: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:07:06.306: INFO: node-problem-detector-2zzv5 from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.306: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:07:06.306: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-e0a3711c5d19438ba264d7868f9 before test
May 29 17:07:06.322: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-tfm2v from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:07:06.322: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:07:06.322: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:07:06.322: INFO: kube-proxy-zht88 from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.322: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:07:06.323: INFO: flannel-sdznm from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.323: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:07:06.323: INFO: nginx-ingress-xtm7d from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.323: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:07:06.323: INFO: kubernetes-dashboard-79d67755f4-n25sj from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.323: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 17:07:06.323: INFO: monitoring-influxdb-6948b9bb8c-hzzfl from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.323: INFO: 	Container influxdb ready: true, restart count 0
May 29 17:07:06.323: INFO: node-problem-detector-tznqn from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.323: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:07:06.324: INFO: metrics-server-8d8786867-ndcld from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.324: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:07:06.324: INFO: coredns-646fc55c44-kbpn2 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.324: INFO: 	Container coredns ready: true, restart count 0
May 29 17:07:06.324: INFO: heapster-6c7494c65c-z8kq5 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:07:06.324: INFO: 	Container heapster ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a336530f346dc9], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:07:07.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3362" for this suite.
May 29 17:07:13.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:07:13.646: INFO: namespace sched-pred-3362 deletion completed in 6.260019472s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.541 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:07:13.646: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 29 17:07:17.856: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-344190d2-8234-11e9-abea-da3eb1f4b18f,GenerateName:,Namespace:events-1757,SelfLink:/api/v1/namespaces/events-1757/pods/send-events-344190d2-8234-11e9-abea-da3eb1f4b18f,UID:3442d319-8234-11e9-85f5-12d277f6ce64,ResourceVersion:948366704,Generation:0,CreationTimestamp:2019-05-29 17:07:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 813326454,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vgvkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vgvkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-vgvkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b81810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b81840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:07:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:07:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:07:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:07:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.81,StartTime:2019-05-29 17:07:13 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-29 17:07:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://543a471f6769f1a76ad531a7bc5188850a9b49a1eea32f3e4a9943f1e4fef404}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 29 17:07:19.866: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 29 17:07:21.874: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:07:21.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1757" for this suite.
May 29 17:08:01.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:08:02.198: INFO: namespace events-1757 deletion completed in 40.303112306s

• [SLOW TEST:48.552 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:08:02.198: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 29 17:08:02.374: INFO: Waiting up to 5m0s for pod "pod-5131712c-8234-11e9-abea-da3eb1f4b18f" in namespace "emptydir-676" to be "success or failure"
May 29 17:08:02.380: INFO: Pod "pod-5131712c-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167972ms
May 29 17:08:04.389: INFO: Pod "pod-5131712c-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014498237s
May 29 17:08:06.397: INFO: Pod "pod-5131712c-8234-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022586424s
STEP: Saw pod success
May 29 17:08:06.397: INFO: Pod "pod-5131712c-8234-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:08:06.404: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-5131712c-8234-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:08:06.434: INFO: Waiting for pod pod-5131712c-8234-11e9-abea-da3eb1f4b18f to disappear
May 29 17:08:06.441: INFO: Pod pod-5131712c-8234-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:08:06.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-676" for this suite.
May 29 17:08:12.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:08:12.741: INFO: namespace emptydir-676 deletion completed in 6.289100497s

• [SLOW TEST:10.543 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:08:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:08:12.913: INFO: Creating ReplicaSet my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f
May 29 17:08:12.929: INFO: Pod name my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f: Found 0 pods out of 1
May 29 17:08:17.937: INFO: Pod name my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f: Found 1 pods out of 1
May 29 17:08:17.937: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f" is running
May 29 17:08:17.944: INFO: Pod "my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f-zlctt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:08:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:08:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:08:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:08:12 +0000 UTC Reason: Message:}])
May 29 17:08:17.944: INFO: Trying to dial the pod
May 29 17:08:23.055: INFO: Controller my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f: Got expected result from replica 1 [my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f-zlctt]: "my-hostname-basic-577b80b0-8234-11e9-abea-da3eb1f4b18f-zlctt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:08:23.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9124" for this suite.
May 29 17:08:29.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:08:29.325: INFO: namespace replicaset-9124 deletion completed in 6.25906501s

• [SLOW TEST:16.582 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:08:29.326: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9310
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 29 17:08:34.054: INFO: Successfully updated pod "pod-update-615d56c7-8234-11e9-abea-da3eb1f4b18f"
STEP: verifying the updated pod is in kubernetes
May 29 17:08:34.069: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:08:34.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9310" for this suite.
May 29 17:08:58.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:08:58.351: INFO: namespace pods-9310 deletion completed in 24.271068317s

• [SLOW TEST:29.025 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:08:58.353: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-72ab080e-8234-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:08:58.544: INFO: Waiting up to 5m0s for pod "pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f" in namespace "configmap-4174" to be "success or failure"
May 29 17:08:58.551: INFO: Pod "pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.649588ms
May 29 17:09:00.560: INFO: Pod "pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015331643s
May 29 17:09:02.568: INFO: Pod "pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023098498s
STEP: Saw pod success
May 29 17:09:02.568: INFO: Pod "pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:09:02.574: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:09:02.609: INFO: Waiting for pod pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f to disappear
May 29 17:09:02.616: INFO: Pod pod-configmaps-72ac21c1-8234-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:09:02.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4174" for this suite.
May 29 17:09:08.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:09:08.862: INFO: namespace configmap-4174 deletion completed in 6.238020883s

• [SLOW TEST:10.509 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:09:08.862: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6144
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 17:09:09.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-6144'
May 29 17:09:09.544: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 29 17:09:09.544: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
May 29 17:09:13.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6144'
May 29 17:09:13.701: INFO: stderr: ""
May 29 17:09:13.701: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:09:13.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6144" for this suite.
May 29 17:09:19.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:09:19.969: INFO: namespace kubectl-6144 deletion completed in 6.256366827s

• [SLOW TEST:11.106 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:09:19.970: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:09:20.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f" in namespace "downward-api-9020" to be "success or failure"
May 29 17:09:20.160: INFO: Pod "downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.764965ms
May 29 17:09:22.168: INFO: Pod "downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014230249s
May 29 17:09:24.176: INFO: Pod "downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021765674s
STEP: Saw pod success
May 29 17:09:24.176: INFO: Pod "downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:09:24.183: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:09:24.218: INFO: Waiting for pod downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f to disappear
May 29 17:09:24.224: INFO: Pod downwardapi-volume-7f8d830c-8234-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:09:24.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9020" for this suite.
May 29 17:09:30.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:09:30.488: INFO: namespace downward-api-9020 deletion completed in 6.255160813s

• [SLOW TEST:10.518 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:09:30.488: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8435
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 17:09:30.653: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 29 17:09:54.807: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.94:8080/dial?request=hostName&protocol=udp&host=100.64.0.84&port=8081&tries=1'] Namespace:pod-network-test-8435 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:54.807: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:09:55.015: INFO: Waiting for endpoints: map[]
May 29 17:09:55.023: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.94:8080/dial?request=hostName&protocol=udp&host=100.64.1.93&port=8081&tries=1'] Namespace:pod-network-test-8435 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:55.023: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:09:55.209: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:09:55.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8435" for this suite.
May 29 17:10:17.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:10:17.457: INFO: namespace pod-network-test-8435 deletion completed in 22.239500035s

• [SLOW TEST:46.970 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:10:17.458: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
May 29 17:10:17.637: INFO: Waiting up to 5m0s for pod "client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f" in namespace "containers-6712" to be "success or failure"
May 29 17:10:17.643: INFO: Pod "client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035423ms
May 29 17:10:19.651: INFO: Pod "client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013850526s
May 29 17:10:21.660: INFO: Pod "client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022865344s
STEP: Saw pod success
May 29 17:10:21.660: INFO: Pod "client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:10:21.668: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:10:21.717: INFO: Waiting for pod client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f to disappear
May 29 17:10:21.726: INFO: Pod client-containers-a1d061d6-8234-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:21.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6712" for this suite.
May 29 17:10:27.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:10:27.996: INFO: namespace containers-6712 deletion completed in 6.261111719s

• [SLOW TEST:10.539 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:10:27.997: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
May 29 17:10:28.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 --namespace=kubectl-4727 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 29 17:10:30.764: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 29 17:10:30.764: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:32.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4727" for this suite.
May 29 17:10:42.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:10:43.057: INFO: namespace kubectl-4727 deletion completed in 10.269041769s

• [SLOW TEST:15.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:10:43.058: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:10:43.245: INFO: (0) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.192806ms)
May 29 17:10:43.254: INFO: (1) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.320151ms)
May 29 17:10:43.263: INFO: (2) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.735933ms)
May 29 17:10:43.272: INFO: (3) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.904339ms)
May 29 17:10:43.280: INFO: (4) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.178514ms)
May 29 17:10:43.288: INFO: (5) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.366648ms)
May 29 17:10:43.297: INFO: (6) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.251641ms)
May 29 17:10:43.306: INFO: (7) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.8621ms)
May 29 17:10:43.313: INFO: (8) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.217967ms)
May 29 17:10:43.322: INFO: (9) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.970365ms)
May 29 17:10:43.331: INFO: (10) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.738367ms)
May 29 17:10:43.340: INFO: (11) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.234771ms)
May 29 17:10:43.349: INFO: (12) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.094216ms)
May 29 17:10:43.357: INFO: (13) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.113641ms)
May 29 17:10:43.365: INFO: (14) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.683362ms)
May 29 17:10:43.372: INFO: (15) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.264896ms)
May 29 17:10:43.388: INFO: (16) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.224718ms)
May 29 17:10:43.396: INFO: (17) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.317435ms)
May 29 17:10:43.405: INFO: (18) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.156143ms)
May 29 17:10:43.414: INFO: (19) /api/v1/nodes/scw-sono14-default-174540dd770e42e2af1af25266f/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.183835ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:43.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9942" for this suite.
May 29 17:10:49.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:10:49.664: INFO: namespace proxy-9942 deletion completed in 6.241899922s

• [SLOW TEST:6.606 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:10:49.664: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:10:49.829: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:54.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4874" for this suite.
May 29 17:11:32.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:32.316: INFO: namespace pods-4874 deletion completed in 38.243246311s

• [SLOW TEST:42.652 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:11:32.318: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:32.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4653" for this suite.
May 29 17:11:54.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:54.762: INFO: namespace kubelet-test-4653 deletion completed in 22.250398367s

• [SLOW TEST:22.444 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:11:54.762: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:11:54.956: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 29 17:11:54.986: INFO: Number of nodes with available pods: 0
May 29 17:11:54.986: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:11:56.002: INFO: Number of nodes with available pods: 0
May 29 17:11:56.002: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:11:57.003: INFO: Number of nodes with available pods: 0
May 29 17:11:57.003: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:11:58.003: INFO: Number of nodes with available pods: 2
May 29 17:11:58.003: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 29 17:11:58.065: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:11:58.065: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:11:59.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:11:59.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:00.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:00.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:01.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:01.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:01.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:02.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:02.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:02.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:03.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:03.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:03.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:04.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:04.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:04.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:05.084: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:05.084: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:05.084: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:06.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:06.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:06.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:07.084: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:07.084: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:07.084: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:08.084: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:08.084: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:08.084: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:09.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:09.083: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:09.083: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:10.095: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:10.095: INFO: Wrong image for pod: daemon-set-zq547. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:10.095: INFO: Pod daemon-set-zq547 is not available
May 29 17:12:11.082: INFO: Pod daemon-set-5qcg4 is not available
May 29 17:12:11.082: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:12.083: INFO: Pod daemon-set-5qcg4 is not available
May 29 17:12:12.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:13.082: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:14.083: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:15.085: INFO: Wrong image for pod: daemon-set-zhfz8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 29 17:12:15.085: INFO: Pod daemon-set-zhfz8 is not available
May 29 17:12:16.083: INFO: Pod daemon-set-zj24p is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 29 17:12:16.126: INFO: Number of nodes with available pods: 1
May 29 17:12:16.126: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:12:17.142: INFO: Number of nodes with available pods: 1
May 29 17:12:17.142: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:12:18.143: INFO: Number of nodes with available pods: 2
May 29 17:12:18.143: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6395, will wait for the garbage collector to delete the pods
May 29 17:12:18.281: INFO: Deleting DaemonSet.extensions daemon-set took: 22.420112ms
May 29 17:12:18.581: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.258721ms
May 29 17:12:29.189: INFO: Number of nodes with available pods: 0
May 29 17:12:29.189: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:12:29.199: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6395/daemonsets","resourceVersion":"948392152"},"items":null}

May 29 17:12:29.207: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6395/pods","resourceVersion":"948392152"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:29.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6395" for this suite.
May 29 17:12:35.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:12:35.525: INFO: namespace daemonsets-6395 deletion completed in 6.277891512s

• [SLOW TEST:40.763 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:12:35.525: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9028
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0529 17:12:41.793378      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 17:12:41.793: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:41.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9028" for this suite.
May 29 17:12:47.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:12:48.340: INFO: namespace gc-9028 deletion completed in 6.539670676s

• [SLOW TEST:12.815 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:12:48.340: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3366
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:12:48.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f" in namespace "projected-3366" to be "success or failure"
May 29 17:12:48.563: INFO: Pod "downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.178844ms
May 29 17:12:50.574: INFO: Pod "downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019261403s
May 29 17:12:52.583: INFO: Pod "downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027722141s
STEP: Saw pod success
May 29 17:12:52.583: INFO: Pod "downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:12:52.589: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:12:52.630: INFO: Waiting for pod downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f to disappear
May 29 17:12:52.637: INFO: Pod downwardapi-volume-fbc519f1-8234-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:52.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3366" for this suite.
May 29 17:12:58.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:12:58.906: INFO: namespace projected-3366 deletion completed in 6.260209934s

• [SLOW TEST:10.566 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:12:58.907: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-020daee4-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:12:59.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f" in namespace "projected-5047" to be "success or failure"
May 29 17:12:59.113: INFO: Pod "pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.603673ms
May 29 17:13:01.121: INFO: Pod "pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015354443s
May 29 17:13:03.129: INFO: Pod "pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023506739s
STEP: Saw pod success
May 29 17:13:03.129: INFO: Pod "pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:13:03.137: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:13:03.167: INFO: Waiting for pod pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:13:03.173: INFO: Pod pod-projected-configmaps-020edbbf-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:03.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5047" for this suite.
May 29 17:13:09.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:09.442: INFO: namespace projected-5047 deletion completed in 6.261131524s

• [SLOW TEST:10.535 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:13:09.443: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:13:10.253: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 29 17:13:15.263: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 17:13:15.263: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 29 17:13:17.272: INFO: Creating deployment "test-rollover-deployment"
May 29 17:13:17.288: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 29 17:13:19.304: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 29 17:13:19.319: INFO: Ensure that both replica sets have 1 created replica
May 29 17:13:19.333: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 29 17:13:19.347: INFO: Updating deployment test-rollover-deployment
May 29 17:13:19.347: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 29 17:13:21.361: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 29 17:13:21.375: INFO: Make sure deployment "test-rollover-deployment" is complete
May 29 17:13:21.390: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:21.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746799, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:23.408: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:23.408: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746801, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:25.405: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:25.406: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746801, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:27.406: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:27.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746801, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:29.407: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:29.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746801, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:31.406: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:13:31.407: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746801, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746797, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:13:33.407: INFO: 
May 29 17:13:33.407: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 29 17:13:33.431: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-775,SelfLink:/apis/apps/v1/namespaces/deployment-775/deployments/test-rollover-deployment,UID:0ce60647-8235-11e9-85f5-12d277f6ce64,ResourceVersion:948397313,Generation:2,CreationTimestamp:2019-05-29 17:13:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-29 17:13:17 +0000 UTC 2019-05-29 17:13:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-29 17:13:31 +0000 UTC 2019-05-29 17:13:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:13:33.438: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-775,SelfLink:/apis/apps/v1/namespaces/deployment-775/replicasets/test-rollover-deployment-766b4d6c9d,UID:0e2213ab-8235-11e9-85f5-12d277f6ce64,ResourceVersion:948397298,Generation:2,CreationTimestamp:2019-05-29 17:13:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0ce60647-8235-11e9-85f5-12d277f6ce64 0xc00290dd57 0xc00290dd58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 29 17:13:33.439: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 29 17:13:33.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-775,SelfLink:/apis/apps/v1/namespaces/deployment-775/replicasets/test-rollover-controller,UID:08b48b04-8235-11e9-85f5-12d277f6ce64,ResourceVersion:948397311,Generation:2,CreationTimestamp:2019-05-29 17:13:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0ce60647-8235-11e9-85f5-12d277f6ce64 0xc00290dba7 0xc00290dba8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 17:13:33.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-775,SelfLink:/apis/apps/v1/namespaces/deployment-775/replicasets/test-rollover-deployment-6455657675,UID:0ce89dbb-8235-11e9-85f5-12d277f6ce64,ResourceVersion:948396361,Generation:2,CreationTimestamp:2019-05-29 17:13:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0ce60647-8235-11e9-85f5-12d277f6ce64 0xc00290dc77 0xc00290dc78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 17:13:33.447: INFO: Pod "test-rollover-deployment-766b4d6c9d-ccndg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-ccndg,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-775,SelfLink:/api/v1/namespaces/deployment-775/pods/test-rollover-deployment-766b4d6c9d-ccndg,UID:0e260914-8235-11e9-85f5-12d277f6ce64,ResourceVersion:948396534,Generation:0,CreationTimestamp:2019-05-29 17:13:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 0e2213ab-8235-11e9-85f5-12d277f6ce64 0xc002fce937 0xc002fce938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hn5ts {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hn5ts,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hn5ts true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fce9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fce9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:13:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:13:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:13:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:13:19 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.106,StartTime:2019-05-29 17:13:19 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-29 17:13:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://05658db0785b3efaa558352b87fbc2f2612edb82f8a034a82d6b65b57d4998c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:33.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-775" for this suite.
May 29 17:13:39.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:39.706: INFO: namespace deployment-775 deletion completed in 6.25009773s

• [SLOW TEST:30.264 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:13:39.710: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8483/configmap-test-1a5e39bb-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:13:39.896: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f" in namespace "configmap-8483" to be "success or failure"
May 29 17:13:39.903: INFO: Pod "pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12313ms
May 29 17:13:41.912: INFO: Pod "pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01602442s
May 29 17:13:43.921: INFO: Pod "pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024871388s
STEP: Saw pod success
May 29 17:13:43.921: INFO: Pod "pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:13:43.929: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f container env-test: <nil>
STEP: delete the pod
May 29 17:13:43.960: INFO: Waiting for pod pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:13:43.967: INFO: Pod pod-configmaps-1a5f6645-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:43.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8483" for this suite.
May 29 17:13:49.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:50.222: INFO: namespace configmap-8483 deletion completed in 6.246906004s

• [SLOW TEST:10.513 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:13:50.223: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-542
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
May 29 17:13:54.936: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-542 pod-service-account-20f18881-8235-11e9-abea-da3eb1f4b18f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 29 17:13:55.258: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-542 pod-service-account-20f18881-8235-11e9-abea-da3eb1f4b18f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 29 17:13:55.532: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-542 pod-service-account-20f18881-8235-11e9-abea-da3eb1f4b18f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:55.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-542" for this suite.
May 29 17:14:01.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:14:02.104: INFO: namespace svcaccounts-542 deletion completed in 6.263269688s

• [SLOW TEST:11.881 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:14:02.105: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1149
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 17:14:02.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1149'
May 29 17:14:02.414: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 29 17:14:02.414: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 29 17:14:02.428: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-696rh]
May 29 17:14:02.428: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-696rh" in namespace "kubectl-1149" to be "running and ready"
May 29 17:14:02.434: INFO: Pod "e2e-test-nginx-rc-696rh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016256ms
May 29 17:14:04.443: INFO: Pod "e2e-test-nginx-rc-696rh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014331061s
May 29 17:14:06.451: INFO: Pod "e2e-test-nginx-rc-696rh": Phase="Running", Reason="", readiness=true. Elapsed: 4.022586855s
May 29 17:14:06.451: INFO: Pod "e2e-test-nginx-rc-696rh" satisfied condition "running and ready"
May 29 17:14:06.451: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-696rh]
May 29 17:14:06.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 logs rc/e2e-test-nginx-rc --namespace=kubectl-1149'
May 29 17:14:06.655: INFO: stderr: ""
May 29 17:14:06.655: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
May 29 17:14:06.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete rc e2e-test-nginx-rc --namespace=kubectl-1149'
May 29 17:14:06.804: INFO: stderr: ""
May 29 17:14:06.804: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:14:06.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1149" for this suite.
May 29 17:14:28.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:14:29.082: INFO: namespace kubectl-1149 deletion completed in 22.26692416s

• [SLOW TEST:26.977 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:14:29.086: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-dgf2
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:14:29.288: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dgf2" in namespace "subpath-5517" to be "success or failure"
May 29 17:14:29.295: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.334365ms
May 29 17:14:31.303: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014742133s
May 29 17:14:33.312: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 4.024055274s
May 29 17:14:35.322: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 6.033533545s
May 29 17:14:37.331: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 8.04230138s
May 29 17:14:39.339: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 10.050877133s
May 29 17:14:41.348: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 12.05952427s
May 29 17:14:43.357: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 14.068810069s
May 29 17:14:45.366: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 16.077158944s
May 29 17:14:47.373: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 18.084862516s
May 29 17:14:49.383: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 20.094852839s
May 29 17:14:51.393: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Running", Reason="", readiness=true. Elapsed: 22.104727475s
May 29 17:14:53.402: INFO: Pod "pod-subpath-test-configmap-dgf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.113173793s
STEP: Saw pod success
May 29 17:14:53.402: INFO: Pod "pod-subpath-test-configmap-dgf2" satisfied condition "success or failure"
May 29 17:14:53.407: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-subpath-test-configmap-dgf2 container test-container-subpath-configmap-dgf2: <nil>
STEP: delete the pod
May 29 17:14:53.445: INFO: Waiting for pod pod-subpath-test-configmap-dgf2 to disappear
May 29 17:14:53.452: INFO: Pod pod-subpath-test-configmap-dgf2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dgf2
May 29 17:14:53.452: INFO: Deleting pod "pod-subpath-test-configmap-dgf2" in namespace "subpath-5517"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:14:53.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5517" for this suite.
May 29 17:14:59.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:14:59.714: INFO: namespace subpath-5517 deletion completed in 6.247555374s

• [SLOW TEST:30.629 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:14:59.715: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
May 29 17:14:59.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7155'
May 29 17:15:00.219: INFO: stderr: ""
May 29 17:15:00.219: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:15:00.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7155'
May 29 17:15:00.359: INFO: stderr: ""
May 29 17:15:00.359: INFO: stdout: "update-demo-nautilus-dxb5q update-demo-nautilus-j9hqx "
May 29 17:15:00.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-dxb5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:00.469: INFO: stderr: ""
May 29 17:15:00.469: INFO: stdout: ""
May 29 17:15:00.469: INFO: update-demo-nautilus-dxb5q is created but not running
May 29 17:15:05.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7155'
May 29 17:15:05.594: INFO: stderr: ""
May 29 17:15:05.594: INFO: stdout: "update-demo-nautilus-dxb5q update-demo-nautilus-j9hqx "
May 29 17:15:05.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-dxb5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:05.701: INFO: stderr: ""
May 29 17:15:05.702: INFO: stdout: "true"
May 29 17:15:05.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-dxb5q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:05.829: INFO: stderr: ""
May 29 17:15:05.829: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:15:05.829: INFO: validating pod update-demo-nautilus-dxb5q
May 29 17:15:05.926: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:15:05.926: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:15:05.926: INFO: update-demo-nautilus-dxb5q is verified up and running
May 29 17:15:05.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-j9hqx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:06.051: INFO: stderr: ""
May 29 17:15:06.051: INFO: stdout: "true"
May 29 17:15:06.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-j9hqx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:06.183: INFO: stderr: ""
May 29 17:15:06.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:15:06.183: INFO: validating pod update-demo-nautilus-j9hqx
May 29 17:15:06.286: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:15:06.286: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:15:06.286: INFO: update-demo-nautilus-j9hqx is verified up and running
STEP: rolling-update to new replication controller
May 29 17:15:06.288: INFO: scanned /root for discovery docs: <nil>
May 29 17:15:06.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7155'
May 29 17:15:29.004: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 29 17:15:29.004: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:15:29.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7155'
May 29 17:15:29.113: INFO: stderr: ""
May 29 17:15:29.113: INFO: stdout: "update-demo-kitten-cp887 update-demo-kitten-qjx7r "
May 29 17:15:29.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-kitten-cp887 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:29.221: INFO: stderr: ""
May 29 17:15:29.221: INFO: stdout: "true"
May 29 17:15:29.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-kitten-cp887 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:29.338: INFO: stderr: ""
May 29 17:15:29.338: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 29 17:15:29.338: INFO: validating pod update-demo-kitten-cp887
May 29 17:15:29.438: INFO: got data: {
  "image": "kitten.jpg"
}

May 29 17:15:29.438: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 29 17:15:29.438: INFO: update-demo-kitten-cp887 is verified up and running
May 29 17:15:29.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-kitten-qjx7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:29.557: INFO: stderr: ""
May 29 17:15:29.557: INFO: stdout: "true"
May 29 17:15:29.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-kitten-qjx7r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7155'
May 29 17:15:29.667: INFO: stderr: ""
May 29 17:15:29.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 29 17:15:29.667: INFO: validating pod update-demo-kitten-qjx7r
May 29 17:15:29.766: INFO: got data: {
  "image": "kitten.jpg"
}

May 29 17:15:29.766: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 29 17:15:29.766: INFO: update-demo-kitten-qjx7r is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:15:29.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7155" for this suite.
May 29 17:15:51.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:15:52.024: INFO: namespace kubectl-7155 deletion completed in 22.247751307s

• [SLOW TEST:52.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:15:52.026: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f
May 29 17:15:52.210: INFO: Pod name my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f: Found 0 pods out of 1
May 29 17:15:57.219: INFO: Pod name my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f: Found 1 pods out of 1
May 29 17:15:57.219: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f" are running
May 29 17:15:57.308: INFO: Pod "my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f-dsw76" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:15:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:15:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:15:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 17:15:52 +0000 UTC Reason: Message:}])
May 29 17:15:57.308: INFO: Trying to dial the pod
May 29 17:16:02.422: INFO: Controller my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f: Got expected result from replica 1 [my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f-dsw76]: "my-hostname-basic-693c255b-8235-11e9-abea-da3eb1f4b18f-dsw76", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:16:02.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2293" for this suite.
May 29 17:16:08.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:16:08.727: INFO: namespace replication-controller-2293 deletion completed in 6.296295246s

• [SLOW TEST:16.702 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:16:08.729: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
May 29 17:16:08.907: INFO: Waiting up to 5m0s for pod "client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f" in namespace "containers-3892" to be "success or failure"
May 29 17:16:08.914: INFO: Pod "client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.8426ms
May 29 17:16:10.923: INFO: Pod "client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01614303s
May 29 17:16:12.932: INFO: Pod "client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02508296s
STEP: Saw pod success
May 29 17:16:12.932: INFO: Pod "client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:16:12.939: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:16:12.974: INFO: Waiting for pod client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:16:12.980: INFO: Pod client-containers-73307be8-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:16:12.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3892" for this suite.
May 29 17:16:21.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:16:21.258: INFO: namespace containers-3892 deletion completed in 8.269336309s

• [SLOW TEST:12.529 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:16:21.259: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1144
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 29 17:16:21.421: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:16:21.438: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:16:21.445: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-174540dd770e42e2af1af25266f before test
May 29 17:16:21.459: INFO: node-problem-detector-2zzv5 from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.459: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:16:21.459: INFO: kube-proxy-9zfn6 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.459: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:16:21.459: INFO: flannel-2crp5 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.459: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:16:21.459: INFO: nginx-ingress-z47rs from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.459: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:16:21.459: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-29 16:06:56 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.459: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:16:21.459: INFO: sonobuoy-e2e-job-f013d2ad922949b9 from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:16:21.460: INFO: 	Container e2e ready: true, restart count 0
May 29 17:16:21.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:16:21.460: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-6jrjh from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:16:21.460: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 29 17:16:21.460: INFO: 	Container systemd-logs ready: true, restart count 1
May 29 17:16:21.460: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-e0a3711c5d19438ba264d7868f9 before test
May 29 17:16:21.474: INFO: coredns-646fc55c44-kbpn2 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container coredns ready: true, restart count 0
May 29 17:16:21.474: INFO: heapster-6c7494c65c-z8kq5 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container heapster ready: true, restart count 0
May 29 17:16:21.474: INFO: node-problem-detector-tznqn from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:16:21.474: INFO: metrics-server-8d8786867-ndcld from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:16:21.474: INFO: nginx-ingress-xtm7d from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:16:21.474: INFO: kubernetes-dashboard-79d67755f4-n25sj from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 17:16:21.474: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-tfm2v from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:16:21.474: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 29 17:16:21.474: INFO: 	Container systemd-logs ready: true, restart count 1
May 29 17:16:21.474: INFO: kube-proxy-zht88 from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.475: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:16:21.475: INFO: flannel-sdznm from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.475: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:16:21.475: INFO: monitoring-influxdb-6948b9bb8c-hzzfl from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:16:21.475: INFO: 	Container influxdb ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7d1aa555-8235-11e9-abea-da3eb1f4b18f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7d1aa555-8235-11e9-abea-da3eb1f4b18f off the node scw-sono14-default-e0a3711c5d19438ba264d7868f9
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7d1aa555-8235-11e9-abea-da3eb1f4b18f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:16:29.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1144" for this suite.
May 29 17:16:37.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:16:37.917: INFO: namespace sched-pred-1144 deletion completed in 8.289609368s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.659 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:16:37.919: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
May 29 17:16:38.924: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 29 17:16:41.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:43.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:45.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:47.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:49.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:51.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:53.022: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:55.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:16:57.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694746998, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:17:01.133: INFO: Waited 2.109902608s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:02.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1413" for this suite.
May 29 17:17:08.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:17:08.315: INFO: namespace aggregator-1413 deletion completed in 6.287530908s

• [SLOW TEST:30.396 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:17:08.316: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-96b4d989-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:17:08.502: INFO: Waiting up to 5m0s for pod "pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f" in namespace "configmap-8448" to be "success or failure"
May 29 17:17:08.509: INFO: Pod "pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.496309ms
May 29 17:17:10.518: INFO: Pod "pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015139408s
May 29 17:17:12.527: INFO: Pod "pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024459239s
STEP: Saw pod success
May 29 17:17:12.527: INFO: Pod "pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:17:12.534: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:17:12.565: INFO: Waiting for pod pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:17:12.571: INFO: Pod pod-configmaps-96b5f14e-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:12.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8448" for this suite.
May 29 17:17:18.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:17:18.831: INFO: namespace configmap-8448 deletion completed in 6.252091845s

• [SLOW TEST:10.515 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:17:18.833: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-505
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9cf9ceff-8235-11e9-abea-da3eb1f4b18f
STEP: Creating configMap with name cm-test-opt-upd-9cf9cf84-8235-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9cf9ceff-8235-11e9-abea-da3eb1f4b18f
STEP: Updating configmap cm-test-opt-upd-9cf9cf84-8235-11e9-abea-da3eb1f4b18f
STEP: Creating configMap with name cm-test-opt-create-9cf9cfba-8235-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:27.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-505" for this suite.
May 29 17:17:49.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:17:49.488: INFO: namespace projected-505 deletion completed in 22.255328078s

• [SLOW TEST:30.655 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:17:49.488: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8243
May 29 17:17:53.685: INFO: Started pod liveness-http in namespace container-probe-8243
STEP: checking the pod's current state and verifying that restartCount is present
May 29 17:17:53.692: INFO: Initial restart count of pod liveness-http is 0
May 29 17:18:09.773: INFO: Restart count of pod container-probe-8243/liveness-http is now 1 (16.081050535s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:09.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8243" for this suite.
May 29 17:18:15.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:16.034: INFO: namespace container-probe-8243 deletion completed in 6.236287086s

• [SLOW TEST:26.546 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:18:16.034: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6801
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6801
I0529 17:18:16.241373      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6801, replica count: 1
I0529 17:18:17.292055      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:18:18.292272      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:18:19.292484      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 17:18:19.415: INFO: Created: latency-svc-cf5pk
May 29 17:18:19.420: INFO: Got endpoints: latency-svc-cf5pk [27.880313ms]
May 29 17:18:19.443: INFO: Created: latency-svc-rkjpl
May 29 17:18:19.447: INFO: Got endpoints: latency-svc-rkjpl [26.014244ms]
May 29 17:18:19.455: INFO: Created: latency-svc-b4l4z
May 29 17:18:19.465: INFO: Got endpoints: latency-svc-b4l4z [43.507428ms]
May 29 17:18:19.467: INFO: Created: latency-svc-st6gn
May 29 17:18:19.473: INFO: Got endpoints: latency-svc-st6gn [51.697723ms]
May 29 17:18:19.507: INFO: Created: latency-svc-rpzdb
May 29 17:18:19.512: INFO: Got endpoints: latency-svc-rpzdb [90.957281ms]
May 29 17:18:19.518: INFO: Created: latency-svc-n6qjr
May 29 17:18:19.528: INFO: Got endpoints: latency-svc-n6qjr [106.743675ms]
May 29 17:18:19.535: INFO: Created: latency-svc-d4k9l
May 29 17:18:19.539: INFO: Got endpoints: latency-svc-d4k9l [117.375593ms]
May 29 17:18:19.542: INFO: Created: latency-svc-zkhgl
May 29 17:18:19.546: INFO: Got endpoints: latency-svc-zkhgl [124.199329ms]
May 29 17:18:19.558: INFO: Created: latency-svc-7wl4k
May 29 17:18:19.564: INFO: Got endpoints: latency-svc-7wl4k [142.541661ms]
May 29 17:18:19.573: INFO: Created: latency-svc-sr6ms
May 29 17:18:19.611: INFO: Created: latency-svc-jntjf
May 29 17:18:19.611: INFO: Got endpoints: latency-svc-sr6ms [189.642526ms]
May 29 17:18:19.619: INFO: Got endpoints: latency-svc-jntjf [197.509756ms]
May 29 17:18:19.626: INFO: Created: latency-svc-hbtm6
May 29 17:18:19.637: INFO: Got endpoints: latency-svc-hbtm6 [215.324215ms]
May 29 17:18:19.640: INFO: Created: latency-svc-72822
May 29 17:18:19.646: INFO: Got endpoints: latency-svc-72822 [224.112095ms]
May 29 17:18:19.654: INFO: Created: latency-svc-lfcqk
May 29 17:18:19.658: INFO: Got endpoints: latency-svc-lfcqk [236.140851ms]
May 29 17:18:19.667: INFO: Created: latency-svc-x9wwh
May 29 17:18:19.712: INFO: Got endpoints: latency-svc-x9wwh [290.680139ms]
May 29 17:18:19.719: INFO: Created: latency-svc-tdlms
May 29 17:18:19.725: INFO: Got endpoints: latency-svc-tdlms [304.348078ms]
May 29 17:18:19.732: INFO: Created: latency-svc-gd9lt
May 29 17:18:19.739: INFO: Got endpoints: latency-svc-gd9lt [26.346638ms]
May 29 17:18:19.748: INFO: Created: latency-svc-m8tmw
May 29 17:18:19.753: INFO: Got endpoints: latency-svc-m8tmw [305.811832ms]
May 29 17:18:19.765: INFO: Created: latency-svc-kb9tk
May 29 17:18:19.770: INFO: Got endpoints: latency-svc-kb9tk [305.505816ms]
May 29 17:18:19.804: INFO: Created: latency-svc-8nrzd
May 29 17:18:19.809: INFO: Got endpoints: latency-svc-8nrzd [336.279391ms]
May 29 17:18:19.823: INFO: Created: latency-svc-4bvsw
May 29 17:18:19.830: INFO: Got endpoints: latency-svc-4bvsw [317.521437ms]
May 29 17:18:19.833: INFO: Created: latency-svc-pdq85
May 29 17:18:19.838: INFO: Got endpoints: latency-svc-pdq85 [309.509397ms]
May 29 17:18:19.846: INFO: Created: latency-svc-bvqjn
May 29 17:18:19.852: INFO: Got endpoints: latency-svc-bvqjn [313.486358ms]
May 29 17:18:19.861: INFO: Created: latency-svc-sdh2l
May 29 17:18:19.867: INFO: Got endpoints: latency-svc-sdh2l [320.868243ms]
May 29 17:18:19.904: INFO: Created: latency-svc-8r2sp
May 29 17:18:19.917: INFO: Got endpoints: latency-svc-8r2sp [353.124466ms]
May 29 17:18:19.920: INFO: Created: latency-svc-j9mkl
May 29 17:18:19.925: INFO: Got endpoints: latency-svc-j9mkl [313.986789ms]
May 29 17:18:19.935: INFO: Created: latency-svc-k76xs
May 29 17:18:19.940: INFO: Got endpoints: latency-svc-k76xs [320.661524ms]
May 29 17:18:19.949: INFO: Created: latency-svc-vzdcx
May 29 17:18:19.954: INFO: Got endpoints: latency-svc-vzdcx [316.851016ms]
May 29 17:18:19.962: INFO: Created: latency-svc-fcmbh
May 29 17:18:19.970: INFO: Got endpoints: latency-svc-fcmbh [323.895767ms]
May 29 17:18:20.020: INFO: Created: latency-svc-lbz7z
May 29 17:18:20.027: INFO: Got endpoints: latency-svc-lbz7z [369.136436ms]
May 29 17:18:20.036: INFO: Created: latency-svc-v9vp9
May 29 17:18:20.041: INFO: Got endpoints: latency-svc-v9vp9 [315.749484ms]
May 29 17:18:20.053: INFO: Created: latency-svc-tbhpg
May 29 17:18:20.057: INFO: Got endpoints: latency-svc-tbhpg [318.451337ms]
May 29 17:18:20.069: INFO: Created: latency-svc-ckkp4
May 29 17:18:20.074: INFO: Got endpoints: latency-svc-ckkp4 [321.455687ms]
May 29 17:18:20.085: INFO: Created: latency-svc-bddn8
May 29 17:18:20.091: INFO: Got endpoints: latency-svc-bddn8 [320.410442ms]
May 29 17:18:20.135: INFO: Created: latency-svc-n4jbt
May 29 17:18:20.144: INFO: Got endpoints: latency-svc-n4jbt [333.619367ms]
May 29 17:18:20.148: INFO: Created: latency-svc-5574k
May 29 17:18:20.154: INFO: Got endpoints: latency-svc-5574k [323.970267ms]
May 29 17:18:20.612: INFO: Created: latency-svc-2kvm2
May 29 17:18:20.907: INFO: Got endpoints: latency-svc-2kvm2 [1.069347902s]
May 29 17:18:20.922: INFO: Created: latency-svc-b587k
May 29 17:18:21.006: INFO: Got endpoints: latency-svc-b587k [1.153347695s]
May 29 17:18:21.009: INFO: Created: latency-svc-wjxr7
May 29 17:18:21.014: INFO: Got endpoints: latency-svc-wjxr7 [1.147731711s]
May 29 17:18:21.025: INFO: Created: latency-svc-plzcn
May 29 17:18:21.038: INFO: Created: latency-svc-dtpv4
May 29 17:18:21.107: INFO: Got endpoints: latency-svc-plzcn [1.19033097s]
May 29 17:18:21.115: INFO: Got endpoints: latency-svc-dtpv4 [1.189324728s]
May 29 17:18:21.119: INFO: Created: latency-svc-vn2h8
May 29 17:18:21.125: INFO: Got endpoints: latency-svc-vn2h8 [1.184969125s]
May 29 17:18:21.133: INFO: Created: latency-svc-ggfcn
May 29 17:18:21.137: INFO: Got endpoints: latency-svc-ggfcn [1.182695998s]
May 29 17:18:21.146: INFO: Created: latency-svc-vjgsj
May 29 17:18:21.150: INFO: Got endpoints: latency-svc-vjgsj [1.180529263s]
May 29 17:18:21.205: INFO: Created: latency-svc-lv2br
May 29 17:18:21.208: INFO: Got endpoints: latency-svc-lv2br [1.180974722s]
May 29 17:18:21.209: INFO: Created: latency-svc-pqc2t
May 29 17:18:21.215: INFO: Got endpoints: latency-svc-pqc2t [1.173955528s]
May 29 17:18:21.222: INFO: Created: latency-svc-78zlh
May 29 17:18:21.229: INFO: Got endpoints: latency-svc-78zlh [1.171167615s]
May 29 17:18:21.237: INFO: Created: latency-svc-qr8qt
May 29 17:18:21.242: INFO: Got endpoints: latency-svc-qr8qt [1.167772177s]
May 29 17:18:21.250: INFO: Created: latency-svc-548rz
May 29 17:18:21.256: INFO: Got endpoints: latency-svc-548rz [1.16560474s]
May 29 17:18:21.317: INFO: Created: latency-svc-spqn4
May 29 17:18:21.322: INFO: Got endpoints: latency-svc-spqn4 [1.178482594s]
May 29 17:18:21.330: INFO: Created: latency-svc-b2t6j
May 29 17:18:21.335: INFO: Got endpoints: latency-svc-b2t6j [1.181044863s]
May 29 17:18:21.344: INFO: Created: latency-svc-llpnp
May 29 17:18:21.349: INFO: Got endpoints: latency-svc-llpnp [441.565495ms]
May 29 17:18:21.358: INFO: Created: latency-svc-w4fxw
May 29 17:18:21.364: INFO: Got endpoints: latency-svc-w4fxw [358.426741ms]
May 29 17:18:21.372: INFO: Created: latency-svc-c5g69
May 29 17:18:21.377: INFO: Got endpoints: latency-svc-c5g69 [362.480826ms]
May 29 17:18:21.408: INFO: Created: latency-svc-b8sbf
May 29 17:18:21.415: INFO: Got endpoints: latency-svc-b8sbf [307.333854ms]
May 29 17:18:21.423: INFO: Created: latency-svc-vkkk2
May 29 17:18:21.429: INFO: Got endpoints: latency-svc-vkkk2 [313.971861ms]
May 29 17:18:21.438: INFO: Created: latency-svc-b9sx9
May 29 17:18:21.443: INFO: Got endpoints: latency-svc-b9sx9 [317.728105ms]
May 29 17:18:21.451: INFO: Created: latency-svc-j6lh6
May 29 17:18:21.457: INFO: Got endpoints: latency-svc-j6lh6 [319.730562ms]
May 29 17:18:21.465: INFO: Created: latency-svc-qrnlm
May 29 17:18:21.469: INFO: Got endpoints: latency-svc-qrnlm [319.127519ms]
May 29 17:18:21.481: INFO: Created: latency-svc-48p8r
May 29 17:18:21.505: INFO: Got endpoints: latency-svc-48p8r [297.073985ms]
May 29 17:18:21.518: INFO: Created: latency-svc-ww969
May 29 17:18:21.528: INFO: Got endpoints: latency-svc-ww969 [312.389294ms]
May 29 17:18:21.531: INFO: Created: latency-svc-fwmss
May 29 17:18:21.537: INFO: Got endpoints: latency-svc-fwmss [308.551104ms]
May 29 17:18:21.546: INFO: Created: latency-svc-kd6sw
May 29 17:18:21.553: INFO: Got endpoints: latency-svc-kd6sw [310.720225ms]
May 29 17:18:21.560: INFO: Created: latency-svc-fzklt
May 29 17:18:21.564: INFO: Got endpoints: latency-svc-fzklt [307.984578ms]
May 29 17:18:21.608: INFO: Created: latency-svc-wx9gd
May 29 17:18:21.613: INFO: Got endpoints: latency-svc-wx9gd [290.609616ms]
May 29 17:18:21.623: INFO: Created: latency-svc-t9g8z
May 29 17:18:21.630: INFO: Got endpoints: latency-svc-t9g8z [294.480808ms]
May 29 17:18:21.638: INFO: Created: latency-svc-p4ljf
May 29 17:18:21.641: INFO: Got endpoints: latency-svc-p4ljf [292.378533ms]
May 29 17:18:21.650: INFO: Created: latency-svc-xnzfz
May 29 17:18:21.657: INFO: Got endpoints: latency-svc-xnzfz [292.230685ms]
May 29 17:18:21.664: INFO: Created: latency-svc-4vmhh
May 29 17:18:21.669: INFO: Got endpoints: latency-svc-4vmhh [292.204677ms]
May 29 17:18:21.709: INFO: Created: latency-svc-skx6b
May 29 17:18:21.714: INFO: Got endpoints: latency-svc-skx6b [298.549962ms]
May 29 17:18:21.724: INFO: Created: latency-svc-pjcmp
May 29 17:18:21.738: INFO: Got endpoints: latency-svc-pjcmp [309.599867ms]
May 29 17:18:21.743: INFO: Created: latency-svc-vsn2c
May 29 17:18:21.748: INFO: Got endpoints: latency-svc-vsn2c [304.6683ms]
May 29 17:18:21.756: INFO: Created: latency-svc-krg92
May 29 17:18:21.761: INFO: Got endpoints: latency-svc-krg92 [303.767125ms]
May 29 17:18:21.769: INFO: Created: latency-svc-72hrp
May 29 17:18:21.808: INFO: Created: latency-svc-zlqxj
May 29 17:18:21.813: INFO: Got endpoints: latency-svc-zlqxj [307.149157ms]
May 29 17:18:21.813: INFO: Got endpoints: latency-svc-72hrp [343.253009ms]
May 29 17:18:21.822: INFO: Created: latency-svc-5xkrt
May 29 17:18:21.827: INFO: Got endpoints: latency-svc-5xkrt [299.234299ms]
May 29 17:18:21.836: INFO: Created: latency-svc-r6nlz
May 29 17:18:21.841: INFO: Got endpoints: latency-svc-r6nlz [303.382041ms]
May 29 17:18:21.849: INFO: Created: latency-svc-jddmx
May 29 17:18:21.854: INFO: Got endpoints: latency-svc-jddmx [300.772863ms]
May 29 17:18:21.865: INFO: Created: latency-svc-rpmc6
May 29 17:18:21.909: INFO: Got endpoints: latency-svc-rpmc6 [343.792283ms]
May 29 17:18:21.910: INFO: Created: latency-svc-zm9jr
May 29 17:18:21.921: INFO: Got endpoints: latency-svc-zm9jr [307.990289ms]
May 29 17:18:21.926: INFO: Created: latency-svc-ng4pz
May 29 17:18:21.941: INFO: Created: latency-svc-vg7wg
May 29 17:18:21.958: INFO: Created: latency-svc-jsfvc
May 29 17:18:21.972: INFO: Got endpoints: latency-svc-ng4pz [341.883632ms]
May 29 17:18:22.004: INFO: Created: latency-svc-g8gx4
May 29 17:18:22.023: INFO: Got endpoints: latency-svc-vg7wg [381.206629ms]
May 29 17:18:22.026: INFO: Created: latency-svc-jtxh4
May 29 17:18:22.045: INFO: Created: latency-svc-jm2mr
May 29 17:18:22.063: INFO: Created: latency-svc-77vc7
May 29 17:18:22.072: INFO: Got endpoints: latency-svc-jsfvc [415.372495ms]
May 29 17:18:22.106: INFO: Created: latency-svc-g4wl7
May 29 17:18:22.124: INFO: Got endpoints: latency-svc-g8gx4 [454.162619ms]
May 29 17:18:22.125: INFO: Created: latency-svc-z9ghb
May 29 17:18:22.143: INFO: Created: latency-svc-wxlr6
May 29 17:18:22.161: INFO: Created: latency-svc-pqqlc
May 29 17:18:22.172: INFO: Got endpoints: latency-svc-jtxh4 [458.047126ms]
May 29 17:18:22.205: INFO: Created: latency-svc-7dkf9
May 29 17:18:22.205: INFO: Created: latency-svc-p64hl
May 29 17:18:22.230: INFO: Got endpoints: latency-svc-jm2mr [491.861019ms]
May 29 17:18:22.232: INFO: Created: latency-svc-fkmq6
May 29 17:18:22.248: INFO: Created: latency-svc-srdv9
May 29 17:18:22.274: INFO: Created: latency-svc-nb679
May 29 17:18:22.275: INFO: Got endpoints: latency-svc-77vc7 [526.937138ms]
May 29 17:18:22.277: INFO: Created: latency-svc-szsct
May 29 17:18:22.306: INFO: Created: latency-svc-7p9ql
May 29 17:18:22.316: INFO: Created: latency-svc-mqjlj
May 29 17:18:22.321: INFO: Got endpoints: latency-svc-g4wl7 [560.052438ms]
May 29 17:18:22.335: INFO: Created: latency-svc-4hgtn
May 29 17:18:22.349: INFO: Created: latency-svc-whcxm
May 29 17:18:22.365: INFO: Created: latency-svc-kxkfm
May 29 17:18:22.606: INFO: Created: latency-svc-mmb4m
May 29 17:18:22.709: INFO: Got endpoints: latency-svc-p64hl [854.537734ms]
May 29 17:18:22.709: INFO: Got endpoints: latency-svc-wxlr6 [894.809996ms]
May 29 17:18:22.709: INFO: Got endpoints: latency-svc-z9ghb [895.666547ms]
May 29 17:18:22.709: INFO: Got endpoints: latency-svc-7dkf9 [868.058305ms]
May 29 17:18:22.709: INFO: Got endpoints: latency-svc-pqqlc [882.074049ms]
May 29 17:18:22.807: INFO: Got endpoints: latency-svc-nb679 [834.994524ms]
May 29 17:18:22.807: INFO: Got endpoints: latency-svc-srdv9 [885.728654ms]
May 29 17:18:22.807: INFO: Got endpoints: latency-svc-fkmq6 [898.355515ms]
May 29 17:18:22.907: INFO: Got endpoints: latency-svc-szsct [884.193636ms]
May 29 17:18:23.006: INFO: Got endpoints: latency-svc-7p9ql [934.431935ms]
May 29 17:18:23.008: INFO: Got endpoints: latency-svc-mqjlj [883.372321ms]
May 29 17:18:23.012: INFO: Got endpoints: latency-svc-4hgtn [839.855385ms]
May 29 17:18:23.012: INFO: Created: latency-svc-cv58g
May 29 17:18:23.012: INFO: Got endpoints: latency-svc-whcxm [781.861481ms]
May 29 17:18:23.112: INFO: Got endpoints: latency-svc-kxkfm [837.552424ms]
May 29 17:18:23.121: INFO: Got endpoints: latency-svc-cv58g [412.20124ms]
May 29 17:18:23.121: INFO: Got endpoints: latency-svc-mmb4m [800.211426ms]
May 29 17:18:23.123: INFO: Created: latency-svc-q9rxr
May 29 17:18:23.138: INFO: Created: latency-svc-j6xkc
May 29 17:18:23.209: INFO: Got endpoints: latency-svc-q9rxr [500.44698ms]
May 29 17:18:23.217: INFO: Created: latency-svc-ldtqw
May 29 17:18:23.220: INFO: Got endpoints: latency-svc-j6xkc [510.986705ms]
May 29 17:18:23.231: INFO: Created: latency-svc-qs455
May 29 17:18:23.245: INFO: Created: latency-svc-44p8p
May 29 17:18:23.258: INFO: Created: latency-svc-f6vng
May 29 17:18:23.271: INFO: Got endpoints: latency-svc-ldtqw [561.786049ms]
May 29 17:18:23.272: INFO: Created: latency-svc-rjfqg
May 29 17:18:23.305: INFO: Created: latency-svc-xghsf
May 29 17:18:23.320: INFO: Created: latency-svc-bdn48
May 29 17:18:23.320: INFO: Got endpoints: latency-svc-qs455 [610.877039ms]
May 29 17:18:23.333: INFO: Created: latency-svc-zhpbg
May 29 17:18:23.347: INFO: Created: latency-svc-ghmxk
May 29 17:18:23.364: INFO: Created: latency-svc-rjkgb
May 29 17:18:23.374: INFO: Got endpoints: latency-svc-44p8p [566.98081ms]
May 29 17:18:23.376: INFO: Created: latency-svc-wvfm2
May 29 17:18:23.391: INFO: Created: latency-svc-d5mvb
May 29 17:18:23.417: INFO: Created: latency-svc-f84l5
May 29 17:18:23.421: INFO: Got endpoints: latency-svc-f6vng [613.252667ms]
May 29 17:18:23.431: INFO: Created: latency-svc-rhd79
May 29 17:18:23.445: INFO: Created: latency-svc-dpkv6
May 29 17:18:23.459: INFO: Created: latency-svc-6n2lc
May 29 17:18:23.472: INFO: Got endpoints: latency-svc-rjfqg [664.761454ms]
May 29 17:18:23.473: INFO: Created: latency-svc-kvxx2
May 29 17:18:23.487: INFO: Created: latency-svc-gv6g9
May 29 17:18:23.516: INFO: Created: latency-svc-jtxh5
May 29 17:18:23.521: INFO: Got endpoints: latency-svc-xghsf [613.472931ms]
May 29 17:18:23.529: INFO: Created: latency-svc-nmf8n
May 29 17:18:23.544: INFO: Created: latency-svc-gczrj
May 29 17:18:23.574: INFO: Got endpoints: latency-svc-bdn48 [566.109491ms]
May 29 17:18:23.606: INFO: Created: latency-svc-7pnmr
May 29 17:18:23.621: INFO: Got endpoints: latency-svc-zhpbg [608.162512ms]
May 29 17:18:23.641: INFO: Created: latency-svc-kdrb6
May 29 17:18:23.671: INFO: Got endpoints: latency-svc-ghmxk [664.114658ms]
May 29 17:18:23.693: INFO: Created: latency-svc-h8lmw
May 29 17:18:23.721: INFO: Got endpoints: latency-svc-rjkgb [708.863961ms]
May 29 17:18:23.744: INFO: Created: latency-svc-2f8ds
May 29 17:18:23.771: INFO: Got endpoints: latency-svc-wvfm2 [658.434965ms]
May 29 17:18:23.793: INFO: Created: latency-svc-kgr4w
May 29 17:18:23.821: INFO: Got endpoints: latency-svc-d5mvb [699.916793ms]
May 29 17:18:23.847: INFO: Created: latency-svc-mt7xf
May 29 17:18:23.871: INFO: Got endpoints: latency-svc-f84l5 [750.065141ms]
May 29 17:18:23.894: INFO: Created: latency-svc-qk97r
May 29 17:18:23.921: INFO: Got endpoints: latency-svc-rhd79 [712.137289ms]
May 29 17:18:23.944: INFO: Created: latency-svc-qkzcb
May 29 17:18:23.971: INFO: Got endpoints: latency-svc-dpkv6 [751.286789ms]
May 29 17:18:23.992: INFO: Created: latency-svc-jdfwh
May 29 17:18:24.021: INFO: Got endpoints: latency-svc-6n2lc [750.052006ms]
May 29 17:18:24.043: INFO: Created: latency-svc-d8ks2
May 29 17:18:24.070: INFO: Got endpoints: latency-svc-kvxx2 [750.309752ms]
May 29 17:18:24.093: INFO: Created: latency-svc-kf45t
May 29 17:18:24.121: INFO: Got endpoints: latency-svc-gv6g9 [746.702286ms]
May 29 17:18:24.143: INFO: Created: latency-svc-q2fg8
May 29 17:18:24.172: INFO: Got endpoints: latency-svc-jtxh5 [750.420479ms]
May 29 17:18:24.193: INFO: Created: latency-svc-8c465
May 29 17:18:24.221: INFO: Got endpoints: latency-svc-nmf8n [748.097239ms]
May 29 17:18:24.244: INFO: Created: latency-svc-xh9ln
May 29 17:18:24.273: INFO: Got endpoints: latency-svc-gczrj [751.864485ms]
May 29 17:18:24.295: INFO: Created: latency-svc-f4hwq
May 29 17:18:24.322: INFO: Got endpoints: latency-svc-7pnmr [747.66694ms]
May 29 17:18:24.347: INFO: Created: latency-svc-mjtnf
May 29 17:18:24.371: INFO: Got endpoints: latency-svc-kdrb6 [750.668927ms]
May 29 17:18:24.394: INFO: Created: latency-svc-2kxrp
May 29 17:18:24.421: INFO: Got endpoints: latency-svc-h8lmw [750.381957ms]
May 29 17:18:24.443: INFO: Created: latency-svc-5vjf6
May 29 17:18:24.471: INFO: Got endpoints: latency-svc-2f8ds [750.139291ms]
May 29 17:18:24.494: INFO: Created: latency-svc-sqgs2
May 29 17:18:24.522: INFO: Got endpoints: latency-svc-kgr4w [750.873301ms]
May 29 17:18:24.544: INFO: Created: latency-svc-zg24t
May 29 17:18:24.571: INFO: Got endpoints: latency-svc-mt7xf [750.06964ms]
May 29 17:18:24.594: INFO: Created: latency-svc-hr8kr
May 29 17:18:24.621: INFO: Got endpoints: latency-svc-qk97r [749.436749ms]
May 29 17:18:24.643: INFO: Created: latency-svc-9h77l
May 29 17:18:24.672: INFO: Got endpoints: latency-svc-qkzcb [750.379883ms]
May 29 17:18:24.693: INFO: Created: latency-svc-9z6wr
May 29 17:18:24.722: INFO: Got endpoints: latency-svc-jdfwh [750.225363ms]
May 29 17:18:24.745: INFO: Created: latency-svc-vm24l
May 29 17:18:24.771: INFO: Got endpoints: latency-svc-d8ks2 [749.784573ms]
May 29 17:18:24.793: INFO: Created: latency-svc-ntzrk
May 29 17:18:24.821: INFO: Got endpoints: latency-svc-kf45t [750.930098ms]
May 29 17:18:24.843: INFO: Created: latency-svc-cgrhz
May 29 17:18:24.871: INFO: Got endpoints: latency-svc-q2fg8 [750.008635ms]
May 29 17:18:24.894: INFO: Created: latency-svc-jshpx
May 29 17:18:24.921: INFO: Got endpoints: latency-svc-8c465 [748.971424ms]
May 29 17:18:24.943: INFO: Created: latency-svc-kxrh5
May 29 17:18:24.971: INFO: Got endpoints: latency-svc-xh9ln [750.207709ms]
May 29 17:18:24.992: INFO: Created: latency-svc-7hrzx
May 29 17:18:25.021: INFO: Got endpoints: latency-svc-f4hwq [747.680816ms]
May 29 17:18:25.044: INFO: Created: latency-svc-kwj4j
May 29 17:18:25.072: INFO: Got endpoints: latency-svc-mjtnf [749.630533ms]
May 29 17:18:25.096: INFO: Created: latency-svc-hmrl7
May 29 17:18:25.121: INFO: Got endpoints: latency-svc-2kxrp [748.704802ms]
May 29 17:18:25.144: INFO: Created: latency-svc-qqxrq
May 29 17:18:25.172: INFO: Got endpoints: latency-svc-5vjf6 [750.204664ms]
May 29 17:18:25.194: INFO: Created: latency-svc-6zd6s
May 29 17:18:25.221: INFO: Got endpoints: latency-svc-sqgs2 [750.10717ms]
May 29 17:18:25.244: INFO: Created: latency-svc-gz96d
May 29 17:18:25.272: INFO: Got endpoints: latency-svc-zg24t [749.774274ms]
May 29 17:18:25.295: INFO: Created: latency-svc-9vz5m
May 29 17:18:25.322: INFO: Got endpoints: latency-svc-hr8kr [749.874011ms]
May 29 17:18:25.348: INFO: Created: latency-svc-x9g66
May 29 17:18:25.372: INFO: Got endpoints: latency-svc-9h77l [751.136777ms]
May 29 17:18:25.394: INFO: Created: latency-svc-c4q4l
May 29 17:18:25.420: INFO: Got endpoints: latency-svc-9z6wr [747.945544ms]
May 29 17:18:25.444: INFO: Created: latency-svc-mll25
May 29 17:18:25.472: INFO: Got endpoints: latency-svc-vm24l [750.230462ms]
May 29 17:18:25.493: INFO: Created: latency-svc-lqswx
May 29 17:18:25.521: INFO: Got endpoints: latency-svc-ntzrk [749.484448ms]
May 29 17:18:25.541: INFO: Created: latency-svc-xfzfb
May 29 17:18:25.571: INFO: Got endpoints: latency-svc-cgrhz [749.24004ms]
May 29 17:18:25.593: INFO: Created: latency-svc-wv88q
May 29 17:18:25.622: INFO: Got endpoints: latency-svc-jshpx [750.504216ms]
May 29 17:18:25.645: INFO: Created: latency-svc-fwpkh
May 29 17:18:25.672: INFO: Got endpoints: latency-svc-kxrh5 [751.285677ms]
May 29 17:18:25.695: INFO: Created: latency-svc-cz6st
May 29 17:18:25.722: INFO: Got endpoints: latency-svc-7hrzx [750.642667ms]
May 29 17:18:25.746: INFO: Created: latency-svc-j4dpn
May 29 17:18:25.771: INFO: Got endpoints: latency-svc-kwj4j [749.681259ms]
May 29 17:18:25.794: INFO: Created: latency-svc-jx5vq
May 29 17:18:25.821: INFO: Got endpoints: latency-svc-hmrl7 [748.276207ms]
May 29 17:18:25.844: INFO: Created: latency-svc-4gtjk
May 29 17:18:25.871: INFO: Got endpoints: latency-svc-qqxrq [750.392487ms]
May 29 17:18:26.017: INFO: Got endpoints: latency-svc-gz96d [795.227972ms]
May 29 17:18:26.017: INFO: Got endpoints: latency-svc-6zd6s [844.997448ms]
May 29 17:18:26.114: INFO: Got endpoints: latency-svc-x9g66 [792.221196ms]
May 29 17:18:26.115: INFO: Got endpoints: latency-svc-9vz5m [842.50562ms]
May 29 17:18:26.312: INFO: Got endpoints: latency-svc-mll25 [891.982647ms]
May 29 17:18:26.313: INFO: Got endpoints: latency-svc-c4q4l [940.712959ms]
May 29 17:18:26.313: INFO: Created: latency-svc-gss6x
May 29 17:18:26.415: INFO: Got endpoints: latency-svc-xfzfb [894.505794ms]
May 29 17:18:26.416: INFO: Got endpoints: latency-svc-lqswx [943.630467ms]
May 29 17:18:26.416: INFO: Got endpoints: latency-svc-wv88q [844.596143ms]
May 29 17:18:26.416: INFO: Got endpoints: latency-svc-fwpkh [794.087897ms]
May 29 17:18:26.419: INFO: Created: latency-svc-7smj7
May 29 17:18:26.422: INFO: Got endpoints: latency-svc-cz6st [748.995539ms]
May 29 17:18:26.506: INFO: Created: latency-svc-gbzrx
May 29 17:18:26.511: INFO: Got endpoints: latency-svc-j4dpn [788.702658ms]
May 29 17:18:26.519: INFO: Created: latency-svc-grtlh
May 29 17:18:26.521: INFO: Got endpoints: latency-svc-4gtjk [699.489458ms]
May 29 17:18:26.533: INFO: Created: latency-svc-pm5jk
May 29 17:18:26.548: INFO: Created: latency-svc-7dj2s
May 29 17:18:26.605: INFO: Created: latency-svc-6l5nz
May 29 17:18:26.608: INFO: Got endpoints: latency-svc-jx5vq [836.562542ms]
May 29 17:18:26.620: INFO: Created: latency-svc-dbpj2
May 29 17:18:26.621: INFO: Got endpoints: latency-svc-gss6x [749.558789ms]
May 29 17:18:26.635: INFO: Created: latency-svc-dj4hn
May 29 17:18:26.649: INFO: Created: latency-svc-2rjvk
May 29 17:18:26.663: INFO: Created: latency-svc-62j4p
May 29 17:18:26.675: INFO: Got endpoints: latency-svc-7smj7 [658.606387ms]
May 29 17:18:26.707: INFO: Created: latency-svc-nnrxr
May 29 17:18:26.720: INFO: Created: latency-svc-tk49p
May 29 17:18:26.720: INFO: Got endpoints: latency-svc-gbzrx [702.864737ms]
May 29 17:18:26.734: INFO: Created: latency-svc-ps2fk
May 29 17:18:26.748: INFO: Created: latency-svc-m8rrx
May 29 17:18:26.764: INFO: Created: latency-svc-7xjhx
May 29 17:18:26.776: INFO: Got endpoints: latency-svc-grtlh [661.237957ms]
May 29 17:18:26.783: INFO: Created: latency-svc-sqwp9
May 29 17:18:26.819: INFO: Created: latency-svc-q6l7k
May 29 17:18:26.821: INFO: Got endpoints: latency-svc-pm5jk [705.590454ms]
May 29 17:18:26.835: INFO: Created: latency-svc-v4j9b
May 29 17:18:26.850: INFO: Created: latency-svc-brkt5
May 29 17:18:26.871: INFO: Got endpoints: latency-svc-7dj2s [558.381455ms]
May 29 17:18:26.895: INFO: Created: latency-svc-cnmh8
May 29 17:18:26.924: INFO: Got endpoints: latency-svc-6l5nz [611.511552ms]
May 29 17:18:26.946: INFO: Created: latency-svc-bhn6n
May 29 17:18:26.971: INFO: Got endpoints: latency-svc-dbpj2 [554.82246ms]
May 29 17:18:26.994: INFO: Created: latency-svc-blsz6
May 29 17:18:27.022: INFO: Got endpoints: latency-svc-dj4hn [606.255555ms]
May 29 17:18:27.042: INFO: Created: latency-svc-7xjbw
May 29 17:18:27.071: INFO: Got endpoints: latency-svc-2rjvk [654.584141ms]
May 29 17:18:27.092: INFO: Created: latency-svc-nrdsb
May 29 17:18:27.121: INFO: Got endpoints: latency-svc-62j4p [705.257448ms]
May 29 17:18:27.145: INFO: Created: latency-svc-2lrbx
May 29 17:18:27.171: INFO: Got endpoints: latency-svc-nnrxr [749.349144ms]
May 29 17:18:27.193: INFO: Created: latency-svc-nhh4c
May 29 17:18:27.221: INFO: Got endpoints: latency-svc-tk49p [710.36172ms]
May 29 17:18:27.242: INFO: Created: latency-svc-k5ffl
May 29 17:18:27.272: INFO: Got endpoints: latency-svc-ps2fk [751.656806ms]
May 29 17:18:27.322: INFO: Got endpoints: latency-svc-m8rrx [714.066988ms]
May 29 17:18:27.373: INFO: Got endpoints: latency-svc-7xjhx [751.135244ms]
May 29 17:18:27.421: INFO: Got endpoints: latency-svc-sqwp9 [745.398303ms]
May 29 17:18:27.472: INFO: Got endpoints: latency-svc-q6l7k [752.088697ms]
May 29 17:18:27.521: INFO: Got endpoints: latency-svc-v4j9b [745.28518ms]
May 29 17:18:27.572: INFO: Got endpoints: latency-svc-brkt5 [751.029394ms]
May 29 17:18:27.621: INFO: Got endpoints: latency-svc-cnmh8 [750.369454ms]
May 29 17:18:27.672: INFO: Got endpoints: latency-svc-bhn6n [747.828193ms]
May 29 17:18:27.722: INFO: Got endpoints: latency-svc-blsz6 [750.377408ms]
May 29 17:18:27.771: INFO: Got endpoints: latency-svc-7xjbw [749.398307ms]
May 29 17:18:27.821: INFO: Got endpoints: latency-svc-nrdsb [750.338907ms]
May 29 17:18:27.878: INFO: Got endpoints: latency-svc-2lrbx [756.740257ms]
May 29 17:18:27.921: INFO: Got endpoints: latency-svc-nhh4c [749.356438ms]
May 29 17:18:27.972: INFO: Got endpoints: latency-svc-k5ffl [750.342713ms]
May 29 17:18:27.972: INFO: Latencies: [26.014244ms 26.346638ms 43.507428ms 51.697723ms 90.957281ms 106.743675ms 117.375593ms 124.199329ms 142.541661ms 189.642526ms 197.509756ms 215.324215ms 224.112095ms 236.140851ms 290.609616ms 290.680139ms 292.204677ms 292.230685ms 292.378533ms 294.480808ms 297.073985ms 298.549962ms 299.234299ms 300.772863ms 303.382041ms 303.767125ms 304.348078ms 304.6683ms 305.505816ms 305.811832ms 307.149157ms 307.333854ms 307.984578ms 307.990289ms 308.551104ms 309.509397ms 309.599867ms 310.720225ms 312.389294ms 313.486358ms 313.971861ms 313.986789ms 315.749484ms 316.851016ms 317.521437ms 317.728105ms 318.451337ms 319.127519ms 319.730562ms 320.410442ms 320.661524ms 320.868243ms 321.455687ms 323.895767ms 323.970267ms 333.619367ms 336.279391ms 341.883632ms 343.253009ms 343.792283ms 353.124466ms 358.426741ms 362.480826ms 369.136436ms 381.206629ms 412.20124ms 415.372495ms 441.565495ms 454.162619ms 458.047126ms 491.861019ms 500.44698ms 510.986705ms 526.937138ms 554.82246ms 558.381455ms 560.052438ms 561.786049ms 566.109491ms 566.98081ms 606.255555ms 608.162512ms 610.877039ms 611.511552ms 613.252667ms 613.472931ms 654.584141ms 658.434965ms 658.606387ms 661.237957ms 664.114658ms 664.761454ms 699.489458ms 699.916793ms 702.864737ms 705.257448ms 705.590454ms 708.863961ms 710.36172ms 712.137289ms 714.066988ms 745.28518ms 745.398303ms 746.702286ms 747.66694ms 747.680816ms 747.828193ms 747.945544ms 748.097239ms 748.276207ms 748.704802ms 748.971424ms 748.995539ms 749.24004ms 749.349144ms 749.356438ms 749.398307ms 749.436749ms 749.484448ms 749.558789ms 749.630533ms 749.681259ms 749.774274ms 749.784573ms 749.874011ms 750.008635ms 750.052006ms 750.065141ms 750.06964ms 750.10717ms 750.139291ms 750.204664ms 750.207709ms 750.225363ms 750.230462ms 750.309752ms 750.338907ms 750.342713ms 750.369454ms 750.377408ms 750.379883ms 750.381957ms 750.392487ms 750.420479ms 750.504216ms 750.642667ms 750.668927ms 750.873301ms 750.930098ms 751.029394ms 751.135244ms 751.136777ms 751.285677ms 751.286789ms 751.656806ms 751.864485ms 752.088697ms 756.740257ms 781.861481ms 788.702658ms 792.221196ms 794.087897ms 795.227972ms 800.211426ms 834.994524ms 836.562542ms 837.552424ms 839.855385ms 842.50562ms 844.596143ms 844.997448ms 854.537734ms 868.058305ms 882.074049ms 883.372321ms 884.193636ms 885.728654ms 891.982647ms 894.505794ms 894.809996ms 895.666547ms 898.355515ms 934.431935ms 940.712959ms 943.630467ms 1.069347902s 1.147731711s 1.153347695s 1.16560474s 1.167772177s 1.171167615s 1.173955528s 1.178482594s 1.180529263s 1.180974722s 1.181044863s 1.182695998s 1.184969125s 1.189324728s 1.19033097s]
May 29 17:18:27.973: INFO: 50 %ile: 714.066988ms
May 29 17:18:27.973: INFO: 90 %ile: 895.666547ms
May 29 17:18:27.973: INFO: 99 %ile: 1.189324728s
May 29 17:18:27.973: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:27.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6801" for this suite.
May 29 17:18:42.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:42.291: INFO: namespace svc-latency-6801 deletion completed in 14.308416208s

• [SLOW TEST:26.257 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:18:42.291: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:18:42.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f" in namespace "projected-5659" to be "success or failure"
May 29 17:18:42.478: INFO: Pod "downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.382408ms
May 29 17:18:44.486: INFO: Pod "downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017786s
May 29 17:18:46.495: INFO: Pod "downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026383156s
STEP: Saw pod success
May 29 17:18:46.495: INFO: Pod "downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:18:46.507: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:18:46.544: INFO: Waiting for pod downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:18:46.550: INFO: Pod downwardapi-volume-ceb83c9b-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:46.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5659" for this suite.
May 29 17:18:52.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:52.822: INFO: namespace projected-5659 deletion completed in 6.262403354s

• [SLOW TEST:10.531 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:18:52.823: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-18
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
May 29 17:18:53.533: INFO: created pod pod-service-account-defaultsa
May 29 17:18:53.533: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 29 17:18:53.540: INFO: created pod pod-service-account-mountsa
May 29 17:18:53.542: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 29 17:18:53.551: INFO: created pod pod-service-account-nomountsa
May 29 17:18:53.551: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 29 17:18:53.558: INFO: created pod pod-service-account-defaultsa-mountspec
May 29 17:18:53.558: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 29 17:18:53.566: INFO: created pod pod-service-account-mountsa-mountspec
May 29 17:18:53.566: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 29 17:18:53.573: INFO: created pod pod-service-account-nomountsa-mountspec
May 29 17:18:53.573: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 29 17:18:53.580: INFO: created pod pod-service-account-defaultsa-nomountspec
May 29 17:18:53.580: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 29 17:18:53.588: INFO: created pod pod-service-account-mountsa-nomountspec
May 29 17:18:53.588: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 29 17:18:53.608: INFO: created pod pod-service-account-nomountsa-nomountspec
May 29 17:18:53.608: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:53.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-18" for this suite.
May 29 17:18:59.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:59.861: INFO: namespace svcaccounts-18 deletion completed in 6.243923253s

• [SLOW TEST:7.038 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:18:59.862: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-d930a73a-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:19:00.043: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f" in namespace "projected-6276" to be "success or failure"
May 29 17:19:00.049: INFO: Pod "pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.268842ms
May 29 17:19:02.058: INFO: Pod "pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015254488s
May 29 17:19:04.066: INFO: Pod "pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022949546s
STEP: Saw pod success
May 29 17:19:04.066: INFO: Pod "pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:19:04.074: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:19:04.105: INFO: Waiting for pod pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:19:04.112: INFO: Pod pod-projected-secrets-d931c691-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:04.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6276" for this suite.
May 29 17:19:10.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:10.377: INFO: namespace projected-6276 deletion completed in 6.251251805s

• [SLOW TEST:10.516 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:19:10.379: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-df76347e-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:19:10.568: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f" in namespace "projected-5451" to be "success or failure"
May 29 17:19:10.574: INFO: Pod "pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.261348ms
May 29 17:19:12.582: INFO: Pod "pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014310211s
May 29 17:19:14.591: INFO: Pod "pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022969121s
STEP: Saw pod success
May 29 17:19:14.591: INFO: Pod "pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:19:14.599: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:19:14.707: INFO: Waiting for pod pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:19:15.112: INFO: Pod pod-projected-secrets-df779cf8-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:15.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5451" for this suite.
May 29 17:19:21.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:21.459: INFO: namespace projected-5451 deletion completed in 6.253881048s

• [SLOW TEST:11.080 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:19:21.460: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8207
STEP: Creating secret with name secret-test-e6174459-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:19:21.855: INFO: Waiting up to 5m0s for pod "pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f" in namespace "secrets-2668" to be "success or failure"
May 29 17:19:21.862: INFO: Pod "pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.637795ms
May 29 17:19:23.870: INFO: Pod "pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015624161s
May 29 17:19:25.880: INFO: Pod "pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025681101s
STEP: Saw pod success
May 29 17:19:25.881: INFO: Pod "pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:19:25.889: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:19:25.929: INFO: Waiting for pod pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:19:25.935: INFO: Pod pod-secrets-e631f04d-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:25.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2668" for this suite.
May 29 17:19:31.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:32.240: INFO: namespace secrets-2668 deletion completed in 6.295431101s
STEP: Destroying namespace "secret-namespace-8207" for this suite.
May 29 17:19:38.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:38.545: INFO: namespace secret-namespace-8207 deletion completed in 6.30552536s

• [SLOW TEST:17.086 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:19:38.549: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3432
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f040b12d-8235-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:19:38.736: INFO: Waiting up to 5m0s for pod "pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f" in namespace "secrets-3432" to be "success or failure"
May 29 17:19:38.743: INFO: Pod "pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.529491ms
May 29 17:19:40.751: INFO: Pod "pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014927951s
May 29 17:19:42.760: INFO: Pod "pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024121827s
STEP: Saw pod success
May 29 17:19:42.760: INFO: Pod "pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:19:42.768: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:19:42.807: INFO: Waiting for pod pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f to disappear
May 29 17:19:42.814: INFO: Pod pod-secrets-f041dbf5-8235-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:42.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3432" for this suite.
May 29 17:19:48.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:49.065: INFO: namespace secrets-3432 deletion completed in 6.242995179s

• [SLOW TEST:10.516 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:19:49.066: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8038
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 17:19:49.234: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 29 17:20:09.357: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.124 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8038 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:20:09.357: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:20:10.540: INFO: Found all expected endpoints: [netserver-0]
May 29 17:20:10.547: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.109 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8038 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:20:10.547: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:20:11.731: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:20:11.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8038" for this suite.
May 29 17:20:33.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:20:33.988: INFO: namespace pod-network-test-8038 deletion completed in 22.248689935s

• [SLOW TEST:44.923 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:20:33.989: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:20:34.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f" in namespace "projected-8314" to be "success or failure"
May 29 17:20:34.249: INFO: Pod "downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.442879ms
May 29 17:20:36.257: INFO: Pod "downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015564625s
May 29 17:20:38.266: INFO: Pod "downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0241847s
STEP: Saw pod success
May 29 17:20:38.266: INFO: Pod "downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:20:38.273: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:20:38.304: INFO: Waiting for pod downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:20:38.310: INFO: Pod downwardapi-volume-1157576a-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:20:38.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8314" for this suite.
May 29 17:20:44.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:20:44.561: INFO: namespace projected-8314 deletion completed in 6.242018063s

• [SLOW TEST:10.572 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:20:44.561: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4618
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-179be84d-8236-11e9-abea-da3eb1f4b18f
STEP: Creating configMap with name cm-test-opt-upd-179be89f-8236-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-179be84d-8236-11e9-abea-da3eb1f4b18f
STEP: Updating configmap cm-test-opt-upd-179be89f-8236-11e9-abea-da3eb1f4b18f
STEP: Creating configMap with name cm-test-opt-create-179be8b9-8236-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:20:53.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4618" for this suite.
May 29 17:21:15.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:15.266: INFO: namespace configmap-4618 deletion completed in 22.251028865s

• [SLOW TEST:30.705 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:21:15.267: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j7qf8 in namespace proxy-2925
I0529 17:21:15.472624      18 runners.go:184] Created replication controller with name: proxy-service-j7qf8, namespace: proxy-2925, replica count: 1
I0529 17:21:16.523128      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:17.523405      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:18.523683      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:19.524170      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:20.524531      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:21.524838      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:22.525157      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:23.525632      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:21:24.525939      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 17:21:25.530826      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 17:21:26.531072      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 17:21:27.531405      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 17:21:28.531734      18 runners.go:184] proxy-service-j7qf8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 17:21:28.539: INFO: setup took 13.100462019s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 29 17:21:28.555: INFO: (0) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 13.845774ms)
May 29 17:21:28.555: INFO: (0) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 14.511696ms)
May 29 17:21:28.555: INFO: (0) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 14.335335ms)
May 29 17:21:28.604: INFO: (0) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 63.568972ms)
May 29 17:21:28.604: INFO: (0) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 63.017085ms)
May 29 17:21:28.604: INFO: (0) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 64.515023ms)
May 29 17:21:28.604: INFO: (0) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 62.67946ms)
May 29 17:21:28.604: INFO: (0) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 62.913079ms)
May 29 17:21:28.607: INFO: (0) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 65.926757ms)
May 29 17:21:28.607: INFO: (0) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 65.511126ms)
May 29 17:21:28.607: INFO: (0) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 66.554427ms)
May 29 17:21:28.612: INFO: (0) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 71.640104ms)
May 29 17:21:28.612: INFO: (0) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 71.364295ms)
May 29 17:21:28.613: INFO: (0) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 71.282702ms)
May 29 17:21:28.613: INFO: (0) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 71.537181ms)
May 29 17:21:28.616: INFO: (0) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 76.189212ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 9.72383ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 8.608142ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.656323ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 9.784714ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 9.178985ms)
May 29 17:21:28.627: INFO: (1) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.784073ms)
May 29 17:21:28.628: INFO: (1) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.321134ms)
May 29 17:21:28.628: INFO: (1) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 10.189286ms)
May 29 17:21:28.628: INFO: (1) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.910082ms)
May 29 17:21:28.628: INFO: (1) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.09513ms)
May 29 17:21:28.628: INFO: (1) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 11.867663ms)
May 29 17:21:28.629: INFO: (1) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 10.522723ms)
May 29 17:21:28.629: INFO: (1) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 12.155224ms)
May 29 17:21:28.629: INFO: (1) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 11.475715ms)
May 29 17:21:28.629: INFO: (1) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 11.593287ms)
May 29 17:21:28.630: INFO: (1) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 12.143662ms)
May 29 17:21:28.639: INFO: (2) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 9.056696ms)
May 29 17:21:28.639: INFO: (2) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.214753ms)
May 29 17:21:28.640: INFO: (2) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 9.035426ms)
May 29 17:21:28.640: INFO: (2) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.524155ms)
May 29 17:21:28.640: INFO: (2) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 9.213742ms)
May 29 17:21:28.640: INFO: (2) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.004377ms)
May 29 17:21:28.640: INFO: (2) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 10.590141ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 9.974943ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.299513ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.85051ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 10.912106ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 10.253047ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 10.91937ms)
May 29 17:21:28.641: INFO: (2) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.532844ms)
May 29 17:21:28.642: INFO: (2) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 10.697121ms)
May 29 17:21:28.706: INFO: (2) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 75.435734ms)
May 29 17:21:28.728: INFO: (3) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 21.268736ms)
May 29 17:21:28.728: INFO: (3) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 20.674228ms)
May 29 17:21:28.728: INFO: (3) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 21.458403ms)
May 29 17:21:28.728: INFO: (3) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 20.425802ms)
May 29 17:21:28.728: INFO: (3) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 21.482349ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 20.961609ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 21.194957ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 21.782712ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 21.076475ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 20.964815ms)
May 29 17:21:28.729: INFO: (3) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 21.654813ms)
May 29 17:21:28.735: INFO: (3) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 27.590698ms)
May 29 17:21:28.735: INFO: (3) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 27.742984ms)
May 29 17:21:28.735: INFO: (3) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 27.293589ms)
May 29 17:21:28.735: INFO: (3) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 27.57585ms)
May 29 17:21:28.735: INFO: (3) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 28.748937ms)
May 29 17:21:28.746: INFO: (4) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.084068ms)
May 29 17:21:28.746: INFO: (4) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 10.449376ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.073429ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 10.102924ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.877631ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 11.443676ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 10.318098ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.097845ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.8761ms)
May 29 17:21:28.747: INFO: (4) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 11.591534ms)
May 29 17:21:28.749: INFO: (4) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 12.433097ms)
May 29 17:21:28.749: INFO: (4) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 12.100681ms)
May 29 17:21:28.749: INFO: (4) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 13.507578ms)
May 29 17:21:28.749: INFO: (4) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 13.690131ms)
May 29 17:21:28.749: INFO: (4) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 13.552432ms)
May 29 17:21:28.804: INFO: (4) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 67.585257ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 20.651555ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 20.705146ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 20.647638ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 21.315435ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 20.552991ms)
May 29 17:21:28.826: INFO: (5) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 21.771844ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 20.555475ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 21.405183ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 21.805626ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 21.219262ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 21.442092ms)
May 29 17:21:28.827: INFO: (5) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 21.742489ms)
May 29 17:21:28.868: INFO: (5) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 63.850892ms)
May 29 17:21:28.868: INFO: (5) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 63.082218ms)
May 29 17:21:28.868: INFO: (5) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 63.560447ms)
May 29 17:21:28.868: INFO: (5) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 62.703785ms)
May 29 17:21:28.878: INFO: (6) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 8.532018ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 34.487821ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 35.186425ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 34.568043ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 34.312672ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 35.364551ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 35.097859ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 34.161427ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 35.570527ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 34.597737ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 34.509432ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 34.998733ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 34.91293ms)
May 29 17:21:28.904: INFO: (6) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 35.805219ms)
May 29 17:21:28.905: INFO: (6) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 35.660126ms)
May 29 17:21:28.908: INFO: (6) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 37.658044ms)
May 29 17:21:28.917: INFO: (7) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.227667ms)
May 29 17:21:28.917: INFO: (7) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 8.954794ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.591852ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 9.478549ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 9.881297ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 9.922574ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 9.64905ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 9.787681ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 9.469292ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.45775ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.591272ms)
May 29 17:21:28.918: INFO: (7) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 10.422785ms)
May 29 17:21:28.920: INFO: (7) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.709736ms)
May 29 17:21:28.920: INFO: (7) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 11.497838ms)
May 29 17:21:28.920: INFO: (7) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 11.609758ms)
May 29 17:21:28.920: INFO: (7) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 11.531461ms)
May 29 17:21:28.931: INFO: (8) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.421152ms)
May 29 17:21:28.931: INFO: (8) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.255931ms)
May 29 17:21:28.931: INFO: (8) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 11.177234ms)
May 29 17:21:28.931: INFO: (8) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.108976ms)
May 29 17:21:28.931: INFO: (8) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 11.363204ms)
May 29 17:21:29.007: INFO: (8) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 86.847911ms)
May 29 17:21:29.007: INFO: (8) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 87.540112ms)
May 29 17:21:29.007: INFO: (8) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 87.325778ms)
May 29 17:21:29.007: INFO: (8) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 87.189273ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 87.615735ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 87.45915ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 87.764885ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 87.290743ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 87.916459ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 87.463809ms)
May 29 17:21:29.008: INFO: (8) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 87.658776ms)
May 29 17:21:29.035: INFO: (9) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 27.083414ms)
May 29 17:21:29.035: INFO: (9) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 27.322413ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 27.436499ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 27.875254ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 27.557486ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 27.868279ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 27.610786ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 27.535775ms)
May 29 17:21:29.036: INFO: (9) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 28.246702ms)
May 29 17:21:29.037: INFO: (9) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 28.317165ms)
May 29 17:21:29.039: INFO: (9) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 30.19125ms)
May 29 17:21:29.039: INFO: (9) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 30.928206ms)
May 29 17:21:29.039: INFO: (9) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 31.264158ms)
May 29 17:21:29.040: INFO: (9) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 31.343126ms)
May 29 17:21:29.040: INFO: (9) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 31.340401ms)
May 29 17:21:29.040: INFO: (9) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 31.958293ms)
May 29 17:21:29.050: INFO: (10) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.353744ms)
May 29 17:21:29.050: INFO: (10) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 9.645213ms)
May 29 17:21:29.050: INFO: (10) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.884843ms)
May 29 17:21:29.050: INFO: (10) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.354666ms)
May 29 17:21:29.051: INFO: (10) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 8.910952ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 10.334548ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.004979ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 9.828517ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.338868ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 10.11759ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 11.472259ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 10.452511ms)
May 29 17:21:29.052: INFO: (10) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.519017ms)
May 29 17:21:29.053: INFO: (10) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 11.261703ms)
May 29 17:21:29.053: INFO: (10) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 12.911236ms)
May 29 17:21:29.104: INFO: (10) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 61.783334ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.502978ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 10.714383ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 12.102564ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.334502ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 11.46689ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.87098ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 11.109097ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 12.465738ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 12.086255ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 12.14821ms)
May 29 17:21:29.116: INFO: (11) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 11.034616ms)
May 29 17:21:29.160: INFO: (11) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 55.299499ms)
May 29 17:21:29.160: INFO: (11) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 55.760475ms)
May 29 17:21:29.160: INFO: (11) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 55.699059ms)
May 29 17:21:29.160: INFO: (11) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 55.206944ms)
May 29 17:21:29.160: INFO: (11) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 56.318444ms)
May 29 17:21:29.207: INFO: (12) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 46.68796ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 45.096075ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 46.575398ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 45.094882ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 47.3373ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 45.349621ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 45.823765ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 46.913334ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 46.692207ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 46.363629ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 45.852197ms)
May 29 17:21:29.208: INFO: (12) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 46.285613ms)
May 29 17:21:29.256: INFO: (12) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 95.228304ms)
May 29 17:21:29.256: INFO: (12) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 94.583722ms)
May 29 17:21:29.256: INFO: (12) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 94.112725ms)
May 29 17:21:29.256: INFO: (12) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 93.683848ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 11.134384ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.210386ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 10.498247ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 9.946719ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.530636ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 9.722778ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.020949ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.194075ms)
May 29 17:21:29.267: INFO: (13) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.506963ms)
May 29 17:21:29.268: INFO: (13) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.518604ms)
May 29 17:21:29.269: INFO: (13) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 12.322439ms)
May 29 17:21:29.269: INFO: (13) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 13.061649ms)
May 29 17:21:29.270: INFO: (13) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 12.230305ms)
May 29 17:21:29.270: INFO: (13) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 11.573288ms)
May 29 17:21:29.270: INFO: (13) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 11.752466ms)
May 29 17:21:29.313: INFO: (13) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 55.648044ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.434608ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.193234ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 10.264288ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.597393ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 10.530357ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 11.084389ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 10.139703ms)
May 29 17:21:29.324: INFO: (14) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.843446ms)
May 29 17:21:29.325: INFO: (14) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 11.052549ms)
May 29 17:21:29.325: INFO: (14) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.97856ms)
May 29 17:21:29.325: INFO: (14) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 10.395724ms)
May 29 17:21:29.326: INFO: (14) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 12.288555ms)
May 29 17:21:29.326: INFO: (14) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 11.881889ms)
May 29 17:21:29.327: INFO: (14) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 12.328088ms)
May 29 17:21:29.327: INFO: (14) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 13.162899ms)
May 29 17:21:29.327: INFO: (14) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 12.888043ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 10.661094ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.072276ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.583088ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 11.350911ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 10.100509ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 11.299465ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.996365ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 10.712892ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 11.60036ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 10.662576ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 12.012576ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 10.593376ms)
May 29 17:21:29.339: INFO: (15) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 11.672797ms)
May 29 17:21:29.340: INFO: (15) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 11.317969ms)
May 29 17:21:29.340: INFO: (15) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 12.215237ms)
May 29 17:21:29.340: INFO: (15) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 11.938998ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 66.850375ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 66.847689ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 67.488044ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 67.859793ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 68.105747ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 66.811482ms)
May 29 17:21:29.408: INFO: (16) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 66.536064ms)
May 29 17:21:29.409: INFO: (16) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 67.571422ms)
May 29 17:21:29.409: INFO: (16) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 66.822914ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 69.766912ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 69.722127ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 69.653818ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 69.408868ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 70.247255ms)
May 29 17:21:29.411: INFO: (16) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 70.495132ms)
May 29 17:21:29.412: INFO: (16) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 69.7768ms)
May 29 17:21:29.422: INFO: (17) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.243067ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 10.03724ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 8.946158ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 8.732215ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.137267ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 8.647295ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 10.074169ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 10.674378ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 11.237838ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 9.767953ms)
May 29 17:21:29.423: INFO: (17) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 9.547438ms)
May 29 17:21:29.424: INFO: (17) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 9.993668ms)
May 29 17:21:29.425: INFO: (17) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 10.007123ms)
May 29 17:21:29.425: INFO: (17) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 12.524178ms)
May 29 17:21:29.425: INFO: (17) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 11.591053ms)
May 29 17:21:29.425: INFO: (17) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 10.725575ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 83.23757ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 82.799966ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 83.061078ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 82.702674ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 82.615018ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 83.042894ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 82.971078ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 83.388042ms)
May 29 17:21:29.508: INFO: (18) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 83.302632ms)
May 29 17:21:29.509: INFO: (18) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 83.692976ms)
May 29 17:21:29.509: INFO: (18) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 83.51962ms)
May 29 17:21:29.510: INFO: (18) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 84.466161ms)
May 29 17:21:29.510: INFO: (18) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 84.595844ms)
May 29 17:21:29.510: INFO: (18) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 85.577602ms)
May 29 17:21:29.511: INFO: (18) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 85.614441ms)
May 29 17:21:29.512: INFO: (18) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 87.280354ms)
May 29 17:21:29.522: INFO: (19) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:460/proxy/: tls baz (200; 9.816955ms)
May 29 17:21:29.522: INFO: (19) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">test<... (200; 9.818227ms)
May 29 17:21:29.522: INFO: (19) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 9.483638ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:443/proxy/tlsrewritem... (200; 10.28672ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 9.866027ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq/proxy/rewriteme">test</a> (200; 10.333747ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:160/proxy/: foo (200; 10.908589ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/: <a href="/api/v1/namespaces/proxy-2925/pods/http:proxy-service-j7qf8-6j4hq:1080/proxy/rewriteme">... (200; 10.480735ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname1/proxy/: tls baz (200; 10.994621ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/proxy-service-j7qf8-6j4hq:162/proxy/: bar (200; 10.46251ms)
May 29 17:21:29.523: INFO: (19) /api/v1/namespaces/proxy-2925/pods/https:proxy-service-j7qf8-6j4hq:462/proxy/: tls qux (200; 10.397888ms)
May 29 17:21:29.524: INFO: (19) /api/v1/namespaces/proxy-2925/services/https:proxy-service-j7qf8:tlsportname2/proxy/: tls qux (200; 10.704344ms)
May 29 17:21:29.526: INFO: (19) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname1/proxy/: foo (200; 13.31211ms)
May 29 17:21:29.527: INFO: (19) /api/v1/namespaces/proxy-2925/services/proxy-service-j7qf8:portname2/proxy/: bar (200; 14.144505ms)
May 29 17:21:29.527: INFO: (19) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname2/proxy/: bar (200; 14.379808ms)
May 29 17:21:29.528: INFO: (19) /api/v1/namespaces/proxy-2925/services/http:proxy-service-j7qf8:portname1/proxy/: foo (200; 14.07776ms)
STEP: deleting ReplicationController proxy-service-j7qf8 in namespace proxy-2925, will wait for the garbage collector to delete the pods
May 29 17:21:29.620: INFO: Deleting ReplicationController proxy-service-j7qf8 took: 32.809674ms
May 29 17:21:30.021: INFO: Terminating ReplicationController proxy-service-j7qf8 pods took: 400.229749ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:39.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2925" for this suite.
May 29 17:21:45.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:45.477: INFO: namespace proxy-2925 deletion completed in 6.245643173s

• [SLOW TEST:30.211 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:21:45.478: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:21:45.653: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f" in namespace "projected-6582" to be "success or failure"
May 29 17:21:45.661: INFO: Pod "downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.60258ms
May 29 17:21:47.669: INFO: Pod "downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015702213s
May 29 17:21:49.678: INFO: Pod "downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025118411s
STEP: Saw pod success
May 29 17:21:49.679: INFO: Pod "downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:21:49.685: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:21:49.718: INFO: Waiting for pod downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:21:49.724: INFO: Pod downwardapi-volume-3be8014d-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:49.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6582" for this suite.
May 29 17:21:55.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:55.987: INFO: namespace projected-6582 deletion completed in 6.254645816s

• [SLOW TEST:10.509 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:21:55.987: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7954
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:21:56.186: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 29 17:21:56.202: INFO: Number of nodes with available pods: 0
May 29 17:21:56.202: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 29 17:21:56.233: INFO: Number of nodes with available pods: 0
May 29 17:21:56.233: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:21:57.240: INFO: Number of nodes with available pods: 0
May 29 17:21:57.240: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:21:58.241: INFO: Number of nodes with available pods: 0
May 29 17:21:58.241: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:21:59.241: INFO: Number of nodes with available pods: 1
May 29 17:21:59.241: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 29 17:21:59.275: INFO: Number of nodes with available pods: 1
May 29 17:21:59.275: INFO: Number of running nodes: 0, number of available pods: 1
May 29 17:22:00.283: INFO: Number of nodes with available pods: 0
May 29 17:22:00.283: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 29 17:22:00.299: INFO: Number of nodes with available pods: 0
May 29 17:22:00.299: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:01.308: INFO: Number of nodes with available pods: 0
May 29 17:22:01.308: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:02.308: INFO: Number of nodes with available pods: 0
May 29 17:22:02.308: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:03.307: INFO: Number of nodes with available pods: 0
May 29 17:22:03.307: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:04.307: INFO: Number of nodes with available pods: 0
May 29 17:22:04.307: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:05.308: INFO: Number of nodes with available pods: 0
May 29 17:22:05.308: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:06.307: INFO: Number of nodes with available pods: 0
May 29 17:22:06.307: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:07.307: INFO: Number of nodes with available pods: 0
May 29 17:22:07.307: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:08.306: INFO: Number of nodes with available pods: 0
May 29 17:22:08.306: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:09.308: INFO: Number of nodes with available pods: 0
May 29 17:22:09.308: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:10.308: INFO: Number of nodes with available pods: 0
May 29 17:22:10.314: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:11.308: INFO: Number of nodes with available pods: 0
May 29 17:22:11.308: INFO: Node scw-sono14-default-174540dd770e42e2af1af25266f is running more than one daemon pod
May 29 17:22:12.310: INFO: Number of nodes with available pods: 1
May 29 17:22:12.310: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7954, will wait for the garbage collector to delete the pods
May 29 17:22:12.394: INFO: Deleting DaemonSet.extensions daemon-set took: 12.889997ms
May 29 17:22:12.795: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.584586ms
May 29 17:22:15.903: INFO: Number of nodes with available pods: 0
May 29 17:22:15.903: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:22:15.909: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7954/daemonsets","resourceVersion":"948438948"},"items":null}

May 29 17:22:15.915: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7954/pods","resourceVersion":"948438948"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:22:15.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7954" for this suite.
May 29 17:22:21.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:22:22.207: INFO: namespace daemonsets-7954 deletion completed in 6.252451547s

• [SLOW TEST:26.220 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:22:22.208: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:22:26.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5792" for this suite.
May 29 17:23:06.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:23:06.698: INFO: namespace kubelet-test-5792 deletion completed in 40.25129815s

• [SLOW TEST:44.490 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:23:06.698: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:23:06.869: INFO: Creating deployment "nginx-deployment"
May 29 17:23:06.876: INFO: Waiting for observed generation 1
May 29 17:23:08.945: INFO: Waiting for all required pods to come up
May 29 17:23:08.956: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 29 17:23:10.972: INFO: Waiting for deployment "nginx-deployment" to complete
May 29 17:23:10.984: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 29 17:23:11.000: INFO: Updating deployment nginx-deployment
May 29 17:23:11.000: INFO: Waiting for observed generation 2
May 29 17:23:13.015: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 29 17:23:13.021: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 29 17:23:13.028: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 29 17:23:13.049: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 29 17:23:13.049: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 29 17:23:13.056: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 29 17:23:13.068: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 29 17:23:13.068: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 29 17:23:13.088: INFO: Updating deployment nginx-deployment
May 29 17:23:13.088: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 29 17:23:13.100: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 29 17:23:15.115: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 29 17:23:15.128: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3888,SelfLink:/apis/apps/v1/namespaces/deployment-3888/deployments/nginx-deployment,UID:6c5360ad-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443470,Generation:3,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-29 17:23:13 +0000 UTC 2019-05-29 17:23:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-29 17:23:13 +0000 UTC 2019-05-29 17:23:06 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 29 17:23:15.136: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-3888,SelfLink:/apis/apps/v1/namespaces/deployment-3888/replicasets/nginx-deployment-5f9595f595,UID:6ec93dea-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443455,Generation:3,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6c5360ad-8236-11e9-85f5-12d277f6ce64 0xc001202bc7 0xc001202bc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 17:23:15.136: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 29 17:23:15.136: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-3888,SelfLink:/apis/apps/v1/namespaces/deployment-3888/replicasets/nginx-deployment-6f478d8d8,UID:6c543bef-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443451,Generation:3,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6c5360ad-8236-11e9-85f5-12d277f6ce64 0xc001202db7 0xc001202db8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 29 17:23:15.150: INFO: Pod "nginx-deployment-5f9595f595-2n9zj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2n9zj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-2n9zj,UID:700bf0e1-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443596,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295c4b7 0xc00295c4b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295c520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295c540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.150: INFO: Pod "nginx-deployment-5f9595f595-dj844" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dj844,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-dj844,UID:700bca06-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443536,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295c617 0xc00295c618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295c680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295c6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.150: INFO: Pod "nginx-deployment-5f9595f595-fzhz7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fzhz7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-fzhz7,UID:700bdcef-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443591,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295c777 0xc00295c778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295c7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295c800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-g5pml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g5pml,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-g5pml,UID:6ecae1c7-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443201,Generation:0,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295c8d7 0xc00295c8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295c950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295c970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-gl228" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-gl228,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-gl228,UID:7009d523-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443481,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295ca47 0xc00295ca48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295cab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295cad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-kzzt5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-kzzt5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-kzzt5,UID:700bc64d-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443563,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295cba7 0xc00295cba8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295cc10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295cc30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-lv6n9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lv6n9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-lv6n9,UID:6ed9cbd2-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443224,Generation:0,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295cd07 0xc00295cd08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295cd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295cd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-p9g2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-p9g2f,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-p9g2f,UID:6ec9f666-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443176,Generation:0,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295ce67 0xc00295ce68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295ced0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295cef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.151: INFO: Pod "nginx-deployment-5f9595f595-qcj26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qcj26,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-qcj26,UID:6ecaf0e6-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443179,Generation:0,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295cfc7 0xc00295cfc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-5f9595f595-r4b77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-r4b77,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-r4b77,UID:700ac43b-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443437,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295d127 0xc00295d128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-5f9595f595-srv22" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-srv22,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-srv22,UID:6edac0bb-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443228,Generation:0,CreationTimestamp:2019-05-29 17:23:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295d287 0xc00295d288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:11 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-5f9595f595-td8cp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-td8cp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-td8cp,UID:7019b718-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443456,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295d3e7 0xc00295d3e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-5f9595f595-x6f6z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-x6f6z,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-5f9595f595-x6f6z,UID:700ade95-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443505,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 6ec93dea-8236-11e9-85f5-12d277f6ce64 0xc00295d4f7 0xc00295d4f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-6f478d8d8-2q7zb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2q7zb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-2q7zb,UID:700adf8c-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443498,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295d657 0xc00295d658}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-6f478d8d8-4jxcq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4jxcq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-4jxcq,UID:6c577b99-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443008,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295d7a7 0xc00295d7a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.130,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://40627b4600e7858b157da5567bd381ff25b2c2bc91e08ca2fa9371dbc47bba2e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.152: INFO: Pod "nginx-deployment-6f478d8d8-4svd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4svd8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-4svd8,UID:700bdb48-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443633,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295d907 0xc00295d908}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295d970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295d990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-594zg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-594zg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-594zg,UID:7009cdc9-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443472,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295da57 0xc00295da58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295dac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295dae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-6g8bb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6g8bb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-6g8bb,UID:6c58c89f-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443121,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295dba7 0xc00295dba8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295dc10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295dc30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.132,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6f3c75bb9c6ef976e47afedfcf0552f9f87f8db87aa645a785a90c09af0f10f5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-8jjrh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8jjrh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-8jjrh,UID:6c59f3a9-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443114,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295dd07 0xc00295dd08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295dd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295dd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.133,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://61b2ccd5492dc924108bf8c4682ea2a1878b86ae7fabd264ec42d63251906c31}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-8l2vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8l2vg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-8l2vg,UID:700bd1b4-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443445,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295de67 0xc00295de68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295ded0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00295def0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-957zj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-957zj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-957zj,UID:7009c90f-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443434,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc00295df77 0xc00295df78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00295dfe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013900b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-b254c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-b254c,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-b254c,UID:6c58ebcc-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443082,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001390257 0xc001390258}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013902c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013902e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.114,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:08 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://29abec22e0b707e5bf933c21b6fb9b03268b126f7ad2a730d6cee8c9f910b775}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-bx9zt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bx9zt,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-bx9zt,UID:6c58ec27-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443118,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001390597 0xc001390598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001390670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001390690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.134,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b496465b57624a05c0fc3b8b42b5b206b905640eb186658bb712c6e45460c86c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.153: INFO: Pod "nginx-deployment-6f478d8d8-cdtpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cdtpn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-cdtpn,UID:700beb23-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443566,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001390797 0xc001390798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001390800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001390820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-jzqv5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jzqv5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-jzqv5,UID:700af170-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443464,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001390b07 0xc001390b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001390cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001390d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-ksrm7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ksrm7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-ksrm7,UID:700bf8c1-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443630,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001390f07 0xc001390f08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001390fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001390ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-lt2fs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lt2fs,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-lt2fs,UID:700af798-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443532,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391197 0xc001391198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001391300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001391320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-ppdxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ppdxb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-ppdxb,UID:700bfb0b-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443446,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391457 0xc001391458}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013914c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013914e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-sbt4w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sbt4w,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-sbt4w,UID:7008f7c0-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443454,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391567 0xc001391568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013915d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013915f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-t2nxh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-t2nxh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-t2nxh,UID:6c569009-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443076,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc0013917a7 0xc0013917a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001391810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001391830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.113,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:08 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://fc7eeedfa0ea1f79e291bbce795e1585c5e40e995f732e1eb0545d85883b714c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-tf6np" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tf6np,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-tf6np,UID:6c59db74-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443069,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391927 0xc001391928}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001391990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013919b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.115,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e93e964b4a68e9140408d64f7a45cb6584045f9339ba4ca1e0da959d97abe366}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.154: INFO: Pod "nginx-deployment-6f478d8d8-vwwhb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vwwhb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-vwwhb,UID:700ace5a-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443460,Generation:0,CreationTimestamp:2019-05-29 17:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391b47 0xc001391b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001391cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001391d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:13 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:,StartTime:2019-05-29 17:23:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 17:23:15.155: INFO: Pod "nginx-deployment-6f478d8d8-zv7c7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zv7c7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3888,SelfLink:/api/v1/namespaces/deployment-3888/pods/nginx-deployment-6f478d8d8-zv7c7,UID:6c59fea4-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948443087,Generation:0,CreationTimestamp:2019-05-29 17:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 6c543bef-8236-11e9-85f5-12d277f6ce64 0xc001391ef7 0xc001391ef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-62q6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62q6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62q6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-e0a3711c5d19438ba264d7868f9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001391f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001391f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:23:06 +0000 UTC  }],Message:,Reason:,HostIP:10.12.141.205,PodIP:100.64.0.116,StartTime:2019-05-29 17:23:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 17:23:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7ada4ef7e98d572e44f21a828ebb670e5a5cf2f64a6b8bf9796ce7bfba469590}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:15.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3888" for this suite.
May 29 17:23:23.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:23:23.458: INFO: namespace deployment-3888 deletion completed in 8.294977103s

• [SLOW TEST:16.759 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:23:23.458: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
May 29 17:23:23.629: INFO: Waiting up to 5m0s for pod "var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f" in namespace "var-expansion-1861" to be "success or failure"
May 29 17:23:23.636: INFO: Pod "var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.968107ms
May 29 17:23:25.645: INFO: Pod "var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015985322s
May 29 17:23:27.653: INFO: Pod "var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023682373s
STEP: Saw pod success
May 29 17:23:27.653: INFO: Pod "var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:23:27.660: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 17:23:27.689: INFO: Waiting for pod var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:23:27.695: INFO: Pod var-expansion-764e0866-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:27.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1861" for this suite.
May 29 17:23:33.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:23:33.969: INFO: namespace var-expansion-1861 deletion completed in 6.266469316s

• [SLOW TEST:10.511 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:23:33.971: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-7c920d05-8236-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:23:34.150: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f" in namespace "configmap-2331" to be "success or failure"
May 29 17:23:34.157: INFO: Pod "pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.000988ms
May 29 17:23:36.165: INFO: Pod "pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013941698s
May 29 17:23:38.174: INFO: Pod "pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0235267s
STEP: Saw pod success
May 29 17:23:38.174: INFO: Pod "pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:23:38.181: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:23:38.215: INFO: Waiting for pod pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:23:38.222: INFO: Pod pod-configmaps-7c931da8-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:38.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2331" for this suite.
May 29 17:23:44.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:23:44.478: INFO: namespace configmap-2331 deletion completed in 6.246927917s

• [SLOW TEST:10.507 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:23:44.480: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:23:44.652: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f" in namespace "downward-api-3291" to be "success or failure"
May 29 17:23:44.659: INFO: Pod "downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253673ms
May 29 17:23:46.668: INFO: Pod "downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016099686s
May 29 17:23:48.677: INFO: Pod "downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024843245s
STEP: Saw pod success
May 29 17:23:48.677: INFO: Pod "downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:23:48.685: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:23:48.715: INFO: Waiting for pod downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:23:48.721: INFO: Pod downwardapi-volume-82d5d50f-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:48.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3291" for this suite.
May 29 17:23:54.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:23:54.975: INFO: namespace downward-api-3291 deletion completed in 6.246166566s

• [SLOW TEST:10.496 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:23:54.976: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 29 17:23:55.173: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4149,SelfLink:/api/v1/namespaces/watch-4149/configmaps/e2e-watch-test-watch-closed,UID:891ab9ab-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948446945,Generation:0,CreationTimestamp:2019-05-29 17:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 17:23:55.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4149,SelfLink:/api/v1/namespaces/watch-4149/configmaps/e2e-watch-test-watch-closed,UID:891ab9ab-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948446946,Generation:0,CreationTimestamp:2019-05-29 17:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 29 17:23:55.203: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4149,SelfLink:/api/v1/namespaces/watch-4149/configmaps/e2e-watch-test-watch-closed,UID:891ab9ab-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948446947,Generation:0,CreationTimestamp:2019-05-29 17:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 17:23:55.203: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4149,SelfLink:/api/v1/namespaces/watch-4149/configmaps/e2e-watch-test-watch-closed,UID:891ab9ab-8236-11e9-85f5-12d277f6ce64,ResourceVersion:948446948,Generation:0,CreationTimestamp:2019-05-29 17:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:55.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4149" for this suite.
May 29 17:24:01.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:24:01.481: INFO: namespace watch-4149 deletion completed in 6.268838619s

• [SLOW TEST:6.505 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:24:01.485: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 29 17:24:09.812: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:09.819: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:11.823: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:11.830: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:13.819: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:13.829: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:15.819: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:15.827: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:17.819: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:17.828: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:19.819: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:19.828: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:24:21.819: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:24:21.831: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:21.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4475" for this suite.
May 29 17:24:43.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:24:44.145: INFO: namespace container-lifecycle-hook-4475 deletion completed in 22.288286086s

• [SLOW TEST:42.660 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:24:44.145: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 29 17:24:44.304: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:48.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2039" for this suite.
May 29 17:25:10.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:25:11.169: INFO: namespace init-container-2039 deletion completed in 22.245507643s

• [SLOW TEST:27.024 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:25:11.169: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:25:11.344: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f" in namespace "projected-5376" to be "success or failure"
May 29 17:25:11.351: INFO: Pod "downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.281746ms
May 29 17:25:13.361: INFO: Pod "downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016429372s
May 29 17:25:15.370: INFO: Pod "downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025669263s
STEP: Saw pod success
May 29 17:25:15.370: INFO: Pod "downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:25:15.377: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:25:15.413: INFO: Waiting for pod downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:25:15.419: INFO: Pod downwardapi-volume-b681c77c-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:25:15.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5376" for this suite.
May 29 17:25:21.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:25:21.682: INFO: namespace projected-5376 deletion completed in 6.254528395s

• [SLOW TEST:10.513 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:25:21.683: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6238
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 29 17:25:21.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-6238'
May 29 17:25:22.628: INFO: stderr: ""
May 29 17:25:22.628: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:25:22.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:22.769: INFO: stderr: ""
May 29 17:25:22.769: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-zlnh8 "
May 29 17:25:22.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:22.899: INFO: stderr: ""
May 29 17:25:22.899: INFO: stdout: ""
May 29 17:25:22.899: INFO: update-demo-nautilus-grzbq is created but not running
May 29 17:25:27.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:28.050: INFO: stderr: ""
May 29 17:25:28.050: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-zlnh8 "
May 29 17:25:28.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:28.198: INFO: stderr: ""
May 29 17:25:28.198: INFO: stdout: "true"
May 29 17:25:28.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:28.326: INFO: stderr: ""
May 29 17:25:28.326: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:28.326: INFO: validating pod update-demo-nautilus-grzbq
May 29 17:25:28.425: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:28.425: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:28.425: INFO: update-demo-nautilus-grzbq is verified up and running
May 29 17:25:28.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-zlnh8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:28.557: INFO: stderr: ""
May 29 17:25:28.557: INFO: stdout: "true"
May 29 17:25:28.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-zlnh8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:28.682: INFO: stderr: ""
May 29 17:25:28.682: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:28.682: INFO: validating pod update-demo-nautilus-zlnh8
May 29 17:25:28.780: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:28.780: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:28.780: INFO: update-demo-nautilus-zlnh8 is verified up and running
STEP: scaling down the replication controller
May 29 17:25:28.782: INFO: scanned /root for discovery docs: <nil>
May 29 17:25:28.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6238'
May 29 17:25:29.965: INFO: stderr: ""
May 29 17:25:29.965: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:25:29.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:30.092: INFO: stderr: ""
May 29 17:25:30.092: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-zlnh8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 29 17:25:35.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:35.269: INFO: stderr: ""
May 29 17:25:35.269: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-zlnh8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 29 17:25:40.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:40.369: INFO: stderr: ""
May 29 17:25:40.369: INFO: stdout: "update-demo-nautilus-grzbq "
May 29 17:25:40.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:40.587: INFO: stderr: ""
May 29 17:25:40.587: INFO: stdout: "true"
May 29 17:25:40.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:40.706: INFO: stderr: ""
May 29 17:25:40.706: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:40.707: INFO: validating pod update-demo-nautilus-grzbq
May 29 17:25:40.715: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:40.715: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:40.715: INFO: update-demo-nautilus-grzbq is verified up and running
STEP: scaling up the replication controller
May 29 17:25:40.717: INFO: scanned /root for discovery docs: <nil>
May 29 17:25:40.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6238'
May 29 17:25:41.891: INFO: stderr: ""
May 29 17:25:41.891: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:25:41.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:42.024: INFO: stderr: ""
May 29 17:25:42.024: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-xmf2p "
May 29 17:25:42.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:42.148: INFO: stderr: ""
May 29 17:25:42.148: INFO: stdout: "true"
May 29 17:25:42.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:42.284: INFO: stderr: ""
May 29 17:25:42.284: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:42.284: INFO: validating pod update-demo-nautilus-grzbq
May 29 17:25:42.293: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:42.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:42.293: INFO: update-demo-nautilus-grzbq is verified up and running
May 29 17:25:42.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-xmf2p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:42.410: INFO: stderr: ""
May 29 17:25:42.410: INFO: stdout: ""
May 29 17:25:42.410: INFO: update-demo-nautilus-xmf2p is created but not running
May 29 17:25:47.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6238'
May 29 17:25:47.526: INFO: stderr: ""
May 29 17:25:47.526: INFO: stdout: "update-demo-nautilus-grzbq update-demo-nautilus-xmf2p "
May 29 17:25:47.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:47.645: INFO: stderr: ""
May 29 17:25:47.645: INFO: stdout: "true"
May 29 17:25:47.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-grzbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:47.747: INFO: stderr: ""
May 29 17:25:47.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:47.747: INFO: validating pod update-demo-nautilus-grzbq
May 29 17:25:47.756: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:47.756: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:47.756: INFO: update-demo-nautilus-grzbq is verified up and running
May 29 17:25:47.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-xmf2p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:47.864: INFO: stderr: ""
May 29 17:25:47.864: INFO: stdout: "true"
May 29 17:25:47.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods update-demo-nautilus-xmf2p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6238'
May 29 17:25:48.024: INFO: stderr: ""
May 29 17:25:48.024: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:25:48.024: INFO: validating pod update-demo-nautilus-xmf2p
May 29 17:25:48.124: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:25:48.124: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:25:48.124: INFO: update-demo-nautilus-xmf2p is verified up and running
STEP: using delete to clean up resources
May 29 17:25:48.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-6238'
May 29 17:25:48.254: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:48.254: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 17:25:48.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6238'
May 29 17:25:48.381: INFO: stderr: "No resources found.\n"
May 29 17:25:48.381: INFO: stdout: ""
May 29 17:25:48.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=update-demo --namespace=kubectl-6238 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:25:48.495: INFO: stderr: ""
May 29 17:25:48.495: INFO: stdout: "update-demo-nautilus-grzbq\nupdate-demo-nautilus-xmf2p\n"
May 29 17:25:48.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6238'
May 29 17:25:49.164: INFO: stderr: "No resources found.\n"
May 29 17:25:49.164: INFO: stdout: ""
May 29 17:25:49.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=update-demo --namespace=kubectl-6238 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:25:49.324: INFO: stderr: ""
May 29 17:25:49.324: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:25:49.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6238" for this suite.
May 29 17:26:11.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:26:11.602: INFO: namespace kubectl-6238 deletion completed in 22.268123276s

• [SLOW TEST:49.919 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:26:11.602: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4640
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4640.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 130.213.33.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.33.213.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.213.33.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.33.213.130_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4640.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4640.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 130.213.33.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.33.213.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.213.33.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.33.213.130_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:26:15.952: INFO: Unable to read wheezy_udp@dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:15.997: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.008: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.017: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.505: INFO: Unable to read jessie_udp@dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.513: INFO: Unable to read jessie_tcp@dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.522: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.530: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local from pod dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f: the server could not find the requested resource (get pods dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f)
May 29 17:26:16.932: INFO: Lookups using dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f failed for: [wheezy_udp@dns-test-service.dns-4640.svc.cluster.local wheezy_tcp@dns-test-service.dns-4640.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local jessie_udp@dns-test-service.dns-4640.svc.cluster.local jessie_tcp@dns-test-service.dns-4640.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4640.svc.cluster.local]

May 29 17:26:23.320: INFO: DNS probes using dns-4640/dns-test-da8ba2cb-8236-11e9-abea-da3eb1f4b18f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:26:23.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4640" for this suite.
May 29 17:26:29.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:26:29.671: INFO: namespace dns-4640 deletion completed in 6.266737295s

• [SLOW TEST:18.069 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:26:29.673: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4275
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e54d8034-8236-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:26:29.862: INFO: Waiting up to 5m0s for pod "pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f" in namespace "configmap-4275" to be "success or failure"
May 29 17:26:29.869: INFO: Pod "pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.466955ms
May 29 17:26:31.877: INFO: Pod "pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01471633s
May 29 17:26:33.886: INFO: Pod "pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023169389s
STEP: Saw pod success
May 29 17:26:33.886: INFO: Pod "pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:26:33.893: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:26:33.929: INFO: Waiting for pod pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:26:33.934: INFO: Pod pod-configmaps-e54e9ec3-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:26:33.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4275" for this suite.
May 29 17:26:39.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:26:40.199: INFO: namespace configmap-4275 deletion completed in 6.256703742s

• [SLOW TEST:10.526 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:26:40.199: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 17:26:40.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7929'
May 29 17:26:40.488: INFO: stderr: ""
May 29 17:26:40.488: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
May 29 17:26:40.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete pods e2e-test-nginx-pod --namespace=kubectl-7929'
May 29 17:26:50.734: INFO: stderr: ""
May 29 17:26:50.735: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:26:50.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7929" for this suite.
May 29 17:26:56.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:26:56.988: INFO: namespace kubectl-7929 deletion completed in 6.244680686s

• [SLOW TEST:16.790 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:26:56.989: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 29 17:26:57.240: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 29 17:27:06.298: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:27:06.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5569" for this suite.
May 29 17:27:12.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:27:12.610: INFO: namespace pods-5569 deletion completed in 6.296908885s

• [SLOW TEST:15.621 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:27:12.610: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8647
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
May 29 17:27:12.788: INFO: Waiting up to 5m0s for pod "pod-fee4af75-8236-11e9-abea-da3eb1f4b18f" in namespace "emptydir-8647" to be "success or failure"
May 29 17:27:12.796: INFO: Pod "pod-fee4af75-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.502813ms
May 29 17:27:14.806: INFO: Pod "pod-fee4af75-8236-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017308083s
May 29 17:27:16.814: INFO: Pod "pod-fee4af75-8236-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025447962s
STEP: Saw pod success
May 29 17:27:16.814: INFO: Pod "pod-fee4af75-8236-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:27:16.821: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-fee4af75-8236-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:27:16.853: INFO: Waiting for pod pod-fee4af75-8236-11e9-abea-da3eb1f4b18f to disappear
May 29 17:27:16.859: INFO: Pod pod-fee4af75-8236-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:27:16.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8647" for this suite.
May 29 17:27:22.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:27:23.109: INFO: namespace emptydir-8647 deletion completed in 6.241956489s

• [SLOW TEST:10.498 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:27:23.109: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 29 17:27:23.288: INFO: Waiting up to 5m0s for pod "pod-0526dc83-8237-11e9-abea-da3eb1f4b18f" in namespace "emptydir-3649" to be "success or failure"
May 29 17:27:23.295: INFO: Pod "pod-0526dc83-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.930936ms
May 29 17:27:25.304: INFO: Pod "pod-0526dc83-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015854629s
May 29 17:27:27.317: INFO: Pod "pod-0526dc83-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028517556s
STEP: Saw pod success
May 29 17:27:27.317: INFO: Pod "pod-0526dc83-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:27:27.325: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-0526dc83-8237-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:27:27.358: INFO: Waiting for pod pod-0526dc83-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:27:27.364: INFO: Pod pod-0526dc83-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:27:27.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3649" for this suite.
May 29 17:27:33.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:27:33.652: INFO: namespace emptydir-3649 deletion completed in 6.280636405s

• [SLOW TEST:10.543 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:27:33.653: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1569
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-0b724d29-8237-11e9-abea-da3eb1f4b18f
STEP: Creating secret with name s-test-opt-upd-0b724d84-8237-11e9-abea-da3eb1f4b18f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0b724d29-8237-11e9-abea-da3eb1f4b18f
STEP: Updating secret s-test-opt-upd-0b724d84-8237-11e9-abea-da3eb1f4b18f
STEP: Creating secret with name s-test-opt-create-0b724db4-8237-11e9-abea-da3eb1f4b18f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:27:40.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1569" for this suite.
May 29 17:28:02.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:28:02.351: INFO: namespace projected-1569 deletion completed in 22.301919422s

• [SLOW TEST:28.698 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:28:02.352: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8240
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 17:28:02.526: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 29 17:28:28.667: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.138:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8240 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:28:28.667: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:28:28.886: INFO: Found all expected endpoints: [netserver-0]
May 29 17:28:28.894: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.157:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8240 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:28:28.894: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
May 29 17:28:29.097: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:28:29.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8240" for this suite.
May 29 17:28:51.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:28:51.344: INFO: namespace pod-network-test-8240 deletion completed in 22.237544552s

• [SLOW TEST:48.992 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:28:51.345: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 29 17:28:56.069: INFO: Successfully updated pod "pod-update-activedeadlineseconds-39be6ccb-8237-11e9-abea-da3eb1f4b18f"
May 29 17:28:56.069: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-39be6ccb-8237-11e9-abea-da3eb1f4b18f" in namespace "pods-513" to be "terminated due to deadline exceeded"
May 29 17:28:56.076: INFO: Pod "pod-update-activedeadlineseconds-39be6ccb-8237-11e9-abea-da3eb1f4b18f": Phase="Running", Reason="", readiness=true. Elapsed: 6.801825ms
May 29 17:28:58.084: INFO: Pod "pod-update-activedeadlineseconds-39be6ccb-8237-11e9-abea-da3eb1f4b18f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.015056868s
May 29 17:28:58.084: INFO: Pod "pod-update-activedeadlineseconds-39be6ccb-8237-11e9-abea-da3eb1f4b18f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:28:58.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-513" for this suite.
May 29 17:29:04.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:29:04.344: INFO: namespace pods-513 deletion completed in 6.249008689s

• [SLOW TEST:12.999 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:29:04.345: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 29 17:29:04.509: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 29 17:29:04.525: INFO: Pod name sample-pod: Found 0 pods out of 1
May 29 17:29:09.606: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 17:29:09.607: INFO: Creating deployment "test-rolling-update-deployment"
May 29 17:29:09.615: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 29 17:29:09.627: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 29 17:29:11.642: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 29 17:29:11.651: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747749, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747749, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747749, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747749, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:29:13.659: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 29 17:29:13.679: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9308,SelfLink:/apis/apps/v1/namespaces/deployment-9308/deployments/test-rolling-update-deployment,UID:4488faf2-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471286,Generation:1,CreationTimestamp:2019-05-29 17:29:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-29 17:29:09 +0000 UTC 2019-05-29 17:29:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-29 17:29:11 +0000 UTC 2019-05-29 17:29:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:29:13.687: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-9308,SelfLink:/apis/apps/v1/namespaces/deployment-9308/replicasets/test-rolling-update-deployment-67599b4d9,UID:448baf36-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471272,Generation:1,CreationTimestamp:2019-05-29 17:29:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4488faf2-8237-11e9-85f5-12d277f6ce64 0xc00267f290 0xc00267f291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 29 17:29:13.687: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 29 17:29:13.688: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9308,SelfLink:/apis/apps/v1/namespaces/deployment-9308/replicasets/test-rolling-update-controller,UID:417f2600-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471284,Generation:2,CreationTimestamp:2019-05-29 17:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4488faf2-8237-11e9-85f5-12d277f6ce64 0xc00267f1c7 0xc00267f1c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 17:29:13.695: INFO: Pod "test-rolling-update-deployment-67599b4d9-w6n6t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-w6n6t,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-9308,SelfLink:/api/v1/namespaces/deployment-9308/pods/test-rolling-update-deployment-67599b4d9-w6n6t,UID:449720fc-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471271,Generation:0,CreationTimestamp:2019-05-29 17:29:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 448baf36-8237-11e9-85f5-12d277f6ce64 0xc00267fbd0 0xc00267fbd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-w8v9l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w8v9l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-w8v9l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-sono14-default-174540dd770e42e2af1af25266f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00267fc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00267fc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:29:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:29:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:29:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:29:09 +0000 UTC  }],Message:,Reason:,HostIP:10.12.138.1,PodIP:100.64.1.160,StartTime:2019-05-29 17:29:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-29 17:29:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e0130e704f37e3ebc28545313bad9b4e62c751a9fadec53bfacae0385c1e2740}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:13.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9308" for this suite.
May 29 17:29:19.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:29:19.943: INFO: namespace deployment-9308 deletion completed in 6.238395586s

• [SLOW TEST:15.599 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:29:19.944: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 29 17:29:20.144: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471908,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 17:29:20.145: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471910,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 29 17:29:20.145: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948471913,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 29 17:29:30.202: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948472671,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 17:29:30.202: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948472672,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 29 17:29:30.202: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2283,SelfLink:/api/v1/namespaces/watch-2283/configmaps/e2e-watch-test-label-changed,UID:4acb8da6-8237-11e9-85f5-12d277f6ce64,ResourceVersion:948472674,Generation:0,CreationTimestamp:2019-05-29 17:29:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:30.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2283" for this suite.
May 29 17:29:36.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:29:37.150: INFO: namespace watch-2283 deletion completed in 6.937565904s

• [SLOW TEST:17.207 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:29:37.151: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0529 17:30:07.375465      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 17:30:07.375: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:30:07.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7499" for this suite.
May 29 17:30:13.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:30:13.681: INFO: namespace gc-7499 deletion completed in 6.299480553s

• [SLOW TEST:36.531 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:30:13.682: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 29 17:30:13.845: INFO: PodSpec: initContainers in spec.initContainers
May 29 17:30:56.635: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6ad1cc62-8237-11e9-abea-da3eb1f4b18f", GenerateName:"", Namespace:"init-container-3056", SelfLink:"/api/v1/namespaces/init-container-3056/pods/pod-init-6ad1cc62-8237-11e9-abea-da3eb1f4b18f", UID:"6ad3a779-8237-11e9-85f5-12d277f6ce64", ResourceVersion:"948479335", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694747813, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"845726906"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fm7gj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001fc4dc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fm7gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fm7gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fm7gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001060f48), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"scw-sono14-default-e0a3711c5d19438ba264d7868f9", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d93740), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001060fc0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001060ff0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001060ff8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001060ffc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747813, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747813, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747813, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694747813, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.12.141.205", PodIP:"100.64.0.141", StartTime:(*v1.Time)(0xc0021978a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000840620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000840700)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a50ab5a6d0681ae9cfbb8624298c0b8924eb154b2db8c457d399931990896588"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021978e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021978c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:30:56.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3056" for this suite.
May 29 17:31:18.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:18.936: INFO: namespace init-container-3056 deletion completed in 22.291093554s

• [SLOW TEST:65.254 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:31:18.936: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
May 29 17:31:19.115: INFO: Waiting up to 5m0s for pod "var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f" in namespace "var-expansion-8012" to be "success or failure"
May 29 17:31:19.123: INFO: Pod "var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.393397ms
May 29 17:31:21.130: INFO: Pod "var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014963931s
May 29 17:31:23.203: INFO: Pod "var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.08813639s
STEP: Saw pod success
May 29 17:31:23.204: INFO: Pod "var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:31:23.210: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 17:31:23.245: INFO: Waiting for pod var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:31:23.251: INFO: Pod var-expansion-91b6d704-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:23.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8012" for this suite.
May 29 17:31:29.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:29.502: INFO: namespace var-expansion-8012 deletion completed in 6.242416902s

• [SLOW TEST:10.566 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:31:29.503: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 29 17:31:29.684: INFO: Waiting up to 5m0s for pod "downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f" in namespace "downward-api-9410" to be "success or failure"
May 29 17:31:29.703: INFO: Pod "downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.349235ms
May 29 17:31:31.712: INFO: Pod "downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027105418s
May 29 17:31:33.720: INFO: Pod "downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035266843s
STEP: Saw pod success
May 29 17:31:33.720: INFO: Pod "downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:31:33.727: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 17:31:33.759: INFO: Waiting for pod downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:31:33.766: INFO: Pod downward-api-98042d36-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:33.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9410" for this suite.
May 29 17:31:39.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:40.012: INFO: namespace downward-api-9410 deletion completed in 6.237600082s

• [SLOW TEST:10.509 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:31:40.012: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 17:31:40.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-1195'
May 29 17:31:40.320: INFO: stderr: ""
May 29 17:31:40.320: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 29 17:31:45.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pod e2e-test-nginx-pod --namespace=kubectl-1195 -o json'
May 29 17:31:45.494: INFO: stderr: ""
May 29 17:31:45.494: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-29T17:31:40Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-1195\",\n        \"resourceVersion\": \"948482895\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1195/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9e595251-8237-11e9-b7d7-5638c02536be\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-cj8jn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"scw-sono14-default-174540dd770e42e2af1af25266f\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-cj8jn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-cj8jn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-29T17:31:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-29T17:31:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-29T17:31:42Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-29T17:31:40Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0413bdd0704d4cd554aa6ea75c2c70550c429694fd2d73b035fc1bdfe02565ce\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-29T17:31:41Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.12.138.1\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.164\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-29T17:31:40Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 29 17:31:45.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 replace -f - --namespace=kubectl-1195'
May 29 17:31:45.786: INFO: stderr: ""
May 29 17:31:45.786: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
May 29 17:31:45.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete pods e2e-test-nginx-pod --namespace=kubectl-1195'
May 29 17:31:47.579: INFO: stderr: ""
May 29 17:31:47.579: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:47.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1195" for this suite.
May 29 17:31:53.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:53.832: INFO: namespace kubectl-1195 deletion completed in 6.244843146s

• [SLOW TEST:13.820 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:31:53.833: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7650
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-a683fcde-8237-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:31:54.033: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f" in namespace "projected-7650" to be "success or failure"
May 29 17:31:54.042: INFO: Pod "pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.993807ms
May 29 17:31:56.050: INFO: Pod "pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016413015s
May 29 17:31:58.059: INFO: Pod "pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025271802s
STEP: Saw pod success
May 29 17:31:58.059: INFO: Pod "pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:31:58.066: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:31:58.101: INFO: Waiting for pod pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:31:58.108: INFO: Pod pod-projected-secrets-a686083f-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:58.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7650" for this suite.
May 29 17:32:04.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:04.372: INFO: namespace projected-7650 deletion completed in 6.256235255s

• [SLOW TEST:10.540 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:32:04.374: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:29.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2023" for this suite.
May 29 17:32:35.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:36.202: INFO: namespace container-runtime-2023 deletion completed in 6.231323875s

• [SLOW TEST:31.829 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:32:36.203: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:36.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3541" for this suite.
May 29 17:32:58.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:58.650: INFO: namespace pods-3541 deletion completed in 22.256854927s

• [SLOW TEST:22.448 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:32:58.650: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
May 29 17:32:58.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 create -f - --namespace=kubectl-7886'
May 29 17:32:59.163: INFO: stderr: ""
May 29 17:32:59.163: INFO: stdout: "pod/pause created\n"
May 29 17:32:59.163: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 29 17:32:59.163: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7886" to be "running and ready"
May 29 17:32:59.170: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.511449ms
May 29 17:33:01.178: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015082262s
May 29 17:33:03.186: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.023006309s
May 29 17:33:03.186: INFO: Pod "pause" satisfied condition "running and ready"
May 29 17:33:03.186: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
May 29 17:33:03.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 label pods pause testing-label=testing-label-value --namespace=kubectl-7886'
May 29 17:33:03.321: INFO: stderr: ""
May 29 17:33:03.321: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 29 17:33:03.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pod pause -L testing-label --namespace=kubectl-7886'
May 29 17:33:03.430: INFO: stderr: ""
May 29 17:33:03.430: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 29 17:33:03.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 label pods pause testing-label- --namespace=kubectl-7886'
May 29 17:33:03.557: INFO: stderr: ""
May 29 17:33:03.557: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 29 17:33:03.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pod pause -L testing-label --namespace=kubectl-7886'
May 29 17:33:03.662: INFO: stderr: ""
May 29 17:33:03.662: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
May 29 17:33:03.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete --grace-period=0 --force -f - --namespace=kubectl-7886'
May 29 17:33:03.806: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:33:03.806: INFO: stdout: "pod \"pause\" force deleted\n"
May 29 17:33:03.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get rc,svc -l name=pause --no-headers --namespace=kubectl-7886'
May 29 17:33:03.952: INFO: stderr: "No resources found.\n"
May 29 17:33:03.952: INFO: stdout: ""
May 29 17:33:03.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -l name=pause --namespace=kubectl-7886 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:33:04.088: INFO: stderr: ""
May 29 17:33:04.088: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:33:04.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7886" for this suite.
May 29 17:33:10.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:33:10.519: INFO: namespace kubectl-7886 deletion completed in 6.422526885s

• [SLOW TEST:11.869 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:33:10.520: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-d43938e1-8237-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume configMaps
May 29 17:33:10.704: INFO: Waiting up to 5m0s for pod "pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f" in namespace "configmap-9046" to be "success or failure"
May 29 17:33:10.711: INFO: Pod "pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994237ms
May 29 17:33:12.719: INFO: Pod "pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015085078s
May 29 17:33:14.727: INFO: Pod "pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023140803s
STEP: Saw pod success
May 29 17:33:14.727: INFO: Pod "pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:33:14.734: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:33:14.765: INFO: Waiting for pod pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:33:14.771: INFO: Pod pod-configmaps-d43a6006-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:33:14.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9046" for this suite.
May 29 17:33:20.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:33:21.010: INFO: namespace configmap-9046 deletion completed in 6.231655547s

• [SLOW TEST:10.491 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:33:21.010: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 29 17:33:21.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4471'
May 29 17:33:21.376: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 29 17:33:21.376: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 29 17:33:21.386: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 29 17:33:21.393: INFO: scanned /root for discovery docs: <nil>
May 29 17:33:21.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4471'
May 29 17:33:37.370: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 29 17:33:37.370: INFO: stdout: "Created e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560\nScaling up e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 29 17:33:37.370: INFO: stdout: "Created e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560\nScaling up e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 29 17:33:37.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4471'
May 29 17:33:37.519: INFO: stderr: ""
May 29 17:33:37.519: INFO: stdout: "e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560-dgj8r "
May 29 17:33:37.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560-dgj8r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4471'
May 29 17:33:37.639: INFO: stderr: ""
May 29 17:33:37.639: INFO: stdout: "true"
May 29 17:33:37.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 get pods e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560-dgj8r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4471'
May 29 17:33:37.752: INFO: stderr: ""
May 29 17:33:37.752: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 29 17:33:37.752: INFO: e2e-test-nginx-rc-33f012581c1d4da217bcfbee14d76560-dgj8r is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
May 29 17:33:37.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 delete rc e2e-test-nginx-rc --namespace=kubectl-4471'
May 29 17:33:37.875: INFO: stderr: ""
May 29 17:33:37.875: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:33:37.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4471" for this suite.
May 29 17:33:59.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:34:00.140: INFO: namespace kubectl-4471 deletion completed in 22.256270643s

• [SLOW TEST:39.130 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:34:00.144: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f1ce5e85-8237-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:34:00.336: INFO: Waiting up to 5m0s for pod "pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f" in namespace "secrets-8990" to be "success or failure"
May 29 17:34:00.347: INFO: Pod "pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.359878ms
May 29 17:34:02.355: INFO: Pod "pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019305256s
May 29 17:34:04.364: INFO: Pod "pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027941412s
STEP: Saw pod success
May 29 17:34:04.364: INFO: Pod "pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:34:04.371: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:34:04.409: INFO: Waiting for pod pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f to disappear
May 29 17:34:04.415: INFO: Pod pod-secrets-f1cfb7a8-8237-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:34:04.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8990" for this suite.
May 29 17:34:10.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:34:10.674: INFO: namespace secrets-8990 deletion completed in 6.251067902s

• [SLOW TEST:10.530 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:34:10.675: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 29 17:34:11.248: INFO: Pod name wrapped-volume-race-f84ee1ff-8237-11e9-abea-da3eb1f4b18f: Found 0 pods out of 5
May 29 17:34:16.260: INFO: Pod name wrapped-volume-race-f84ee1ff-8237-11e9-abea-da3eb1f4b18f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f84ee1ff-8237-11e9-abea-da3eb1f4b18f in namespace emptydir-wrapper-8233, will wait for the garbage collector to delete the pods
May 29 17:34:28.387: INFO: Deleting ReplicationController wrapped-volume-race-f84ee1ff-8237-11e9-abea-da3eb1f4b18f took: 14.26358ms
May 29 17:34:28.688: INFO: Terminating ReplicationController wrapped-volume-race-f84ee1ff-8237-11e9-abea-da3eb1f4b18f pods took: 300.261287ms
STEP: Creating RC which spawns configmap-volume pods
May 29 17:35:09.619: INFO: Pod name wrapped-volume-race-1b188cd1-8238-11e9-abea-da3eb1f4b18f: Found 0 pods out of 5
May 29 17:35:14.632: INFO: Pod name wrapped-volume-race-1b188cd1-8238-11e9-abea-da3eb1f4b18f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1b188cd1-8238-11e9-abea-da3eb1f4b18f in namespace emptydir-wrapper-8233, will wait for the garbage collector to delete the pods
May 29 17:35:26.758: INFO: Deleting ReplicationController wrapped-volume-race-1b188cd1-8238-11e9-abea-da3eb1f4b18f took: 14.627053ms
May 29 17:35:27.060: INFO: Terminating ReplicationController wrapped-volume-race-1b188cd1-8238-11e9-abea-da3eb1f4b18f pods took: 301.927191ms
STEP: Creating RC which spawns configmap-volume pods
May 29 17:36:09.191: INFO: Pod name wrapped-volume-race-3e9a8496-8238-11e9-abea-da3eb1f4b18f: Found 0 pods out of 5
May 29 17:36:14.206: INFO: Pod name wrapped-volume-race-3e9a8496-8238-11e9-abea-da3eb1f4b18f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3e9a8496-8238-11e9-abea-da3eb1f4b18f in namespace emptydir-wrapper-8233, will wait for the garbage collector to delete the pods
May 29 17:36:26.343: INFO: Deleting ReplicationController wrapped-volume-race-3e9a8496-8238-11e9-abea-da3eb1f4b18f took: 13.568492ms
May 29 17:36:26.644: INFO: Terminating ReplicationController wrapped-volume-race-3e9a8496-8238-11e9-abea-da3eb1f4b18f pods took: 300.324115ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:37:10.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8233" for this suite.
May 29 17:37:18.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:37:18.968: INFO: namespace emptydir-wrapper-8233 deletion completed in 8.239498435s

• [SLOW TEST:188.294 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:37:18.970: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-dfgv
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:37:19.162: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dfgv" in namespace "subpath-5473" to be "success or failure"
May 29 17:37:19.168: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Pending", Reason="", readiness=false. Elapsed: 5.774543ms
May 29 17:37:21.176: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013684331s
May 29 17:37:23.184: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 4.02220007s
May 29 17:37:25.193: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 6.030816527s
May 29 17:37:27.202: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 8.040529306s
May 29 17:37:29.210: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 10.048460746s
May 29 17:37:31.219: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 12.056856729s
May 29 17:37:33.227: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 14.06479427s
May 29 17:37:35.234: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 16.072558514s
May 29 17:37:37.242: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 18.08050989s
May 29 17:37:39.251: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 20.089556968s
May 29 17:37:41.263: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Running", Reason="", readiness=true. Elapsed: 22.101071007s
May 29 17:37:43.272: INFO: Pod "pod-subpath-test-projected-dfgv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.110081706s
STEP: Saw pod success
May 29 17:37:43.272: INFO: Pod "pod-subpath-test-projected-dfgv" satisfied condition "success or failure"
May 29 17:37:43.278: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-subpath-test-projected-dfgv container test-container-subpath-projected-dfgv: <nil>
STEP: delete the pod
May 29 17:37:43.314: INFO: Waiting for pod pod-subpath-test-projected-dfgv to disappear
May 29 17:37:43.319: INFO: Pod pod-subpath-test-projected-dfgv no longer exists
STEP: Deleting pod pod-subpath-test-projected-dfgv
May 29 17:37:43.319: INFO: Deleting pod "pod-subpath-test-projected-dfgv" in namespace "subpath-5473"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:37:43.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5473" for this suite.
May 29 17:37:49.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:37:49.604: INFO: namespace subpath-5473 deletion completed in 6.269787015s

• [SLOW TEST:30.634 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:37:49.604: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 29 17:37:49.827: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:37:49.843: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:37:49.850: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-174540dd770e42e2af1af25266f before test
May 29 17:37:49.864: INFO: sonobuoy-e2e-job-f013d2ad922949b9 from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container e2e ready: true, restart count 0
May 29 17:37:49.864: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:37:49.864: INFO: kube-proxy-9zfn6 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:37:49.864: INFO: flannel-2crp5 from kube-system started at 2019-05-29 16:02:29 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:37:49.864: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-6jrjh from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 29 17:37:49.864: INFO: 	Container systemd-logs ready: true, restart count 1
May 29 17:37:49.864: INFO: nginx-ingress-z47rs from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:37:49.864: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-29 16:06:56 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:37:49.864: INFO: node-problem-detector-2zzv5 from kube-system started at 2019-05-29 16:02:59 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.864: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:37:49.864: INFO: 
Logging pods the kubelet thinks is on node scw-sono14-default-e0a3711c5d19438ba264d7868f9 before test
May 29 17:37:49.876: INFO: kube-proxy-zht88 from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:37:49.876: INFO: flannel-sdznm from kube-system started at 2019-05-29 16:02:01 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:37:49.876: INFO: nginx-ingress-xtm7d from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 29 17:37:49.876: INFO: kubernetes-dashboard-79d67755f4-n25sj from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 17:37:49.876: INFO: sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-tfm2v from heptio-sonobuoy started at 2019-05-29 16:07:06 +0000 UTC (2 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 29 17:37:49.876: INFO: 	Container systemd-logs ready: true, restart count 1
May 29 17:37:49.876: INFO: monitoring-influxdb-6948b9bb8c-hzzfl from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container influxdb ready: true, restart count 0
May 29 17:37:49.876: INFO: node-problem-detector-tznqn from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container node-problem-detector ready: true, restart count 0
May 29 17:37:49.876: INFO: metrics-server-8d8786867-ndcld from kube-system started at 2019-05-29 16:02:31 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:37:49.876: INFO: coredns-646fc55c44-kbpn2 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container coredns ready: true, restart count 0
May 29 17:37:49.876: INFO: heapster-6c7494c65c-z8kq5 from kube-system started at 2019-05-29 16:02:33 +0000 UTC (1 container statuses recorded)
May 29 17:37:49.876: INFO: 	Container heapster ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node scw-sono14-default-174540dd770e42e2af1af25266f
STEP: verifying the node has the label node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.931: INFO: Pod sonobuoy requesting resource cpu=0m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.931: INFO: Pod sonobuoy-e2e-job-f013d2ad922949b9 requesting resource cpu=0m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.931: INFO: Pod sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-6jrjh requesting resource cpu=0m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.931: INFO: Pod sonobuoy-systemd-logs-daemon-set-9c8dc5b403a747a9-tfm2v requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.931: INFO: Pod coredns-646fc55c44-kbpn2 requesting resource cpu=100m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.931: INFO: Pod flannel-2crp5 requesting resource cpu=100m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.931: INFO: Pod flannel-sdznm requesting resource cpu=100m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod heapster-6c7494c65c-z8kq5 requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod kube-proxy-9zfn6 requesting resource cpu=0m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.932: INFO: Pod kube-proxy-zht88 requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod kubernetes-dashboard-79d67755f4-n25sj requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod metrics-server-8d8786867-ndcld requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod monitoring-influxdb-6948b9bb8c-hzzfl requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod nginx-ingress-xtm7d requesting resource cpu=0m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
May 29 17:37:49.932: INFO: Pod nginx-ingress-z47rs requesting resource cpu=0m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.932: INFO: Pod node-problem-detector-2zzv5 requesting resource cpu=20m on Node scw-sono14-default-174540dd770e42e2af1af25266f
May 29 17:37:49.932: INFO: Pod node-problem-detector-tznqn requesting resource cpu=20m on Node scw-sono14-default-e0a3711c5d19438ba264d7868f9
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f.15a338004d81b55a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3836/filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f to scw-sono14-default-174540dd770e42e2af1af25266f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f.15a3380093b484f8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f.15a338009b25c675], Reason = [Created], Message = [Created container filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f.15a33800ad1799f4], Reason = [Started], Message = [Started container filler-pod-7aab0d10-8238-11e9-abea-da3eb1f4b18f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f.15a338004dd57966], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3836/filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f to scw-sono14-default-e0a3711c5d19438ba264d7868f9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f.15a3380093c2c549], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f.15a33800987a80c7], Reason = [Created], Message = [Created container filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f.15a33800a8c4616b], Reason = [Started], Message = [Started container filler-pod-7aacb23f-8238-11e9-abea-da3eb1f4b18f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a338013e99816b], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node scw-sono14-default-174540dd770e42e2af1af25266f
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node scw-sono14-default-e0a3711c5d19438ba264d7868f9
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:37:55.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3836" for this suite.
May 29 17:38:01.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:38:01.337: INFO: namespace sched-pred-3836 deletion completed in 6.27751956s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.733 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:38:01.338: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-81900b31-8238-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:38:01.525: INFO: Waiting up to 5m0s for pod "pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f" in namespace "secrets-4909" to be "success or failure"
May 29 17:38:01.532: INFO: Pod "pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.437398ms
May 29 17:38:03.539: INFO: Pod "pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013703466s
May 29 17:38:05.547: INFO: Pod "pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021766934s
STEP: Saw pod success
May 29 17:38:05.547: INFO: Pod "pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:38:05.553: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:38:05.583: INFO: Waiting for pod pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:38:05.589: INFO: Pod pod-secrets-8191737b-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:38:05.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4909" for this suite.
May 29 17:38:11.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:38:11.903: INFO: namespace secrets-4909 deletion completed in 6.304636388s

• [SLOW TEST:10.564 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:38:11.903: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 29 17:38:14.651: INFO: Successfully updated pod "annotationupdate87dd8104-8238-11e9-abea-da3eb1f4b18f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:38:18.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3225" for this suite.
May 29 17:38:42.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:38:42.962: INFO: namespace projected-3225 deletion completed in 24.240086869s

• [SLOW TEST:31.059 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:38:42.963: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0529 17:39:23.204535      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 17:39:23.204: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:39:23.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-739" for this suite.
May 29 17:39:29.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:39:29.540: INFO: namespace gc-739 deletion completed in 6.323628639s

• [SLOW TEST:46.578 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:39:29.541: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 29 17:39:29.749: INFO: Waiting up to 5m0s for pod "pod-b6282b56-8238-11e9-abea-da3eb1f4b18f" in namespace "emptydir-1135" to be "success or failure"
May 29 17:39:29.756: INFO: Pod "pod-b6282b56-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.665518ms
May 29 17:39:31.765: INFO: Pod "pod-b6282b56-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016016135s
May 29 17:39:33.774: INFO: Pod "pod-b6282b56-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02534918s
STEP: Saw pod success
May 29 17:39:33.774: INFO: Pod "pod-b6282b56-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:39:33.782: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-b6282b56-8238-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:39:33.822: INFO: Waiting for pod pod-b6282b56-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:39:33.828: INFO: Pod pod-b6282b56-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:39:33.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1135" for this suite.
May 29 17:39:39.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:39:40.081: INFO: namespace emptydir-1135 deletion completed in 6.243885132s

• [SLOW TEST:10.540 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:39:40.081: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:39:45.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7293" for this suite.
May 29 17:40:07.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:07.574: INFO: namespace replication-controller-7293 deletion completed in 22.237417452s

• [SLOW TEST:27.493 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:07.575: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-ccceb129-8238-11e9-abea-da3eb1f4b18f
STEP: Creating a pod to test consume secrets
May 29 17:40:07.760: INFO: Waiting up to 5m0s for pod "pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f" in namespace "secrets-3361" to be "success or failure"
May 29 17:40:07.769: INFO: Pod "pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.742435ms
May 29 17:40:09.777: INFO: Pod "pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017352499s
May 29 17:40:11.784: INFO: Pod "pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024613988s
STEP: Saw pod success
May 29 17:40:11.785: INFO: Pod "pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:40:11.791: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:40:11.820: INFO: Waiting for pod pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:40:11.826: INFO: Pod pod-secrets-cccfefe0-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:11.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3361" for this suite.
May 29 17:40:17.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:19.163: INFO: namespace secrets-3361 deletion completed in 7.329595918s

• [SLOW TEST:11.589 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:19.164: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 29 17:40:19.369: INFO: Waiting up to 5m0s for pod "pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f" in namespace "emptydir-7976" to be "success or failure"
May 29 17:40:19.374: INFO: Pod "pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.467864ms
May 29 17:40:21.382: INFO: Pod "pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013412017s
May 29 17:40:23.390: INFO: Pod "pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02133037s
STEP: Saw pod success
May 29 17:40:23.390: INFO: Pod "pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:40:23.397: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f container test-container: <nil>
STEP: delete the pod
May 29 17:40:23.431: INFO: Waiting for pod pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:40:23.437: INFO: Pod pod-d3bb6828-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:23.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7976" for this suite.
May 29 17:40:29.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:29.689: INFO: namespace emptydir-7976 deletion completed in 6.243086359s

• [SLOW TEST:10.525 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:29.689: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
May 29 17:40:29.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-762736658 cluster-info'
May 29 17:40:30.382: INFO: stderr: ""
May 29 17:40:30.382: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:30.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4629" for this suite.
May 29 17:40:36.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:36.639: INFO: namespace kubectl-4629 deletion completed in 6.248590292s

• [SLOW TEST:6.950 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:36.640: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
May 29 17:40:36.816: INFO: Waiting up to 5m0s for pod "var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f" in namespace "var-expansion-7607" to be "success or failure"
May 29 17:40:36.822: INFO: Pod "var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.99706ms
May 29 17:40:38.830: INFO: Pod "var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014580574s
May 29 17:40:40.839: INFO: Pod "var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02302664s
STEP: Saw pod success
May 29 17:40:40.839: INFO: Pod "var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:40:40.847: INFO: Trying to get logs from node scw-sono14-default-174540dd770e42e2af1af25266f pod var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f container dapi-container: <nil>
STEP: delete the pod
May 29 17:40:40.882: INFO: Waiting for pod var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:40:40.889: INFO: Pod var-expansion-de21c449-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:40.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7607" for this suite.
May 29 17:40:46.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:47.143: INFO: namespace var-expansion-7607 deletion completed in 6.246694476s

• [SLOW TEST:10.504 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:47.143: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 29 17:40:47.316: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f" in namespace "projected-2700" to be "success or failure"
May 29 17:40:47.322: INFO: Pod "downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.609693ms
May 29 17:40:49.331: INFO: Pod "downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01484927s
May 29 17:40:51.339: INFO: Pod "downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023192152s
STEP: Saw pod success
May 29 17:40:51.339: INFO: Pod "downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f" satisfied condition "success or failure"
May 29 17:40:51.346: INFO: Trying to get logs from node scw-sono14-default-e0a3711c5d19438ba264d7868f9 pod downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f container client-container: <nil>
STEP: delete the pod
May 29 17:40:51.376: INFO: Waiting for pod downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f to disappear
May 29 17:40:51.382: INFO: Pod downwardapi-volume-e463bee6-8238-11e9-abea-da3eb1f4b18f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:51.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2700" for this suite.
May 29 17:40:57.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:57.711: INFO: namespace projected-2700 deletion completed in 6.322011988s

• [SLOW TEST:10.568 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:40:57.712: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 29 17:41:02.444: INFO: Successfully updated pod "labelsupdateeab0920e-8238-11e9-abea-da3eb1f4b18f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:04.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3110" for this suite.
May 29 17:41:26.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:41:26.747: INFO: namespace projected-3110 deletion completed in 22.260555041s

• [SLOW TEST:29.035 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 29 17:41:26.747: INFO: >>> kubeConfig: /tmp/kubeconfig-762736658
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
May 29 17:41:26.906: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-762736658 proxy --unix-socket=/tmp/kubectl-proxy-unix163026829/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:26.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4873" for this suite.
May 29 17:41:33.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:41:33.243: INFO: namespace kubectl-4873 deletion completed in 6.234993918s

• [SLOW TEST:6.496 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSMay 29 17:41:33.243: INFO: Running AfterSuite actions on all nodes
May 29 17:41:33.243: INFO: Running AfterSuite actions on node 1
May 29 17:41:33.244: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5624.051 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h33m46.459985966s
Test Suite Passed
