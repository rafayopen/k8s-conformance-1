I0624 15:32:03.543156      20 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-766262415
I0624 15:32:03.543276      20 e2e.go:240] Starting e2e run "368df000-9695-11e9-8bcb-526dc0a539dd" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1561390322 - Will randomize all specs
Will run 204 of 3585 specs

Jun 24 15:32:03.741: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 15:32:03.743: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 24 15:32:03.759: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 24 15:32:03.807: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 24 15:32:03.807: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jun 24 15:32:03.807: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun 24 15:32:03.817: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jun 24 15:32:03.817: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Jun 24 15:32:03.817: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Jun 24 15:32:03.817: INFO: e2e test version: v1.14.3
Jun 24 15:32:03.818: INFO: kube-apiserver version: v1.14.3
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:32:03.819: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename dns
Jun 24 15:32:03.873: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7895.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7895.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 24 15:32:15.950: INFO: DNS probes using dns-7895/dns-test-379bab8b-9695-11e9-8bcb-526dc0a539dd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:32:16.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7895" for this suite.
Jun 24 15:32:24.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:32:24.198: INFO: namespace dns-7895 deletion completed in 8.122404887s

• [SLOW TEST:20.379 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:32:24.198: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-43bcd7dd-9695-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:32:24.237: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd" in namespace "projected-9514" to be "success or failure"
Jun 24 15:32:24.241: INFO: Pod "pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046003ms
Jun 24 15:32:26.245: INFO: Pod "pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00829243s
Jun 24 15:32:28.626: INFO: Pod "pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.389816629s
STEP: Saw pod success
Jun 24 15:32:28.627: INFO: Pod "pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:32:28.631: INFO: Trying to get logs from node minion pod pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:32:28.696: INFO: Waiting for pod pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:32:28.708: INFO: Pod pod-projected-configmaps-43bd3eb7-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:32:28.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9514" for this suite.
Jun 24 15:32:36.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:32:36.812: INFO: namespace projected-9514 deletion completed in 8.10134749s

• [SLOW TEST:12.614 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:32:36.813: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9603
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9603
STEP: Deleting pre-stop pod
Jun 24 15:32:49.895: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:32:49.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9603" for this suite.
Jun 24 15:33:27.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:33:28.021: INFO: namespace prestop-9603 deletion completed in 38.114780397s

• [SLOW TEST:51.208 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:33:28.025: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3290
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 24 15:33:28.058: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 24 15:33:50.133: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.251.128.5 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3290 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 15:33:50.134: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 15:33:51.297: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:33:51.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3290" for this suite.
Jun 24 15:34:13.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:13.415: INFO: namespace pod-network-test-3290 deletion completed in 22.113151957s

• [SLOW TEST:45.389 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:13.418: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-84d7adee-9695-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:34:13.464: INFO: Waiting up to 5m0s for pod "pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd" in namespace "configmap-2979" to be "success or failure"
Jun 24 15:34:13.471: INFO: Pod "pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.54126ms
Jun 24 15:34:15.481: INFO: Pod "pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017137834s
STEP: Saw pod success
Jun 24 15:34:15.481: INFO: Pod "pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:34:15.483: INFO: Trying to get logs from node minion pod pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:34:15.513: INFO: Waiting for pod pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:34:15.517: INFO: Pod pod-configmaps-84d8723f-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2979" for this suite.
Jun 24 15:34:21.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:21.636: INFO: namespace configmap-2979 deletion completed in 6.115165037s

• [SLOW TEST:8.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Jun 24 15:34:21.675: INFO: Waiting up to 5m0s for pod "client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd" in namespace "containers-522" to be "success or failure"
Jun 24 15:34:21.684: INFO: Pod "client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.625831ms
Jun 24 15:34:23.687: INFO: Pod "client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01219794s
Jun 24 15:34:25.691: INFO: Pod "client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016161513s
STEP: Saw pod success
Jun 24 15:34:25.691: INFO: Pod "client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:34:25.695: INFO: Trying to get logs from node minion pod client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:34:25.734: INFO: Waiting for pod client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:34:25.741: INFO: Pod client-containers-89bd81cf-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:25.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-522" for this suite.
Jun 24 15:34:31.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:31.862: INFO: namespace containers-522 deletion completed in 6.116368709s

• [SLOW TEST:10.223 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:31.862: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Jun 24 15:34:31.911: INFO: Waiting up to 5m0s for pod "var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd" in namespace "var-expansion-848" to be "success or failure"
Jun 24 15:34:31.914: INFO: Pod "var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.405233ms
Jun 24 15:34:33.919: INFO: Pod "var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00788514s
STEP: Saw pod success
Jun 24 15:34:33.919: INFO: Pod "var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:34:33.923: INFO: Trying to get logs from node minion pod var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 15:34:33.947: INFO: Waiting for pod var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:34:33.951: INFO: Pod var-expansion-8fd6fa7a-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:33.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-848" for this suite.
Jun 24 15:34:39.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:40.052: INFO: namespace var-expansion-848 deletion completed in 6.098501283s

• [SLOW TEST:8.191 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:40.054: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 15:34:40.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd" in namespace "projected-8902" to be "success or failure"
Jun 24 15:34:40.119: INFO: Pod "downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.661716ms
Jun 24 15:34:42.125: INFO: Pod "downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026175199s
STEP: Saw pod success
Jun 24 15:34:42.125: INFO: Pod "downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:34:42.128: INFO: Trying to get logs from node minion pod downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 15:34:42.153: INFO: Waiting for pod downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:34:42.155: INFO: Pod downwardapi-volume-94b8501e-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:42.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8902" for this suite.
Jun 24 15:34:48.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:48.257: INFO: namespace projected-8902 deletion completed in 6.098623671s

• [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:48.257: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 15:34:48.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd" in namespace "downward-api-4463" to be "success or failure"
Jun 24 15:34:48.300: INFO: Pod "downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.10714ms
Jun 24 15:34:50.305: INFO: Pod "downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010478835s
STEP: Saw pod success
Jun 24 15:34:50.305: INFO: Pod "downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:34:50.310: INFO: Trying to get logs from node minion pod downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 15:34:50.333: INFO: Waiting for pod downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:34:50.336: INFO: Pod downwardapi-volume-999b425b-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:50.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4463" for this suite.
Jun 24 15:34:56.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:34:56.445: INFO: namespace downward-api-4463 deletion completed in 6.106112191s

• [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:34:56.445: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 24 15:34:56.506: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7852,SelfLink:/api/v1/namespaces/watch-7852/configmaps/e2e-watch-test-resource-version,UID:9e7c9280-9695-11e9-b70d-fa163ef83c94,ResourceVersion:1666,Generation:0,CreationTimestamp:2019-06-24 15:34:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 24 15:34:56.506: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7852,SelfLink:/api/v1/namespaces/watch-7852/configmaps/e2e-watch-test-resource-version,UID:9e7c9280-9695-11e9-b70d-fa163ef83c94,ResourceVersion:1667,Generation:0,CreationTimestamp:2019-06-24 15:34:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:34:56.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7852" for this suite.
Jun 24 15:35:02.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:35:02.599: INFO: namespace watch-7852 deletion completed in 6.090505769s

• [SLOW TEST:6.154 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:35:02.599: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jun 24 15:35:02.653: INFO: Waiting up to 5m0s for pod "downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd" in namespace "downward-api-2161" to be "success or failure"
Jun 24 15:35:02.658: INFO: Pod "downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032032ms
Jun 24 15:35:04.662: INFO: Pod "downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009171578s
STEP: Saw pod success
Jun 24 15:35:04.662: INFO: Pod "downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:35:04.666: INFO: Trying to get logs from node minion pod downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 15:35:04.695: INFO: Waiting for pod downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:35:04.699: INFO: Pod downward-api-a2284c70-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:35:04.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2161" for this suite.
Jun 24 15:35:10.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:35:10.813: INFO: namespace downward-api-2161 deletion completed in 6.109942723s

• [SLOW TEST:8.214 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:35:10.814: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8674/configmap-test-a70f1f5d-9695-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:35:10.870: INFO: Waiting up to 5m0s for pod "pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd" in namespace "configmap-8674" to be "success or failure"
Jun 24 15:35:10.878: INFO: Pod "pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.315749ms
Jun 24 15:35:12.882: INFO: Pod "pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012664044s
STEP: Saw pod success
Jun 24 15:35:12.882: INFO: Pod "pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:35:12.886: INFO: Trying to get logs from node minion pod pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd container env-test: <nil>
STEP: delete the pod
Jun 24 15:35:12.908: INFO: Waiting for pod pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:35:12.910: INFO: Pod pod-configmaps-a70fa11f-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:35:12.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8674" for this suite.
Jun 24 15:35:18.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:35:19.023: INFO: namespace configmap-8674 deletion completed in 6.108714399s

• [SLOW TEST:8.209 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:35:19.024: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 15:35:19.090: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"abf5aef2-9695-11e9-b70d-fa163ef83c94", Controller:(*bool)(0xc0028915be), BlockOwnerDeletion:(*bool)(0xc0028915bf)}}
Jun 24 15:35:19.099: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"abf38bd8-9695-11e9-b70d-fa163ef83c94", Controller:(*bool)(0xc002891786), BlockOwnerDeletion:(*bool)(0xc002891787)}}
Jun 24 15:35:19.105: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"abf478a0-9695-11e9-b70d-fa163ef83c94", Controller:(*bool)(0xc002abc576), BlockOwnerDeletion:(*bool)(0xc002abc577)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:35:24.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1802" for this suite.
Jun 24 15:35:30.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:35:30.225: INFO: namespace gc-1802 deletion completed in 6.107074393s

• [SLOW TEST:11.201 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:35:30.227: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-b2a1670b-9695-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:35:30.282: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd" in namespace "configmap-50" to be "success or failure"
Jun 24 15:35:30.287: INFO: Pod "pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.722655ms
Jun 24 15:35:32.298: INFO: Pod "pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015911803s
Jun 24 15:35:34.303: INFO: Pod "pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020175486s
STEP: Saw pod success
Jun 24 15:35:34.303: INFO: Pod "pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:35:34.306: INFO: Trying to get logs from node minion pod pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:35:34.331: INFO: Waiting for pod pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:35:34.334: INFO: Pod pod-configmaps-b2a1d426-9695-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:35:34.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-50" for this suite.
Jun 24 15:35:40.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:35:40.459: INFO: namespace configmap-50 deletion completed in 6.122308265s

• [SLOW TEST:10.233 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:35:40.461: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9511
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-9511
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9511
Jun 24 15:35:40.511: INFO: Found 0 stateful pods, waiting for 1
Jun 24 15:35:50.516: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 24 15:35:50.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 15:35:50.804: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 15:35:50.804: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 15:35:50.804: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 15:35:50.808: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 24 15:36:00.816: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 15:36:00.816: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 15:36:00.833: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:00.833: INFO: ss-0  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:00.833: INFO: 
Jun 24 15:36:00.833: INFO: StatefulSet ss has not reached scale 3, at 1
Jun 24 15:36:01.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994728308s
Jun 24 15:36:02.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989567682s
Jun 24 15:36:03.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985171301s
Jun 24 15:36:04.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980870397s
Jun 24 15:36:05.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975742074s
Jun 24 15:36:06.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971527882s
Jun 24 15:36:07.865: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966382288s
Jun 24 15:36:08.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962112159s
Jun 24 15:36:09.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.717219ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9511
Jun 24 15:36:10.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:36:11.155: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 15:36:11.155: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 15:36:11.155: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 15:36:11.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:36:11.430: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 24 15:36:11.430: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 15:36:11.430: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 15:36:11.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:36:11.700: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 24 15:36:11.701: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 15:36:11.701: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 15:36:11.705: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jun 24 15:36:21.709: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 15:36:21.710: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 15:36:21.710: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 24 15:36:21.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 15:36:21.979: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 15:36:21.979: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 15:36:21.979: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 15:36:21.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 15:36:22.247: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 15:36:22.247: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 15:36:22.247: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 15:36:22.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 15:36:22.526: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 15:36:22.526: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 15:36:22.526: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 15:36:22.526: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 15:36:22.530: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 24 15:36:32.538: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 15:36:32.538: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 15:36:32.538: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 15:36:32.549: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:32.549: INFO: ss-0  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:32.549: INFO: ss-1  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:32.550: INFO: ss-2  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:32.550: INFO: 
Jun 24 15:36:32.550: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:33.555: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:33.555: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:33.555: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:33.555: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:33.555: INFO: 
Jun 24 15:36:33.555: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:34.560: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:34.560: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:34.560: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:34.560: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:34.560: INFO: 
Jun 24 15:36:34.560: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:35.565: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:35.565: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:35.565: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:35.565: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:35.565: INFO: 
Jun 24 15:36:35.565: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:36.569: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:36.569: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:36.569: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:36.570: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:36.570: INFO: 
Jun 24 15:36:36.570: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:37.574: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:37.574: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:37.574: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:37.574: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:37.574: INFO: 
Jun 24 15:36:37.574: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:38.579: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:38.579: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:38.579: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:38.580: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:38.580: INFO: 
Jun 24 15:36:38.580: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:39.584: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:39.584: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:39.584: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:39.584: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:39.584: INFO: 
Jun 24 15:36:39.584: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:40.589: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:40.589: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:40.589: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:40.589: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:40.589: INFO: 
Jun 24 15:36:40.589: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 24 15:36:41.594: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Jun 24 15:36:41.594: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:35:40 +0000 UTC  }]
Jun 24 15:36:41.594: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:41.594: INFO: ss-2  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:36:00 +0000 UTC  }]
Jun 24 15:36:41.594: INFO: 
Jun 24 15:36:41.594: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9511
Jun 24 15:36:42.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:36:42.791: INFO: rc: 1
Jun 24 15:36:42.791: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002da0330 exit status 1 <nil> <nil> true [0xc003197308 0xc003197358 0xc003197380] [0xc003197308 0xc003197358 0xc003197380] [0xc003197340 0xc003197378] [0x9c00a0 0x9c00a0] 0xc0027d97a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jun 24 15:36:52.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:36:52.884: INFO: rc: 1
Jun 24 15:36:52.884: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002da0690 exit status 1 <nil> <nil> true [0xc003197388 0xc0031973a0 0xc0031973c8] [0xc003197388 0xc0031973a0 0xc0031973c8] [0xc003197398 0xc0031973b0] [0x9c00a0 0x9c00a0] 0xc002d96060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:02.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:02.976: INFO: rc: 1
Jun 24 15:37:02.976: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002da09c0 exit status 1 <nil> <nil> true [0xc0031973e0 0xc0031973f8 0xc003197410] [0xc0031973e0 0xc0031973f8 0xc003197410] [0xc0031973f0 0xc003197408] [0x9c00a0 0x9c00a0] 0xc002d963c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:12.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:13.066: INFO: rc: 1
Jun 24 15:37:13.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a21e60 exit status 1 <nil> <nil> true [0xc002150e30 0xc002150e60 0xc002150e78] [0xc002150e30 0xc002150e60 0xc002150e78] [0xc002150e50 0xc002150e70] [0x9c00a0 0x9c00a0] 0xc002551380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:23.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:23.165: INFO: rc: 1
Jun 24 15:37:23.165: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002da0d50 exit status 1 <nil> <nil> true [0xc003197418 0xc003197430 0xc003197470] [0xc003197418 0xc003197430 0xc003197470] [0xc003197428 0xc003197450] [0x9c00a0 0x9c00a0] 0xc002d96780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:33.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:33.257: INFO: rc: 1
Jun 24 15:37:33.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16300 exit status 1 <nil> <nil> true [0xc0001720c0 0xc000172190 0xc000172370] [0xc0001720c0 0xc000172190 0xc000172370] [0xc000172148 0xc000172298] [0x9c00a0 0x9c00a0] 0xc002960720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:43.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:43.349: INFO: rc: 1
Jun 24 15:37:43.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00278e300 exit status 1 <nil> <nil> true [0xc000702070 0xc00042d110 0xc00042d380] [0xc000702070 0xc00042d110 0xc00042d380] [0xc00042d0b8 0xc00042d308] [0x9c00a0 0x9c00a0] 0xc0027d8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:37:53.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:37:53.440: INFO: rc: 1
Jun 24 15:37:53.440: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f6e330 exit status 1 <nil> <nil> true [0xc00054a088 0xc00054a120 0xc00054a198] [0xc00054a088 0xc00054a120 0xc00054a198] [0xc00054a0a0 0xc00054a188] [0x9c00a0 0x9c00a0] 0xc00231c840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:03.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:03.529: INFO: rc: 1
Jun 24 15:38:03.529: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f6e660 exit status 1 <nil> <nil> true [0xc00054a1a8 0xc00054a208 0xc00054a2a8] [0xc00054a1a8 0xc00054a208 0xc00054a2a8] [0xc00054a1e8 0xc00054a280] [0x9c00a0 0x9c00a0] 0xc00231d440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:13.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:13.620: INFO: rc: 1
Jun 24 15:38:13.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f6e9c0 exit status 1 <nil> <nil> true [0xc00054a300 0xc00054a348 0xc00054a380] [0xc00054a300 0xc00054a348 0xc00054a380] [0xc00054a328 0xc00054a370] [0x9c00a0 0x9c00a0] 0xc00231df80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:23.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:23.713: INFO: rc: 1
Jun 24 15:38:23.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef4360 exit status 1 <nil> <nil> true [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000105b0 0xc000010730] [0x9c00a0 0x9c00a0] 0xc00204a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:33.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:33.804: INFO: rc: 1
Jun 24 15:38:33.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16660 exit status 1 <nil> <nil> true [0xc000172380 0xc000172540 0xc000172af8] [0xc000172380 0xc000172540 0xc000172af8] [0xc0001723e0 0xc000172ae8] [0x9c00a0 0x9c00a0] 0xc002960ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:43.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:43.893: INFO: rc: 1
Jun 24 15:38:43.893: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef46c0 exit status 1 <nil> <nil> true [0xc000010878 0xc000010950 0xc0000109a8] [0xc000010878 0xc000010950 0xc0000109a8] [0xc0000108f8 0xc000010998] [0x9c00a0 0x9c00a0] 0xc001bc8cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:38:53.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:38:53.982: INFO: rc: 1
Jun 24 15:38:53.982: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef4ab0 exit status 1 <nil> <nil> true [0xc0000109c8 0xc000010b00 0xc000010bb0] [0xc0000109c8 0xc000010b00 0xc000010bb0] [0xc000010a88 0xc000010ba0] [0x9c00a0 0x9c00a0] 0xc0019f35c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:03.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:04.073: INFO: rc: 1
Jun 24 15:39:04.073: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16990 exit status 1 <nil> <nil> true [0xc000172b18 0xc000172c78 0xc000172e08] [0xc000172b18 0xc000172c78 0xc000172e08] [0xc000172be0 0xc000172d98] [0x9c00a0 0x9c00a0] 0xc002960e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:14.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:14.172: INFO: rc: 1
Jun 24 15:39:14.172: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16cc0 exit status 1 <nil> <nil> true [0xc000172e60 0xc000173010 0xc000173158] [0xc000172e60 0xc000173010 0xc000173158] [0xc000172f48 0xc000173108] [0x9c00a0 0x9c00a0] 0xc0029611a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:24.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:24.266: INFO: rc: 1
Jun 24 15:39:24.266: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef4e40 exit status 1 <nil> <nil> true [0xc000010bd0 0xc000010c40 0xc000010c90] [0xc000010bd0 0xc000010c40 0xc000010c90] [0xc000010c10 0xc000010c78] [0x9c00a0 0x9c00a0] 0xc001271f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:34.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:34.354: INFO: rc: 1
Jun 24 15:39:34.354: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16330 exit status 1 <nil> <nil> true [0xc0007021b8 0xc000172100 0xc000172240] [0xc0007021b8 0xc000172100 0xc000172240] [0xc0001720c0 0xc000172190] [0x9c00a0 0x9c00a0] 0xc001bd81e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:44.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:44.444: INFO: rc: 1
Jun 24 15:39:44.444: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e166c0 exit status 1 <nil> <nil> true [0xc000172298 0xc000172390 0xc000172a98] [0xc000172298 0xc000172390 0xc000172a98] [0xc000172380 0xc000172540] [0x9c00a0 0x9c00a0] 0xc001bc8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:39:54.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:39:54.535: INFO: rc: 1
Jun 24 15:39:54.535: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00278e330 exit status 1 <nil> <nil> true [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000105b0 0xc000010730] [0x9c00a0 0x9c00a0] 0xc00225e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:04.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:04.629: INFO: rc: 1
Jun 24 15:40:04.629: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef4330 exit status 1 <nil> <nil> true [0xc00042d0b8 0xc00042d308 0xc00042d488] [0xc00042d0b8 0xc00042d308 0xc00042d488] [0xc00042d248 0xc00042d478] [0x9c00a0 0x9c00a0] 0xc00231c840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:14.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:14.718: INFO: rc: 1
Jun 24 15:40:14.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ef4750 exit status 1 <nil> <nil> true [0xc00042d4f0 0xc00042d688 0xc00042d820] [0xc00042d4f0 0xc00042d688 0xc00042d820] [0xc00042d660 0xc00042d7a8] [0x9c00a0 0x9c00a0] 0xc00231d440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:24.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:24.807: INFO: rc: 1
Jun 24 15:40:24.807: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00278e6c0 exit status 1 <nil> <nil> true [0xc000010878 0xc000010950 0xc0000109a8] [0xc000010878 0xc000010950 0xc0000109a8] [0xc0000108f8 0xc000010998] [0x9c00a0 0x9c00a0] 0xc002960300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:34.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:34.896: INFO: rc: 1
Jun 24 15:40:34.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16a20 exit status 1 <nil> <nil> true [0xc000172ae8 0xc000172b78 0xc000172d50] [0xc000172ae8 0xc000172b78 0xc000172d50] [0xc000172b18 0xc000172c78] [0x9c00a0 0x9c00a0] 0xc0027d8240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:44.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:44.985: INFO: rc: 1
Jun 24 15:40:44.985: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00278ea20 exit status 1 <nil> <nil> true [0xc0000109c8 0xc000010b00 0xc000010bb0] [0xc0000109c8 0xc000010b00 0xc000010bb0] [0xc000010a88 0xc000010ba0] [0x9c00a0 0x9c00a0] 0xc002960900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:40:54.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:40:55.078: INFO: rc: 1
Jun 24 15:40:55.078: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e16de0 exit status 1 <nil> <nil> true [0xc000172d98 0xc000172e98 0xc000173078] [0xc000172d98 0xc000172e98 0xc000173078] [0xc000172e60 0xc000173010] [0x9c00a0 0x9c00a0] 0xc0027d8a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:41:05.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:41:05.183: INFO: rc: 1
Jun 24 15:41:05.183: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f6e360 exit status 1 <nil> <nil> true [0xc00054a088 0xc00054a120 0xc00054a198] [0xc00054a088 0xc00054a120 0xc00054a198] [0xc00054a0a0 0xc00054a188] [0x9c00a0 0x9c00a0] 0xc001cb9560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:41:15.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:41:15.276: INFO: rc: 1
Jun 24 15:41:15.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e17260 exit status 1 <nil> <nil> true [0xc000173108 0xc0001732a8 0xc000173318] [0xc000173108 0xc0001732a8 0xc000173318] [0xc0001731e8 0xc0001732d8] [0x9c00a0 0x9c00a0] 0xc0027d9260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:41:25.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:41:25.371: INFO: rc: 1
Jun 24 15:41:25.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00278eea0 exit status 1 <nil> <nil> true [0xc000010bd0 0xc000010c40 0xc000010c90] [0xc000010bd0 0xc000010c40 0xc000010c90] [0xc000010c10 0xc000010c78] [0x9c00a0 0x9c00a0] 0xc002960c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:41:35.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:41:35.466: INFO: rc: 1
Jun 24 15:41:35.466: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f6e630 exit status 1 <nil> <nil> true [0xc00042d8f0 0xc00054a1c0 0xc00054a250] [0xc00042d8f0 0xc00054a1c0 0xc00054a250] [0xc00054a1a8 0xc00054a208] [0x9c00a0 0x9c00a0] 0xc001d1cfc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jun 24 15:41:45.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-9511 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 15:41:45.556: INFO: rc: 1
Jun 24 15:41:45.556: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Jun 24 15:41:45.556: INFO: Scaling statefulset ss to 0
Jun 24 15:41:45.566: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 24 15:41:45.569: INFO: Deleting all statefulset in ns statefulset-9511
Jun 24 15:41:45.571: INFO: Scaling statefulset ss to 0
Jun 24 15:41:45.581: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 15:41:45.586: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:41:45.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9511" for this suite.
Jun 24 15:41:51.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:41:51.704: INFO: namespace statefulset-9511 deletion completed in 6.105855495s

• [SLOW TEST:371.243 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:41:51.704: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-9600529b-9696-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 15:41:51.749: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd" in namespace "projected-9989" to be "success or failure"
Jun 24 15:41:51.761: INFO: Pod "pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.661467ms
Jun 24 15:41:53.765: INFO: Pod "pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014724001s
STEP: Saw pod success
Jun 24 15:41:53.765: INFO: Pod "pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:41:53.768: INFO: Trying to get logs from node minion pod pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 24 15:41:53.795: INFO: Waiting for pod pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:41:53.798: INFO: Pod pod-projected-secrets-9600ec2e-9696-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:41:53.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9989" for this suite.
Jun 24 15:41:59.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:41:59.902: INFO: namespace projected-9989 deletion completed in 6.101493612s

• [SLOW TEST:8.198 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:41:59.903: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 24 15:41:59.934: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 24 15:41:59.941: INFO: Waiting for terminating namespaces to be deleted...
Jun 24 15:41:59.943: INFO: 
Logging pods the kubelet thinks is on node minion before test
Jun 24 15:41:59.952: INFO: kube-proxy-d8w54 from kube-system started at 2019-06-24 15:29:46 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 24 15:41:59.952: INFO: weave-scope-app-5bcb7f46b9-pv6gl from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container app ready: true, restart count 0
Jun 24 15:41:59.952: INFO: weave-scope-agent-mmtsr from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container agent ready: true, restart count 0
Jun 24 15:41:59.952: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-24 15:31:39 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 24 15:41:59.952: INFO: nginx-proxy-minion from kube-system started at <nil> (0 container statuses recorded)
Jun 24 15:41:59.952: INFO: weave-net-p4t4q from kube-system started at 2019-06-24 15:29:30 +0000 UTC (2 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container weave ready: true, restart count 0
Jun 24 15:41:59.952: INFO: 	Container weave-npc ready: true, restart count 0
Jun 24 15:41:59.952: INFO: coredns-97c4b444f-9954l from kube-system started at 2019-06-24 15:30:06 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container coredns ready: true, restart count 0
Jun 24 15:41:59.952: INFO: nodelocaldns-vmsgk from kube-system started at 2019-06-24 15:30:09 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container node-cache ready: true, restart count 0
Jun 24 15:41:59.952: INFO: kubernetes-dashboard-6c7466966c-v95zd from kube-system started at 2019-06-24 15:30:10 +0000 UTC (1 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 24 15:41:59.952: INFO: sonobuoy-systemd-logs-daemon-set-7e1461ca4731443f-8ql79 from heptio-sonobuoy started at 2019-06-24 15:31:43 +0000 UTC (2 container statuses recorded)
Jun 24 15:41:59.952: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jun 24 15:41:59.952: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ab2cc4e43fea22], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:42:00.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8256" for this suite.
Jun 24 15:42:06.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:42:07.091: INFO: namespace sched-pred-8256 deletion completed in 6.1136384s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.188 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:42:07.094: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4231
Jun 24 15:42:11.159: INFO: Started pod liveness-http in namespace container-probe-4231
STEP: checking the pod's current state and verifying that restartCount is present
Jun 24 15:42:11.162: INFO: Initial restart count of pod liveness-http is 0
Jun 24 15:42:27.198: INFO: Restart count of pod container-probe-4231/liveness-http is now 1 (16.036128064s elapsed)
Jun 24 15:42:47.240: INFO: Restart count of pod container-probe-4231/liveness-http is now 2 (36.077289007s elapsed)
Jun 24 15:43:09.284: INFO: Restart count of pod container-probe-4231/liveness-http is now 3 (58.121753871s elapsed)
Jun 24 15:43:27.321: INFO: Restart count of pod container-probe-4231/liveness-http is now 4 (1m16.158712779s elapsed)
Jun 24 15:44:41.475: INFO: Restart count of pod container-probe-4231/liveness-http is now 5 (2m30.312412572s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:44:41.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4231" for this suite.
Jun 24 15:44:47.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:44:47.593: INFO: namespace container-probe-4231 deletion completed in 6.102816305s

• [SLOW TEST:160.499 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:44:47.593: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-fed833fc-9696-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:44:49.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7793" for this suite.
Jun 24 15:45:11.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:45:11.791: INFO: namespace configmap-7793 deletion completed in 22.10457756s

• [SLOW TEST:24.198 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:45:11.792: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 15:45:11.853: INFO: (0) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.936169ms)
Jun 24 15:45:11.857: INFO: (1) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.677971ms)
Jun 24 15:45:11.862: INFO: (2) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.413766ms)
Jun 24 15:45:11.867: INFO: (3) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.879439ms)
Jun 24 15:45:11.871: INFO: (4) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.361157ms)
Jun 24 15:45:11.877: INFO: (5) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.718386ms)
Jun 24 15:45:11.881: INFO: (6) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.828271ms)
Jun 24 15:45:11.885: INFO: (7) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.090293ms)
Jun 24 15:45:11.891: INFO: (8) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.722122ms)
Jun 24 15:45:11.895: INFO: (9) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.232245ms)
Jun 24 15:45:11.900: INFO: (10) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.794338ms)
Jun 24 15:45:11.907: INFO: (11) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.317571ms)
Jun 24 15:45:11.911: INFO: (12) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.089445ms)
Jun 24 15:45:11.917: INFO: (13) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.447431ms)
Jun 24 15:45:11.921: INFO: (14) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.232543ms)
Jun 24 15:45:11.927: INFO: (15) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.181912ms)
Jun 24 15:45:11.931: INFO: (16) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.502013ms)
Jun 24 15:45:11.934: INFO: (17) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.390695ms)
Jun 24 15:45:11.938: INFO: (18) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.706964ms)
Jun 24 15:45:11.949: INFO: (19) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 10.935907ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:45:11.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7928" for this suite.
Jun 24 15:45:17.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:45:18.049: INFO: namespace proxy-7928 deletion completed in 6.097284257s

• [SLOW TEST:6.258 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:45:18.049: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 15:45:18.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2544'
Jun 24 15:45:18.717: INFO: stderr: ""
Jun 24 15:45:18.717: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Jun 24 15:45:18.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete pods e2e-test-nginx-pod --namespace=kubectl-2544'
Jun 24 15:45:26.770: INFO: stderr: ""
Jun 24 15:45:26.770: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:45:26.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2544" for this suite.
Jun 24 15:45:32.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:45:32.874: INFO: namespace kubectl-2544 deletion completed in 6.099398906s

• [SLOW TEST:14.825 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:45:32.874: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 24 15:45:32.914: INFO: Waiting up to 5m0s for pod "pod-19d4601f-9697-11e9-8bcb-526dc0a539dd" in namespace "emptydir-3357" to be "success or failure"
Jun 24 15:45:32.925: INFO: Pod "pod-19d4601f-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.288644ms
Jun 24 15:45:34.929: INFO: Pod "pod-19d4601f-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014437656s
STEP: Saw pod success
Jun 24 15:45:34.929: INFO: Pod "pod-19d4601f-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:45:34.933: INFO: Trying to get logs from node minion pod pod-19d4601f-9697-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:45:34.966: INFO: Waiting for pod pod-19d4601f-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:45:34.970: INFO: Pod pod-19d4601f-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:45:34.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3357" for this suite.
Jun 24 15:45:40.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:45:41.068: INFO: namespace emptydir-3357 deletion completed in 6.094623461s

• [SLOW TEST:8.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:45:41.073: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2877
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 24 15:45:41.113: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 24 15:45:55.174: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.251.128.5:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2877 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 15:45:55.174: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 15:45:55.341: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:45:55.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2877" for this suite.
Jun 24 15:46:17.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:46:17.445: INFO: namespace pod-network-test-2877 deletion completed in 22.100115882s

• [SLOW TEST:36.373 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:46:17.449: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 24 15:46:17.491: INFO: Waiting up to 5m0s for pod "pod-346604ed-9697-11e9-8bcb-526dc0a539dd" in namespace "emptydir-1548" to be "success or failure"
Jun 24 15:46:17.499: INFO: Pod "pod-346604ed-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.280912ms
Jun 24 15:46:19.503: INFO: Pod "pod-346604ed-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012320463s
Jun 24 15:46:21.507: INFO: Pod "pod-346604ed-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016318357s
STEP: Saw pod success
Jun 24 15:46:21.507: INFO: Pod "pod-346604ed-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:46:21.511: INFO: Trying to get logs from node minion pod pod-346604ed-9697-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:46:21.542: INFO: Waiting for pod pod-346604ed-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:46:21.545: INFO: Pod pod-346604ed-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:46:21.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1548" for this suite.
Jun 24 15:46:27.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:46:27.645: INFO: namespace emptydir-1548 deletion completed in 6.089623721s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:46:27.646: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 15:46:27.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1773'
Jun 24 15:46:27.806: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 24 15:46:27.806: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jun 24 15:46:27.817: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mbtpd]
Jun 24 15:46:27.817: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mbtpd" in namespace "kubectl-1773" to be "running and ready"
Jun 24 15:46:27.820: INFO: Pod "e2e-test-nginx-rc-mbtpd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.839639ms
Jun 24 15:46:29.824: INFO: Pod "e2e-test-nginx-rc-mbtpd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006962384s
Jun 24 15:46:31.828: INFO: Pod "e2e-test-nginx-rc-mbtpd": Phase="Running", Reason="", readiness=true. Elapsed: 4.011082665s
Jun 24 15:46:31.828: INFO: Pod "e2e-test-nginx-rc-mbtpd" satisfied condition "running and ready"
Jun 24 15:46:31.829: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mbtpd]
Jun 24 15:46:31.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 logs rc/e2e-test-nginx-rc --namespace=kubectl-1773'
Jun 24 15:46:31.954: INFO: stderr: ""
Jun 24 15:46:31.954: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Jun 24 15:46:31.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete rc e2e-test-nginx-rc --namespace=kubectl-1773'
Jun 24 15:46:32.057: INFO: stderr: ""
Jun 24 15:46:32.057: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:46:32.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1773" for this suite.
Jun 24 15:46:38.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:46:38.159: INFO: namespace kubectl-1773 deletion completed in 6.098671605s

• [SLOW TEST:10.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:46:38.164: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-328
Jun 24 15:46:42.221: INFO: Started pod liveness-http in namespace container-probe-328
STEP: checking the pod's current state and verifying that restartCount is present
Jun 24 15:46:42.224: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:50:42.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-328" for this suite.
Jun 24 15:50:48.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:50:48.854: INFO: namespace container-probe-328 deletion completed in 6.095846839s

• [SLOW TEST:250.690 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:50:48.854: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Jun 24 15:50:48.898: INFO: Waiting up to 5m0s for pod "client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd" in namespace "containers-1790" to be "success or failure"
Jun 24 15:50:48.906: INFO: Pod "client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.709077ms
Jun 24 15:50:50.910: INFO: Pod "client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012674098s
Jun 24 15:50:52.915: INFO: Pod "client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016973954s
STEP: Saw pod success
Jun 24 15:50:52.915: INFO: Pod "client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:50:52.918: INFO: Trying to get logs from node minion pod client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:50:52.949: INFO: Waiting for pod client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:50:52.952: INFO: Pod client-containers-d62b272e-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:50:52.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1790" for this suite.
Jun 24 15:50:58.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:50:59.061: INFO: namespace containers-1790 deletion completed in 6.106319462s

• [SLOW TEST:10.207 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:50:59.065: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-dc40d08a-9697-11e9-8bcb-526dc0a539dd
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:50:59.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2094" for this suite.
Jun 24 15:51:05.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:51:05.221: INFO: namespace configmap-2094 deletion completed in 6.11670035s

• [SLOW TEST:6.156 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:51:05.221: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-dfecb812-9697-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 15:51:05.268: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd" in namespace "projected-2235" to be "success or failure"
Jun 24 15:51:05.277: INFO: Pod "pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.178639ms
Jun 24 15:51:07.280: INFO: Pod "pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012870208s
Jun 24 15:51:09.285: INFO: Pod "pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017386476s
STEP: Saw pod success
Jun 24 15:51:09.285: INFO: Pod "pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:51:09.289: INFO: Trying to get logs from node minion pod pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 24 15:51:09.313: INFO: Waiting for pod pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:51:09.318: INFO: Pod pod-projected-secrets-dfed50a7-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:51:09.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2235" for this suite.
Jun 24 15:51:15.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:51:15.418: INFO: namespace projected-2235 deletion completed in 6.097271207s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:51:15.419: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:51:39.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5956" for this suite.
Jun 24 15:51:45.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:51:45.780: INFO: namespace container-runtime-5956 deletion completed in 6.097604615s

• [SLOW TEST:30.361 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:51:45.786: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jun 24 15:51:45.831: INFO: Waiting up to 5m0s for pod "downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd" in namespace "downward-api-7603" to be "success or failure"
Jun 24 15:51:45.838: INFO: Pod "downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.075675ms
Jun 24 15:51:47.842: INFO: Pod "downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01114212s
STEP: Saw pod success
Jun 24 15:51:47.843: INFO: Pod "downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:51:47.846: INFO: Trying to get logs from node minion pod downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 15:51:47.875: INFO: Waiting for pod downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:51:47.877: INFO: Pod downward-api-f81adc89-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:51:47.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7603" for this suite.
Jun 24 15:51:53.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:51:53.996: INFO: namespace downward-api-7603 deletion completed in 6.114231405s

• [SLOW TEST:8.210 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:51:53.996: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-3359/secret-test-fd024c5c-9697-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 15:51:54.064: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd" in namespace "secrets-3359" to be "success or failure"
Jun 24 15:51:54.075: INFO: Pod "pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.471112ms
Jun 24 15:51:56.079: INFO: Pod "pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01526796s
STEP: Saw pod success
Jun 24 15:51:56.079: INFO: Pod "pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:51:56.083: INFO: Trying to get logs from node minion pod pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd container env-test: <nil>
STEP: delete the pod
Jun 24 15:51:56.105: INFO: Waiting for pod pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:51:56.108: INFO: Pod pod-configmaps-fd02c91d-9697-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:51:56.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3359" for this suite.
Jun 24 15:52:02.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:52:02.222: INFO: namespace secrets-3359 deletion completed in 6.108833036s

• [SLOW TEST:8.226 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:52:02.225: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2105
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 24 15:52:02.263: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 24 15:52:26.344: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.6:8080/dial?request=hostName&protocol=udp&host=10.251.128.5&port=8081&tries=1'] Namespace:pod-network-test-2105 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 15:52:26.344: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 15:52:26.536: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:52:26.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2105" for this suite.
Jun 24 15:52:48.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:52:48.648: INFO: namespace pod-network-test-2105 deletion completed in 22.107164752s

• [SLOW TEST:46.423 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:52:48.650: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-1d931846-9698-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 15:52:48.704: INFO: Waiting up to 5m0s for pod "pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd" in namespace "secrets-5933" to be "success or failure"
Jun 24 15:52:48.710: INFO: Pod "pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.389789ms
Jun 24 15:52:50.713: INFO: Pod "pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008965825s
STEP: Saw pod success
Jun 24 15:52:50.713: INFO: Pod "pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:52:50.717: INFO: Trying to get logs from node minion pod pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd container secret-env-test: <nil>
STEP: delete the pod
Jun 24 15:52:50.740: INFO: Waiting for pod pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:52:50.745: INFO: Pod pod-secrets-1d94a75e-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:52:50.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5933" for this suite.
Jun 24 15:52:56.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:52:56.851: INFO: namespace secrets-5933 deletion completed in 6.103129807s

• [SLOW TEST:8.201 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:52:56.851: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 15:52:56.895: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd" in namespace "downward-api-4675" to be "success or failure"
Jun 24 15:52:56.904: INFO: Pod "downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.420268ms
Jun 24 15:52:58.909: INFO: Pod "downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013818501s
STEP: Saw pod success
Jun 24 15:52:58.909: INFO: Pod "downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:52:58.913: INFO: Trying to get logs from node minion pod downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 15:52:58.935: INFO: Waiting for pod downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:52:58.940: INFO: Pod downwardapi-volume-22760a86-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:52:58.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4675" for this suite.
Jun 24 15:53:04.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:53:05.040: INFO: namespace downward-api-4675 deletion completed in 6.097416203s

• [SLOW TEST:8.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:53:05.041: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jun 24 15:53:15.212: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 279
	[quantile=0.9] = 302560
	[quantile=0.99] = 400882
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 238958
	[quantile=0.9] = 547121
	[quantile=0.99] = 610111
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 36
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 17
	[quantile=0.9] = 34
	[quantile=0.99] = 73
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 21
	[quantile=0.99] = 41
For namespace_queue_latency_sum:
	[] = 1439
For namespace_queue_latency_count:
	[] = 76
For namespace_retries:
	[] = 77
For namespace_work_duration:
	[quantile=0.5] = 161773
	[quantile=0.9] = 248480
	[quantile=0.99] = 288714
For namespace_work_duration_sum:
	[] = 11915036
For namespace_work_duration_count:
	[] = 76
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:53:15.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9093" for this suite.
Jun 24 15:53:21.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:53:21.315: INFO: namespace gc-9093 deletion completed in 6.098023482s

• [SLOW TEST:16.273 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:53:21.316: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jun 24 15:53:21.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4575'
Jun 24 15:53:21.727: INFO: stderr: ""
Jun 24 15:53:21.727: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 15:53:21.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:21.838: INFO: stderr: ""
Jun 24 15:53:21.838: INFO: stdout: "update-demo-nautilus-kx8ql update-demo-nautilus-zvq6x "
Jun 24 15:53:21.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:21.922: INFO: stderr: ""
Jun 24 15:53:21.922: INFO: stdout: ""
Jun 24 15:53:21.922: INFO: update-demo-nautilus-kx8ql is created but not running
Jun 24 15:53:26.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:27.027: INFO: stderr: ""
Jun 24 15:53:27.027: INFO: stdout: "update-demo-nautilus-kx8ql update-demo-nautilus-zvq6x "
Jun 24 15:53:27.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:27.115: INFO: stderr: ""
Jun 24 15:53:27.116: INFO: stdout: "true"
Jun 24 15:53:27.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:27.210: INFO: stderr: ""
Jun 24 15:53:27.210: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:53:27.210: INFO: validating pod update-demo-nautilus-kx8ql
Jun 24 15:53:27.220: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:53:27.220: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:53:27.220: INFO: update-demo-nautilus-kx8ql is verified up and running
Jun 24 15:53:27.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-zvq6x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:27.306: INFO: stderr: ""
Jun 24 15:53:27.306: INFO: stdout: "true"
Jun 24 15:53:27.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-zvq6x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:27.397: INFO: stderr: ""
Jun 24 15:53:27.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:53:27.398: INFO: validating pod update-demo-nautilus-zvq6x
Jun 24 15:53:27.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:53:27.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:53:27.407: INFO: update-demo-nautilus-zvq6x is verified up and running
STEP: scaling down the replication controller
Jun 24 15:53:27.418: INFO: scanned /root for discovery docs: <nil>
Jun 24 15:53:27.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4575'
Jun 24 15:53:28.539: INFO: stderr: ""
Jun 24 15:53:28.539: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 15:53:28.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:28.640: INFO: stderr: ""
Jun 24 15:53:28.640: INFO: stdout: "update-demo-nautilus-kx8ql update-demo-nautilus-zvq6x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 24 15:53:33.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:33.740: INFO: stderr: ""
Jun 24 15:53:33.740: INFO: stdout: "update-demo-nautilus-kx8ql update-demo-nautilus-zvq6x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 24 15:53:38.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:38.834: INFO: stderr: ""
Jun 24 15:53:38.834: INFO: stdout: "update-demo-nautilus-kx8ql "
Jun 24 15:53:38.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:38.935: INFO: stderr: ""
Jun 24 15:53:38.935: INFO: stdout: "true"
Jun 24 15:53:38.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:39.024: INFO: stderr: ""
Jun 24 15:53:39.024: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:53:39.024: INFO: validating pod update-demo-nautilus-kx8ql
Jun 24 15:53:39.029: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:53:39.029: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:53:39.029: INFO: update-demo-nautilus-kx8ql is verified up and running
STEP: scaling up the replication controller
Jun 24 15:53:39.033: INFO: scanned /root for discovery docs: <nil>
Jun 24 15:53:39.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4575'
Jun 24 15:53:40.166: INFO: stderr: ""
Jun 24 15:53:40.166: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 15:53:40.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:40.277: INFO: stderr: ""
Jun 24 15:53:40.277: INFO: stdout: "update-demo-nautilus-h4sqw update-demo-nautilus-kx8ql "
Jun 24 15:53:40.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-h4sqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:40.369: INFO: stderr: ""
Jun 24 15:53:40.369: INFO: stdout: ""
Jun 24 15:53:40.369: INFO: update-demo-nautilus-h4sqw is created but not running
Jun 24 15:53:45.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4575'
Jun 24 15:53:45.468: INFO: stderr: ""
Jun 24 15:53:45.468: INFO: stdout: "update-demo-nautilus-h4sqw update-demo-nautilus-kx8ql "
Jun 24 15:53:45.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-h4sqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:45.560: INFO: stderr: ""
Jun 24 15:53:45.560: INFO: stdout: "true"
Jun 24 15:53:45.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-h4sqw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:45.659: INFO: stderr: ""
Jun 24 15:53:45.659: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:53:45.659: INFO: validating pod update-demo-nautilus-h4sqw
Jun 24 15:53:45.669: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:53:45.669: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:53:45.669: INFO: update-demo-nautilus-h4sqw is verified up and running
Jun 24 15:53:45.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:45.761: INFO: stderr: ""
Jun 24 15:53:45.761: INFO: stdout: "true"
Jun 24 15:53:45.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kx8ql -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4575'
Jun 24 15:53:45.849: INFO: stderr: ""
Jun 24 15:53:45.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:53:45.849: INFO: validating pod update-demo-nautilus-kx8ql
Jun 24 15:53:45.854: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:53:45.854: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:53:45.854: INFO: update-demo-nautilus-kx8ql is verified up and running
STEP: using delete to clean up resources
Jun 24 15:53:45.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4575'
Jun 24 15:53:45.954: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 15:53:45.954: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 24 15:53:45.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4575'
Jun 24 15:53:46.060: INFO: stderr: "No resources found.\n"
Jun 24 15:53:46.060: INFO: stdout: ""
Jun 24 15:53:46.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=update-demo --namespace=kubectl-4575 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 15:53:46.175: INFO: stderr: ""
Jun 24 15:53:46.175: INFO: stdout: "update-demo-nautilus-h4sqw\nupdate-demo-nautilus-kx8ql\n"
Jun 24 15:53:46.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4575'
Jun 24 15:53:46.779: INFO: stderr: "No resources found.\n"
Jun 24 15:53:46.779: INFO: stdout: ""
Jun 24 15:53:46.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=update-demo --namespace=kubectl-4575 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 15:53:46.876: INFO: stderr: ""
Jun 24 15:53:46.876: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:53:46.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4575" for this suite.
Jun 24 15:54:08.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:54:08.973: INFO: namespace kubectl-4575 deletion completed in 22.093982103s

• [SLOW TEST:47.657 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:54:08.974: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun 24 15:54:14.043: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:54:15.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9772" for this suite.
Jun 24 15:54:37.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:54:37.200: INFO: namespace replicaset-9772 deletion completed in 22.135101984s

• [SLOW TEST:28.226 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:54:37.200: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-5e47d761-9698-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 15:54:37.258: INFO: Waiting up to 5m0s for pod "pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd" in namespace "secrets-1522" to be "success or failure"
Jun 24 15:54:37.263: INFO: Pod "pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263667ms
Jun 24 15:54:39.267: INFO: Pod "pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00879421s
STEP: Saw pod success
Jun 24 15:54:39.268: INFO: Pod "pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:54:39.271: INFO: Trying to get logs from node minion pod pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 15:54:39.293: INFO: Waiting for pod pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:54:39.295: INFO: Pod pod-secrets-5e4853f5-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:54:39.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1522" for this suite.
Jun 24 15:54:45.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:54:45.397: INFO: namespace secrets-1522 deletion completed in 6.099101445s

• [SLOW TEST:8.197 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:54:45.404: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 15:54:45.448: INFO: Waiting up to 5m0s for pod "downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd" in namespace "projected-9588" to be "success or failure"
Jun 24 15:54:45.459: INFO: Pod "downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.388825ms
Jun 24 15:54:47.462: INFO: Pod "downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014307849s
STEP: Saw pod success
Jun 24 15:54:47.463: INFO: Pod "downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:54:47.472: INFO: Trying to get logs from node minion pod downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 15:54:47.496: INFO: Waiting for pod downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:54:47.499: INFO: Pod downwardapi-volume-632a2216-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:54:47.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9588" for this suite.
Jun 24 15:54:53.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:54:53.605: INFO: namespace projected-9588 deletion completed in 6.102912815s

• [SLOW TEST:8.201 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:54:53.605: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:54:56.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3973" for this suite.
Jun 24 15:55:18.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:55:18.792: INFO: namespace replication-controller-3973 deletion completed in 22.104395323s

• [SLOW TEST:25.187 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:55:18.792: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 15:55:18.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd" in namespace "projected-9914" to be "success or failure"
Jun 24 15:55:18.842: INFO: Pod "downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.732622ms
Jun 24 15:55:20.847: INFO: Pod "downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007212215s
Jun 24 15:55:22.851: INFO: Pod "downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01162262s
STEP: Saw pod success
Jun 24 15:55:22.851: INFO: Pod "downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:55:22.855: INFO: Trying to get logs from node minion pod downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 15:55:22.875: INFO: Waiting for pod downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:55:22.880: INFO: Pod downwardapi-volume-77117e6a-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:55:22.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9914" for this suite.
Jun 24 15:55:28.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:55:28.990: INFO: namespace projected-9914 deletion completed in 6.106291269s

• [SLOW TEST:10.199 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:55:28.991: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 24 15:55:29.031: INFO: Waiting up to 5m0s for pod "pod-7d24751c-9698-11e9-8bcb-526dc0a539dd" in namespace "emptydir-5321" to be "success or failure"
Jun 24 15:55:29.037: INFO: Pod "pod-7d24751c-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.976608ms
Jun 24 15:55:31.041: INFO: Pod "pod-7d24751c-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009964947s
STEP: Saw pod success
Jun 24 15:55:31.041: INFO: Pod "pod-7d24751c-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:55:31.044: INFO: Trying to get logs from node minion pod pod-7d24751c-9698-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:55:31.071: INFO: Waiting for pod pod-7d24751c-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:55:31.074: INFO: Pod pod-7d24751c-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:55:31.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5321" for this suite.
Jun 24 15:55:37.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:55:37.177: INFO: namespace emptydir-5321 deletion completed in 6.099694915s

• [SLOW TEST:8.186 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:55:37.179: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-8205ec24-9698-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:55:37.221: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd" in namespace "projected-9396" to be "success or failure"
Jun 24 15:55:37.227: INFO: Pod "pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.83712ms
Jun 24 15:55:39.231: INFO: Pod "pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00975951s
STEP: Saw pod success
Jun 24 15:55:39.231: INFO: Pod "pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:55:39.235: INFO: Trying to get logs from node minion pod pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:55:39.263: INFO: Waiting for pod pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:55:39.267: INFO: Pod pod-projected-configmaps-82065045-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:55:39.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9396" for this suite.
Jun 24 15:55:45.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:55:45.369: INFO: namespace projected-9396 deletion completed in 6.099817172s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:55:45.370: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 15:55:45.421: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 24 15:55:45.433: INFO: Number of nodes with available pods: 0
Jun 24 15:55:45.433: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 24 15:55:45.452: INFO: Number of nodes with available pods: 0
Jun 24 15:55:45.452: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:46.455: INFO: Number of nodes with available pods: 0
Jun 24 15:55:46.455: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:47.456: INFO: Number of nodes with available pods: 1
Jun 24 15:55:47.456: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 24 15:55:47.476: INFO: Number of nodes with available pods: 1
Jun 24 15:55:47.476: INFO: Number of running nodes: 0, number of available pods: 1
Jun 24 15:55:48.480: INFO: Number of nodes with available pods: 0
Jun 24 15:55:48.480: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 24 15:55:48.496: INFO: Number of nodes with available pods: 0
Jun 24 15:55:48.496: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:49.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:49.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:50.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:50.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:51.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:51.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:52.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:52.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:53.499: INFO: Number of nodes with available pods: 0
Jun 24 15:55:53.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:54.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:54.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:55.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:55.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:56.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:56.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:57.500: INFO: Number of nodes with available pods: 0
Jun 24 15:55:57.500: INFO: Node minion is running more than one daemon pod
Jun 24 15:55:58.500: INFO: Number of nodes with available pods: 1
Jun 24 15:55:58.500: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4438, will wait for the garbage collector to delete the pods
Jun 24 15:55:58.567: INFO: Deleting DaemonSet.extensions daemon-set took: 6.926656ms
Jun 24 15:55:58.867: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.386965ms
Jun 24 15:56:06.871: INFO: Number of nodes with available pods: 0
Jun 24 15:56:06.871: INFO: Number of running nodes: 0, number of available pods: 0
Jun 24 15:56:06.879: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4438/daemonsets","resourceVersion":"5029"},"items":null}

Jun 24 15:56:06.887: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4438/pods","resourceVersion":"5029"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:56:06.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4438" for this suite.
Jun 24 15:56:12.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:56:13.004: INFO: namespace daemonsets-4438 deletion completed in 6.097408951s

• [SLOW TEST:27.635 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:56:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 24 15:56:13.062: INFO: Waiting up to 5m0s for pod "pod-97630893-9698-11e9-8bcb-526dc0a539dd" in namespace "emptydir-8553" to be "success or failure"
Jun 24 15:56:13.064: INFO: Pod "pod-97630893-9698-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.432573ms
Jun 24 15:56:15.068: INFO: Pod "pod-97630893-9698-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006799047s
STEP: Saw pod success
Jun 24 15:56:15.069: INFO: Pod "pod-97630893-9698-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:56:15.073: INFO: Trying to get logs from node minion pod pod-97630893-9698-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 15:56:15.108: INFO: Waiting for pod pod-97630893-9698-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:56:15.111: INFO: Pod pod-97630893-9698-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:56:15.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8553" for this suite.
Jun 24 15:56:21.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:56:21.237: INFO: namespace emptydir-8553 deletion completed in 6.120560288s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:56:21.238: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-2988
STEP: Creating a pod to test atomic-volume-subpath
Jun 24 15:56:21.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2988" in namespace "subpath-2164" to be "success or failure"
Jun 24 15:56:21.293: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822617ms
Jun 24 15:56:23.297: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 2.011878018s
Jun 24 15:56:25.302: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 4.016719352s
Jun 24 15:56:27.306: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 6.020780398s
Jun 24 15:56:29.310: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 8.024901395s
Jun 24 15:56:31.315: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 10.029209964s
Jun 24 15:56:33.319: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 12.033278385s
Jun 24 15:56:35.323: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 14.037556946s
Jun 24 15:56:37.327: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 16.041422178s
Jun 24 15:56:39.331: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 18.045402173s
Jun 24 15:56:41.335: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Running", Reason="", readiness=true. Elapsed: 20.04959376s
Jun 24 15:56:43.345: INFO: Pod "pod-subpath-test-configmap-2988": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.059358778s
STEP: Saw pod success
Jun 24 15:56:43.345: INFO: Pod "pod-subpath-test-configmap-2988" satisfied condition "success or failure"
Jun 24 15:56:43.348: INFO: Trying to get logs from node minion pod pod-subpath-test-configmap-2988 container test-container-subpath-configmap-2988: <nil>
STEP: delete the pod
Jun 24 15:56:43.370: INFO: Waiting for pod pod-subpath-test-configmap-2988 to disappear
Jun 24 15:56:43.376: INFO: Pod pod-subpath-test-configmap-2988 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2988
Jun 24 15:56:43.376: INFO: Deleting pod "pod-subpath-test-configmap-2988" in namespace "subpath-2164"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:56:43.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2164" for this suite.
Jun 24 15:56:49.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:56:49.498: INFO: namespace subpath-2164 deletion completed in 6.117339846s

• [SLOW TEST:28.260 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:56:49.499: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jun 24 15:56:49.538: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun 24 15:56:56.579: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:56:56.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6998" for this suite.
Jun 24 15:57:02.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:57:02.689: INFO: namespace pods-6998 deletion completed in 6.102688957s

• [SLOW TEST:13.190 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:57:02.689: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jun 24 15:57:02.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-8652'
Jun 24 15:57:03.529: INFO: stderr: ""
Jun 24 15:57:03.529: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 15:57:03.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8652'
Jun 24 15:57:03.638: INFO: stderr: ""
Jun 24 15:57:03.638: INFO: stdout: "update-demo-nautilus-kz6jn update-demo-nautilus-p28sh "
Jun 24 15:57:03.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kz6jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8652'
Jun 24 15:57:03.727: INFO: stderr: ""
Jun 24 15:57:03.727: INFO: stdout: ""
Jun 24 15:57:03.727: INFO: update-demo-nautilus-kz6jn is created but not running
Jun 24 15:57:08.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8652'
Jun 24 15:57:08.823: INFO: stderr: ""
Jun 24 15:57:08.823: INFO: stdout: "update-demo-nautilus-kz6jn update-demo-nautilus-p28sh "
Jun 24 15:57:08.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kz6jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8652'
Jun 24 15:57:08.912: INFO: stderr: ""
Jun 24 15:57:08.912: INFO: stdout: "true"
Jun 24 15:57:08.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-kz6jn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8652'
Jun 24 15:57:08.997: INFO: stderr: ""
Jun 24 15:57:08.997: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:57:08.997: INFO: validating pod update-demo-nautilus-kz6jn
Jun 24 15:57:09.006: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:57:09.006: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:57:09.006: INFO: update-demo-nautilus-kz6jn is verified up and running
Jun 24 15:57:09.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-p28sh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8652'
Jun 24 15:57:09.095: INFO: stderr: ""
Jun 24 15:57:09.095: INFO: stdout: "true"
Jun 24 15:57:09.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-p28sh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8652'
Jun 24 15:57:09.194: INFO: stderr: ""
Jun 24 15:57:09.194: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 15:57:09.194: INFO: validating pod update-demo-nautilus-p28sh
Jun 24 15:57:09.207: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 15:57:09.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 15:57:09.207: INFO: update-demo-nautilus-p28sh is verified up and running
STEP: using delete to clean up resources
Jun 24 15:57:09.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-8652'
Jun 24 15:57:09.304: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 15:57:09.304: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 24 15:57:09.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8652'
Jun 24 15:57:09.407: INFO: stderr: "No resources found.\n"
Jun 24 15:57:09.407: INFO: stdout: ""
Jun 24 15:57:09.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=update-demo --namespace=kubectl-8652 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 15:57:09.501: INFO: stderr: ""
Jun 24 15:57:09.501: INFO: stdout: "update-demo-nautilus-kz6jn\nupdate-demo-nautilus-p28sh\n"
Jun 24 15:57:10.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8652'
Jun 24 15:57:10.110: INFO: stderr: "No resources found.\n"
Jun 24 15:57:10.110: INFO: stdout: ""
Jun 24 15:57:10.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=update-demo --namespace=kubectl-8652 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 15:57:10.209: INFO: stderr: ""
Jun 24 15:57:10.209: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:57:10.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8652" for this suite.
Jun 24 15:57:32.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:57:32.319: INFO: namespace kubectl-8652 deletion completed in 22.104560994s

• [SLOW TEST:29.630 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:57:32.322: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 24 15:57:38.405: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:38.408: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:40.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:40.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:42.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:42.414: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:44.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:44.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:46.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:46.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:48.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:48.415: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:50.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:50.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:52.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:52.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:54.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:54.414: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:56.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:56.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:57:58.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:57:58.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:58:00.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:58:00.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:58:02.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:58:02.414: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:58:04.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:58:04.413: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:58:06.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:58:06.412: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 24 15:58:08.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 24 15:58:08.412: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:58:08.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2643" for this suite.
Jun 24 15:58:30.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:58:30.523: INFO: namespace container-lifecycle-hook-2643 deletion completed in 22.093934751s

• [SLOW TEST:58.201 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:58:30.523: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Jun 24 15:58:30.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 cluster-info'
Jun 24 15:58:30.654: INFO: stderr: ""
Jun 24 15:58:30.654: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:58:30.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1420" for this suite.
Jun 24 15:58:36.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:58:36.762: INFO: namespace kubectl-1420 deletion completed in 6.103828103s

• [SLOW TEST:6.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:58:36.763: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Jun 24 15:58:36.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-7002'
Jun 24 15:58:37.081: INFO: stderr: ""
Jun 24 15:58:37.081: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Jun 24 15:58:38.085: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 15:58:38.086: INFO: Found 0 / 1
Jun 24 15:58:39.086: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 15:58:39.086: INFO: Found 0 / 1
Jun 24 15:58:40.086: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 15:58:40.086: INFO: Found 1 / 1
Jun 24 15:58:40.086: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 24 15:58:40.089: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 15:58:40.089: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jun 24 15:58:40.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 logs redis-master-mpsvg redis-master --namespace=kubectl-7002'
Jun 24 15:58:40.247: INFO: stderr: ""
Jun 24 15:58:40.247: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Jun 15:58:39.350 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Jun 15:58:39.350 # Server started, Redis version 3.2.12\n1:M 24 Jun 15:58:39.350 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Jun 15:58:39.350 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jun 24 15:58:40.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 log redis-master-mpsvg redis-master --namespace=kubectl-7002 --tail=1'
Jun 24 15:58:40.363: INFO: stderr: ""
Jun 24 15:58:40.363: INFO: stdout: "1:M 24 Jun 15:58:39.350 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jun 24 15:58:40.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 log redis-master-mpsvg redis-master --namespace=kubectl-7002 --limit-bytes=1'
Jun 24 15:58:40.465: INFO: stderr: ""
Jun 24 15:58:40.465: INFO: stdout: " "
STEP: exposing timestamps
Jun 24 15:58:40.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 log redis-master-mpsvg redis-master --namespace=kubectl-7002 --tail=1 --timestamps'
Jun 24 15:58:40.568: INFO: stderr: ""
Jun 24 15:58:40.569: INFO: stdout: "2019-06-24T15:58:39.351000601Z 1:M 24 Jun 15:58:39.350 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jun 24 15:58:43.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 log redis-master-mpsvg redis-master --namespace=kubectl-7002 --since=1s'
Jun 24 15:58:43.205: INFO: stderr: ""
Jun 24 15:58:43.205: INFO: stdout: ""
Jun 24 15:58:43.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 log redis-master-mpsvg redis-master --namespace=kubectl-7002 --since=24h'
Jun 24 15:58:43.316: INFO: stderr: ""
Jun 24 15:58:43.316: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Jun 15:58:39.350 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Jun 15:58:39.350 # Server started, Redis version 3.2.12\n1:M 24 Jun 15:58:39.350 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Jun 15:58:39.350 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Jun 24 15:58:43.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-7002'
Jun 24 15:58:43.415: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 15:58:43.415: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jun 24 15:58:43.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7002'
Jun 24 15:58:43.515: INFO: stderr: "No resources found.\n"
Jun 24 15:58:43.515: INFO: stdout: ""
Jun 24 15:58:43.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=nginx --namespace=kubectl-7002 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 15:58:43.607: INFO: stderr: ""
Jun 24 15:58:43.607: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:58:43.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7002" for this suite.
Jun 24 15:59:05.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:59:05.704: INFO: namespace kubectl-7002 deletion completed in 22.089919963s

• [SLOW TEST:28.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:59:05.705: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Jun 24 15:59:05.749: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-766262415 proxy --unix-socket=/tmp/kubectl-proxy-unix076242082/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:59:05.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6831" for this suite.
Jun 24 15:59:11.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:59:11.932: INFO: namespace kubectl-6831 deletion completed in 6.105696565s

• [SLOW TEST:6.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:59:11.932: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 15:59:11.967: INFO: Creating deployment "nginx-deployment"
Jun 24 15:59:11.973: INFO: Waiting for observed generation 1
Jun 24 15:59:13.980: INFO: Waiting for all required pods to come up
Jun 24 15:59:13.988: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun 24 15:59:19.997: INFO: Waiting for deployment "nginx-deployment" to complete
Jun 24 15:59:20.005: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jun 24 15:59:20.012: INFO: Updating deployment nginx-deployment
Jun 24 15:59:20.012: INFO: Waiting for observed generation 2
Jun 24 15:59:22.021: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun 24 15:59:22.025: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun 24 15:59:22.028: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 24 15:59:22.034: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun 24 15:59:22.034: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun 24 15:59:22.037: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 24 15:59:22.042: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jun 24 15:59:22.042: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jun 24 15:59:22.048: INFO: Updating deployment nginx-deployment
Jun 24 15:59:22.048: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jun 24 15:59:22.059: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun 24 15:59:22.082: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 24 15:59:24.113: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1956,SelfLink:/apis/apps/v1/namespaces/deployment-1956/deployments/nginx-deployment,UID:0207217a-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5824,Generation:3,CreationTimestamp:2019-06-24 15:59:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-06-24 15:59:22 +0000 UTC 2019-06-24 15:59:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-24 15:59:22 +0000 UTC 2019-06-24 15:59:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jun 24 15:59:24.117: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-1956,SelfLink:/apis/apps/v1/namespaces/deployment-1956/replicasets/nginx-deployment-5f9595f595,UID:06d28dfb-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5818,Generation:3,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0207217a-9699-11e9-b70d-fa163ef83c94 0xc002a5d9e7 0xc002a5d9e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 15:59:24.117: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jun 24 15:59:24.118: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-1956,SelfLink:/apis/apps/v1/namespaces/deployment-1956/replicasets/nginx-deployment-6f478d8d8,UID:0207d700-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5819,Generation:3,CreationTimestamp:2019-06-24 15:59:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0207217a-9699-11e9-b70d-fa163ef83c94 0xc002a5dab7 0xc002a5dab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jun 24 15:59:24.132: INFO: Pod "nginx-deployment-5f9595f595-46j64" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-46j64,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-46j64,UID:080d1e1f-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5793,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8390 0xc0025d8391}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.132: INFO: Pod "nginx-deployment-5f9595f595-4cxl4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4cxl4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-4cxl4,UID:080f6a93-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5801,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d84b0 0xc0025d84b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.132: INFO: Pod "nginx-deployment-5f9595f595-66xt6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-66xt6,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-66xt6,UID:080f7d4f-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5802,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d85d0 0xc0025d85d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.133: INFO: Pod "nginx-deployment-5f9595f595-8m9nr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8m9nr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-8m9nr,UID:06d4b8fc-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5742,Generation:0,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d86f0 0xc0025d86f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.133: INFO: Pod "nginx-deployment-5f9595f595-b6bsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b6bsc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-b6bsc,UID:06df2564-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5747,Generation:0,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8870 0xc0025d8871}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d88f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.133: INFO: Pod "nginx-deployment-5f9595f595-c7nlf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-c7nlf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-c7nlf,UID:080f6025-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5805,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d89e0 0xc0025d89e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.134: INFO: Pod "nginx-deployment-5f9595f595-jc77l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jc77l,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-jc77l,UID:06d34103-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5721,Generation:0,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8b10 0xc0025d8b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.134: INFO: Pod "nginx-deployment-5f9595f595-m4lnv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-m4lnv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-m4lnv,UID:080f6dc4-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5806,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8cb0 0xc0025d8cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.134: INFO: Pod "nginx-deployment-5f9595f595-nlbmj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nlbmj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-nlbmj,UID:080adf9c-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5825,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8dd0 0xc0025d8dd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.136: INFO: Pod "nginx-deployment-5f9595f595-pb92h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-pb92h,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-pb92h,UID:081125dc-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5815,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d8f50 0xc0025d8f51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d8fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d8ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.136: INFO: Pod "nginx-deployment-5f9595f595-t297z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-t297z,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-t297z,UID:080d06ae-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5875,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d9080 0xc0025d9081}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.137: INFO: Pod "nginx-deployment-5f9595f595-ts2s8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-ts2s8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-ts2s8,UID:06ddf821-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5746,Generation:0,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d91f0 0xc0025d91f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d92a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.137: INFO: Pod "nginx-deployment-5f9595f595-txwz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-txwz2,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-5f9595f595-txwz2,UID:06d4b880-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5732,Generation:0,CreationTimestamp:2019-06-24 15:59:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 06d28dfb-9699-11e9-b70d-fa163ef83c94 0xc0025d9370 0xc0025d9371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d93f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:20 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.138: INFO: Pod "nginx-deployment-6f478d8d8-7ktgp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7ktgp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-7ktgp,UID:020967fa-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5687,Generation:0,CreationTimestamp:2019-06-24 15:59:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d94e0 0xc0025d94e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.5,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b2bc7aae46be01eab0ec88fc54c58c19eca6068ebcb0ba090bff546de21dedeb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.139: INFO: Pod "nginx-deployment-6f478d8d8-c4927" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-c4927,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-c4927,UID:080cfbdd-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5867,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9640 0xc0025d9641}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d96b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d96d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.139: INFO: Pod "nginx-deployment-6f478d8d8-cfbxd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cfbxd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-cfbxd,UID:020dc1e9-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5690,Generation:0,CreationTimestamp:2019-06-24 15:59:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9790 0xc0025d9791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.10,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://304b3c8180c6529ad6c69c6fec3497e26e45a17137eec93ca8ac3187aa6b71a5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.140: INFO: Pod "nginx-deployment-6f478d8d8-cl49h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cl49h,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-cl49h,UID:020dac13-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5677,Generation:0,CreationTimestamp:2019-06-24 15:59:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d98f0 0xc0025d98f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.8,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://cbab7cdbbb4bc52ca853299f17e84611083c137c8f9de813ac17721506c83ec9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.141: INFO: Pod "nginx-deployment-6f478d8d8-dqz4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dqz4g,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-dqz4g,UID:080ac56e-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5851,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9a50 0xc0025d9a51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.141: INFO: Pod "nginx-deployment-6f478d8d8-g262z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g262z,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-g262z,UID:080f76c1-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5808,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9ba0 0xc0025d9ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.143: INFO: Pod "nginx-deployment-6f478d8d8-g6v5c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g6v5c,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-g6v5c,UID:080d1331-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5784,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9cb0 0xc0025d9cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.143: INFO: Pod "nginx-deployment-6f478d8d8-hxxz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hxxz2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-hxxz2,UID:080d0c00-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5786,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9dc0 0xc0025d9dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.144: INFO: Pod "nginx-deployment-6f478d8d8-j59rx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j59rx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-j59rx,UID:020dbb37-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5672,Generation:0,CreationTimestamp:2019-06-24 15:59:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0025d9ed0 0xc0025d9ed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d9f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d9f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.9,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://eb588ddeed0825aa14bc2d8ead41ef0377828381be11fa9da42be2d81c56a2c4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.145: INFO: Pod "nginx-deployment-6f478d8d8-l7tv7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-l7tv7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-l7tv7,UID:080d0419-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5861,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266030 0xc003266031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032660a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032660c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.145: INFO: Pod "nginx-deployment-6f478d8d8-ncd5d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ncd5d,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-ncd5d,UID:020ebdf9-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5667,Generation:0,CreationTimestamp:2019-06-24 15:59:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266180 0xc003266181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032661f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.14,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://070b322bec583daa2d1a6be19a852b56c36adb58b6211b0b592cac32cc37be1e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.147: INFO: Pod "nginx-deployment-6f478d8d8-nnrj4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nnrj4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-nnrj4,UID:080f7a5c-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5800,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0032662e0 0xc0032662e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.147: INFO: Pod "nginx-deployment-6f478d8d8-nr95r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nr95r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-nr95r,UID:080ae83a-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5841,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0032663f0 0xc0032663f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.147: INFO: Pod "nginx-deployment-6f478d8d8-qtl5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qtl5h,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-qtl5h,UID:080f7908-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5807,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266540 0xc003266541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032665b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032665d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.147: INFO: Pod "nginx-deployment-6f478d8d8-t4r87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-t4r87,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-t4r87,UID:080f8432-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5804,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266650 0xc003266651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032666c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032666e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.148: INFO: Pod "nginx-deployment-6f478d8d8-vc2th" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vc2th,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-vc2th,UID:020adb4d-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5660,Generation:0,CreationTimestamp:2019-06-24 15:59:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266760 0xc003266761}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032667d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032667f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.7,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ce34970af0177953aab24cb914064e3fc510199e0e25c263b87a64cdd429d999}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.149: INFO: Pod "nginx-deployment-6f478d8d8-vnswk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vnswk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-vnswk,UID:080f6d1a-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5810,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0032668c0 0xc0032668c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.149: INFO: Pod "nginx-deployment-6f478d8d8-x8tw5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x8tw5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-x8tw5,UID:0809e224-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5803,Generation:0,CreationTimestamp:2019-06-24 15:59:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc0032669d0 0xc0032669d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:22 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 15:59:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.150: INFO: Pod "nginx-deployment-6f478d8d8-zbcvp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zbcvp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-zbcvp,UID:020db72e-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5655,Generation:0,CreationTimestamp:2019-06-24 15:59:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266b20 0xc003266b21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.11,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0f3e0e5019e02282f069622dc706186ead76400a40f23533bea97c8a7e0d6139}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 15:59:24.150: INFO: Pod "nginx-deployment-6f478d8d8-zdm5l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zdm5l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-1956,SelfLink:/api/v1/namespaces/deployment-1956/pods/nginx-deployment-6f478d8d8-zdm5l,UID:020ac41f-9699-11e9-b70d-fa163ef83c94,ResourceVersion:5682,Generation:0,CreationTimestamp:2019-06-24 15:59:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 0207d700-9699-11e9-b70d-fa163ef83c94 0xc003266c80 0xc003266c81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4bm7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4bm7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4bm7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003266cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003266d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 15:59:12 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.6,StartTime:2019-06-24 15:59:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 15:59:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4a80d1828a58f71ca82c09dfd2d20d091d02fecfcce46fe2664259d31cb82aa1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:59:24.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1956" for this suite.
Jun 24 15:59:32.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:59:32.258: INFO: namespace deployment-1956 deletion completed in 8.104668028s

• [SLOW TEST:20.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:59:32.258: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jun 24 15:59:42.360: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 269
	[quantile=0.9] = 252821
	[quantile=0.99] = 400882
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 230260
	[quantile=0.9] = 546901
	[quantile=0.99] = 610111
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 8
	[quantile=0.99] = 32
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 16
	[quantile=0.9] = 30
	[quantile=0.99] = 67
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 16
	[quantile=0.9] = 28
	[quantile=0.99] = 46
For namespace_queue_latency_sum:
	[] = 2266
For namespace_queue_latency_count:
	[] = 120
For namespace_retries:
	[] = 121
For namespace_work_duration:
	[quantile=0.5] = 167316
	[quantile=0.9] = 265926
	[quantile=0.99] = 628482
For namespace_work_duration_sum:
	[] = 18970293
For namespace_work_duration_count:
	[] = 120
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:59:42.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9835" for this suite.
Jun 24 15:59:48.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:59:48.467: INFO: namespace gc-9835 deletion completed in 6.101494983s

• [SLOW TEST:16.209 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:59:48.468: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-17cd27c4-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:59:48.507: INFO: Waiting up to 5m0s for pod "pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd" in namespace "configmap-9551" to be "success or failure"
Jun 24 15:59:48.514: INFO: Pod "pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.107993ms
Jun 24 15:59:50.518: INFO: Pod "pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010157362s
STEP: Saw pod success
Jun 24 15:59:50.518: INFO: Pod "pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:59:50.521: INFO: Trying to get logs from node minion pod pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:59:50.543: INFO: Waiting for pod pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:59:50.546: INFO: Pod pod-configmaps-17cd99ca-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:59:50.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9551" for this suite.
Jun 24 15:59:56.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 15:59:56.655: INFO: namespace configmap-9551 deletion completed in 6.106620704s

• [SLOW TEST:8.187 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 15:59:56.670: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-1cb10acb-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 15:59:56.712: INFO: Waiting up to 5m0s for pod "pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd" in namespace "configmap-1270" to be "success or failure"
Jun 24 15:59:56.729: INFO: Pod "pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.373835ms
Jun 24 15:59:58.733: INFO: Pod "pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021423113s
STEP: Saw pod success
Jun 24 15:59:58.734: INFO: Pod "pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 15:59:58.737: INFO: Trying to get logs from node minion pod pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 15:59:58.761: INFO: Waiting for pod pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 15:59:58.765: INFO: Pod pod-configmaps-1cb170ee-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 15:59:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1270" for this suite.
Jun 24 16:00:04.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:00:04.858: INFO: namespace configmap-1270 deletion completed in 6.088745203s

• [SLOW TEST:8.189 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:00:04.859: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-2192d5f2-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:00:04.906: INFO: Waiting up to 5m0s for pod "pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd" in namespace "secrets-670" to be "success or failure"
Jun 24 16:00:04.910: INFO: Pod "pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.421114ms
Jun 24 16:00:06.914: INFO: Pod "pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007716365s
STEP: Saw pod success
Jun 24 16:00:06.914: INFO: Pod "pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:00:06.916: INFO: Trying to get logs from node minion pod pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:00:06.946: INFO: Waiting for pod pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:00:06.949: INFO: Pod pod-secrets-21934d6b-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:00:06.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-670" for this suite.
Jun 24 16:00:12.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:00:13.048: INFO: namespace secrets-670 deletion completed in 6.095251541s

• [SLOW TEST:8.190 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:00:13.051: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9284
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9284
STEP: Creating statefulset with conflicting port in namespace statefulset-9284
STEP: Waiting until pod test-pod will start running in namespace statefulset-9284
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9284
Jun 24 16:00:17.136: INFO: Observed stateful pod in namespace: statefulset-9284, name: ss-0, uid: 28c22aeb-9699-11e9-b70d-fa163ef83c94, status phase: Pending. Waiting for statefulset controller to delete.
Jun 24 16:00:17.727: INFO: Observed stateful pod in namespace: statefulset-9284, name: ss-0, uid: 28c22aeb-9699-11e9-b70d-fa163ef83c94, status phase: Failed. Waiting for statefulset controller to delete.
Jun 24 16:00:17.741: INFO: Observed stateful pod in namespace: statefulset-9284, name: ss-0, uid: 28c22aeb-9699-11e9-b70d-fa163ef83c94, status phase: Failed. Waiting for statefulset controller to delete.
Jun 24 16:00:17.748: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9284
STEP: Removing pod with conflicting port in namespace statefulset-9284
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9284 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 24 16:00:21.784: INFO: Deleting all statefulset in ns statefulset-9284
Jun 24 16:00:21.787: INFO: Scaling statefulset ss to 0
Jun 24 16:00:31.806: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 16:00:31.809: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:00:31.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9284" for this suite.
Jun 24 16:00:37.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:00:37.924: INFO: namespace statefulset-9284 deletion completed in 6.099239185s

• [SLOW TEST:24.873 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:00:37.924: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-354acc3b-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:00:37.988: INFO: Waiting up to 5m0s for pod "pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd" in namespace "secrets-6882" to be "success or failure"
Jun 24 16:00:37.992: INFO: Pod "pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.184168ms
Jun 24 16:00:39.996: INFO: Pod "pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00840933s
Jun 24 16:00:42.000: INFO: Pod "pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012528527s
STEP: Saw pod success
Jun 24 16:00:42.000: INFO: Pod "pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:00:42.004: INFO: Trying to get logs from node minion pod pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:00:42.032: INFO: Waiting for pod pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:00:42.045: INFO: Pod pod-secrets-354bbb70-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:00:42.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6882" for this suite.
Jun 24 16:00:48.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:00:48.153: INFO: namespace secrets-6882 deletion completed in 6.104548604s

• [SLOW TEST:10.229 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:00:48.154: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:00:48.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 version --client'
Jun 24 16:00:48.260: INFO: stderr: ""
Jun 24 16:00:48.260: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jun 24 16:00:48.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-2036'
Jun 24 16:00:48.529: INFO: stderr: ""
Jun 24 16:00:48.529: INFO: stdout: "replicationcontroller/redis-master created\n"
Jun 24 16:00:48.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-2036'
Jun 24 16:00:48.775: INFO: stderr: ""
Jun 24 16:00:48.775: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 24 16:00:49.780: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:00:49.780: INFO: Found 0 / 1
Jun 24 16:00:50.780: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:00:50.780: INFO: Found 1 / 1
Jun 24 16:00:50.780: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 24 16:00:50.785: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:00:50.785: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 24 16:00:50.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 describe pod redis-master-mx74f --namespace=kubectl-2036'
Jun 24 16:00:50.898: INFO: stderr: ""
Jun 24 16:00:50.898: INFO: stdout: "Name:               redis-master-mx74f\nNamespace:          kubectl-2036\nPriority:           0\nPriorityClassName:  <none>\nNode:               minion/10.1.0.12\nStart Time:         Mon, 24 Jun 2019 16:00:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.251.128.5\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://26e5a5277a33103a23b08228d61521eba2285b769e264f0d9c7bc0eacbcbf0fd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 24 Jun 2019 16:00:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g9f7h (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g9f7h:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g9f7h\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2036/redis-master-mx74f to minion\n  Normal  Pulled     1s    kubelet, minion    Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, minion    Created container redis-master\n  Normal  Started    1s    kubelet, minion    Started container redis-master\n"
Jun 24 16:00:50.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 describe rc redis-master --namespace=kubectl-2036'
Jun 24 16:00:51.011: INFO: stderr: ""
Jun 24 16:00:51.011: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2036\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-mx74f\n"
Jun 24 16:00:51.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 describe service redis-master --namespace=kubectl-2036'
Jun 24 16:00:51.121: INFO: stderr: ""
Jun 24 16:00:51.121: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2036\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.241.235.106\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.251.128.5:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun 24 16:00:51.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 describe node master'
Jun 24 16:00:51.253: INFO: stderr: ""
Jun 24 16:00:51.253: INFO: stdout: "Name:               master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    zone=master\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 24 Jun 2019 15:28:04 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 24 Jun 2019 15:29:36 +0000   Mon, 24 Jun 2019 15:29:36 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Mon, 24 Jun 2019 16:00:44 +0000   Mon, 24 Jun 2019 15:27:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 24 Jun 2019 16:00:44 +0000   Mon, 24 Jun 2019 15:27:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 24 Jun 2019 16:00:44 +0000   Mon, 24 Jun 2019 15:27:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 24 Jun 2019 16:00:44 +0000   Mon, 24 Jun 2019 15:29:22 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.1.0.11\n  Hostname:    master\nCapacity:\n cpu:                8\n ephemeral-storage:  50758760Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             32946808Ki\n pods:               110\nAllocatable:\n cpu:                7800m\n ephemeral-storage:  46779273139\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             32344408Ki\n pods:               110\nSystem Info:\n Machine ID:                 cf0103b22e87455d840ec02695143254\n System UUID:                CF0103B2-2E87-455D-840E-C02695143254\n Boot ID:                    7000569d-154a-42af-b9c1-51f773bea7e3\n Kernel Version:             4.4.0-141-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.14.3\n Kube-Proxy Version:         v1.14.3\nPodCIDR:                     10.251.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-5b2a161d72614acd                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-7e1461ca4731443f-2pk4z    0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m\n  kube-system                coredns-97c4b444f-8l248                                    100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     30m\n  kube-system                dns-autoscaler-5fc5fdbf6-v2qt9                             20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         30m\n  kube-system                kube-apiserver-master                                      250m (3%)     0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                kube-controller-manager-master                             200m (2%)     0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                kube-proxy-29wx4                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\n  kube-system                kube-scheduler-master                                      100m (1%)     0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                nodelocaldns-9lhfh                                         100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     30m\n  kube-system                weave-net-r2zvv                                            20m (0%)      0 (0%)      0 (0%)           0 (0%)         31m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                790m (10%)  0 (0%)\n  memory             150Mi (0%)  340Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                Message\n  ----    ------                   ----               ----                -------\n  Normal  NodeHasSufficientMemory  32m (x8 over 32m)  kubelet, master     Node master status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    32m (x8 over 32m)  kubelet, master     Node master status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     32m (x7 over 32m)  kubelet, master     Node master status is now: NodeHasSufficientPID\n  Normal  Starting                 32m                kube-proxy, master  Starting kube-proxy.\n  Normal  Starting                 32m                kubelet, master     Starting kubelet.\n  Normal  NodeHasSufficientMemory  32m                kubelet, master     Node master status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    32m                kubelet, master     Node master status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     32m                kubelet, master     Node master status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  32m                kubelet, master     Updated Node Allocatable limit across pods\n  Normal  NodeReady                31m                kubelet, master     Node master status is now: NodeReady\n  Normal  Starting                 31m                kube-proxy, master  Starting kube-proxy.\n  Normal  Starting                 29m                kubelet, master     Starting kubelet.\n  Normal  NodeHasSufficientMemory  29m (x8 over 29m)  kubelet, master     Node master status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    29m (x8 over 29m)  kubelet, master     Node master status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     29m (x7 over 29m)  kubelet, master     Node master status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  29m                kubelet, master     Updated Node Allocatable limit across pods\n"
Jun 24 16:00:51.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 describe namespace kubectl-2036'
Jun 24 16:00:51.359: INFO: stderr: ""
Jun 24 16:00:51.359: INFO: stdout: "Name:         kubectl-2036\nLabels:       e2e-framework=kubectl\n              e2e-run=368df000-9695-11e9-8bcb-526dc0a539dd\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:00:51.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2036" for this suite.
Jun 24 16:01:13.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:01:13.450: INFO: namespace kubectl-2036 deletion completed in 22.08749386s

• [SLOW TEST:25.296 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:01:13.450: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4a74d2f7-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:01:13.499: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd" in namespace "projected-3391" to be "success or failure"
Jun 24 16:01:13.506: INFO: Pod "pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.741287ms
Jun 24 16:01:15.510: INFO: Pod "pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011176311s
STEP: Saw pod success
Jun 24 16:01:15.510: INFO: Pod "pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:01:15.515: INFO: Trying to get logs from node minion pod pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:01:15.544: INFO: Waiting for pod pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:01:15.547: INFO: Pod pod-projected-configmaps-4a7546d7-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:01:15.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3391" for this suite.
Jun 24 16:01:21.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:01:21.656: INFO: namespace projected-3391 deletion completed in 6.106506019s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:01:21.657: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 24 16:01:29.731: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:29.731: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:29.914: INFO: Exec stderr: ""
Jun 24 16:01:29.914: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:29.914: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.076: INFO: Exec stderr: ""
Jun 24 16:01:30.076: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.076: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.232: INFO: Exec stderr: ""
Jun 24 16:01:30.232: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.232: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.385: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 24 16:01:30.386: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.386: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.562: INFO: Exec stderr: ""
Jun 24 16:01:30.563: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.565: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.727: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 24 16:01:30.728: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.728: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:30.888: INFO: Exec stderr: ""
Jun 24 16:01:30.888: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:30.888: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:31.043: INFO: Exec stderr: ""
Jun 24 16:01:31.043: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:31.043: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:31.198: INFO: Exec stderr: ""
Jun 24 16:01:31.198: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5554 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:01:31.198: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:01:31.350: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:01:31.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5554" for this suite.
Jun 24 16:02:27.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:02:27.453: INFO: namespace e2e-kubelet-etc-hosts-5554 deletion completed in 56.099428119s

• [SLOW TEST:65.797 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:02:27.457: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7691f085-9699-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7691f085-9699-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:02:31.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7145" for this suite.
Jun 24 16:02:53.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:02:53.671: INFO: namespace projected-7145 deletion completed in 22.09708662s

• [SLOW TEST:26.214 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:02:53.671: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jun 24 16:02:53.722: INFO: Waiting up to 5m0s for pod "downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd" in namespace "downward-api-206" to be "success or failure"
Jun 24 16:02:53.727: INFO: Pod "downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.341877ms
Jun 24 16:02:55.731: INFO: Pod "downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008611914s
Jun 24 16:02:57.735: INFO: Pod "downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012630415s
STEP: Saw pod success
Jun 24 16:02:57.735: INFO: Pod "downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:02:57.738: INFO: Trying to get logs from node minion pod downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 16:02:57.772: INFO: Waiting for pod downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:02:57.776: INFO: Pod downward-api-8632c40b-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:02:57.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-206" for this suite.
Jun 24 16:03:03.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:03:03.874: INFO: namespace downward-api-206 deletion completed in 6.095245355s

• [SLOW TEST:10.203 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:03:03.875: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-mjdz
STEP: Creating a pod to test atomic-volume-subpath
Jun 24 16:03:03.922: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mjdz" in namespace "subpath-3202" to be "success or failure"
Jun 24 16:03:03.928: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.07247ms
Jun 24 16:03:05.932: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 2.010204467s
Jun 24 16:03:07.937: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 4.014468202s
Jun 24 16:03:09.941: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 6.018559929s
Jun 24 16:03:11.945: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 8.022665605s
Jun 24 16:03:13.949: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 10.027155328s
Jun 24 16:03:15.964: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 12.042160319s
Jun 24 16:03:17.968: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 14.04616342s
Jun 24 16:03:19.973: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 16.050456308s
Jun 24 16:03:21.977: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 18.054532135s
Jun 24 16:03:23.982: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Running", Reason="", readiness=true. Elapsed: 20.059710518s
Jun 24 16:03:25.986: INFO: Pod "pod-subpath-test-configmap-mjdz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.06373029s
STEP: Saw pod success
Jun 24 16:03:25.986: INFO: Pod "pod-subpath-test-configmap-mjdz" satisfied condition "success or failure"
Jun 24 16:03:25.992: INFO: Trying to get logs from node minion pod pod-subpath-test-configmap-mjdz container test-container-subpath-configmap-mjdz: <nil>
STEP: delete the pod
Jun 24 16:03:26.017: INFO: Waiting for pod pod-subpath-test-configmap-mjdz to disappear
Jun 24 16:03:26.019: INFO: Pod pod-subpath-test-configmap-mjdz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mjdz
Jun 24 16:03:26.019: INFO: Deleting pod "pod-subpath-test-configmap-mjdz" in namespace "subpath-3202"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:03:26.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3202" for this suite.
Jun 24 16:03:32.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:03:32.139: INFO: namespace subpath-3202 deletion completed in 6.112955013s

• [SLOW TEST:28.265 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:03:32.139: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Jun 24 16:03:32.170: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jun 24 16:03:32.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:32.446: INFO: stderr: ""
Jun 24 16:03:32.446: INFO: stdout: "service/redis-slave created\n"
Jun 24 16:03:32.446: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jun 24 16:03:32.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:32.725: INFO: stderr: ""
Jun 24 16:03:32.725: INFO: stdout: "service/redis-master created\n"
Jun 24 16:03:32.725: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun 24 16:03:32.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:32.978: INFO: stderr: ""
Jun 24 16:03:32.978: INFO: stdout: "service/frontend created\n"
Jun 24 16:03:32.978: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jun 24 16:03:32.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:33.225: INFO: stderr: ""
Jun 24 16:03:33.225: INFO: stdout: "deployment.apps/frontend created\n"
Jun 24 16:03:33.225: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 24 16:03:33.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:33.490: INFO: stderr: ""
Jun 24 16:03:33.490: INFO: stdout: "deployment.apps/redis-master created\n"
Jun 24 16:03:33.490: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jun 24 16:03:33.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-4144'
Jun 24 16:03:33.733: INFO: stderr: ""
Jun 24 16:03:33.733: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jun 24 16:03:33.733: INFO: Waiting for all frontend pods to be Running.
Jun 24 16:03:48.785: INFO: Waiting for frontend to serve content.
Jun 24 16:03:49.816: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jun 24 16:03:54.840: INFO: Trying to add a new entry to the guestbook.
Jun 24 16:03:54.861: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun 24 16:03:54.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.005: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.005: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun 24 16:03:55.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.139: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.139: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 24 16:03:55.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.248: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.248: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 24 16:03:55.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.357: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.357: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 24 16:03:55.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.454: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 24 16:03:55.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-4144'
Jun 24 16:03:55.546: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 16:03:55.547: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:03:55.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4144" for this suite.
Jun 24 16:04:33.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:04:33.648: INFO: namespace kubectl-4144 deletion completed in 38.098654296s

• [SLOW TEST:61.509 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:04:33.649: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6597
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 24 16:04:33.678: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 24 16:04:51.762: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.6:8080/dial?request=hostName&protocol=http&host=10.251.128.5&port=8080&tries=1'] Namespace:pod-network-test-6597 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 24 16:04:51.762: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
Jun 24 16:04:51.966: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:04:51.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6597" for this suite.
Jun 24 16:05:13.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:05:14.084: INFO: namespace pod-network-test-6597 deletion completed in 22.113813569s

• [SLOW TEST:40.435 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:05:14.089: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-d9e44754-9699-11e9-8bcb-526dc0a539dd
STEP: Creating secret with name s-test-opt-upd-d9e447a3-9699-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d9e44754-9699-11e9-8bcb-526dc0a539dd
STEP: Updating secret s-test-opt-upd-d9e447a3-9699-11e9-8bcb-526dc0a539dd
STEP: Creating secret with name s-test-opt-create-d9e447c6-9699-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:05:20.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-199" for this suite.
Jun 24 16:05:42.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:05:42.371: INFO: namespace secrets-199 deletion completed in 22.098571597s

• [SLOW TEST:28.282 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:05:42.371: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:05:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9756" for this suite.
Jun 24 16:05:52.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:05:52.581: INFO: namespace emptydir-wrapper-9756 deletion completed in 6.101664816s

• [SLOW TEST:10.211 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:05:52.582: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 24 16:05:52.638: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5654,SelfLink:/api/v1/namespaces/watch-5654/configmaps/e2e-watch-test-watch-closed,UID:f0d6e395-9699-11e9-b70d-fa163ef83c94,ResourceVersion:7492,Generation:0,CreationTimestamp:2019-06-24 16:05:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 24 16:05:52.639: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5654,SelfLink:/api/v1/namespaces/watch-5654/configmaps/e2e-watch-test-watch-closed,UID:f0d6e395-9699-11e9-b70d-fa163ef83c94,ResourceVersion:7493,Generation:0,CreationTimestamp:2019-06-24 16:05:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 24 16:05:52.654: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5654,SelfLink:/api/v1/namespaces/watch-5654/configmaps/e2e-watch-test-watch-closed,UID:f0d6e395-9699-11e9-b70d-fa163ef83c94,ResourceVersion:7494,Generation:0,CreationTimestamp:2019-06-24 16:05:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 24 16:05:52.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5654,SelfLink:/api/v1/namespaces/watch-5654/configmaps/e2e-watch-test-watch-closed,UID:f0d6e395-9699-11e9-b70d-fa163ef83c94,ResourceVersion:7495,Generation:0,CreationTimestamp:2019-06-24 16:05:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:05:52.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5654" for this suite.
Jun 24 16:05:58.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:05:58.757: INFO: namespace watch-5654 deletion completed in 6.099840946s

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:05:58.758: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f483a055-9699-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:05:58.805: INFO: Waiting up to 5m0s for pod "pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd" in namespace "secrets-7085" to be "success or failure"
Jun 24 16:05:58.807: INFO: Pod "pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.440539ms
Jun 24 16:06:00.812: INFO: Pod "pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006695084s
Jun 24 16:06:02.816: INFO: Pod "pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010681s
STEP: Saw pod success
Jun 24 16:06:02.816: INFO: Pod "pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:06:02.819: INFO: Trying to get logs from node minion pod pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:06:02.862: INFO: Waiting for pod pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:06:02.864: INFO: Pod pod-secrets-f48435d2-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:06:02.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7085" for this suite.
Jun 24 16:06:08.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:06:08.959: INFO: namespace secrets-7085 deletion completed in 6.088443825s

• [SLOW TEST:10.201 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:06:08.959: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 24 16:06:09.007: INFO: Waiting up to 5m0s for pod "pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd" in namespace "emptydir-3666" to be "success or failure"
Jun 24 16:06:09.011: INFO: Pod "pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.651673ms
Jun 24 16:06:11.016: INFO: Pod "pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008718382s
STEP: Saw pod success
Jun 24 16:06:11.016: INFO: Pod "pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:06:11.019: INFO: Trying to get logs from node minion pod pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:06:11.041: INFO: Waiting for pod pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:06:11.044: INFO: Pod pod-fa973d3f-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:06:11.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3666" for this suite.
Jun 24 16:06:17.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:06:17.154: INFO: namespace emptydir-3666 deletion completed in 6.106549778s

• [SLOW TEST:8.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:06:17.160: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 24 16:06:17.209: INFO: Waiting up to 5m0s for pod "pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd" in namespace "emptydir-4212" to be "success or failure"
Jun 24 16:06:17.218: INFO: Pod "pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.19459ms
Jun 24 16:06:19.222: INFO: Pod "pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013042374s
STEP: Saw pod success
Jun 24 16:06:19.222: INFO: Pod "pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:06:19.226: INFO: Trying to get logs from node minion pod pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:06:19.271: INFO: Waiting for pod pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:06:19.276: INFO: Pod pod-ff7c273a-9699-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:06:19.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4212" for this suite.
Jun 24 16:06:25.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:06:25.401: INFO: namespace emptydir-4212 deletion completed in 6.120353227s

• [SLOW TEST:8.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:06:25.402: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:06:25.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd" in namespace "downward-api-6677" to be "success or failure"
Jun 24 16:06:25.443: INFO: Pod "downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.443238ms
Jun 24 16:06:27.447: INFO: Pod "downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007697854s
STEP: Saw pod success
Jun 24 16:06:27.447: INFO: Pod "downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:06:27.453: INFO: Trying to get logs from node minion pod downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:06:27.489: INFO: Waiting for pod downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:06:27.493: INFO: Pod downwardapi-volume-046484b7-969a-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:06:27.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6677" for this suite.
Jun 24 16:06:33.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:06:33.589: INFO: namespace downward-api-6677 deletion completed in 6.089997073s

• [SLOW TEST:8.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:06:33.589: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jun 24 16:07:13.693: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 8
	[quantile=0.9] = 40
	[quantile=0.99] = 63
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 20993
	[quantile=0.9] = 216179
	[quantile=0.99] = 231418
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 18
	[quantile=0.9] = 18
	[quantile=0.99] = 18
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 263792
	[quantile=0.9] = 263792
	[quantile=0.99] = 263792
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 8
	[quantile=0.99] = 44
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 15
	[quantile=0.9] = 31
	[quantile=0.99] = 63
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 16
	[quantile=0.9] = 38
	[quantile=0.99] = 45
For namespace_queue_latency_sum:
	[] = 3560
For namespace_queue_latency_count:
	[] = 182
For namespace_retries:
	[] = 184
For namespace_work_duration:
	[quantile=0.5] = 168353
	[quantile=0.9] = 248812
	[quantile=0.99] = 437209
For namespace_work_duration_sum:
	[] = 27578094
For namespace_work_duration_count:
	[] = 182
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:07:13.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6787" for this suite.
Jun 24 16:07:19.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:07:19.793: INFO: namespace gc-6787 deletion completed in 6.095722964s

• [SLOW TEST:46.203 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:07:19.793: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-24d0ed29-969a-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:07:19.842: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd" in namespace "projected-7326" to be "success or failure"
Jun 24 16:07:19.848: INFO: Pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.546134ms
Jun 24 16:07:21.852: INFO: Pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010631027s
Jun 24 16:07:23.856: INFO: Pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014642169s
Jun 24 16:07:25.860: INFO: Pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018688158s
STEP: Saw pod success
Jun 24 16:07:25.861: INFO: Pod "pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:07:25.864: INFO: Trying to get logs from node minion pod pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:07:25.888: INFO: Waiting for pod pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:07:25.892: INFO: Pod pod-projected-secrets-24d182b9-969a-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:07:25.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7326" for this suite.
Jun 24 16:07:31.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:07:31.997: INFO: namespace projected-7326 deletion completed in 6.102473015s

• [SLOW TEST:12.204 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:07:32.001: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:07:32.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd" in namespace "downward-api-603" to be "success or failure"
Jun 24 16:07:32.050: INFO: Pod "downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.560829ms
Jun 24 16:07:34.054: INFO: Pod "downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010018667s
Jun 24 16:07:36.059: INFO: Pod "downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0145361s
STEP: Saw pod success
Jun 24 16:07:36.059: INFO: Pod "downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:07:36.063: INFO: Trying to get logs from node minion pod downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:07:36.105: INFO: Waiting for pod downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:07:36.110: INFO: Pod downwardapi-volume-2c1730f3-969a-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:07:36.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-603" for this suite.
Jun 24 16:07:42.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:07:42.227: INFO: namespace downward-api-603 deletion completed in 6.110204243s

• [SLOW TEST:10.225 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:07:42.227: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1428
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jun 24 16:07:42.280: INFO: Found 0 stateful pods, waiting for 3
Jun 24 16:07:52.286: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 16:07:52.286: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 16:07:52.286: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 24 16:07:52.322: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 24 16:08:02.370: INFO: Updating stateful set ss2
Jun 24 16:08:02.383: INFO: Waiting for Pod statefulset-1428/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jun 24 16:08:12.466: INFO: Found 2 stateful pods, waiting for 3
Jun 24 16:08:22.479: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 16:08:22.479: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 16:08:22.479: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 24 16:08:22.505: INFO: Updating stateful set ss2
Jun 24 16:08:22.518: INFO: Waiting for Pod statefulset-1428/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 24 16:08:32.548: INFO: Updating stateful set ss2
Jun 24 16:08:32.559: INFO: Waiting for StatefulSet statefulset-1428/ss2 to complete update
Jun 24 16:08:32.559: INFO: Waiting for Pod statefulset-1428/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 24 16:08:42.566: INFO: Deleting all statefulset in ns statefulset-1428
Jun 24 16:08:42.570: INFO: Scaling statefulset ss2 to 0
Jun 24 16:08:52.593: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 16:08:52.597: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:08:52.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1428" for this suite.
Jun 24 16:08:58.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:08:58.737: INFO: namespace statefulset-1428 deletion completed in 6.120604308s

• [SLOW TEST:76.510 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:08:58.737: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:09:58.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7351" for this suite.
Jun 24 16:10:20.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:10:20.896: INFO: namespace container-probe-7351 deletion completed in 22.112328916s

• [SLOW TEST:82.159 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:10:20.896: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:10:20.926: INFO: Creating deployment "test-recreate-deployment"
Jun 24 16:10:20.929: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun 24 16:10:20.939: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jun 24 16:10:22.947: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun 24 16:10:22.951: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun 24 16:10:22.960: INFO: Updating deployment test-recreate-deployment
Jun 24 16:10:22.960: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 24 16:10:23.054: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7341,SelfLink:/apis/apps/v1/namespaces/deployment-7341/deployments/test-recreate-deployment,UID:90c1f484-969a-11e9-b70d-fa163ef83c94,ResourceVersion:8580,Generation:2,CreationTimestamp:2019-06-24 16:10:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-06-24 16:10:23 +0000 UTC 2019-06-24 16:10:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-24 16:10:23 +0000 UTC 2019-06-24 16:10:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jun 24 16:10:23.059: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-7341,SelfLink:/apis/apps/v1/namespaces/deployment-7341/replicasets/test-recreate-deployment-c9cbd8684,UID:91ff50a5-969a-11e9-b70d-fa163ef83c94,ResourceVersion:8577,Generation:1,CreationTimestamp:2019-06-24 16:10:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 90c1f484-969a-11e9-b70d-fa163ef83c94 0xc002d40650 0xc002d40651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:10:23.059: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun 24 16:10:23.059: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-7341,SelfLink:/apis/apps/v1/namespaces/deployment-7341/replicasets/test-recreate-deployment-7d57d5ff7c,UID:90c27708-969a-11e9-b70d-fa163ef83c94,ResourceVersion:8567,Generation:2,CreationTimestamp:2019-06-24 16:10:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 90c1f484-969a-11e9-b70d-fa163ef83c94 0xc002d40597 0xc002d40598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:10:23.066: INFO: Pod "test-recreate-deployment-c9cbd8684-cf2wm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-cf2wm,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-7341,SelfLink:/api/v1/namespaces/deployment-7341/pods/test-recreate-deployment-c9cbd8684-cf2wm,UID:91ffc6c4-969a-11e9-b70d-fa163ef83c94,ResourceVersion:8579,Generation:0,CreationTimestamp:2019-06-24 16:10:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 91ff50a5-969a-11e9-b70d-fa163ef83c94 0xc002d414e0 0xc002d414e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rk6qt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rk6qt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rk6qt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d41590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d415b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:10:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:10:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:10:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:10:23 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:,StartTime:2019-06-24 16:10:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:10:23.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7341" for this suite.
Jun 24 16:10:29.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:10:29.188: INFO: namespace deployment-7341 deletion completed in 6.11685244s

• [SLOW TEST:8.292 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:10:29.188: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-blngs in namespace proxy-5572
I0624 16:10:29.240985      20 runners.go:184] Created replication controller with name: proxy-service-blngs, namespace: proxy-5572, replica count: 1
I0624 16:10:30.291555      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0624 16:10:31.291939      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0624 16:10:32.292346      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0624 16:10:33.292798      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:34.293181      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:35.293541      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:36.293867      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:37.294152      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:38.294500      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0624 16:10:39.294825      20 runners.go:184] proxy-service-blngs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 24 16:10:39.298: INFO: setup took 10.080438632s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 24 16:10:39.319: INFO: (0) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 20.537774ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 21.517444ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 21.607939ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 21.333591ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 21.70163ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 21.282773ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 21.480069ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 21.52677ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 21.905001ms)
Jun 24 16:10:39.320: INFO: (0) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 22.265085ms)
Jun 24 16:10:39.322: INFO: (0) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 23.919892ms)
Jun 24 16:10:39.336: INFO: (0) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 38.494572ms)
Jun 24 16:10:39.348: INFO: (0) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 50.078696ms)
Jun 24 16:10:39.349: INFO: (0) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 50.479517ms)
Jun 24 16:10:39.351: INFO: (0) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 53.594139ms)
Jun 24 16:10:39.372: INFO: (0) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 74.006302ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 11.165788ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.122235ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 11.210882ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 11.265597ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 11.508148ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.433362ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 11.207725ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 11.202508ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.228609ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 11.335879ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 11.234775ms)
Jun 24 16:10:39.387: INFO: (1) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 11.354767ms)
Jun 24 16:10:39.389: INFO: (1) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 13.668264ms)
Jun 24 16:10:39.389: INFO: (1) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 13.560476ms)
Jun 24 16:10:39.389: INFO: (1) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 13.552088ms)
Jun 24 16:10:39.389: INFO: (1) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 13.710415ms)
Jun 24 16:10:39.396: INFO: (2) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 6.044522ms)
Jun 24 16:10:39.396: INFO: (2) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 6.224434ms)
Jun 24 16:10:39.396: INFO: (2) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 6.625488ms)
Jun 24 16:10:39.396: INFO: (2) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 6.100337ms)
Jun 24 16:10:39.397: INFO: (2) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 6.700671ms)
Jun 24 16:10:39.397: INFO: (2) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 7.392773ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 12.780007ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 12.469386ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 12.625799ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 12.709184ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 13.008442ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 12.810603ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 12.937097ms)
Jun 24 16:10:39.403: INFO: (2) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 12.532943ms)
Jun 24 16:10:39.404: INFO: (2) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 14.061939ms)
Jun 24 16:10:39.405: INFO: (2) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 14.832643ms)
Jun 24 16:10:39.412: INFO: (3) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 6.093189ms)
Jun 24 16:10:39.412: INFO: (3) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 6.37184ms)
Jun 24 16:10:39.412: INFO: (3) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 6.355242ms)
Jun 24 16:10:39.412: INFO: (3) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 6.056151ms)
Jun 24 16:10:39.414: INFO: (3) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 8.381997ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 8.979591ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 9.27375ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.167536ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 9.330442ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.474045ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 9.50202ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.434418ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.339043ms)
Jun 24 16:10:39.415: INFO: (3) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 9.650717ms)
Jun 24 16:10:39.416: INFO: (3) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.882236ms)
Jun 24 16:10:39.418: INFO: (3) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.380048ms)
Jun 24 16:10:39.425: INFO: (4) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 6.281557ms)
Jun 24 16:10:39.426: INFO: (4) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 6.040229ms)
Jun 24 16:10:39.426: INFO: (4) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 7.208757ms)
Jun 24 16:10:39.426: INFO: (4) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 7.364948ms)
Jun 24 16:10:39.429: INFO: (4) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.108642ms)
Jun 24 16:10:39.429: INFO: (4) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.259966ms)
Jun 24 16:10:39.429: INFO: (4) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 10.618863ms)
Jun 24 16:10:39.430: INFO: (4) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 9.893447ms)
Jun 24 16:10:39.433: INFO: (4) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 13.466819ms)
Jun 24 16:10:39.433: INFO: (4) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 13.47068ms)
Jun 24 16:10:39.433: INFO: (4) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 13.480202ms)
Jun 24 16:10:39.434: INFO: (4) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 13.885944ms)
Jun 24 16:10:39.434: INFO: (4) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 13.937208ms)
Jun 24 16:10:39.435: INFO: (4) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 15.243259ms)
Jun 24 16:10:39.435: INFO: (4) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 15.248334ms)
Jun 24 16:10:39.435: INFO: (4) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 15.333756ms)
Jun 24 16:10:39.441: INFO: (5) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 5.777582ms)
Jun 24 16:10:39.443: INFO: (5) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 7.086868ms)
Jun 24 16:10:39.443: INFO: (5) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 7.508936ms)
Jun 24 16:10:39.444: INFO: (5) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 8.718451ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 10.509525ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.918749ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 10.13868ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 9.997108ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 10.042517ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 10.198437ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 10.484626ms)
Jun 24 16:10:39.446: INFO: (5) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 10.123586ms)
Jun 24 16:10:39.448: INFO: (5) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 12.352286ms)
Jun 24 16:10:39.448: INFO: (5) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 12.356638ms)
Jun 24 16:10:39.448: INFO: (5) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 12.050724ms)
Jun 24 16:10:39.448: INFO: (5) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 12.114133ms)
Jun 24 16:10:39.457: INFO: (6) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 8.681295ms)
Jun 24 16:10:39.457: INFO: (6) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 8.991697ms)
Jun 24 16:10:39.457: INFO: (6) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 9.143971ms)
Jun 24 16:10:39.457: INFO: (6) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.103836ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 14.320599ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 14.518903ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 14.373666ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 14.656788ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 14.542069ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 14.754367ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 14.638432ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 14.601516ms)
Jun 24 16:10:39.463: INFO: (6) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 14.534883ms)
Jun 24 16:10:39.466: INFO: (6) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 17.138995ms)
Jun 24 16:10:39.466: INFO: (6) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 17.365252ms)
Jun 24 16:10:39.466: INFO: (6) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 16.953148ms)
Jun 24 16:10:39.473: INFO: (7) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 7.027539ms)
Jun 24 16:10:39.477: INFO: (7) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 11.533198ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 11.226335ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 11.503209ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.450627ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 11.414852ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 11.125342ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 11.411309ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 11.345523ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.222837ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 11.406983ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 11.506288ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 11.584418ms)
Jun 24 16:10:39.478: INFO: (7) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.740415ms)
Jun 24 16:10:39.479: INFO: (7) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 12.644678ms)
Jun 24 16:10:39.480: INFO: (7) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 14.339913ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 7.621395ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 7.204119ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 7.859658ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 7.507943ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 7.370767ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 7.359513ms)
Jun 24 16:10:39.488: INFO: (8) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 7.873753ms)
Jun 24 16:10:39.489: INFO: (8) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 7.824777ms)
Jun 24 16:10:39.491: INFO: (8) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.77415ms)
Jun 24 16:10:39.491: INFO: (8) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 9.709414ms)
Jun 24 16:10:39.491: INFO: (8) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 10.028531ms)
Jun 24 16:10:39.491: INFO: (8) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 9.628229ms)
Jun 24 16:10:39.491: INFO: (8) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.876814ms)
Jun 24 16:10:39.492: INFO: (8) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 10.390003ms)
Jun 24 16:10:39.492: INFO: (8) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 10.134372ms)
Jun 24 16:10:39.493: INFO: (8) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 12.838466ms)
Jun 24 16:10:39.503: INFO: (9) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.551738ms)
Jun 24 16:10:39.503: INFO: (9) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.617019ms)
Jun 24 16:10:39.504: INFO: (9) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 10.727682ms)
Jun 24 16:10:39.504: INFO: (9) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 10.688748ms)
Jun 24 16:10:39.504: INFO: (9) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 10.751365ms)
Jun 24 16:10:39.505: INFO: (9) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 11.445608ms)
Jun 24 16:10:39.505: INFO: (9) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 11.405084ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 12.246719ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 12.242563ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 12.23512ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 12.297745ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 12.278512ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 12.400508ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 12.557859ms)
Jun 24 16:10:39.506: INFO: (9) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 12.803833ms)
Jun 24 16:10:39.507: INFO: (9) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 14.040837ms)
Jun 24 16:10:39.513: INFO: (10) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 4.867477ms)
Jun 24 16:10:39.513: INFO: (10) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 5.126211ms)
Jun 24 16:10:39.514: INFO: (10) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 6.434685ms)
Jun 24 16:10:39.514: INFO: (10) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 6.239018ms)
Jun 24 16:10:39.515: INFO: (10) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 7.182091ms)
Jun 24 16:10:39.515: INFO: (10) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 6.094337ms)
Jun 24 16:10:39.515: INFO: (10) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 6.550151ms)
Jun 24 16:10:39.515: INFO: (10) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 6.477646ms)
Jun 24 16:10:39.515: INFO: (10) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 6.228284ms)
Jun 24 16:10:39.518: INFO: (10) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 9.811498ms)
Jun 24 16:10:39.518: INFO: (10) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 9.762486ms)
Jun 24 16:10:39.519: INFO: (10) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 10.552907ms)
Jun 24 16:10:39.520: INFO: (10) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 10.982607ms)
Jun 24 16:10:39.520: INFO: (10) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 11.477247ms)
Jun 24 16:10:39.520: INFO: (10) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.431067ms)
Jun 24 16:10:39.520: INFO: (10) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 12.026063ms)
Jun 24 16:10:39.524: INFO: (11) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 3.792294ms)
Jun 24 16:10:39.524: INFO: (11) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 4.189531ms)
Jun 24 16:10:39.525: INFO: (11) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 4.93209ms)
Jun 24 16:10:39.526: INFO: (11) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 5.853249ms)
Jun 24 16:10:39.527: INFO: (11) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 5.954097ms)
Jun 24 16:10:39.527: INFO: (11) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 6.627002ms)
Jun 24 16:10:39.532: INFO: (11) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 11.239394ms)
Jun 24 16:10:39.532: INFO: (11) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.300257ms)
Jun 24 16:10:39.532: INFO: (11) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 11.427904ms)
Jun 24 16:10:39.532: INFO: (11) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 12.333572ms)
Jun 24 16:10:39.532: INFO: (11) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 11.816546ms)
Jun 24 16:10:39.533: INFO: (11) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 11.587168ms)
Jun 24 16:10:39.533: INFO: (11) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 11.206511ms)
Jun 24 16:10:39.533: INFO: (11) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 11.290788ms)
Jun 24 16:10:39.535: INFO: (11) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 13.547602ms)
Jun 24 16:10:39.535: INFO: (11) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 13.603003ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 8.546197ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 8.561001ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 8.448749ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 8.464766ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 8.847162ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 8.902046ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 8.996164ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 8.940719ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.061389ms)
Jun 24 16:10:39.544: INFO: (12) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 9.281367ms)
Jun 24 16:10:39.545: INFO: (12) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.629199ms)
Jun 24 16:10:39.545: INFO: (12) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 9.928123ms)
Jun 24 16:10:39.546: INFO: (12) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 10.998044ms)
Jun 24 16:10:39.546: INFO: (12) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 10.941883ms)
Jun 24 16:10:39.546: INFO: (12) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 11.036172ms)
Jun 24 16:10:39.546: INFO: (12) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 10.962963ms)
Jun 24 16:10:39.556: INFO: (13) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 8.659538ms)
Jun 24 16:10:39.556: INFO: (13) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 8.633883ms)
Jun 24 16:10:39.556: INFO: (13) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 8.735888ms)
Jun 24 16:10:39.556: INFO: (13) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 8.813278ms)
Jun 24 16:10:39.556: INFO: (13) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.04371ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 12.862918ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 13.033784ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 13.074701ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 13.579895ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 13.356679ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 13.407875ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 13.510631ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 13.426327ms)
Jun 24 16:10:39.560: INFO: (13) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 13.666212ms)
Jun 24 16:10:39.562: INFO: (13) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 15.004013ms)
Jun 24 16:10:39.562: INFO: (13) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 14.999226ms)
Jun 24 16:10:39.571: INFO: (14) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.028042ms)
Jun 24 16:10:39.573: INFO: (14) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.536849ms)
Jun 24 16:10:39.573: INFO: (14) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.800917ms)
Jun 24 16:10:39.573: INFO: (14) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 10.267933ms)
Jun 24 16:10:39.573: INFO: (14) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.911218ms)
Jun 24 16:10:39.573: INFO: (14) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 9.573741ms)
Jun 24 16:10:39.574: INFO: (14) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 11.363566ms)
Jun 24 16:10:39.574: INFO: (14) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 11.217164ms)
Jun 24 16:10:39.575: INFO: (14) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 12.557899ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 13.168827ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 13.527586ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 12.612621ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 12.575911ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 13.131397ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 12.566391ms)
Jun 24 16:10:39.576: INFO: (14) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 12.610102ms)
Jun 24 16:10:39.583: INFO: (15) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 6.749967ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 9.270831ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.542754ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 9.851606ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 10.25748ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 10.150779ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 10.65628ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 10.47395ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 7.801694ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 9.991788ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 9.788528ms)
Jun 24 16:10:39.587: INFO: (15) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 10.219429ms)
Jun 24 16:10:39.589: INFO: (15) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 11.280326ms)
Jun 24 16:10:39.589: INFO: (15) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.490451ms)
Jun 24 16:10:39.589: INFO: (15) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 11.966512ms)
Jun 24 16:10:39.589: INFO: (15) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 12.352852ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 9.240953ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 7.042265ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 8.700447ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.584497ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 8.852338ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 8.5911ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 9.56962ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 8.780984ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.159889ms)
Jun 24 16:10:39.599: INFO: (16) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 8.997431ms)
Jun 24 16:10:39.600: INFO: (16) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 5.854661ms)
Jun 24 16:10:39.600: INFO: (16) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 5.946663ms)
Jun 24 16:10:39.601: INFO: (16) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 11.826419ms)
Jun 24 16:10:39.601: INFO: (16) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.494671ms)
Jun 24 16:10:39.601: INFO: (16) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 8.733944ms)
Jun 24 16:10:39.601: INFO: (16) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 9.036281ms)
Jun 24 16:10:39.611: INFO: (17) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.193346ms)
Jun 24 16:10:39.611: INFO: (17) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 9.249301ms)
Jun 24 16:10:39.611: INFO: (17) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 9.199967ms)
Jun 24 16:10:39.611: INFO: (17) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 9.276044ms)
Jun 24 16:10:39.612: INFO: (17) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 10.127927ms)
Jun 24 16:10:39.614: INFO: (17) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 12.48275ms)
Jun 24 16:10:39.614: INFO: (17) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 12.635803ms)
Jun 24 16:10:39.614: INFO: (17) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 12.459771ms)
Jun 24 16:10:39.614: INFO: (17) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 12.59404ms)
Jun 24 16:10:39.614: INFO: (17) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 12.612993ms)
Jun 24 16:10:39.615: INFO: (17) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 12.871502ms)
Jun 24 16:10:39.616: INFO: (17) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 14.64149ms)
Jun 24 16:10:39.618: INFO: (17) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 16.111702ms)
Jun 24 16:10:39.618: INFO: (17) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 16.095798ms)
Jun 24 16:10:39.618: INFO: (17) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 16.246047ms)
Jun 24 16:10:39.618: INFO: (17) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 16.228551ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 8.291825ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 8.284048ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 8.002121ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 8.424763ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 8.265014ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 8.19516ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 8.32243ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 8.280213ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 8.402074ms)
Jun 24 16:10:39.626: INFO: (18) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 8.193804ms)
Jun 24 16:10:39.627: INFO: (18) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 8.790222ms)
Jun 24 16:10:39.628: INFO: (18) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 9.549403ms)
Jun 24 16:10:39.629: INFO: (18) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 10.347218ms)
Jun 24 16:10:39.629: INFO: (18) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 10.147388ms)
Jun 24 16:10:39.629: INFO: (18) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 10.585599ms)
Jun 24 16:10:39.629: INFO: (18) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 10.585392ms)
Jun 24 16:10:39.635: INFO: (19) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:460/proxy/: tls baz (200; 5.56397ms)
Jun 24 16:10:39.635: INFO: (19) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:160/proxy/: foo (200; 5.632207ms)
Jun 24 16:10:39.636: INFO: (19) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:1080/proxy/rewriteme">test<... (200; 7.191049ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.695512ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:443/proxy/tlsrewritem... (200; 9.627871ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/pods/https:proxy-service-blngs-zqd8d:462/proxy/: tls qux (200; 9.746323ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname2/proxy/: tls qux (200; 9.447873ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname1/proxy/: foo (200; 9.595756ms)
Jun 24 16:10:39.639: INFO: (19) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d:162/proxy/: bar (200; 9.439763ms)
Jun 24 16:10:39.640: INFO: (19) /api/v1/namespaces/proxy-5572/services/https:proxy-service-blngs:tlsportname1/proxy/: tls baz (200; 11.215657ms)
Jun 24 16:10:39.640: INFO: (19) /api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/proxy-service-blngs-zqd8d/proxy/rewriteme">test</a> (200; 11.30506ms)
Jun 24 16:10:39.641: INFO: (19) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/: <a href="/api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:1080/proxy/rewriteme">... (200; 5.713149ms)
Jun 24 16:10:39.641: INFO: (19) /api/v1/namespaces/proxy-5572/services/http:proxy-service-blngs:portname2/proxy/: bar (200; 11.324573ms)
Jun 24 16:10:39.641: INFO: (19) /api/v1/namespaces/proxy-5572/pods/http:proxy-service-blngs-zqd8d:160/proxy/: foo (200; 11.319362ms)
Jun 24 16:10:39.641: INFO: (19) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname2/proxy/: bar (200; 11.720599ms)
Jun 24 16:10:39.641: INFO: (19) /api/v1/namespaces/proxy-5572/services/proxy-service-blngs:portname1/proxy/: foo (200; 11.71986ms)
STEP: deleting ReplicationController proxy-service-blngs in namespace proxy-5572, will wait for the garbage collector to delete the pods
Jun 24 16:10:39.700: INFO: Deleting ReplicationController proxy-service-blngs took: 7.050569ms
Jun 24 16:10:40.001: INFO: Terminating ReplicationController proxy-service-blngs pods took: 300.368086ms
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:10:46.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5572" for this suite.
Jun 24 16:10:52.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:10:52.903: INFO: namespace proxy-5572 deletion completed in 6.097163857s

• [SLOW TEST:23.714 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:10:52.903: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:10:52.936: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:10:56.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7516" for this suite.
Jun 24 16:11:38.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:11:39.078: INFO: namespace pods-7516 deletion completed in 42.100417192s

• [SLOW TEST:46.175 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:11:39.080: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:11:39.132: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd" in namespace "downward-api-7362" to be "success or failure"
Jun 24 16:11:39.136: INFO: Pod "downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029469ms
Jun 24 16:11:41.140: INFO: Pod "downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008068359s
Jun 24 16:11:43.144: INFO: Pod "downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012122296s
STEP: Saw pod success
Jun 24 16:11:43.144: INFO: Pod "downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:11:43.148: INFO: Trying to get logs from node minion pod downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:11:43.177: INFO: Waiting for pod downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:11:43.180: INFO: Pod downwardapi-volume-bf5dcef3-969a-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:11:43.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7362" for this suite.
Jun 24 16:11:49.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:11:49.297: INFO: namespace downward-api-7362 deletion completed in 6.113161975s

• [SLOW TEST:10.217 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:11:49.298: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-c5758c80-969a-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c5758c80-969a-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:13:01.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8656" for this suite.
Jun 24 16:13:23.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:13:23.991: INFO: namespace configmap-8656 deletion completed in 22.10353588s

• [SLOW TEST:94.694 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:13:23.993: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 24 16:13:24.040: INFO: Waiting up to 5m0s for pod "pod-fde5da67-969a-11e9-8bcb-526dc0a539dd" in namespace "emptydir-4778" to be "success or failure"
Jun 24 16:13:24.043: INFO: Pod "pod-fde5da67-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.442763ms
Jun 24 16:13:26.048: INFO: Pod "pod-fde5da67-969a-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007624174s
Jun 24 16:13:28.052: INFO: Pod "pod-fde5da67-969a-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012027751s
STEP: Saw pod success
Jun 24 16:13:28.052: INFO: Pod "pod-fde5da67-969a-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:13:28.056: INFO: Trying to get logs from node minion pod pod-fde5da67-969a-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:13:28.088: INFO: Waiting for pod pod-fde5da67-969a-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:13:28.090: INFO: Pod pod-fde5da67-969a-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:13:28.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4778" for this suite.
Jun 24 16:13:34.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:13:34.192: INFO: namespace emptydir-4778 deletion completed in 6.098957701s

• [SLOW TEST:10.199 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:13:34.192: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-03f917ca-969b-11e9-8bcb-526dc0a539dd
STEP: Creating secret with name s-test-opt-upd-03f91811-969b-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-03f917ca-969b-11e9-8bcb-526dc0a539dd
STEP: Updating secret s-test-opt-upd-03f91811-969b-11e9-8bcb-526dc0a539dd
STEP: Creating secret with name s-test-opt-create-03f9182e-969b-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:14:48.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2198" for this suite.
Jun 24 16:15:10.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:15:10.957: INFO: namespace projected-2198 deletion completed in 22.118571553s

• [SLOW TEST:96.765 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:15:10.957: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jun 24 16:15:41.056: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 10
	[quantile=0.9] = 10
	[quantile=0.99] = 10
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 213736
	[quantile=0.9] = 215327
	[quantile=0.99] = 215327
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 18
	[quantile=0.9] = 18
	[quantile=0.99] = 18
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 2492
	[quantile=0.9] = 2492
	[quantile=0.99] = 2492
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 28
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 16
	[quantile=0.9] = 32
	[quantile=0.99] = 67
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 31
	[quantile=0.99] = 42
For namespace_queue_latency_sum:
	[] = 4282
For namespace_queue_latency_count:
	[] = 219
For namespace_retries:
	[] = 221
For namespace_work_duration:
	[quantile=0.5] = 163229
	[quantile=0.9] = 240526
	[quantile=0.99] = 286310
For namespace_work_duration_sum:
	[] = 33206364
For namespace_work_duration_count:
	[] = 219
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:15:41.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4563" for this suite.
Jun 24 16:15:47.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:15:47.163: INFO: namespace gc-4563 deletion completed in 6.10399564s

• [SLOW TEST:36.206 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:15:47.165: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:15:47.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd" in namespace "projected-9338" to be "success or failure"
Jun 24 16:15:47.216: INFO: Pod "downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.916759ms
Jun 24 16:15:49.220: INFO: Pod "downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008116525s
STEP: Saw pod success
Jun 24 16:15:49.220: INFO: Pod "downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:15:49.224: INFO: Trying to get logs from node minion pod downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:15:49.244: INFO: Waiting for pod downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:15:49.247: INFO: Pod downwardapi-volume-533b7e61-969b-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:15:49.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9338" for this suite.
Jun 24 16:15:55.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:15:55.362: INFO: namespace projected-9338 deletion completed in 6.111499083s

• [SLOW TEST:8.197 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:15:55.363: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Jun 24 16:15:55.914: INFO: created pod pod-service-account-defaultsa
Jun 24 16:15:55.914: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 24 16:15:55.925: INFO: created pod pod-service-account-mountsa
Jun 24 16:15:55.925: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 24 16:15:55.939: INFO: created pod pod-service-account-nomountsa
Jun 24 16:15:55.939: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 24 16:15:55.948: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 24 16:15:55.948: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 24 16:15:55.956: INFO: created pod pod-service-account-mountsa-mountspec
Jun 24 16:15:55.956: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 24 16:15:55.967: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 24 16:15:55.967: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 24 16:15:55.976: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 24 16:15:55.976: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 24 16:15:55.984: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 24 16:15:55.984: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 24 16:15:55.991: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 24 16:15:55.991: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:15:55.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6781" for this suite.
Jun 24 16:16:18.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:16:18.097: INFO: namespace svcaccounts-6781 deletion completed in 22.099310819s

• [SLOW TEST:22.734 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:16:18.097: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:16:42.151: INFO: Container started at 2019-06-24 16:16:19 +0000 UTC, pod became ready at 2019-06-24 16:16:41 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:16:42.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7940" for this suite.
Jun 24 16:17:04.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:17:04.262: INFO: namespace container-probe-7940 deletion completed in 22.1074384s

• [SLOW TEST:46.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:17:04.266: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jun 24 16:17:04.298: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:17:07.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6332" for this suite.
Jun 24 16:17:13.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:17:13.530: INFO: namespace init-container-6332 deletion completed in 6.098679077s

• [SLOW TEST:9.265 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:17:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:17:13.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd" in namespace "downward-api-4220" to be "success or failure"
Jun 24 16:17:13.584: INFO: Pod "downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.965738ms
Jun 24 16:17:15.589: INFO: Pod "downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013702351s
Jun 24 16:17:17.593: INFO: Pod "downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01788101s
STEP: Saw pod success
Jun 24 16:17:17.593: INFO: Pod "downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:17:17.599: INFO: Trying to get logs from node minion pod downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:17:17.641: INFO: Waiting for pod downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:17:17.646: INFO: Pod downwardapi-volume-86b63327-969b-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:17:17.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4220" for this suite.
Jun 24 16:17:23.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:17:23.755: INFO: namespace downward-api-4220 deletion completed in 6.105455606s

• [SLOW TEST:10.222 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:17:23.755: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd
Jun 24 16:17:23.799: INFO: Pod name my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd: Found 0 pods out of 1
Jun 24 16:17:28.804: INFO: Pod name my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd: Found 1 pods out of 1
Jun 24 16:17:28.804: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd" are running
Jun 24 16:17:28.808: INFO: Pod "my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd-x5286" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:17:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:17:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:17:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:17:23 +0000 UTC Reason: Message:}])
Jun 24 16:17:28.808: INFO: Trying to dial the pod
Jun 24 16:17:33.825: INFO: Controller my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd: Got expected result from replica 1 [my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd-x5286]: "my-hostname-basic-8cce2f58-969b-11e9-8bcb-526dc0a539dd-x5286", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:17:33.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-681" for this suite.
Jun 24 16:17:39.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:17:39.922: INFO: namespace replication-controller-681 deletion completed in 6.093817068s

• [SLOW TEST:16.167 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:17:39.922: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jun 24 16:17:46.018: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 628
	[quantile=0.9] = 47039
	[quantile=0.99] = 55763
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 41093
	[quantile=0.9] = 205299
	[quantile=0.99] = 206201
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 18
	[quantile=0.9] = 18
	[quantile=0.99] = 18
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 2492
	[quantile=0.9] = 2492
	[quantile=0.99] = 2492
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 37
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 17
	[quantile=0.9] = 32
	[quantile=0.99] = 65
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 29
	[quantile=0.99] = 42
For namespace_queue_latency_sum:
	[] = 4609
For namespace_queue_latency_count:
	[] = 235
For namespace_retries:
	[] = 238
For namespace_work_duration:
	[quantile=0.5] = 164087
	[quantile=0.9] = 259619
	[quantile=0.99] = 305926
For namespace_work_duration_sum:
	[] = 35443956
For namespace_work_duration_count:
	[] = 235
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:17:46.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6296" for this suite.
Jun 24 16:17:52.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:17:52.123: INFO: namespace gc-6296 deletion completed in 6.099000161s

• [SLOW TEST:12.201 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:17:52.123: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5811
Jun 24 16:17:54.182: INFO: Started pod liveness-http in namespace container-probe-5811
STEP: checking the pod's current state and verifying that restartCount is present
Jun 24 16:17:54.185: INFO: Initial restart count of pod liveness-http is 0
Jun 24 16:18:12.226: INFO: Restart count of pod container-probe-5811/liveness-http is now 1 (18.040782178s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:18:12.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5811" for this suite.
Jun 24 16:18:18.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:18:18.345: INFO: namespace container-probe-5811 deletion completed in 6.101032897s

• [SLOW TEST:26.222 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:18:18.350: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 16:18:18.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8613'
Jun 24 16:18:19.043: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 24 16:18:19.043: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Jun 24 16:18:19.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8613'
Jun 24 16:18:19.167: INFO: stderr: ""
Jun 24 16:18:19.167: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:18:19.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8613" for this suite.
Jun 24 16:18:25.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:18:25.272: INFO: namespace kubectl-8613 deletion completed in 6.101412746s

• [SLOW TEST:6.922 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:18:25.272: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jun 24 16:18:25.315: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:18:30.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8082" for this suite.
Jun 24 16:18:52.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:18:52.618: INFO: namespace init-container-8082 deletion completed in 22.10202777s

• [SLOW TEST:27.345 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:18:52.618: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jun 24 16:18:52.661: INFO: namespace kubectl-1879
Jun 24 16:18:52.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-1879'
Jun 24 16:18:52.941: INFO: stderr: ""
Jun 24 16:18:52.941: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 24 16:18:53.945: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:18:53.945: INFO: Found 0 / 1
Jun 24 16:18:54.944: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:18:54.944: INFO: Found 1 / 1
Jun 24 16:18:54.944: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 24 16:18:54.952: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 16:18:54.952: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 24 16:18:54.952: INFO: wait on redis-master startup in kubectl-1879 
Jun 24 16:18:54.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 logs redis-master-wsmdn redis-master --namespace=kubectl-1879'
Jun 24 16:18:55.073: INFO: stderr: ""
Jun 24 16:18:55.073: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Jun 16:18:54.145 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Jun 16:18:54.145 # Server started, Redis version 3.2.12\n1:M 24 Jun 16:18:54.145 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Jun 16:18:54.145 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jun 24 16:18:55.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1879'
Jun 24 16:18:55.223: INFO: stderr: ""
Jun 24 16:18:55.223: INFO: stdout: "service/rm2 exposed\n"
Jun 24 16:18:55.227: INFO: Service rm2 in namespace kubectl-1879 found.
STEP: exposing service
Jun 24 16:18:57.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1879'
Jun 24 16:18:57.344: INFO: stderr: ""
Jun 24 16:18:57.344: INFO: stdout: "service/rm3 exposed\n"
Jun 24 16:18:57.348: INFO: Service rm3 in namespace kubectl-1879 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:18:59.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1879" for this suite.
Jun 24 16:19:21.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:19:21.460: INFO: namespace kubectl-1879 deletion completed in 22.103092718s

• [SLOW TEST:28.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:19:21.461: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jun 24 16:19:26.038: INFO: Successfully updated pod "labelsupdated2f6d732-969b-11e9-8bcb-526dc0a539dd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:19:28.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1159" for this suite.
Jun 24 16:19:50.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:19:50.182: INFO: namespace projected-1159 deletion completed in 22.113828642s

• [SLOW TEST:28.721 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:19:50.184: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-e41598eb-969b-11e9-8bcb-526dc0a539dd
STEP: Creating configMap with name cm-test-opt-upd-e4159931-969b-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e41598eb-969b-11e9-8bcb-526dc0a539dd
STEP: Updating configmap cm-test-opt-upd-e4159931-969b-11e9-8bcb-526dc0a539dd
STEP: Creating configMap with name cm-test-opt-create-e415995c-969b-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:21:14.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2084" for this suite.
Jun 24 16:21:36.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:21:36.992: INFO: namespace configmap-2084 deletion completed in 22.098328966s

• [SLOW TEST:106.808 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:21:36.992: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 24 16:21:37.031: INFO: Waiting up to 5m0s for pod "pod-23be209c-969c-11e9-8bcb-526dc0a539dd" in namespace "emptydir-6037" to be "success or failure"
Jun 24 16:21:37.038: INFO: Pod "pod-23be209c-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.741072ms
Jun 24 16:21:39.042: INFO: Pod "pod-23be209c-969c-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011056062s
STEP: Saw pod success
Jun 24 16:21:39.042: INFO: Pod "pod-23be209c-969c-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:21:39.045: INFO: Trying to get logs from node minion pod pod-23be209c-969c-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:21:39.066: INFO: Waiting for pod pod-23be209c-969c-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:21:39.068: INFO: Pod pod-23be209c-969c-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:21:39.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6037" for this suite.
Jun 24 16:21:45.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:21:45.180: INFO: namespace emptydir-6037 deletion completed in 6.10938531s

• [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:21:45.180: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-28a15e61-969c-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:21:45.236: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd" in namespace "projected-130" to be "success or failure"
Jun 24 16:21:45.241: INFO: Pod "pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.761995ms
Jun 24 16:21:47.246: INFO: Pod "pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00995235s
STEP: Saw pod success
Jun 24 16:21:47.246: INFO: Pod "pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:21:47.249: INFO: Trying to get logs from node minion pod pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:21:47.273: INFO: Waiting for pod pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:21:47.277: INFO: Pod pod-projected-secrets-28a1f701-969c-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:21:47.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-130" for this suite.
Jun 24 16:21:53.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:21:53.377: INFO: namespace projected-130 deletion completed in 6.096575535s

• [SLOW TEST:8.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:21:53.378: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-vcfv
STEP: Creating a pod to test atomic-volume-subpath
Jun 24 16:21:53.429: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vcfv" in namespace "subpath-4714" to be "success or failure"
Jun 24 16:21:53.431: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.693831ms
Jun 24 16:21:55.435: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 2.006776161s
Jun 24 16:21:57.439: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 4.010553249s
Jun 24 16:21:59.443: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 6.014540742s
Jun 24 16:22:01.447: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 8.018623165s
Jun 24 16:22:03.452: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 10.023047172s
Jun 24 16:22:05.456: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 12.027318521s
Jun 24 16:22:07.460: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 14.031520483s
Jun 24 16:22:09.464: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 16.035831112s
Jun 24 16:22:11.468: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 18.039835791s
Jun 24 16:22:13.472: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 20.043873736s
Jun 24 16:22:15.477: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Running", Reason="", readiness=true. Elapsed: 22.048279605s
Jun 24 16:22:17.481: INFO: Pod "pod-subpath-test-projected-vcfv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052315944s
STEP: Saw pod success
Jun 24 16:22:17.481: INFO: Pod "pod-subpath-test-projected-vcfv" satisfied condition "success or failure"
Jun 24 16:22:17.484: INFO: Trying to get logs from node minion pod pod-subpath-test-projected-vcfv container test-container-subpath-projected-vcfv: <nil>
STEP: delete the pod
Jun 24 16:22:17.513: INFO: Waiting for pod pod-subpath-test-projected-vcfv to disappear
Jun 24 16:22:17.516: INFO: Pod pod-subpath-test-projected-vcfv no longer exists
STEP: Deleting pod pod-subpath-test-projected-vcfv
Jun 24 16:22:17.516: INFO: Deleting pod "pod-subpath-test-projected-vcfv" in namespace "subpath-4714"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:22:17.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4714" for this suite.
Jun 24 16:22:23.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:22:23.613: INFO: namespace subpath-4714 deletion completed in 6.091157664s

• [SLOW TEST:30.236 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:22:23.614: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 24 16:22:23.667: INFO: Waiting up to 5m0s for pod "pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd" in namespace "emptydir-1883" to be "success or failure"
Jun 24 16:22:23.676: INFO: Pod "pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.81369ms
Jun 24 16:22:25.679: INFO: Pod "pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012209928s
Jun 24 16:22:27.683: INFO: Pod "pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016051296s
STEP: Saw pod success
Jun 24 16:22:27.683: INFO: Pod "pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:22:27.687: INFO: Trying to get logs from node minion pod pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:22:27.724: INFO: Waiting for pod pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:22:27.727: INFO: Pod pod-3f8a241e-969c-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:22:27.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1883" for this suite.
Jun 24 16:22:33.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:22:33.831: INFO: namespace emptydir-1883 deletion completed in 6.100814704s

• [SLOW TEST:10.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:22:33.832: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 24 16:22:33.894: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:22:33.898: INFO: Number of nodes with available pods: 0
Jun 24 16:22:33.898: INFO: Node minion is running more than one daemon pod
Jun 24 16:22:34.903: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:22:34.908: INFO: Number of nodes with available pods: 0
Jun 24 16:22:34.908: INFO: Node minion is running more than one daemon pod
Jun 24 16:22:35.903: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:22:35.907: INFO: Number of nodes with available pods: 0
Jun 24 16:22:35.907: INFO: Node minion is running more than one daemon pod
Jun 24 16:22:36.903: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:22:36.907: INFO: Number of nodes with available pods: 1
Jun 24 16:22:36.907: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 24 16:22:36.924: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:22:36.930: INFO: Number of nodes with available pods: 1
Jun 24 16:22:36.930: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7067, will wait for the garbage collector to delete the pods
Jun 24 16:22:38.008: INFO: Deleting DaemonSet.extensions daemon-set took: 6.541326ms
Jun 24 16:22:38.308: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.358131ms
Jun 24 16:22:46.812: INFO: Number of nodes with available pods: 0
Jun 24 16:22:46.812: INFO: Number of running nodes: 0, number of available pods: 0
Jun 24 16:22:46.815: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7067/daemonsets","resourceVersion":"10758"},"items":null}

Jun 24 16:22:46.818: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7067/pods","resourceVersion":"10758"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:22:46.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7067" for this suite.
Jun 24 16:22:52.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:22:52.929: INFO: namespace daemonsets-7067 deletion completed in 6.099996889s

• [SLOW TEST:19.097 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:22:52.930: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:22:52.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 version'
Jun 24 16:22:53.064: INFO: stderr: ""
Jun 24 16:22:53.065: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:36:19Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:22:53.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5492" for this suite.
Jun 24 16:22:59.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:22:59.190: INFO: namespace kubectl-5492 deletion completed in 6.118448783s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:22:59.190: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 16:22:59.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1568'
Jun 24 16:22:59.354: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 24 16:22:59.354: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Jun 24 16:22:59.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete jobs e2e-test-nginx-job --namespace=kubectl-1568'
Jun 24 16:22:59.455: INFO: stderr: ""
Jun 24 16:22:59.455: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:22:59.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1568" for this suite.
Jun 24 16:23:21.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:23:21.571: INFO: namespace kubectl-1568 deletion completed in 22.107682037s

• [SLOW TEST:22.381 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:23:21.582: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:23:27.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2313" for this suite.
Jun 24 16:23:33.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:23:33.823: INFO: namespace namespaces-2313 deletion completed in 6.095178922s
STEP: Destroying namespace "nsdeletetest-7558" for this suite.
Jun 24 16:23:33.825: INFO: Namespace nsdeletetest-7558 was already deleted
STEP: Destroying namespace "nsdeletetest-9541" for this suite.
Jun 24 16:23:39.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:23:39.909: INFO: namespace nsdeletetest-9541 deletion completed in 6.084154098s

• [SLOW TEST:18.327 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:23:39.910: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6
Jun 24 16:23:41.957: INFO: Started pod liveness-exec in namespace container-probe-6
STEP: checking the pod's current state and verifying that restartCount is present
Jun 24 16:23:41.960: INFO: Initial restart count of pod liveness-exec is 0
Jun 24 16:24:32.064: INFO: Restart count of pod container-probe-6/liveness-exec is now 1 (50.103348867s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:24:32.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6" for this suite.
Jun 24 16:24:38.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:24:38.194: INFO: namespace container-probe-6 deletion completed in 6.107504629s

• [SLOW TEST:58.285 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:24:38.202: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-8fc2a413-969c-11e9-8bcb-526dc0a539dd
STEP: Creating configMap with name cm-test-opt-upd-8fc2a4eb-969c-11e9-8bcb-526dc0a539dd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8fc2a413-969c-11e9-8bcb-526dc0a539dd
STEP: Updating configmap cm-test-opt-upd-8fc2a4eb-969c-11e9-8bcb-526dc0a539dd
STEP: Creating configMap with name cm-test-opt-create-8fc2a50c-969c-11e9-8bcb-526dc0a539dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:25:50.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9015" for this suite.
Jun 24 16:26:12.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:26:12.934: INFO: namespace projected-9015 deletion completed in 22.105141804s

• [SLOW TEST:94.732 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:26:12.934: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:26:12.975: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd" in namespace "projected-9176" to be "success or failure"
Jun 24 16:26:12.979: INFO: Pod "downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154901ms
Jun 24 16:26:14.984: INFO: Pod "downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008437277s
STEP: Saw pod success
Jun 24 16:26:14.984: INFO: Pod "downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:26:14.988: INFO: Trying to get logs from node minion pod downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:26:15.027: INFO: Waiting for pod downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:26:15.030: INFO: Pod downwardapi-volume-c8378e08-969c-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:26:15.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9176" for this suite.
Jun 24 16:26:21.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:26:21.141: INFO: namespace projected-9176 deletion completed in 6.106487039s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:26:21.143: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 16:26:21.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-440'
Jun 24 16:26:21.304: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 24 16:26:21.304: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Jun 24 16:26:23.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete deployment e2e-test-nginx-deployment --namespace=kubectl-440'
Jun 24 16:26:23.435: INFO: stderr: ""
Jun 24 16:26:23.435: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:26:23.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-440" for this suite.
Jun 24 16:26:45.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:26:45.531: INFO: namespace kubectl-440 deletion completed in 22.091399666s

• [SLOW TEST:24.389 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:26:45.532: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Jun 24 16:26:47.581: INFO: Pod pod-hostip-dba4eedd-969c-11e9-8bcb-526dc0a539dd has hostIP: 10.1.0.12
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:26:47.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-326" for this suite.
Jun 24 16:27:09.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:27:09.687: INFO: namespace pods-326 deletion completed in 22.102225994s

• [SLOW TEST:24.156 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:27:09.692: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-ea0c69af-969c-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:27:09.735: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd" in namespace "projected-9728" to be "success or failure"
Jun 24 16:27:09.744: INFO: Pod "pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662598ms
Jun 24 16:27:11.748: INFO: Pod "pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012518992s
Jun 24 16:27:13.752: INFO: Pod "pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016563024s
STEP: Saw pod success
Jun 24 16:27:13.752: INFO: Pod "pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:27:13.755: INFO: Trying to get logs from node minion pod pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:27:13.779: INFO: Waiting for pod pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:27:13.781: INFO: Pod pod-projected-configmaps-ea0ce8ff-969c-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:27:13.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9728" for this suite.
Jun 24 16:27:19.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:27:19.879: INFO: namespace projected-9728 deletion completed in 6.094879475s

• [SLOW TEST:10.187 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:27:19.879: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 24 16:27:19.942: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:19.947: INFO: Number of nodes with available pods: 0
Jun 24 16:27:19.947: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:20.952: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:20.956: INFO: Number of nodes with available pods: 0
Jun 24 16:27:20.956: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:21.952: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:21.957: INFO: Number of nodes with available pods: 0
Jun 24 16:27:21.957: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:22.951: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:22.955: INFO: Number of nodes with available pods: 1
Jun 24 16:27:22.955: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 24 16:27:22.971: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:22.973: INFO: Number of nodes with available pods: 0
Jun 24 16:27:22.973: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:23.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:23.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:23.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:24.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:24.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:24.983: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:25.979: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:25.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:25.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:26.986: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:26.990: INFO: Number of nodes with available pods: 0
Jun 24 16:27:26.990: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:27.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:27.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:27.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:28.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:28.981: INFO: Number of nodes with available pods: 0
Jun 24 16:27:28.981: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:29.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:29.981: INFO: Number of nodes with available pods: 0
Jun 24 16:27:29.981: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:30.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:30.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:30.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:31.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:31.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:31.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:32.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:32.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:32.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:33.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:33.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:33.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:34.979: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:34.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:34.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:35.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:35.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:35.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:36.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:36.982: INFO: Number of nodes with available pods: 0
Jun 24 16:27:36.982: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:37.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:37.983: INFO: Number of nodes with available pods: 0
Jun 24 16:27:37.983: INFO: Node minion is running more than one daemon pod
Jun 24 16:27:38.978: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:27:38.982: INFO: Number of nodes with available pods: 1
Jun 24 16:27:38.982: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8011, will wait for the garbage collector to delete the pods
Jun 24 16:27:39.047: INFO: Deleting DaemonSet.extensions daemon-set took: 8.68959ms
Jun 24 16:27:39.347: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.445072ms
Jun 24 16:27:46.858: INFO: Number of nodes with available pods: 0
Jun 24 16:27:46.858: INFO: Number of running nodes: 0, number of available pods: 0
Jun 24 16:27:46.861: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8011/daemonsets","resourceVersion":"11527"},"items":null}

Jun 24 16:27:46.865: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8011/pods","resourceVersion":"11527"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:27:46.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8011" for this suite.
Jun 24 16:27:52.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:27:52.974: INFO: namespace daemonsets-8011 deletion completed in 6.099412421s

• [SLOW TEST:33.095 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:27:52.976: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:27:53.013: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun 24 16:27:53.024: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun 24 16:27:58.028: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 24 16:27:58.029: INFO: Creating deployment "test-rolling-update-deployment"
Jun 24 16:27:58.035: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun 24 16:27:58.041: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun 24 16:28:00.048: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun 24 16:28:00.051: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696990478, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696990478, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696990478, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696990478, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:28:02.056: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 24 16:28:02.067: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6995,SelfLink:/apis/apps/v1/namespaces/deployment-6995/deployments/test-rolling-update-deployment,UID:06d71de3-969d-11e9-b70d-fa163ef83c94,ResourceVersion:11611,Generation:1,CreationTimestamp:2019-06-24 16:27:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-24 16:27:58 +0000 UTC 2019-06-24 16:27:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-24 16:28:00 +0000 UTC 2019-06-24 16:27:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 24 16:28:02.070: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-6995,SelfLink:/apis/apps/v1/namespaces/deployment-6995/replicasets/test-rolling-update-deployment-67599b4d9,UID:06d95fbc-969d-11e9-b70d-fa163ef83c94,ResourceVersion:11601,Generation:1,CreationTimestamp:2019-06-24 16:27:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 06d71de3-969d-11e9-b70d-fa163ef83c94 0xc0023e7f10 0xc0023e7f11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 24 16:28:02.070: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun 24 16:28:02.070: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6995,SelfLink:/apis/apps/v1/namespaces/deployment-6995/replicasets/test-rolling-update-controller,UID:03d9c33e-969d-11e9-b70d-fa163ef83c94,ResourceVersion:11610,Generation:2,CreationTimestamp:2019-06-24 16:27:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 06d71de3-969d-11e9-b70d-fa163ef83c94 0xc0023e7e47 0xc0023e7e48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:28:02.074: INFO: Pod "test-rolling-update-deployment-67599b4d9-s8pq5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-s8pq5,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-6995,SelfLink:/api/v1/namespaces/deployment-6995/pods/test-rolling-update-deployment-67599b4d9-s8pq5,UID:06d9f570-969d-11e9-b70d-fa163ef83c94,ResourceVersion:11600,Generation:0,CreationTimestamp:2019-06-24 16:27:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 06d95fbc-969d-11e9-b70d-fa163ef83c94 0xc001d55530 0xc001d55531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t9s2s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9s2s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-t9s2s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d55770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d557a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:27:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:28:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:28:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:27:58 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.6,StartTime:2019-06-24 16:27:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-24 16:27:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://12b53f6b3a14d20287a776e029988673ba3f9e2b8264289b1b52a68212c5ae39}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:28:02.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6995" for this suite.
Jun 24 16:28:08.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:28:08.175: INFO: namespace deployment-6995 deletion completed in 6.097879656s

• [SLOW TEST:15.200 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:28:08.177: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0ce7e4f1-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:28:08.218: INFO: Waiting up to 5m0s for pod "pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd" in namespace "secrets-2402" to be "success or failure"
Jun 24 16:28:08.221: INFO: Pod "pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.069447ms
Jun 24 16:28:10.225: INFO: Pod "pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007160226s
Jun 24 16:28:12.229: INFO: Pod "pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011102081s
STEP: Saw pod success
Jun 24 16:28:12.229: INFO: Pod "pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:28:12.233: INFO: Trying to get logs from node minion pod pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:28:12.261: INFO: Waiting for pod pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:28:12.266: INFO: Pod pod-secrets-0ce896ac-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:28:12.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2402" for this suite.
Jun 24 16:28:18.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:28:18.373: INFO: namespace secrets-2402 deletion completed in 6.103259476s

• [SLOW TEST:10.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:28:18.373: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-5750
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5750 to expose endpoints map[]
Jun 24 16:28:18.426: INFO: Get endpoints failed (3.57465ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 24 16:28:19.430: INFO: successfully validated that service multi-endpoint-test in namespace services-5750 exposes endpoints map[] (1.007140318s elapsed)
STEP: Creating pod pod1 in namespace services-5750
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5750 to expose endpoints map[pod1:[100]]
Jun 24 16:28:22.469: INFO: successfully validated that service multi-endpoint-test in namespace services-5750 exposes endpoints map[pod1:[100]] (3.030198836s elapsed)
STEP: Creating pod pod2 in namespace services-5750
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5750 to expose endpoints map[pod1:[100] pod2:[101]]
Jun 24 16:28:24.511: INFO: successfully validated that service multi-endpoint-test in namespace services-5750 exposes endpoints map[pod1:[100] pod2:[101]] (2.034977377s elapsed)
STEP: Deleting pod pod1 in namespace services-5750
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5750 to expose endpoints map[pod2:[101]]
Jun 24 16:28:24.534: INFO: successfully validated that service multi-endpoint-test in namespace services-5750 exposes endpoints map[pod2:[101]] (14.727633ms elapsed)
STEP: Deleting pod pod2 in namespace services-5750
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5750 to expose endpoints map[]
Jun 24 16:28:25.545: INFO: successfully validated that service multi-endpoint-test in namespace services-5750 exposes endpoints map[] (1.005643982s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:28:25.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5750" for this suite.
Jun 24 16:28:47.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:28:47.676: INFO: namespace services-5750 deletion completed in 22.098083427s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.303 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:28:47.677: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-2474b969-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:28:47.728: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-9394" to be "success or failure"
Jun 24 16:28:47.730: INFO: Pod "pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.254737ms
Jun 24 16:28:49.734: INFO: Pod "pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006203406s
STEP: Saw pod success
Jun 24 16:28:49.734: INFO: Pod "pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:28:49.737: INFO: Trying to get logs from node minion pod pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:28:49.760: INFO: Waiting for pod pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:28:49.765: INFO: Pod pod-projected-secrets-24756fb1-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:28:49.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9394" for this suite.
Jun 24 16:28:55.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:28:55.873: INFO: namespace projected-9394 deletion completed in 6.105029639s

• [SLOW TEST:8.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:28:55.874: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Jun 24 16:28:55.925: INFO: Waiting up to 5m0s for pod "client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd" in namespace "containers-8487" to be "success or failure"
Jun 24 16:28:55.932: INFO: Pod "client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.585572ms
Jun 24 16:28:57.936: INFO: Pod "client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01027915s
STEP: Saw pod success
Jun 24 16:28:57.936: INFO: Pod "client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:28:57.941: INFO: Trying to get logs from node minion pod client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:28:57.964: INFO: Waiting for pod client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:28:57.966: INFO: Pod client-containers-2957ef97-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:28:57.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8487" for this suite.
Jun 24 16:29:03.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:29:04.070: INFO: namespace containers-8487 deletion completed in 6.100634312s

• [SLOW TEST:8.195 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:29:04.070: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jun 24 16:29:06.652: INFO: Successfully updated pod "labelsupdate2e3b0771-969d-11e9-8bcb-526dc0a539dd"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:29:08.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6239" for this suite.
Jun 24 16:29:30.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:29:30.793: INFO: namespace downward-api-6239 deletion completed in 22.109019875s

• [SLOW TEST:26.723 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:29:30.793: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:29:30.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9169" for this suite.
Jun 24 16:29:36.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:29:36.941: INFO: namespace services-9169 deletion completed in 6.104507132s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.148 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:29:36.942: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-41d160d0-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:29:36.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd" in namespace "configmap-5793" to be "success or failure"
Jun 24 16:29:36.992: INFO: Pod "pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.842962ms
Jun 24 16:29:38.996: INFO: Pod "pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011210032s
STEP: Saw pod success
Jun 24 16:29:38.996: INFO: Pod "pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:29:39.000: INFO: Trying to get logs from node minion pod pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:29:39.028: INFO: Waiting for pod pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:29:39.031: INFO: Pod pod-configmaps-41d1bd5d-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:29:39.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5793" for this suite.
Jun 24 16:29:45.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:29:45.146: INFO: namespace configmap-5793 deletion completed in 6.111584447s

• [SLOW TEST:8.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:29:45.147: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-46b52af8-969d-11e9-8bcb-526dc0a539dd
STEP: Creating secret with name secret-projected-all-test-volume-46b52ad9-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 24 16:29:45.201: INFO: Waiting up to 5m0s for pod "projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-9562" to be "success or failure"
Jun 24 16:29:45.212: INFO: Pod "projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128848ms
Jun 24 16:29:47.216: INFO: Pod "projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014396754s
STEP: Saw pod success
Jun 24 16:29:47.216: INFO: Pod "projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:29:47.220: INFO: Trying to get logs from node minion pod projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 24 16:29:47.246: INFO: Waiting for pod projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:29:47.249: INFO: Pod projected-volume-46b52a7c-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:29:47.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9562" for this suite.
Jun 24 16:29:53.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:29:53.350: INFO: namespace projected-9562 deletion completed in 6.098131343s

• [SLOW TEST:8.203 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:29:53.355: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:29:53.411: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 24 16:29:53.418: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:53.427: INFO: Number of nodes with available pods: 0
Jun 24 16:29:53.427: INFO: Node minion is running more than one daemon pod
Jun 24 16:29:54.431: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:54.434: INFO: Number of nodes with available pods: 0
Jun 24 16:29:54.434: INFO: Node minion is running more than one daemon pod
Jun 24 16:29:55.431: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:55.435: INFO: Number of nodes with available pods: 1
Jun 24 16:29:55.435: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 24 16:29:55.458: INFO: Wrong image for pod: daemon-set-4vc8s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jun 24 16:29:55.468: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:56.472: INFO: Wrong image for pod: daemon-set-4vc8s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jun 24 16:29:56.477: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:57.472: INFO: Wrong image for pod: daemon-set-4vc8s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jun 24 16:29:57.476: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:58.472: INFO: Wrong image for pod: daemon-set-4vc8s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jun 24 16:29:58.472: INFO: Pod daemon-set-4vc8s is not available
Jun 24 16:29:58.476: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:59.472: INFO: Pod daemon-set-6p2wc is not available
Jun 24 16:29:59.478: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 24 16:29:59.482: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:29:59.486: INFO: Number of nodes with available pods: 0
Jun 24 16:29:59.486: INFO: Node minion is running more than one daemon pod
Jun 24 16:30:00.490: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:30:00.494: INFO: Number of nodes with available pods: 0
Jun 24 16:30:00.494: INFO: Node minion is running more than one daemon pod
Jun 24 16:30:01.492: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 16:30:01.495: INFO: Number of nodes with available pods: 1
Jun 24 16:30:01.495: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8312, will wait for the garbage collector to delete the pods
Jun 24 16:30:01.571: INFO: Deleting DaemonSet.extensions daemon-set took: 7.391006ms
Jun 24 16:30:01.871: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.392311ms
Jun 24 16:30:05.575: INFO: Number of nodes with available pods: 0
Jun 24 16:30:05.575: INFO: Number of running nodes: 0, number of available pods: 0
Jun 24 16:30:05.578: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8312/daemonsets","resourceVersion":"12089"},"items":null}

Jun 24 16:30:05.581: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8312/pods","resourceVersion":"12089"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:30:05.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8312" for this suite.
Jun 24 16:30:11.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:30:11.693: INFO: namespace daemonsets-8312 deletion completed in 6.091929589s

• [SLOW TEST:18.339 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:30:11.694: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 24 16:30:11.750: INFO: Waiting up to 5m0s for pod "pod-56889c21-969d-11e9-8bcb-526dc0a539dd" in namespace "emptydir-9880" to be "success or failure"
Jun 24 16:30:11.753: INFO: Pod "pod-56889c21-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.808394ms
Jun 24 16:30:13.757: INFO: Pod "pod-56889c21-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007653131s
STEP: Saw pod success
Jun 24 16:30:13.757: INFO: Pod "pod-56889c21-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:30:13.766: INFO: Trying to get logs from node minion pod pod-56889c21-969d-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:30:13.787: INFO: Waiting for pod pod-56889c21-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:30:13.791: INFO: Pod pod-56889c21-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:30:13.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9880" for this suite.
Jun 24 16:30:19.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:30:19.890: INFO: namespace emptydir-9880 deletion completed in 6.09541278s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:30:19.890: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:30:19.927: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-6258" to be "success or failure"
Jun 24 16:30:19.945: INFO: Pod "downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.239751ms
Jun 24 16:30:21.949: INFO: Pod "downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021678739s
STEP: Saw pod success
Jun 24 16:30:21.949: INFO: Pod "downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:30:21.954: INFO: Trying to get logs from node minion pod downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:30:21.980: INFO: Waiting for pod downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:30:21.986: INFO: Pod downwardapi-volume-5b69e985-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:30:21.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6258" for this suite.
Jun 24 16:30:28.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:30:28.104: INFO: namespace projected-6258 deletion completed in 6.114964713s

• [SLOW TEST:8.214 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:30:28.105: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:30:28.146: INFO: Creating ReplicaSet my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd
Jun 24 16:30:28.154: INFO: Pod name my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd: Found 0 pods out of 1
Jun 24 16:30:33.159: INFO: Pod name my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd: Found 1 pods out of 1
Jun 24 16:30:33.159: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd" is running
Jun 24 16:30:33.163: INFO: Pod "my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd-6zmnk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:30:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:30:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:30:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-24 16:30:28 +0000 UTC Reason: Message:}])
Jun 24 16:30:33.163: INFO: Trying to dial the pod
Jun 24 16:30:38.180: INFO: Controller my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd: Got expected result from replica 1 [my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd-6zmnk]: "my-hostname-basic-6050fef5-969d-11e9-8bcb-526dc0a539dd-6zmnk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:30:38.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3561" for this suite.
Jun 24 16:30:44.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:30:44.294: INFO: namespace replicaset-3561 deletion completed in 6.106937413s

• [SLOW TEST:16.190 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:30:44.295: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:30:44.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd" in namespace "downward-api-1443" to be "success or failure"
Jun 24 16:30:44.336: INFO: Pod "downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.965195ms
Jun 24 16:30:46.341: INFO: Pod "downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008281932s
Jun 24 16:30:48.345: INFO: Pod "downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01256802s
STEP: Saw pod success
Jun 24 16:30:48.345: INFO: Pod "downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:30:48.349: INFO: Trying to get logs from node minion pod downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:30:48.373: INFO: Waiting for pod downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:30:48.378: INFO: Pod downwardapi-volume-69f5b219-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:30:48.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1443" for this suite.
Jun 24 16:30:54.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:30:54.498: INFO: namespace downward-api-1443 deletion completed in 6.116509154s

• [SLOW TEST:10.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:30:54.498: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-ld88
STEP: Creating a pod to test atomic-volume-subpath
Jun 24 16:30:54.553: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ld88" in namespace "subpath-7091" to be "success or failure"
Jun 24 16:30:54.556: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Pending", Reason="", readiness=false. Elapsed: 3.540142ms
Jun 24 16:30:56.560: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007378343s
Jun 24 16:30:58.565: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 4.012050298s
Jun 24 16:31:00.569: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 6.016199613s
Jun 24 16:31:02.573: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 8.020189326s
Jun 24 16:31:04.577: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 10.024205894s
Jun 24 16:31:06.581: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 12.027997124s
Jun 24 16:31:08.585: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 14.031753928s
Jun 24 16:31:10.590: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 16.037510534s
Jun 24 16:31:12.595: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 18.041736645s
Jun 24 16:31:14.599: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Running", Reason="", readiness=true. Elapsed: 20.045867195s
Jun 24 16:31:16.603: INFO: Pod "pod-subpath-test-downwardapi-ld88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.050011993s
STEP: Saw pod success
Jun 24 16:31:16.603: INFO: Pod "pod-subpath-test-downwardapi-ld88" satisfied condition "success or failure"
Jun 24 16:31:16.607: INFO: Trying to get logs from node minion pod pod-subpath-test-downwardapi-ld88 container test-container-subpath-downwardapi-ld88: <nil>
STEP: delete the pod
Jun 24 16:31:16.627: INFO: Waiting for pod pod-subpath-test-downwardapi-ld88 to disappear
Jun 24 16:31:16.629: INFO: Pod pod-subpath-test-downwardapi-ld88 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ld88
Jun 24 16:31:16.629: INFO: Deleting pod "pod-subpath-test-downwardapi-ld88" in namespace "subpath-7091"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:31:16.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7091" for this suite.
Jun 24 16:31:22.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:31:22.742: INFO: namespace subpath-7091 deletion completed in 6.105527884s

• [SLOW TEST:28.244 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:31:22.742: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:31:22.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-176" to be "success or failure"
Jun 24 16:31:22.804: INFO: Pod "downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.400997ms
Jun 24 16:31:24.808: INFO: Pod "downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013373729s
STEP: Saw pod success
Jun 24 16:31:24.808: INFO: Pod "downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:31:24.812: INFO: Trying to get logs from node minion pod downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:31:24.836: INFO: Waiting for pod downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:31:24.839: INFO: Pod downwardapi-volume-80e2b32e-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:31:24.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-176" for this suite.
Jun 24 16:31:30.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:31:30.932: INFO: namespace projected-176 deletion completed in 6.089771995s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:31:30.932: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 24 16:31:33.509: INFO: Successfully updated pod "pod-update-85c478da-969d-11e9-8bcb-526dc0a539dd"
STEP: verifying the updated pod is in kubernetes
Jun 24 16:31:33.517: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:31:33.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1198" for this suite.
Jun 24 16:31:49.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:31:49.623: INFO: namespace pods-1198 deletion completed in 16.101027795s

• [SLOW TEST:18.691 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:31:49.623: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-90e6245f-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:31:49.662: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-9193" to be "success or failure"
Jun 24 16:31:49.669: INFO: Pod "pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.521233ms
Jun 24 16:31:51.673: INFO: Pod "pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010490835s
STEP: Saw pod success
Jun 24 16:31:51.673: INFO: Pod "pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:31:51.676: INFO: Trying to get logs from node minion pod pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:31:51.703: INFO: Waiting for pod pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:31:51.705: INFO: Pod pod-projected-configmaps-90e6a839-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:31:51.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9193" for this suite.
Jun 24 16:31:57.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:31:57.800: INFO: namespace projected-9193 deletion completed in 6.09124445s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:31:57.800: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Jun 24 16:31:57.847: INFO: Waiting up to 5m0s for pod "var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd" in namespace "var-expansion-4725" to be "success or failure"
Jun 24 16:31:57.856: INFO: Pod "var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.541343ms
Jun 24 16:31:59.860: INFO: Pod "var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013526597s
STEP: Saw pod success
Jun 24 16:31:59.860: INFO: Pod "var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:31:59.863: INFO: Trying to get logs from node minion pod var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 16:31:59.885: INFO: Waiting for pod var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:31:59.888: INFO: Pod var-expansion-95c702fe-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:31:59.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4725" for this suite.
Jun 24 16:32:05.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:32:05.989: INFO: namespace var-expansion-4725 deletion completed in 6.09748296s

• [SLOW TEST:8.189 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:32:05.990: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 16:32:06.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4103'
Jun 24 16:32:06.720: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 24 16:32:06.720: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jun 24 16:32:06.735: INFO: scanned /root for discovery docs: <nil>
Jun 24 16:32:06.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4103'
Jun 24 16:32:22.566: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 24 16:32:22.566: INFO: stdout: "Created e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac\nScaling up e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jun 24 16:32:22.566: INFO: stdout: "Created e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac\nScaling up e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jun 24 16:32:22.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4103'
Jun 24 16:32:22.697: INFO: stderr: ""
Jun 24 16:32:22.697: INFO: stdout: "e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac-9v6x6 "
Jun 24 16:32:22.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac-9v6x6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4103'
Jun 24 16:32:22.789: INFO: stderr: ""
Jun 24 16:32:22.789: INFO: stdout: "true"
Jun 24 16:32:22.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac-9v6x6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4103'
Jun 24 16:32:22.884: INFO: stderr: ""
Jun 24 16:32:22.884: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jun 24 16:32:22.884: INFO: e2e-test-nginx-rc-aeef45e2b1f72c9058a8dcf26ec5bfac-9v6x6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Jun 24 16:32:22.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete rc e2e-test-nginx-rc --namespace=kubectl-4103'
Jun 24 16:32:22.986: INFO: stderr: ""
Jun 24 16:32:22.986: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:32:22.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4103" for this suite.
Jun 24 16:32:29.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:32:29.101: INFO: namespace kubectl-4103 deletion completed in 6.105726091s

• [SLOW TEST:23.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:32:29.102: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Jun 24 16:32:29.142: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-766262415 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:32:29.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-736" for this suite.
Jun 24 16:32:35.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:32:35.333: INFO: namespace kubectl-736 deletion completed in 6.09933232s

• [SLOW TEST:6.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:32:35.337: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-8680
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8680 to expose endpoints map[]
Jun 24 16:32:35.389: INFO: successfully validated that service endpoint-test2 in namespace services-8680 exposes endpoints map[] (4.934356ms elapsed)
STEP: Creating pod pod1 in namespace services-8680
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8680 to expose endpoints map[pod1:[80]]
Jun 24 16:32:37.428: INFO: successfully validated that service endpoint-test2 in namespace services-8680 exposes endpoints map[pod1:[80]] (2.033544328s elapsed)
STEP: Creating pod pod2 in namespace services-8680
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8680 to expose endpoints map[pod1:[80] pod2:[80]]
Jun 24 16:32:39.476: INFO: successfully validated that service endpoint-test2 in namespace services-8680 exposes endpoints map[pod1:[80] pod2:[80]] (2.041484862s elapsed)
STEP: Deleting pod pod1 in namespace services-8680
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8680 to expose endpoints map[pod2:[80]]
Jun 24 16:32:40.506: INFO: successfully validated that service endpoint-test2 in namespace services-8680 exposes endpoints map[pod2:[80]] (1.020626176s elapsed)
STEP: Deleting pod pod2 in namespace services-8680
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8680 to expose endpoints map[]
Jun 24 16:32:40.524: INFO: successfully validated that service endpoint-test2 in namespace services-8680 exposes endpoints map[] (10.711003ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:32:40.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8680" for this suite.
Jun 24 16:32:46.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:32:46.658: INFO: namespace services-8680 deletion completed in 6.108941568s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:11.322 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:32:46.659: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:32:46.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd" in namespace "projected-5165" to be "success or failure"
Jun 24 16:32:46.717: INFO: Pod "downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.140552ms
Jun 24 16:32:48.721: INFO: Pod "downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008204815s
STEP: Saw pod success
Jun 24 16:32:48.721: INFO: Pod "downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:32:48.725: INFO: Trying to get logs from node minion pod downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:32:48.749: INFO: Waiting for pod downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:32:48.751: INFO: Pod downwardapi-volume-b2e5f2a8-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:32:48.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5165" for this suite.
Jun 24 16:32:54.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:32:54.848: INFO: namespace projected-5165 deletion completed in 6.093272616s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:32:54.848: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-b7c7d05b-969d-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:32:54.895: INFO: Waiting up to 5m0s for pod "pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd" in namespace "configmap-2236" to be "success or failure"
Jun 24 16:32:54.898: INFO: Pod "pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.860296ms
Jun 24 16:32:56.902: INFO: Pod "pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00683572s
STEP: Saw pod success
Jun 24 16:32:56.903: INFO: Pod "pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:32:56.906: INFO: Trying to get logs from node minion pod pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:32:56.927: INFO: Waiting for pod pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:32:56.936: INFO: Pod pod-configmaps-b7c853b4-969d-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:32:56.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2236" for this suite.
Jun 24 16:33:02.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:33:03.040: INFO: namespace configmap-2236 deletion completed in 6.10193783s

• [SLOW TEST:8.192 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:33:03.052: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Jun 24 16:33:03.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 --namespace=kubectl-7435 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jun 24 16:33:05.278: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jun 24 16:33:05.278: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:33:07.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7435" for this suite.
Jun 24 16:33:13.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:33:13.389: INFO: namespace kubectl-7435 deletion completed in 6.099603915s

• [SLOW TEST:10.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:33:13.389: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3166
Jun 24 16:33:15.438: INFO: Started pod liveness-exec in namespace container-probe-3166
STEP: checking the pod's current state and verifying that restartCount is present
Jun 24 16:33:15.442: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:37:15.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3166" for this suite.
Jun 24 16:37:21.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:37:22.068: INFO: namespace container-probe-3166 deletion completed in 6.102282723s

• [SLOW TEST:248.678 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:37:22.076: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:37:22.119: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:37:23.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7449" for this suite.
Jun 24 16:37:29.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:37:29.325: INFO: namespace custom-resource-definition-7449 deletion completed in 6.089689312s

• [SLOW TEST:7.250 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:37:29.326: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:37:31.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8044" for this suite.
Jun 24 16:38:09.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:38:09.488: INFO: namespace kubelet-test-8044 deletion completed in 38.089544559s

• [SLOW TEST:40.163 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:38:09.489: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Jun 24 16:38:09.533: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2841" to be "success or failure"
Jun 24 16:38:09.538: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.023312ms
Jun 24 16:38:11.542: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009083s
Jun 24 16:38:13.546: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013243814s
STEP: Saw pod success
Jun 24 16:38:13.546: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun 24 16:38:13.551: INFO: Trying to get logs from node minion pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 24 16:38:13.572: INFO: Waiting for pod pod-host-path-test to disappear
Jun 24 16:38:13.577: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:38:13.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2841" for this suite.
Jun 24 16:38:19.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:38:19.693: INFO: namespace hostpath-2841 deletion completed in 6.103584855s

• [SLOW TEST:10.205 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:38:19.693: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8092.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8092.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8092.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8092.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 203.198.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.198.203_udp@PTR;check="$$(dig +tcp +noall +answer +search 203.198.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.198.203_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8092.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8092.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8092.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8092.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8092.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8092.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 203.198.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.198.203_udp@PTR;check="$$(dig +tcp +noall +answer +search 203.198.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.198.203_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 24 16:38:23.791: INFO: Unable to read wheezy_udp@dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.796: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.801: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.806: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.842: INFO: Unable to read jessie_udp@dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.848: INFO: Unable to read jessie_tcp@dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.854: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.858: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local from pod dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd: the server could not find the requested resource (get pods dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd)
Jun 24 16:38:23.889: INFO: Lookups using dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd failed for: [wheezy_udp@dns-test-service.dns-8092.svc.cluster.local wheezy_tcp@dns-test-service.dns-8092.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local jessie_udp@dns-test-service.dns-8092.svc.cluster.local jessie_tcp@dns-test-service.dns-8092.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8092.svc.cluster.local]

Jun 24 16:38:29.008: INFO: DNS probes using dns-8092/dns-test-796a8baf-969e-11e9-8bcb-526dc0a539dd succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:38:29.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8092" for this suite.
Jun 24 16:38:35.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:38:35.184: INFO: namespace dns-8092 deletion completed in 6.096737947s

• [SLOW TEST:15.491 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:38:35.185: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 24 16:38:37.753: INFO: Successfully updated pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd"
Jun 24 16:38:37.753: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd" in namespace "pods-626" to be "terminated due to deadline exceeded"
Jun 24 16:38:37.760: INFO: Pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd": Phase="Running", Reason="", readiness=true. Elapsed: 6.845753ms
Jun 24 16:38:39.764: INFO: Pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd": Phase="Running", Reason="", readiness=true. Elapsed: 2.010758118s
Jun 24 16:38:41.769: INFO: Pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.0152476s
Jun 24 16:38:41.769: INFO: Pod "pod-update-activedeadlineseconds-82a298c5-969e-11e9-8bcb-526dc0a539dd" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:38:41.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-626" for this suite.
Jun 24 16:38:47.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:38:47.875: INFO: namespace pods-626 deletion completed in 6.101681947s

• [SLOW TEST:12.690 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:38:47.877: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Jun 24 16:38:47.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-3627'
Jun 24 16:38:48.193: INFO: stderr: ""
Jun 24 16:38:48.193: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 16:38:48.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3627'
Jun 24 16:38:48.317: INFO: stderr: ""
Jun 24 16:38:48.317: INFO: stdout: "update-demo-nautilus-bps5n update-demo-nautilus-ldqfv "
Jun 24 16:38:48.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-bps5n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:38:48.406: INFO: stderr: ""
Jun 24 16:38:48.406: INFO: stdout: ""
Jun 24 16:38:48.406: INFO: update-demo-nautilus-bps5n is created but not running
Jun 24 16:38:53.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3627'
Jun 24 16:38:53.508: INFO: stderr: ""
Jun 24 16:38:53.508: INFO: stdout: "update-demo-nautilus-bps5n update-demo-nautilus-ldqfv "
Jun 24 16:38:53.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-bps5n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:38:53.598: INFO: stderr: ""
Jun 24 16:38:53.598: INFO: stdout: "true"
Jun 24 16:38:53.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-bps5n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:38:53.691: INFO: stderr: ""
Jun 24 16:38:53.691: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 16:38:53.691: INFO: validating pod update-demo-nautilus-bps5n
Jun 24 16:38:53.699: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 16:38:53.699: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 16:38:53.699: INFO: update-demo-nautilus-bps5n is verified up and running
Jun 24 16:38:53.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-ldqfv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:38:53.792: INFO: stderr: ""
Jun 24 16:38:53.792: INFO: stdout: "true"
Jun 24 16:38:53.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-nautilus-ldqfv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:38:53.884: INFO: stderr: ""
Jun 24 16:38:53.884: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 24 16:38:53.884: INFO: validating pod update-demo-nautilus-ldqfv
Jun 24 16:38:53.894: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 24 16:38:53.894: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 24 16:38:53.894: INFO: update-demo-nautilus-ldqfv is verified up and running
STEP: rolling-update to new replication controller
Jun 24 16:38:53.896: INFO: scanned /root for discovery docs: <nil>
Jun 24 16:38:53.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3627'
Jun 24 16:39:16.434: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 24 16:39:16.434: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 24 16:39:16.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3627'
Jun 24 16:39:16.544: INFO: stderr: ""
Jun 24 16:39:16.544: INFO: stdout: "update-demo-kitten-q4q89 update-demo-kitten-wmqv9 "
Jun 24 16:39:16.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-kitten-q4q89 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:39:16.670: INFO: stderr: ""
Jun 24 16:39:16.670: INFO: stdout: "true"
Jun 24 16:39:16.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-kitten-q4q89 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:39:16.756: INFO: stderr: ""
Jun 24 16:39:16.756: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 24 16:39:16.756: INFO: validating pod update-demo-kitten-q4q89
Jun 24 16:39:16.779: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 24 16:39:16.779: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 24 16:39:16.779: INFO: update-demo-kitten-q4q89 is verified up and running
Jun 24 16:39:16.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-kitten-wmqv9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:39:16.875: INFO: stderr: ""
Jun 24 16:39:16.875: INFO: stdout: "true"
Jun 24 16:39:16.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods update-demo-kitten-wmqv9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3627'
Jun 24 16:39:16.963: INFO: stderr: ""
Jun 24 16:39:16.964: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 24 16:39:16.964: INFO: validating pod update-demo-kitten-wmqv9
Jun 24 16:39:16.973: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 24 16:39:16.973: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 24 16:39:16.973: INFO: update-demo-kitten-wmqv9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:39:16.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3627" for this suite.
Jun 24 16:39:38.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:39:39.072: INFO: namespace kubectl-3627 deletion completed in 22.095525269s

• [SLOW TEST:51.195 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:39:39.073: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:39:41.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-652" for this suite.
Jun 24 16:40:31.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:40:31.270: INFO: namespace kubelet-test-652 deletion completed in 50.113675238s

• [SLOW TEST:52.198 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:40:31.271: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 24 16:40:31.309: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13887,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 24 16:40:31.309: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13887,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 24 16:40:41.316: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13903,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 24 16:40:41.316: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13903,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 24 16:40:51.326: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13919,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 24 16:40:51.326: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13919,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 24 16:41:01.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13935,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 24 16:41:01.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-a,UID:c7d41ef8-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13935,Generation:0,CreationTimestamp:2019-06-24 16:40:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 24 16:41:11.341: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-b,UID:dfaff19f-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13952,Generation:0,CreationTimestamp:2019-06-24 16:41:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 24 16:41:11.341: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-b,UID:dfaff19f-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13952,Generation:0,CreationTimestamp:2019-06-24 16:41:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 24 16:41:21.348: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-b,UID:dfaff19f-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13968,Generation:0,CreationTimestamp:2019-06-24 16:41:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 24 16:41:21.348: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8046,SelfLink:/api/v1/namespaces/watch-8046/configmaps/e2e-watch-test-configmap-b,UID:dfaff19f-969e-11e9-b70d-fa163ef83c94,ResourceVersion:13968,Generation:0,CreationTimestamp:2019-06-24 16:41:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:41:31.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8046" for this suite.
Jun 24 16:41:37.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:41:37.460: INFO: namespace watch-8046 deletion completed in 6.10754625s

• [SLOW TEST:66.190 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:41:37.462: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun 24 16:41:37.748: INFO: Pod name wrapped-volume-race-ef6bd31e-969e-11e9-8bcb-526dc0a539dd: Found 0 pods out of 5
Jun 24 16:41:42.758: INFO: Pod name wrapped-volume-race-ef6bd31e-969e-11e9-8bcb-526dc0a539dd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ef6bd31e-969e-11e9-8bcb-526dc0a539dd in namespace emptydir-wrapper-5116, will wait for the garbage collector to delete the pods
Jun 24 16:41:52.859: INFO: Deleting ReplicationController wrapped-volume-race-ef6bd31e-969e-11e9-8bcb-526dc0a539dd took: 11.535545ms
Jun 24 16:41:53.159: INFO: Terminating ReplicationController wrapped-volume-race-ef6bd31e-969e-11e9-8bcb-526dc0a539dd pods took: 300.417016ms
STEP: Creating RC which spawns configmap-volume pods
Jun 24 16:42:36.875: INFO: Pod name wrapped-volume-race-12a9e1c6-969f-11e9-8bcb-526dc0a539dd: Found 0 pods out of 5
Jun 24 16:42:41.883: INFO: Pod name wrapped-volume-race-12a9e1c6-969f-11e9-8bcb-526dc0a539dd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-12a9e1c6-969f-11e9-8bcb-526dc0a539dd in namespace emptydir-wrapper-5116, will wait for the garbage collector to delete the pods
Jun 24 16:42:51.984: INFO: Deleting ReplicationController wrapped-volume-race-12a9e1c6-969f-11e9-8bcb-526dc0a539dd took: 10.408039ms
Jun 24 16:42:52.285: INFO: Terminating ReplicationController wrapped-volume-race-12a9e1c6-969f-11e9-8bcb-526dc0a539dd pods took: 300.367776ms
STEP: Creating RC which spawns configmap-volume pods
Jun 24 16:43:37.206: INFO: Pod name wrapped-volume-race-369ed405-969f-11e9-8bcb-526dc0a539dd: Found 0 pods out of 5
Jun 24 16:43:42.214: INFO: Pod name wrapped-volume-race-369ed405-969f-11e9-8bcb-526dc0a539dd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-369ed405-969f-11e9-8bcb-526dc0a539dd in namespace emptydir-wrapper-5116, will wait for the garbage collector to delete the pods
Jun 24 16:43:54.349: INFO: Deleting ReplicationController wrapped-volume-race-369ed405-969f-11e9-8bcb-526dc0a539dd took: 6.828991ms
Jun 24 16:43:54.649: INFO: Terminating ReplicationController wrapped-volume-race-369ed405-969f-11e9-8bcb-526dc0a539dd pods took: 300.548953ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:44:37.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5116" for this suite.
Jun 24 16:44:45.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:44:45.282: INFO: namespace emptydir-wrapper-5116 deletion completed in 8.099177449s

• [SLOW TEST:187.821 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:44:45.282: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 24 16:44:45.338: INFO: Waiting up to 5m0s for pod "pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd" in namespace "emptydir-6168" to be "success or failure"
Jun 24 16:44:45.342: INFO: Pod "pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.857682ms
Jun 24 16:44:47.346: INFO: Pod "pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008037494s
Jun 24 16:44:49.350: INFO: Pod "pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012094437s
STEP: Saw pod success
Jun 24 16:44:49.350: INFO: Pod "pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:44:49.354: INFO: Trying to get logs from node minion pod pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:44:49.382: INFO: Waiting for pod pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:44:49.384: INFO: Pod pod-5f3c7a94-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:44:49.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6168" for this suite.
Jun 24 16:44:55.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:44:55.479: INFO: namespace emptydir-6168 deletion completed in 6.091357366s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:44:55.481: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Jun 24 16:44:56.403: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jun 24 16:44:58.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:45:00.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:45:02.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991496, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:45:05.715: INFO: Waited 1.238086822s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:45:06.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6534" for this suite.
Jun 24 16:45:12.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:45:12.395: INFO: namespace aggregator-6534 deletion completed in 6.250367961s

• [SLOW TEST:16.914 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:45:12.395: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:45:12.434: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:45:14.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1549" for this suite.
Jun 24 16:46:00.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:46:00.710: INFO: namespace pods-1549 deletion completed in 46.099792157s

• [SLOW TEST:48.316 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:46:00.715: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Jun 24 16:46:00.754: INFO: Waiting up to 5m0s for pod "client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd" in namespace "containers-2971" to be "success or failure"
Jun 24 16:46:00.760: INFO: Pod "client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.588536ms
Jun 24 16:46:02.764: INFO: Pod "client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010043588s
STEP: Saw pod success
Jun 24 16:46:02.764: INFO: Pod "client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:46:02.768: INFO: Trying to get logs from node minion pod client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:46:02.797: INFO: Waiting for pod client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:46:02.800: INFO: Pod client-containers-8c30afe1-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:46:02.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2971" for this suite.
Jun 24 16:46:08.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:46:08.899: INFO: namespace containers-2971 deletion completed in 6.095408702s

• [SLOW TEST:8.185 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:46:08.906: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:46:08.953: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jun 24 16:46:13.958: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 24 16:46:13.958: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun 24 16:46:15.962: INFO: Creating deployment "test-rollover-deployment"
Jun 24 16:46:15.971: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun 24 16:46:17.979: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun 24 16:46:17.985: INFO: Ensure that both replica sets have 1 created replica
Jun 24 16:46:17.991: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun 24 16:46:17.998: INFO: Updating deployment test-rollover-deployment
Jun 24 16:46:17.998: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun 24 16:46:20.004: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun 24 16:46:20.017: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun 24 16:46:20.030: INFO: all replica sets need to contain the pod-template-hash label
Jun 24 16:46:20.030: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991580, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:22.038: INFO: all replica sets need to contain the pod-template-hash label
Jun 24 16:46:22.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991580, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:24.038: INFO: all replica sets need to contain the pod-template-hash label
Jun 24 16:46:24.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991580, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:26.038: INFO: all replica sets need to contain the pod-template-hash label
Jun 24 16:46:26.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991580, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:28.038: INFO: all replica sets need to contain the pod-template-hash label
Jun 24 16:46:28.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991580, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:30.045: INFO: 
Jun 24 16:46:30.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991576, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991590, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696991575, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 24 16:46:32.038: INFO: 
Jun 24 16:46:32.038: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 24 16:46:32.048: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2643,SelfLink:/apis/apps/v1/namespaces/deployment-2643/deployments/test-rollover-deployment,UID:95426a8b-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15511,Generation:2,CreationTimestamp:2019-06-24 16:46:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-24 16:46:16 +0000 UTC 2019-06-24 16:46:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-24 16:46:30 +0000 UTC 2019-06-24 16:46:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 24 16:46:32.051: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-2643,SelfLink:/apis/apps/v1/namespaces/deployment-2643/replicasets/test-rollover-deployment-766b4d6c9d,UID:9678fd03-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15501,Generation:2,CreationTimestamp:2019-06-24 16:46:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 95426a8b-969f-11e9-b70d-fa163ef83c94 0xc002abc437 0xc002abc438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 24 16:46:32.051: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun 24 16:46:32.051: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2643,SelfLink:/apis/apps/v1/namespaces/deployment-2643/replicasets/test-rollover-controller,UID:9113ea7b-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15510,Generation:2,CreationTimestamp:2019-06-24 16:46:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 95426a8b-969f-11e9-b70d-fa163ef83c94 0xc002abc287 0xc002abc288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:46:32.052: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-2643,SelfLink:/apis/apps/v1/namespaces/deployment-2643/replicasets/test-rollover-deployment-6455657675,UID:9544748e-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15472,Generation:2,CreationTimestamp:2019-06-24 16:46:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 95426a8b-969f-11e9-b70d-fa163ef83c94 0xc002abc357 0xc002abc358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:46:32.055: INFO: Pod "test-rollover-deployment-766b4d6c9d-ls8bd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-ls8bd,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-2643,SelfLink:/api/v1/namespaces/deployment-2643/pods/test-rollover-deployment-766b4d6c9d-ls8bd,UID:967dfb28-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15483,Generation:0,CreationTimestamp:2019-06-24 16:46:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 9678fd03-969f-11e9-b70d-fa163ef83c94 0xc002abcf87 0xc002abcf88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wvzpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wvzpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wvzpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002abd020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002abd040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:18 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.6,StartTime:2019-06-24 16:46:18 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-24 16:46:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://ec7a6b28f0f1467f86999f35d77575800154f7844d61cb6a6237e049bc61aa9f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:46:32.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2643" for this suite.
Jun 24 16:46:38.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:46:38.156: INFO: namespace deployment-2643 deletion completed in 6.097800657s

• [SLOW TEST:29.250 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:46:38.157: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2711.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2711.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2711.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2711.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2711.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2711.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 24 16:46:42.261: INFO: DNS probes using dns-2711/dns-test-a2829778-969f-11e9-8bcb-526dc0a539dd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:46:42.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2711" for this suite.
Jun 24 16:46:48.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:46:48.390: INFO: namespace dns-2711 deletion completed in 6.10015397s

• [SLOW TEST:10.233 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:46:48.391: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a89cf2ce-969f-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:46:48.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd" in namespace "projected-5724" to be "success or failure"
Jun 24 16:46:48.449: INFO: Pod "pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.257253ms
Jun 24 16:46:50.453: INFO: Pod "pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010100625s
Jun 24 16:46:52.457: INFO: Pod "pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013982253s
STEP: Saw pod success
Jun 24 16:46:52.457: INFO: Pod "pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:46:52.461: INFO: Trying to get logs from node minion pod pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:46:52.489: INFO: Waiting for pod pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:46:52.492: INFO: Pod pod-projected-configmaps-a89d6897-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:46:52.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5724" for this suite.
Jun 24 16:46:58.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:46:58.599: INFO: namespace projected-5724 deletion completed in 6.102770476s

• [SLOW TEST:10.208 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:46:58.599: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:46:58.638: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun 24 16:47:03.642: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 24 16:47:03.642: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 24 16:47:03.666: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9269,SelfLink:/apis/apps/v1/namespaces/deployment-9269/deployments/test-cleanup-deployment,UID:b1ae9ae3-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15682,Generation:1,CreationTimestamp:2019-06-24 16:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jun 24 16:47:03.677: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-9269,SelfLink:/apis/apps/v1/namespaces/deployment-9269/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:b1b10ed7-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15684,Generation:1,CreationTimestamp:2019-06-24 16:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b1ae9ae3-969f-11e9-b70d-fa163ef83c94 0xc002088cc7 0xc002088cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 24 16:47:03.677: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jun 24 16:47:03.677: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-9269,SelfLink:/apis/apps/v1/namespaces/deployment-9269/replicasets/test-cleanup-controller,UID:aeb151c1-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15683,Generation:1,CreationTimestamp:2019-06-24 16:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b1ae9ae3-969f-11e9-b70d-fa163ef83c94 0xc002088bf7 0xc002088bf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 24 16:47:03.684: INFO: Pod "test-cleanup-controller-4z7m7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-4z7m7,GenerateName:test-cleanup-controller-,Namespace:deployment-9269,SelfLink:/api/v1/namespaces/deployment-9269/pods/test-cleanup-controller-4z7m7,UID:aeb22343-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15675,Generation:0,CreationTimestamp:2019-06-24 16:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller aeb151c1-969f-11e9-b70d-fa163ef83c94 0xc0020895a7 0xc0020895a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xszl9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xszl9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xszl9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002089620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002089640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:46:58 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.5,StartTime:2019-06-24 16:46:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-24 16:46:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b66f865f5777a98201b1c82a8b5d515fe98f5f9ddc58f8b33edef0613b4a24ab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 24 16:47:03.685: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-dsrvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-dsrvq,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-9269,SelfLink:/api/v1/namespaces/deployment-9269/pods/test-cleanup-deployment-55cbfbc8f5-dsrvq,UID:b1b1c341-969f-11e9-b70d-fa163ef83c94,ResourceVersion:15687,Generation:0,CreationTimestamp:2019-06-24 16:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 b1b10ed7-969f-11e9-b70d-fa163ef83c94 0xc002089717 0xc002089718}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xszl9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xszl9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xszl9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002089790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020897b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:47:03 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:47:03.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9269" for this suite.
Jun 24 16:47:09.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:47:09.808: INFO: namespace deployment-9269 deletion completed in 6.10978671s

• [SLOW TEST:11.209 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:47:09.809: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-b55fd317-969f-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:47:09.855: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd" in namespace "configmap-3157" to be "success or failure"
Jun 24 16:47:09.861: INFO: Pod "pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.191573ms
Jun 24 16:47:11.865: INFO: Pod "pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010339074s
STEP: Saw pod success
Jun 24 16:47:11.866: INFO: Pod "pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:47:11.869: INFO: Trying to get logs from node minion pod pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:47:11.896: INFO: Waiting for pod pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:47:11.901: INFO: Pod pod-configmaps-b5607d0e-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:47:11.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3157" for this suite.
Jun 24 16:47:17.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:47:17.999: INFO: namespace configmap-3157 deletion completed in 6.093096056s

• [SLOW TEST:8.190 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:47:17.999: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 24 16:47:18.047: INFO: Waiting up to 5m0s for pod "pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd" in namespace "emptydir-9717" to be "success or failure"
Jun 24 16:47:18.050: INFO: Pod "pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.967082ms
Jun 24 16:47:20.054: INFO: Pod "pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007148225s
STEP: Saw pod success
Jun 24 16:47:20.054: INFO: Pod "pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:47:20.058: INFO: Trying to get logs from node minion pod pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:47:20.084: INFO: Waiting for pod pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:47:20.087: INFO: Pod pod-ba41b91c-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:47:20.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9717" for this suite.
Jun 24 16:47:26.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:47:26.193: INFO: namespace emptydir-9717 deletion completed in 6.102721616s

• [SLOW TEST:8.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:47:26.194: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jun 24 16:47:28.777: INFO: Successfully updated pod "annotationupdatebf23b23d-969f-11e9-8bcb-526dc0a539dd"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:47:30.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-336" for this suite.
Jun 24 16:47:52.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:47:52.915: INFO: namespace downward-api-336 deletion completed in 22.103059528s

• [SLOW TEST:26.721 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:47:52.918: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:47:53.021: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd" in namespace "downward-api-5656" to be "success or failure"
Jun 24 16:47:53.024: INFO: Pod "downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.245519ms
Jun 24 16:47:55.028: INFO: Pod "downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006635576s
STEP: Saw pod success
Jun 24 16:47:55.028: INFO: Pod "downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:47:55.031: INFO: Trying to get logs from node minion pod downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:47:55.054: INFO: Waiting for pod downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:47:55.059: INFO: Pod downwardapi-volume-cf1a7b96-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:47:55.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5656" for this suite.
Jun 24 16:48:01.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:48:01.158: INFO: namespace downward-api-5656 deletion completed in 6.095886248s

• [SLOW TEST:8.241 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:48:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Jun 24 16:48:01.200: INFO: Waiting up to 5m0s for pod "var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd" in namespace "var-expansion-5955" to be "success or failure"
Jun 24 16:48:01.204: INFO: Pod "var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.923785ms
Jun 24 16:48:03.208: INFO: Pod "var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007971645s
STEP: Saw pod success
Jun 24 16:48:03.208: INFO: Pod "var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:48:03.212: INFO: Trying to get logs from node minion pod var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 16:48:03.239: INFO: Waiting for pod var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:48:03.242: INFO: Pod var-expansion-d3fb3e09-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:48:03.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5955" for this suite.
Jun 24 16:48:09.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:48:09.341: INFO: namespace var-expansion-5955 deletion completed in 6.095346646s

• [SLOW TEST:8.183 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:48:09.341: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-d8e3fe14-969f-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:48:09.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd" in namespace "projected-9445" to be "success or failure"
Jun 24 16:48:09.451: INFO: Pod "pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032099ms
Jun 24 16:48:11.455: INFO: Pod "pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011641599s
STEP: Saw pod success
Jun 24 16:48:11.455: INFO: Pod "pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:48:11.459: INFO: Trying to get logs from node minion pod pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:48:11.483: INFO: Waiting for pod pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:48:11.486: INFO: Pod pod-projected-secrets-d8e4bd86-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:48:11.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9445" for this suite.
Jun 24 16:48:17.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:48:17.595: INFO: namespace projected-9445 deletion completed in 6.105821047s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:48:17.595: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jun 24 16:48:17.638: INFO: Waiting up to 5m0s for pod "downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd" in namespace "downward-api-7702" to be "success or failure"
Jun 24 16:48:17.641: INFO: Pod "downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109369ms
Jun 24 16:48:19.645: INFO: Pod "downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006985499s
STEP: Saw pod success
Jun 24 16:48:19.645: INFO: Pod "downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:48:19.648: INFO: Trying to get logs from node minion pod downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 16:48:19.674: INFO: Waiting for pod downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:48:19.677: INFO: Pod downward-api-ddc79946-969f-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:48:19.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7702" for this suite.
Jun 24 16:48:25.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:48:25.774: INFO: namespace downward-api-7702 deletion completed in 6.093483115s

• [SLOW TEST:8.179 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:48:25.776: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:48:29.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2378" for this suite.
Jun 24 16:48:35.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:48:35.936: INFO: namespace kubelet-test-2378 deletion completed in 6.101521337s

• [SLOW TEST:10.160 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:48:35.937: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 24 16:48:42.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 24 16:48:42.036: INFO: Pod pod-with-prestop-http-hook still exists
Jun 24 16:48:44.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 24 16:48:44.041: INFO: Pod pod-with-prestop-http-hook still exists
Jun 24 16:48:46.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 24 16:48:46.041: INFO: Pod pod-with-prestop-http-hook still exists
Jun 24 16:48:48.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 24 16:48:48.040: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:48:48.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4042" for this suite.
Jun 24 16:49:10.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:10.155: INFO: namespace container-lifecycle-hook-4042 deletion completed in 22.097188797s

• [SLOW TEST:34.219 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:49:10.156: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 24 16:49:10.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4922'
Jun 24 16:49:10.851: INFO: stderr: ""
Jun 24 16:49:10.851: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jun 24 16:49:15.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pod e2e-test-nginx-pod --namespace=kubectl-4922 -o json'
Jun 24 16:49:16.000: INFO: stderr: ""
Jun 24 16:49:16.000: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-06-24T16:49:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4922\",\n        \"resourceVersion\": \"16168\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4922/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fd7de833-969f-11e9-b70d-fa163ef83c94\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4lqxn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"minion\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4lqxn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4lqxn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-24T16:49:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-24T16:49:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-24T16:49:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-24T16:49:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4801a4228b9cc403b7811c0d2ecac995933c834b142f757e8461a26ab8ef9d6a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-06-24T16:49:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.0.12\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.251.128.5\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-06-24T16:49:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun 24 16:49:16.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 replace -f - --namespace=kubectl-4922'
Jun 24 16:49:16.345: INFO: stderr: ""
Jun 24 16:49:16.345: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Jun 24 16:49:16.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete pods e2e-test-nginx-pod --namespace=kubectl-4922'
Jun 24 16:49:18.985: INFO: stderr: ""
Jun 24 16:49:18.985: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:49:18.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4922" for this suite.
Jun 24 16:49:24.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:25.095: INFO: namespace kubectl-4922 deletion completed in 6.107170761s

• [SLOW TEST:14.940 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:49:25.096: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-060307ad-96a0-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 16:49:25.182: INFO: Waiting up to 5m0s for pod "pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd" in namespace "secrets-7320" to be "success or failure"
Jun 24 16:49:25.187: INFO: Pod "pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.94748ms
Jun 24 16:49:27.191: INFO: Pod "pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009027068s
STEP: Saw pod success
Jun 24 16:49:27.191: INFO: Pod "pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:49:27.195: INFO: Trying to get logs from node minion pod pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 16:49:27.224: INFO: Waiting for pod pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:49:27.227: INFO: Pod pod-secrets-0609ed1e-96a0-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:49:27.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7320" for this suite.
Jun 24 16:49:33.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:33.329: INFO: namespace secrets-7320 deletion completed in 6.09940097s
STEP: Destroying namespace "secret-namespace-4944" for this suite.
Jun 24 16:49:39.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:39.438: INFO: namespace secret-namespace-4944 deletion completed in 6.108803634s

• [SLOW TEST:14.342 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:49:39.438: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9307/configmap-test-0e91a39c-96a0-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:49:39.495: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd" in namespace "configmap-9307" to be "success or failure"
Jun 24 16:49:39.502: INFO: Pod "pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.168952ms
Jun 24 16:49:41.506: INFO: Pod "pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011026273s
STEP: Saw pod success
Jun 24 16:49:41.506: INFO: Pod "pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:49:41.509: INFO: Trying to get logs from node minion pod pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd container env-test: <nil>
STEP: delete the pod
Jun 24 16:49:41.532: INFO: Waiting for pod pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:49:41.549: INFO: Pod pod-configmaps-0e92213c-96a0-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:49:41.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9307" for this suite.
Jun 24 16:49:47.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:47.670: INFO: namespace configmap-9307 deletion completed in 6.11777199s

• [SLOW TEST:8.232 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:49:47.671: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jun 24 16:49:47.712: INFO: Waiting up to 5m0s for pod "downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd" in namespace "downward-api-4458" to be "success or failure"
Jun 24 16:49:47.723: INFO: Pod "downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.213664ms
Jun 24 16:49:49.728: INFO: Pod "downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015110543s
STEP: Saw pod success
Jun 24 16:49:49.728: INFO: Pod "downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:49:49.732: INFO: Trying to get logs from node minion pod downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd container dapi-container: <nil>
STEP: delete the pod
Jun 24 16:49:49.764: INFO: Waiting for pod downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:49:49.769: INFO: Pod downward-api-1377df06-96a0-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:49:49.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4458" for this suite.
Jun 24 16:49:55.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:49:55.875: INFO: namespace downward-api-4458 deletion completed in 6.097193167s

• [SLOW TEST:8.204 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:49:55.875: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:49:55.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2554" for this suite.
Jun 24 16:50:17.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:50:18.027: INFO: namespace pods-2554 deletion completed in 22.090899484s

• [SLOW TEST:22.152 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:50:18.027: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-259115ee-96a0-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume configMaps
Jun 24 16:50:18.081: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd" in namespace "projected-5577" to be "success or failure"
Jun 24 16:50:18.105: INFO: Pod "pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 24.163273ms
Jun 24 16:50:20.109: INFO: Pod "pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02816552s
STEP: Saw pod success
Jun 24 16:50:20.109: INFO: Pod "pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:50:20.114: INFO: Trying to get logs from node minion pod pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 24 16:50:20.137: INFO: Waiting for pod pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:50:20.141: INFO: Pod pod-projected-configmaps-2591ae44-96a0-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:50:20.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5577" for this suite.
Jun 24 16:50:26.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:50:26.246: INFO: namespace projected-5577 deletion completed in 6.098277603s

• [SLOW TEST:8.219 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:50:26.247: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun 24 16:50:28.312: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-2a75d385-96a0-11e9-8bcb-526dc0a539dd,GenerateName:,Namespace:events-5770,SelfLink:/api/v1/namespaces/events-5770/pods/send-events-2a75d385-96a0-11e9-8bcb-526dc0a539dd,UID:2a7679b6-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16448,Generation:0,CreationTimestamp:2019-06-24 16:50:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 280954326,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-w7t6n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w7t6n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-w7t6n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002088d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002088d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:50:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:50:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:50:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-24 16:50:26 +0000 UTC  }],Message:,Reason:,HostIP:10.1.0.12,PodIP:10.251.128.5,StartTime:2019-06-24 16:50:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-06-24 16:50:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://21bf12b41730328a4260c1d56659dea29459e3cc7152a79fb3e57c459fdc8175}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jun 24 16:50:30.317: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun 24 16:50:32.321: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:50:32.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5770" for this suite.
Jun 24 16:51:10.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:51:10.442: INFO: namespace events-5770 deletion completed in 38.105572506s

• [SLOW TEST:44.196 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:51:10.443: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 24 16:51:10.489: INFO: Waiting up to 5m0s for pod "pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd" in namespace "emptydir-2490" to be "success or failure"
Jun 24 16:51:10.493: INFO: Pod "pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.654103ms
Jun 24 16:51:12.496: INFO: Pod "pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007562429s
STEP: Saw pod success
Jun 24 16:51:12.497: INFO: Pod "pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:51:12.500: INFO: Trying to get logs from node minion pod pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 16:51:12.526: INFO: Waiting for pod pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:51:12.530: INFO: Pod pod-44ce2fbc-96a0-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:51:12.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2490" for this suite.
Jun 24 16:51:18.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:51:18.633: INFO: namespace emptydir-2490 deletion completed in 6.091569828s

• [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:51:18.644: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 24 16:51:18.702: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16568,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 24 16:51:18.702: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16569,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 24 16:51:18.702: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16570,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 24 16:51:28.736: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16587,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 24 16:51:28.736: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16588,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun 24 16:51:28.736: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1447,SelfLink:/api/v1/namespaces/watch-1447/configmaps/e2e-watch-test-label-changed,UID:49b24783-96a0-11e9-b70d-fa163ef83c94,ResourceVersion:16589,Generation:0,CreationTimestamp:2019-06-24 16:51:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:51:28.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1447" for this suite.
Jun 24 16:51:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:51:34.838: INFO: namespace watch-1447 deletion completed in 6.09732638s

• [SLOW TEST:16.195 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:51:34.842: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 24 16:51:34.883: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 24 16:51:34.890: INFO: Waiting for terminating namespaces to be deleted...
Jun 24 16:51:34.895: INFO: 
Logging pods the kubelet thinks is on node minion before test
Jun 24 16:51:34.904: INFO: nodelocaldns-vmsgk from kube-system started at 2019-06-24 15:30:09 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container node-cache ready: true, restart count 0
Jun 24 16:51:34.904: INFO: nginx-proxy-minion from kube-system started at <nil> (0 container statuses recorded)
Jun 24 16:51:34.904: INFO: coredns-97c4b444f-9954l from kube-system started at 2019-06-24 15:30:06 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container coredns ready: true, restart count 0
Jun 24 16:51:34.904: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-24 15:31:39 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 24 16:51:34.904: INFO: weave-net-p4t4q from kube-system started at 2019-06-24 15:29:30 +0000 UTC (2 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container weave ready: true, restart count 0
Jun 24 16:51:34.904: INFO: 	Container weave-npc ready: true, restart count 0
Jun 24 16:51:34.904: INFO: kubernetes-dashboard-6c7466966c-v95zd from kube-system started at 2019-06-24 15:30:10 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 24 16:51:34.904: INFO: weave-scope-app-5bcb7f46b9-pv6gl from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container app ready: true, restart count 0
Jun 24 16:51:34.904: INFO: weave-scope-agent-mmtsr from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container agent ready: true, restart count 0
Jun 24 16:51:34.904: INFO: sonobuoy-systemd-logs-daemon-set-7e1461ca4731443f-8ql79 from heptio-sonobuoy started at 2019-06-24 15:31:43 +0000 UTC (2 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jun 24 16:51:34.904: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 24 16:51:34.904: INFO: kube-proxy-d8w54 from kube-system started at 2019-06-24 15:29:46 +0000 UTC (1 container statuses recorded)
Jun 24 16:51:34.904: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-549262e3-96a0-11e9-8bcb-526dc0a539dd 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-549262e3-96a0-11e9-8bcb-526dc0a539dd off the node minion
STEP: verifying the node doesn't have the label kubernetes.io/e2e-549262e3-96a0-11e9-8bcb-526dc0a539dd
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:51:38.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7924" for this suite.
Jun 24 16:52:07.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:52:07.103: INFO: namespace sched-pred-7924 deletion completed in 28.105378008s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:32.262 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:52:07.105: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:52:07.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1734" for this suite.
Jun 24 16:52:13.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:52:13.271: INFO: namespace kubelet-test-1734 deletion completed in 6.099178016s

• [SLOW TEST:6.166 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:52:13.272: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 24 16:54:55.375: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:54:55.382: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:54:57.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:54:57.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:54:59.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:54:59.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:01.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:01.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:03.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:03.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:05.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:05.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:07.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:07.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:09.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:09.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:11.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:11.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:13.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:13.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:15.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:15.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:17.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:17.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:19.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:19.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:21.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:21.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:23.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:23.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:25.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:25.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:27.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:27.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:29.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:29.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:31.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:31.390: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:33.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:33.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:35.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:35.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:37.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:37.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:39.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:39.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:41.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:41.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:43.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:43.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:45.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:45.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:47.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:47.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:49.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:49.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:51.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:51.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:53.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:53.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:55.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:55.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:57.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:57.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:55:59.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:55:59.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:01.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:01.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:03.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:03.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:05.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:05.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:07.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:07.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:09.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:09.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:11.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:11.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:13.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:13.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:15.383: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:15.389: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:17.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:17.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:19.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:19.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:21.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:21.385: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:23.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:23.386: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:25.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:25.391: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 24 16:56:27.382: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 24 16:56:27.386: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:56:27.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4101" for this suite.
Jun 24 16:56:49.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:56:49.498: INFO: namespace container-lifecycle-hook-4101 deletion completed in 22.107969393s

• [SLOW TEST:276.226 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:56:49.498: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Jun 24 16:56:49.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 api-versions'
Jun 24 16:56:49.657: INFO: stderr: ""
Jun 24 16:56:49.657: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:56:49.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4463" for this suite.
Jun 24 16:56:55.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:56:55.759: INFO: namespace kubectl-4463 deletion completed in 6.097441043s

• [SLOW TEST:6.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:56:55.759: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:56:57.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4017" for this suite.
Jun 24 16:57:35.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:57:35.923: INFO: namespace kubelet-test-4017 deletion completed in 38.102212095s

• [SLOW TEST:40.164 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:57:35.923: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2752
I0624 16:57:35.959550      20 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2752, replica count: 1
I0624 16:57:37.010361      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0624 16:57:38.010771      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 24 16:57:38.125: INFO: Created: latency-svc-mk2d6
Jun 24 16:57:38.134: INFO: Got endpoints: latency-svc-mk2d6 [23.808241ms]
Jun 24 16:57:38.151: INFO: Created: latency-svc-2dwjw
Jun 24 16:57:38.171: INFO: Got endpoints: latency-svc-2dwjw [36.167015ms]
Jun 24 16:57:38.172: INFO: Created: latency-svc-pgdfx
Jun 24 16:57:38.175: INFO: Got endpoints: latency-svc-pgdfx [40.71996ms]
Jun 24 16:57:38.184: INFO: Created: latency-svc-2bkpq
Jun 24 16:57:38.186: INFO: Got endpoints: latency-svc-2bkpq [51.229851ms]
Jun 24 16:57:38.196: INFO: Created: latency-svc-vkmsk
Jun 24 16:57:38.205: INFO: Got endpoints: latency-svc-vkmsk [69.609021ms]
Jun 24 16:57:38.212: INFO: Created: latency-svc-9vqxk
Jun 24 16:57:38.215: INFO: Got endpoints: latency-svc-9vqxk [79.68785ms]
Jun 24 16:57:38.222: INFO: Created: latency-svc-52wlg
Jun 24 16:57:38.226: INFO: Got endpoints: latency-svc-52wlg [90.479407ms]
Jun 24 16:57:38.235: INFO: Created: latency-svc-n8b47
Jun 24 16:57:38.249: INFO: Created: latency-svc-47xkd
Jun 24 16:57:38.249: INFO: Got endpoints: latency-svc-n8b47 [114.143197ms]
Jun 24 16:57:38.258: INFO: Got endpoints: latency-svc-47xkd [122.878474ms]
Jun 24 16:57:38.267: INFO: Created: latency-svc-6mnhn
Jun 24 16:57:38.287: INFO: Got endpoints: latency-svc-6mnhn [151.789464ms]
Jun 24 16:57:38.291: INFO: Created: latency-svc-qmrc5
Jun 24 16:57:38.294: INFO: Got endpoints: latency-svc-qmrc5 [158.102837ms]
Jun 24 16:57:38.303: INFO: Created: latency-svc-rnwsm
Jun 24 16:57:38.307: INFO: Got endpoints: latency-svc-rnwsm [171.683707ms]
Jun 24 16:57:38.315: INFO: Created: latency-svc-xgrkm
Jun 24 16:57:38.319: INFO: Got endpoints: latency-svc-xgrkm [183.018394ms]
Jun 24 16:57:38.328: INFO: Created: latency-svc-s6mkw
Jun 24 16:57:38.336: INFO: Got endpoints: latency-svc-s6mkw [200.913751ms]
Jun 24 16:57:38.336: INFO: Created: latency-svc-fq6l2
Jun 24 16:57:38.345: INFO: Created: latency-svc-bddg9
Jun 24 16:57:38.346: INFO: Got endpoints: latency-svc-fq6l2 [210.38973ms]
Jun 24 16:57:38.356: INFO: Got endpoints: latency-svc-bddg9 [220.316373ms]
Jun 24 16:57:38.357: INFO: Created: latency-svc-6mtc4
Jun 24 16:57:38.363: INFO: Got endpoints: latency-svc-6mtc4 [27.037222ms]
Jun 24 16:57:38.372: INFO: Created: latency-svc-8jfvm
Jun 24 16:57:38.376: INFO: Got endpoints: latency-svc-8jfvm [204.888362ms]
Jun 24 16:57:38.383: INFO: Created: latency-svc-4r7tb
Jun 24 16:57:38.405: INFO: Created: latency-svc-9wcmk
Jun 24 16:57:38.405: INFO: Got endpoints: latency-svc-4r7tb [230.101095ms]
Jun 24 16:57:38.411: INFO: Got endpoints: latency-svc-9wcmk [224.556333ms]
Jun 24 16:57:38.420: INFO: Created: latency-svc-8szrq
Jun 24 16:57:38.420: INFO: Got endpoints: latency-svc-8szrq [215.035527ms]
Jun 24 16:57:38.431: INFO: Created: latency-svc-qtfb2
Jun 24 16:57:38.438: INFO: Got endpoints: latency-svc-qtfb2 [223.483128ms]
Jun 24 16:57:38.438: INFO: Created: latency-svc-zkrng
Jun 24 16:57:38.449: INFO: Created: latency-svc-svhgb
Jun 24 16:57:38.449: INFO: Got endpoints: latency-svc-zkrng [223.014835ms]
Jun 24 16:57:38.455: INFO: Got endpoints: latency-svc-svhgb [205.287399ms]
Jun 24 16:57:38.465: INFO: Created: latency-svc-vlppg
Jun 24 16:57:38.469: INFO: Got endpoints: latency-svc-vlppg [210.973223ms]
Jun 24 16:57:38.476: INFO: Created: latency-svc-cx746
Jun 24 16:57:38.486: INFO: Got endpoints: latency-svc-cx746 [198.803246ms]
Jun 24 16:57:38.487: INFO: Created: latency-svc-89bc6
Jun 24 16:57:38.494: INFO: Got endpoints: latency-svc-89bc6 [200.524609ms]
Jun 24 16:57:38.496: INFO: Created: latency-svc-7bfpd
Jun 24 16:57:38.517: INFO: Got endpoints: latency-svc-7bfpd [210.044688ms]
Jun 24 16:57:38.519: INFO: Created: latency-svc-2q8m6
Jun 24 16:57:38.523: INFO: Got endpoints: latency-svc-2q8m6 [204.062494ms]
Jun 24 16:57:38.533: INFO: Created: latency-svc-468r7
Jun 24 16:57:38.537: INFO: Got endpoints: latency-svc-468r7 [190.861551ms]
Jun 24 16:57:38.546: INFO: Created: latency-svc-blcd6
Jun 24 16:57:38.549: INFO: Got endpoints: latency-svc-blcd6 [192.890102ms]
Jun 24 16:57:38.557: INFO: Created: latency-svc-xdnqz
Jun 24 16:57:38.566: INFO: Got endpoints: latency-svc-xdnqz [203.052252ms]
Jun 24 16:57:38.567: INFO: Created: latency-svc-g9jsb
Jun 24 16:57:38.577: INFO: Created: latency-svc-954zj
Jun 24 16:57:38.577: INFO: Got endpoints: latency-svc-g9jsb [201.57824ms]
Jun 24 16:57:38.584: INFO: Got endpoints: latency-svc-954zj [178.021778ms]
Jun 24 16:57:38.592: INFO: Created: latency-svc-bb42w
Jun 24 16:57:38.603: INFO: Got endpoints: latency-svc-bb42w [191.995643ms]
Jun 24 16:57:38.604: INFO: Created: latency-svc-xlc79
Jun 24 16:57:38.613: INFO: Got endpoints: latency-svc-xlc79 [193.55988ms]
Jun 24 16:57:38.613: INFO: Created: latency-svc-pbq77
Jun 24 16:57:38.616: INFO: Got endpoints: latency-svc-pbq77 [177.159957ms]
Jun 24 16:57:38.630: INFO: Created: latency-svc-drlw2
Jun 24 16:57:38.638: INFO: Got endpoints: latency-svc-drlw2 [188.737593ms]
Jun 24 16:57:38.639: INFO: Created: latency-svc-z8srx
Jun 24 16:57:38.650: INFO: Got endpoints: latency-svc-z8srx [195.118472ms]
Jun 24 16:57:38.663: INFO: Created: latency-svc-6q9vl
Jun 24 16:57:38.666: INFO: Got endpoints: latency-svc-6q9vl [197.30379ms]
Jun 24 16:57:38.673: INFO: Created: latency-svc-ch6p6
Jun 24 16:57:38.683: INFO: Created: latency-svc-bvmms
Jun 24 16:57:38.683: INFO: Got endpoints: latency-svc-ch6p6 [196.998771ms]
Jun 24 16:57:38.692: INFO: Created: latency-svc-pmpqn
Jun 24 16:57:38.702: INFO: Created: latency-svc-8c8zx
Jun 24 16:57:38.716: INFO: Created: latency-svc-hvgpb
Jun 24 16:57:38.729: INFO: Created: latency-svc-2wkqz
Jun 24 16:57:38.750: INFO: Created: latency-svc-fx2jx
Jun 24 16:57:38.751: INFO: Got endpoints: latency-svc-bvmms [256.554382ms]
Jun 24 16:57:38.763: INFO: Created: latency-svc-lc2s5
Jun 24 16:57:38.776: INFO: Created: latency-svc-trx7t
Jun 24 16:57:38.780: INFO: Got endpoints: latency-svc-pmpqn [262.504549ms]
Jun 24 16:57:38.789: INFO: Created: latency-svc-kttz9
Jun 24 16:57:38.800: INFO: Created: latency-svc-gf6hh
Jun 24 16:57:38.811: INFO: Created: latency-svc-rm5v4
Jun 24 16:57:38.822: INFO: Created: latency-svc-9tzv6
Jun 24 16:57:38.835: INFO: Got endpoints: latency-svc-8c8zx [312.723174ms]
Jun 24 16:57:38.836: INFO: Created: latency-svc-pst4q
Jun 24 16:57:38.847: INFO: Created: latency-svc-jbvn2
Jun 24 16:57:38.862: INFO: Created: latency-svc-mfg69
Jun 24 16:57:38.880: INFO: Created: latency-svc-j9q9c
Jun 24 16:57:38.880: INFO: Got endpoints: latency-svc-hvgpb [343.062503ms]
Jun 24 16:57:38.894: INFO: Created: latency-svc-g7szk
Jun 24 16:57:38.909: INFO: Created: latency-svc-2k222
Jun 24 16:57:38.918: INFO: Created: latency-svc-7krkx
Jun 24 16:57:38.929: INFO: Got endpoints: latency-svc-2wkqz [379.660147ms]
Jun 24 16:57:38.949: INFO: Created: latency-svc-r6fcs
Jun 24 16:57:38.980: INFO: Got endpoints: latency-svc-fx2jx [413.184654ms]
Jun 24 16:57:38.997: INFO: Created: latency-svc-g9l5h
Jun 24 16:57:39.029: INFO: Got endpoints: latency-svc-lc2s5 [451.172512ms]
Jun 24 16:57:39.042: INFO: Created: latency-svc-pgcll
Jun 24 16:57:39.080: INFO: Got endpoints: latency-svc-trx7t [496.41331ms]
Jun 24 16:57:39.094: INFO: Created: latency-svc-vj7b9
Jun 24 16:57:39.129: INFO: Got endpoints: latency-svc-kttz9 [526.212342ms]
Jun 24 16:57:39.150: INFO: Created: latency-svc-l9pzz
Jun 24 16:57:39.179: INFO: Got endpoints: latency-svc-gf6hh [565.867351ms]
Jun 24 16:57:39.201: INFO: Created: latency-svc-rvb72
Jun 24 16:57:39.229: INFO: Got endpoints: latency-svc-rm5v4 [613.046004ms]
Jun 24 16:57:39.242: INFO: Created: latency-svc-cr5xf
Jun 24 16:57:39.279: INFO: Got endpoints: latency-svc-9tzv6 [641.286082ms]
Jun 24 16:57:39.302: INFO: Created: latency-svc-d7zsp
Jun 24 16:57:39.329: INFO: Got endpoints: latency-svc-pst4q [679.038766ms]
Jun 24 16:57:39.348: INFO: Created: latency-svc-h2rjb
Jun 24 16:57:39.380: INFO: Got endpoints: latency-svc-jbvn2 [714.039867ms]
Jun 24 16:57:39.394: INFO: Created: latency-svc-scmkt
Jun 24 16:57:39.429: INFO: Got endpoints: latency-svc-mfg69 [746.069894ms]
Jun 24 16:57:39.443: INFO: Created: latency-svc-xmhsx
Jun 24 16:57:39.479: INFO: Got endpoints: latency-svc-j9q9c [727.420503ms]
Jun 24 16:57:39.495: INFO: Created: latency-svc-nx9zv
Jun 24 16:57:39.528: INFO: Got endpoints: latency-svc-g7szk [748.725054ms]
Jun 24 16:57:39.544: INFO: Created: latency-svc-chpgs
Jun 24 16:57:39.581: INFO: Got endpoints: latency-svc-2k222 [745.816206ms]
Jun 24 16:57:39.595: INFO: Created: latency-svc-bl4b7
Jun 24 16:57:39.637: INFO: Got endpoints: latency-svc-7krkx [756.778837ms]
Jun 24 16:57:39.650: INFO: Created: latency-svc-42xwg
Jun 24 16:57:39.679: INFO: Got endpoints: latency-svc-r6fcs [750.140357ms]
Jun 24 16:57:39.696: INFO: Created: latency-svc-nhxvb
Jun 24 16:57:39.729: INFO: Got endpoints: latency-svc-g9l5h [749.015552ms]
Jun 24 16:57:39.750: INFO: Created: latency-svc-gmh8s
Jun 24 16:57:39.781: INFO: Got endpoints: latency-svc-pgcll [751.883534ms]
Jun 24 16:57:39.797: INFO: Created: latency-svc-tgxgq
Jun 24 16:57:39.829: INFO: Got endpoints: latency-svc-vj7b9 [749.226226ms]
Jun 24 16:57:39.843: INFO: Created: latency-svc-8vss6
Jun 24 16:57:39.879: INFO: Got endpoints: latency-svc-l9pzz [750.270623ms]
Jun 24 16:57:39.894: INFO: Created: latency-svc-q7ps6
Jun 24 16:57:39.930: INFO: Got endpoints: latency-svc-rvb72 [750.253538ms]
Jun 24 16:57:39.943: INFO: Created: latency-svc-shgql
Jun 24 16:57:39.980: INFO: Got endpoints: latency-svc-cr5xf [750.850297ms]
Jun 24 16:57:39.993: INFO: Created: latency-svc-q8thr
Jun 24 16:57:40.029: INFO: Got endpoints: latency-svc-d7zsp [750.222736ms]
Jun 24 16:57:40.043: INFO: Created: latency-svc-n88pk
Jun 24 16:57:40.093: INFO: Got endpoints: latency-svc-h2rjb [763.91131ms]
Jun 24 16:57:40.109: INFO: Created: latency-svc-s6tb9
Jun 24 16:57:40.133: INFO: Got endpoints: latency-svc-scmkt [752.970215ms]
Jun 24 16:57:40.146: INFO: Created: latency-svc-qbbpj
Jun 24 16:57:40.180: INFO: Got endpoints: latency-svc-xmhsx [750.873297ms]
Jun 24 16:57:40.207: INFO: Created: latency-svc-fp2lp
Jun 24 16:57:40.229: INFO: Got endpoints: latency-svc-nx9zv [749.8353ms]
Jun 24 16:57:40.242: INFO: Created: latency-svc-swv6q
Jun 24 16:57:40.280: INFO: Got endpoints: latency-svc-chpgs [751.551937ms]
Jun 24 16:57:40.293: INFO: Created: latency-svc-4n24v
Jun 24 16:57:40.330: INFO: Got endpoints: latency-svc-bl4b7 [749.116889ms]
Jun 24 16:57:40.343: INFO: Created: latency-svc-sghdp
Jun 24 16:57:40.379: INFO: Got endpoints: latency-svc-42xwg [742.49679ms]
Jun 24 16:57:40.393: INFO: Created: latency-svc-sp5j9
Jun 24 16:57:40.432: INFO: Got endpoints: latency-svc-nhxvb [752.930575ms]
Jun 24 16:57:40.453: INFO: Created: latency-svc-bl8k9
Jun 24 16:57:40.480: INFO: Got endpoints: latency-svc-gmh8s [750.676315ms]
Jun 24 16:57:40.491: INFO: Created: latency-svc-9f99n
Jun 24 16:57:40.529: INFO: Got endpoints: latency-svc-tgxgq [748.314298ms]
Jun 24 16:57:40.553: INFO: Created: latency-svc-v72dg
Jun 24 16:57:40.580: INFO: Got endpoints: latency-svc-8vss6 [750.751627ms]
Jun 24 16:57:40.595: INFO: Created: latency-svc-s76xs
Jun 24 16:57:40.630: INFO: Got endpoints: latency-svc-q7ps6 [750.029382ms]
Jun 24 16:57:40.642: INFO: Created: latency-svc-77cx7
Jun 24 16:57:40.679: INFO: Got endpoints: latency-svc-shgql [749.229188ms]
Jun 24 16:57:40.695: INFO: Created: latency-svc-hrzvz
Jun 24 16:57:40.729: INFO: Got endpoints: latency-svc-q8thr [749.722621ms]
Jun 24 16:57:40.744: INFO: Created: latency-svc-tvqjg
Jun 24 16:57:40.779: INFO: Got endpoints: latency-svc-n88pk [749.348425ms]
Jun 24 16:57:40.796: INFO: Created: latency-svc-wshlj
Jun 24 16:57:40.829: INFO: Got endpoints: latency-svc-s6tb9 [736.281292ms]
Jun 24 16:57:40.842: INFO: Created: latency-svc-gwj68
Jun 24 16:57:40.879: INFO: Got endpoints: latency-svc-qbbpj [745.620729ms]
Jun 24 16:57:40.893: INFO: Created: latency-svc-8kc26
Jun 24 16:57:40.929: INFO: Got endpoints: latency-svc-fp2lp [749.010046ms]
Jun 24 16:57:40.945: INFO: Created: latency-svc-cr45l
Jun 24 16:57:40.987: INFO: Got endpoints: latency-svc-swv6q [757.582475ms]
Jun 24 16:57:41.000: INFO: Created: latency-svc-rt4lm
Jun 24 16:57:41.029: INFO: Got endpoints: latency-svc-4n24v [748.942502ms]
Jun 24 16:57:41.041: INFO: Created: latency-svc-kvsp5
Jun 24 16:57:41.080: INFO: Got endpoints: latency-svc-sghdp [749.120621ms]
Jun 24 16:57:41.108: INFO: Created: latency-svc-4jfd2
Jun 24 16:57:41.131: INFO: Got endpoints: latency-svc-sp5j9 [751.806126ms]
Jun 24 16:57:41.144: INFO: Created: latency-svc-jx6c2
Jun 24 16:57:41.179: INFO: Got endpoints: latency-svc-bl8k9 [747.019481ms]
Jun 24 16:57:41.195: INFO: Created: latency-svc-kdptp
Jun 24 16:57:41.229: INFO: Got endpoints: latency-svc-9f99n [749.186715ms]
Jun 24 16:57:41.245: INFO: Created: latency-svc-94zwf
Jun 24 16:57:41.280: INFO: Got endpoints: latency-svc-v72dg [750.671725ms]
Jun 24 16:57:41.292: INFO: Created: latency-svc-zzrth
Jun 24 16:57:41.329: INFO: Got endpoints: latency-svc-s76xs [749.149287ms]
Jun 24 16:57:41.343: INFO: Created: latency-svc-52f8z
Jun 24 16:57:41.379: INFO: Got endpoints: latency-svc-77cx7 [748.932841ms]
Jun 24 16:57:41.396: INFO: Created: latency-svc-285cr
Jun 24 16:57:41.430: INFO: Got endpoints: latency-svc-hrzvz [750.632043ms]
Jun 24 16:57:41.443: INFO: Created: latency-svc-ngwpx
Jun 24 16:57:41.480: INFO: Got endpoints: latency-svc-tvqjg [750.105102ms]
Jun 24 16:57:41.492: INFO: Created: latency-svc-dw9w5
Jun 24 16:57:41.529: INFO: Got endpoints: latency-svc-wshlj [750.065484ms]
Jun 24 16:57:41.549: INFO: Created: latency-svc-dzjf5
Jun 24 16:57:41.579: INFO: Got endpoints: latency-svc-gwj68 [750.091557ms]
Jun 24 16:57:41.593: INFO: Created: latency-svc-nlcr9
Jun 24 16:57:41.629: INFO: Got endpoints: latency-svc-8kc26 [749.5169ms]
Jun 24 16:57:41.656: INFO: Created: latency-svc-k58nd
Jun 24 16:57:41.679: INFO: Got endpoints: latency-svc-cr45l [750.099475ms]
Jun 24 16:57:41.694: INFO: Created: latency-svc-ftlcw
Jun 24 16:57:41.729: INFO: Got endpoints: latency-svc-rt4lm [742.149023ms]
Jun 24 16:57:41.743: INFO: Created: latency-svc-2m2g2
Jun 24 16:57:41.779: INFO: Got endpoints: latency-svc-kvsp5 [749.676379ms]
Jun 24 16:57:41.792: INFO: Created: latency-svc-s4clv
Jun 24 16:57:41.828: INFO: Got endpoints: latency-svc-4jfd2 [748.694032ms]
Jun 24 16:57:41.841: INFO: Created: latency-svc-hzxxg
Jun 24 16:57:41.880: INFO: Got endpoints: latency-svc-jx6c2 [748.131734ms]
Jun 24 16:57:41.892: INFO: Created: latency-svc-xzhbc
Jun 24 16:57:41.929: INFO: Got endpoints: latency-svc-kdptp [749.768798ms]
Jun 24 16:57:41.943: INFO: Created: latency-svc-qk6mk
Jun 24 16:57:41.986: INFO: Got endpoints: latency-svc-94zwf [757.305359ms]
Jun 24 16:57:41.998: INFO: Created: latency-svc-4n86w
Jun 24 16:57:42.029: INFO: Got endpoints: latency-svc-zzrth [749.708045ms]
Jun 24 16:57:42.043: INFO: Created: latency-svc-jtjsc
Jun 24 16:57:42.081: INFO: Got endpoints: latency-svc-52f8z [751.126508ms]
Jun 24 16:57:42.103: INFO: Created: latency-svc-vffth
Jun 24 16:57:42.130: INFO: Got endpoints: latency-svc-285cr [751.12371ms]
Jun 24 16:57:42.142: INFO: Created: latency-svc-vtmbw
Jun 24 16:57:42.179: INFO: Got endpoints: latency-svc-ngwpx [749.771161ms]
Jun 24 16:57:42.193: INFO: Created: latency-svc-fnbk2
Jun 24 16:57:42.230: INFO: Got endpoints: latency-svc-dw9w5 [750.103575ms]
Jun 24 16:57:42.243: INFO: Created: latency-svc-9c6fc
Jun 24 16:57:42.279: INFO: Got endpoints: latency-svc-dzjf5 [750.412896ms]
Jun 24 16:57:42.292: INFO: Created: latency-svc-6bd5c
Jun 24 16:57:42.329: INFO: Got endpoints: latency-svc-nlcr9 [749.839669ms]
Jun 24 16:57:42.342: INFO: Created: latency-svc-vz7lt
Jun 24 16:57:42.380: INFO: Got endpoints: latency-svc-k58nd [750.426042ms]
Jun 24 16:57:42.392: INFO: Created: latency-svc-zrd49
Jun 24 16:57:42.437: INFO: Got endpoints: latency-svc-ftlcw [758.067853ms]
Jun 24 16:57:42.455: INFO: Created: latency-svc-s8vq2
Jun 24 16:57:42.479: INFO: Got endpoints: latency-svc-2m2g2 [750.200179ms]
Jun 24 16:57:42.492: INFO: Created: latency-svc-ktqnq
Jun 24 16:57:42.529: INFO: Got endpoints: latency-svc-s4clv [750.409649ms]
Jun 24 16:57:42.550: INFO: Created: latency-svc-pm9br
Jun 24 16:57:42.579: INFO: Got endpoints: latency-svc-hzxxg [750.883649ms]
Jun 24 16:57:42.596: INFO: Created: latency-svc-gzgbw
Jun 24 16:57:42.629: INFO: Got endpoints: latency-svc-xzhbc [749.459691ms]
Jun 24 16:57:42.642: INFO: Created: latency-svc-j95bv
Jun 24 16:57:42.679: INFO: Got endpoints: latency-svc-qk6mk [750.352013ms]
Jun 24 16:57:42.693: INFO: Created: latency-svc-mzwn2
Jun 24 16:57:42.729: INFO: Got endpoints: latency-svc-4n86w [743.098154ms]
Jun 24 16:57:42.746: INFO: Created: latency-svc-bsvcf
Jun 24 16:57:42.779: INFO: Got endpoints: latency-svc-jtjsc [749.229857ms]
Jun 24 16:57:42.794: INFO: Created: latency-svc-cpnf6
Jun 24 16:57:42.829: INFO: Got endpoints: latency-svc-vffth [748.466563ms]
Jun 24 16:57:42.846: INFO: Created: latency-svc-h6c6l
Jun 24 16:57:42.879: INFO: Got endpoints: latency-svc-vtmbw [748.720645ms]
Jun 24 16:57:42.896: INFO: Created: latency-svc-ffw8t
Jun 24 16:57:42.930: INFO: Got endpoints: latency-svc-fnbk2 [750.541098ms]
Jun 24 16:57:42.944: INFO: Created: latency-svc-x4kmr
Jun 24 16:57:42.989: INFO: Got endpoints: latency-svc-9c6fc [758.777454ms]
Jun 24 16:57:43.003: INFO: Created: latency-svc-8d8rr
Jun 24 16:57:43.031: INFO: Got endpoints: latency-svc-6bd5c [751.439771ms]
Jun 24 16:57:43.044: INFO: Created: latency-svc-cnh4r
Jun 24 16:57:43.079: INFO: Got endpoints: latency-svc-vz7lt [749.903831ms]
Jun 24 16:57:43.100: INFO: Created: latency-svc-tphk8
Jun 24 16:57:43.129: INFO: Got endpoints: latency-svc-zrd49 [749.904335ms]
Jun 24 16:57:43.143: INFO: Created: latency-svc-7bvpl
Jun 24 16:57:43.179: INFO: Got endpoints: latency-svc-s8vq2 [741.951487ms]
Jun 24 16:57:43.193: INFO: Created: latency-svc-j74qw
Jun 24 16:57:43.228: INFO: Got endpoints: latency-svc-ktqnq [749.074002ms]
Jun 24 16:57:43.245: INFO: Created: latency-svc-2lk4l
Jun 24 16:57:43.279: INFO: Got endpoints: latency-svc-pm9br [749.726883ms]
Jun 24 16:57:43.298: INFO: Created: latency-svc-cs89s
Jun 24 16:57:43.331: INFO: Got endpoints: latency-svc-gzgbw [751.228794ms]
Jun 24 16:57:43.346: INFO: Created: latency-svc-dzlj2
Jun 24 16:57:43.379: INFO: Got endpoints: latency-svc-j95bv [749.678604ms]
Jun 24 16:57:43.397: INFO: Created: latency-svc-r5lww
Jun 24 16:57:43.429: INFO: Got endpoints: latency-svc-mzwn2 [749.252642ms]
Jun 24 16:57:43.450: INFO: Created: latency-svc-qkqmj
Jun 24 16:57:43.479: INFO: Got endpoints: latency-svc-bsvcf [750.016908ms]
Jun 24 16:57:43.493: INFO: Created: latency-svc-2xv55
Jun 24 16:57:43.528: INFO: Got endpoints: latency-svc-cpnf6 [749.600661ms]
Jun 24 16:57:43.553: INFO: Created: latency-svc-snvpg
Jun 24 16:57:43.580: INFO: Got endpoints: latency-svc-h6c6l [750.236466ms]
Jun 24 16:57:43.600: INFO: Created: latency-svc-5k7v5
Jun 24 16:57:43.630: INFO: Got endpoints: latency-svc-ffw8t [750.997699ms]
Jun 24 16:57:43.643: INFO: Created: latency-svc-w96fb
Jun 24 16:57:43.679: INFO: Got endpoints: latency-svc-x4kmr [748.989779ms]
Jun 24 16:57:43.694: INFO: Created: latency-svc-n2md7
Jun 24 16:57:43.729: INFO: Got endpoints: latency-svc-8d8rr [740.275446ms]
Jun 24 16:57:43.743: INFO: Created: latency-svc-fzbrl
Jun 24 16:57:43.779: INFO: Got endpoints: latency-svc-cnh4r [748.359243ms]
Jun 24 16:57:43.803: INFO: Created: latency-svc-zhvv8
Jun 24 16:57:43.829: INFO: Got endpoints: latency-svc-tphk8 [749.510903ms]
Jun 24 16:57:43.843: INFO: Created: latency-svc-pdnr6
Jun 24 16:57:43.888: INFO: Got endpoints: latency-svc-7bvpl [758.262435ms]
Jun 24 16:57:43.902: INFO: Created: latency-svc-xd7wx
Jun 24 16:57:43.929: INFO: Got endpoints: latency-svc-j74qw [749.554574ms]
Jun 24 16:57:43.950: INFO: Created: latency-svc-nt6hf
Jun 24 16:57:43.980: INFO: Got endpoints: latency-svc-2lk4l [751.487249ms]
Jun 24 16:57:44.007: INFO: Created: latency-svc-h95m8
Jun 24 16:57:44.030: INFO: Got endpoints: latency-svc-cs89s [750.645994ms]
Jun 24 16:57:44.042: INFO: Created: latency-svc-mhvrw
Jun 24 16:57:44.079: INFO: Got endpoints: latency-svc-dzlj2 [748.293365ms]
Jun 24 16:57:44.092: INFO: Created: latency-svc-gf7wz
Jun 24 16:57:44.130: INFO: Got endpoints: latency-svc-r5lww [751.275264ms]
Jun 24 16:57:44.143: INFO: Created: latency-svc-xqttr
Jun 24 16:57:44.180: INFO: Got endpoints: latency-svc-qkqmj [750.87391ms]
Jun 24 16:57:44.193: INFO: Created: latency-svc-dzc6m
Jun 24 16:57:44.232: INFO: Got endpoints: latency-svc-2xv55 [752.454319ms]
Jun 24 16:57:44.247: INFO: Created: latency-svc-5bnt7
Jun 24 16:57:44.279: INFO: Got endpoints: latency-svc-snvpg [750.774491ms]
Jun 24 16:57:44.297: INFO: Created: latency-svc-2kwj9
Jun 24 16:57:44.329: INFO: Got endpoints: latency-svc-5k7v5 [749.427617ms]
Jun 24 16:57:44.356: INFO: Created: latency-svc-m7snb
Jun 24 16:57:44.379: INFO: Got endpoints: latency-svc-w96fb [749.551917ms]
Jun 24 16:57:44.394: INFO: Created: latency-svc-x96bj
Jun 24 16:57:44.431: INFO: Got endpoints: latency-svc-n2md7 [751.11685ms]
Jun 24 16:57:44.459: INFO: Created: latency-svc-4b79s
Jun 24 16:57:44.479: INFO: Got endpoints: latency-svc-fzbrl [749.74582ms]
Jun 24 16:57:44.492: INFO: Created: latency-svc-nl25p
Jun 24 16:57:44.529: INFO: Got endpoints: latency-svc-zhvv8 [750.033539ms]
Jun 24 16:57:44.542: INFO: Created: latency-svc-9hd5s
Jun 24 16:57:44.579: INFO: Got endpoints: latency-svc-pdnr6 [749.877065ms]
Jun 24 16:57:44.592: INFO: Created: latency-svc-5vsng
Jun 24 16:57:44.630: INFO: Got endpoints: latency-svc-xd7wx [741.767387ms]
Jun 24 16:57:44.647: INFO: Created: latency-svc-hjwjv
Jun 24 16:57:44.684: INFO: Got endpoints: latency-svc-nt6hf [754.528312ms]
Jun 24 16:57:44.696: INFO: Created: latency-svc-hw92h
Jun 24 16:57:44.729: INFO: Got endpoints: latency-svc-h95m8 [749.114467ms]
Jun 24 16:57:44.752: INFO: Created: latency-svc-vpx6q
Jun 24 16:57:44.780: INFO: Got endpoints: latency-svc-mhvrw [749.676026ms]
Jun 24 16:57:44.812: INFO: Created: latency-svc-x2kvr
Jun 24 16:57:44.830: INFO: Got endpoints: latency-svc-gf7wz [750.769783ms]
Jun 24 16:57:44.849: INFO: Created: latency-svc-n9ng6
Jun 24 16:57:44.884: INFO: Got endpoints: latency-svc-xqttr [753.694126ms]
Jun 24 16:57:44.898: INFO: Created: latency-svc-c7fkn
Jun 24 16:57:44.928: INFO: Got endpoints: latency-svc-dzc6m [748.634053ms]
Jun 24 16:57:44.941: INFO: Created: latency-svc-l8d6h
Jun 24 16:57:44.979: INFO: Got endpoints: latency-svc-5bnt7 [747.109232ms]
Jun 24 16:57:44.992: INFO: Created: latency-svc-5v55z
Jun 24 16:57:45.029: INFO: Got endpoints: latency-svc-2kwj9 [749.858671ms]
Jun 24 16:57:45.053: INFO: Created: latency-svc-8qngg
Jun 24 16:57:45.080: INFO: Got endpoints: latency-svc-m7snb [750.375744ms]
Jun 24 16:57:45.098: INFO: Created: latency-svc-n562m
Jun 24 16:57:45.141: INFO: Got endpoints: latency-svc-x96bj [761.724743ms]
Jun 24 16:57:45.156: INFO: Created: latency-svc-2gkr9
Jun 24 16:57:45.180: INFO: Got endpoints: latency-svc-4b79s [749.34548ms]
Jun 24 16:57:45.193: INFO: Created: latency-svc-sdpgd
Jun 24 16:57:45.229: INFO: Got endpoints: latency-svc-nl25p [750.182557ms]
Jun 24 16:57:45.262: INFO: Created: latency-svc-zlhsd
Jun 24 16:57:45.279: INFO: Got endpoints: latency-svc-9hd5s [749.583535ms]
Jun 24 16:57:45.292: INFO: Created: latency-svc-cmhjf
Jun 24 16:57:45.330: INFO: Got endpoints: latency-svc-5vsng [750.647073ms]
Jun 24 16:57:45.345: INFO: Created: latency-svc-rjq4p
Jun 24 16:57:45.380: INFO: Got endpoints: latency-svc-hjwjv [749.896091ms]
Jun 24 16:57:45.392: INFO: Created: latency-svc-j92kg
Jun 24 16:57:45.429: INFO: Got endpoints: latency-svc-hw92h [745.720692ms]
Jun 24 16:57:45.452: INFO: Created: latency-svc-dcls4
Jun 24 16:57:45.501: INFO: Got endpoints: latency-svc-vpx6q [772.026806ms]
Jun 24 16:57:45.514: INFO: Created: latency-svc-jjbh6
Jun 24 16:57:45.529: INFO: Got endpoints: latency-svc-x2kvr [749.384647ms]
Jun 24 16:57:45.543: INFO: Created: latency-svc-75g82
Jun 24 16:57:45.580: INFO: Got endpoints: latency-svc-n9ng6 [749.705375ms]
Jun 24 16:57:45.596: INFO: Created: latency-svc-dz7rg
Jun 24 16:57:45.629: INFO: Got endpoints: latency-svc-c7fkn [744.921014ms]
Jun 24 16:57:45.647: INFO: Created: latency-svc-86nd9
Jun 24 16:57:45.679: INFO: Got endpoints: latency-svc-l8d6h [750.748403ms]
Jun 24 16:57:45.699: INFO: Created: latency-svc-mvnwt
Jun 24 16:57:45.737: INFO: Got endpoints: latency-svc-5v55z [757.576531ms]
Jun 24 16:57:45.755: INFO: Created: latency-svc-qzdbm
Jun 24 16:57:45.779: INFO: Got endpoints: latency-svc-8qngg [749.991848ms]
Jun 24 16:57:45.794: INFO: Created: latency-svc-9t8wg
Jun 24 16:57:45.830: INFO: Got endpoints: latency-svc-n562m [749.957333ms]
Jun 24 16:57:45.855: INFO: Created: latency-svc-frm24
Jun 24 16:57:45.879: INFO: Got endpoints: latency-svc-2gkr9 [737.363721ms]
Jun 24 16:57:45.900: INFO: Created: latency-svc-qlffp
Jun 24 16:57:45.929: INFO: Got endpoints: latency-svc-sdpgd [748.562776ms]
Jun 24 16:57:45.942: INFO: Created: latency-svc-gtvrg
Jun 24 16:57:45.979: INFO: Got endpoints: latency-svc-zlhsd [749.958903ms]
Jun 24 16:57:46.029: INFO: Got endpoints: latency-svc-cmhjf [750.411965ms]
Jun 24 16:57:46.088: INFO: Got endpoints: latency-svc-rjq4p [758.05995ms]
Jun 24 16:57:46.129: INFO: Got endpoints: latency-svc-j92kg [749.845469ms]
Jun 24 16:57:46.180: INFO: Got endpoints: latency-svc-dcls4 [750.556829ms]
Jun 24 16:57:46.230: INFO: Got endpoints: latency-svc-jjbh6 [728.844338ms]
Jun 24 16:57:46.280: INFO: Got endpoints: latency-svc-75g82 [751.436441ms]
Jun 24 16:57:46.329: INFO: Got endpoints: latency-svc-dz7rg [749.200796ms]
Jun 24 16:57:46.380: INFO: Got endpoints: latency-svc-86nd9 [750.722119ms]
Jun 24 16:57:46.429: INFO: Got endpoints: latency-svc-mvnwt [750.20386ms]
Jun 24 16:57:46.480: INFO: Got endpoints: latency-svc-qzdbm [743.103265ms]
Jun 24 16:57:46.530: INFO: Got endpoints: latency-svc-9t8wg [750.770515ms]
Jun 24 16:57:46.579: INFO: Got endpoints: latency-svc-frm24 [749.304703ms]
Jun 24 16:57:46.630: INFO: Got endpoints: latency-svc-qlffp [751.681845ms]
Jun 24 16:57:46.679: INFO: Got endpoints: latency-svc-gtvrg [750.56611ms]
Jun 24 16:57:46.681: INFO: Latencies: [27.037222ms 36.167015ms 40.71996ms 51.229851ms 69.609021ms 79.68785ms 90.479407ms 114.143197ms 122.878474ms 151.789464ms 158.102837ms 171.683707ms 177.159957ms 178.021778ms 183.018394ms 188.737593ms 190.861551ms 191.995643ms 192.890102ms 193.55988ms 195.118472ms 196.998771ms 197.30379ms 198.803246ms 200.524609ms 200.913751ms 201.57824ms 203.052252ms 204.062494ms 204.888362ms 205.287399ms 210.044688ms 210.38973ms 210.973223ms 215.035527ms 220.316373ms 223.014835ms 223.483128ms 224.556333ms 230.101095ms 256.554382ms 262.504549ms 312.723174ms 343.062503ms 379.660147ms 413.184654ms 451.172512ms 496.41331ms 526.212342ms 565.867351ms 613.046004ms 641.286082ms 679.038766ms 714.039867ms 727.420503ms 728.844338ms 736.281292ms 737.363721ms 740.275446ms 741.767387ms 741.951487ms 742.149023ms 742.49679ms 743.098154ms 743.103265ms 744.921014ms 745.620729ms 745.720692ms 745.816206ms 746.069894ms 747.019481ms 747.109232ms 748.131734ms 748.293365ms 748.314298ms 748.359243ms 748.466563ms 748.562776ms 748.634053ms 748.694032ms 748.720645ms 748.725054ms 748.932841ms 748.942502ms 748.989779ms 749.010046ms 749.015552ms 749.074002ms 749.114467ms 749.116889ms 749.120621ms 749.149287ms 749.186715ms 749.200796ms 749.226226ms 749.229188ms 749.229857ms 749.252642ms 749.304703ms 749.34548ms 749.348425ms 749.384647ms 749.427617ms 749.459691ms 749.510903ms 749.5169ms 749.551917ms 749.554574ms 749.583535ms 749.600661ms 749.676026ms 749.676379ms 749.678604ms 749.705375ms 749.708045ms 749.722621ms 749.726883ms 749.74582ms 749.768798ms 749.771161ms 749.8353ms 749.839669ms 749.845469ms 749.858671ms 749.877065ms 749.896091ms 749.903831ms 749.904335ms 749.957333ms 749.958903ms 749.991848ms 750.016908ms 750.029382ms 750.033539ms 750.065484ms 750.091557ms 750.099475ms 750.103575ms 750.105102ms 750.140357ms 750.182557ms 750.200179ms 750.20386ms 750.222736ms 750.236466ms 750.253538ms 750.270623ms 750.352013ms 750.375744ms 750.409649ms 750.411965ms 750.412896ms 750.426042ms 750.541098ms 750.556829ms 750.56611ms 750.632043ms 750.645994ms 750.647073ms 750.671725ms 750.676315ms 750.722119ms 750.748403ms 750.751627ms 750.769783ms 750.770515ms 750.774491ms 750.850297ms 750.873297ms 750.87391ms 750.883649ms 750.997699ms 751.11685ms 751.12371ms 751.126508ms 751.228794ms 751.275264ms 751.436441ms 751.439771ms 751.487249ms 751.551937ms 751.681845ms 751.806126ms 751.883534ms 752.454319ms 752.930575ms 752.970215ms 753.694126ms 754.528312ms 756.778837ms 757.305359ms 757.576531ms 757.582475ms 758.05995ms 758.067853ms 758.262435ms 758.777454ms 761.724743ms 763.91131ms 772.026806ms]
Jun 24 16:57:46.681: INFO: 50 %ile: 749.348425ms
Jun 24 16:57:46.682: INFO: 90 %ile: 751.551937ms
Jun 24 16:57:46.682: INFO: 99 %ile: 763.91131ms
Jun 24 16:57:46.682: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:57:46.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2752" for this suite.
Jun 24 16:58:00.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:58:00.778: INFO: namespace svc-latency-2752 deletion completed in 14.0921989s

• [SLOW TEST:24.855 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:58:00.778: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jun 24 16:58:00.815: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:58:05.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-814" for this suite.
Jun 24 16:58:11.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:58:11.338: INFO: namespace init-container-814 deletion completed in 6.107514538s

• [SLOW TEST:10.560 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:58:11.338: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Jun 24 16:58:13.926: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3030 pod-service-account-3ffd2768-96a1-11e9-8bcb-526dc0a539dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jun 24 16:58:14.191: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3030 pod-service-account-3ffd2768-96a1-11e9-8bcb-526dc0a539dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jun 24 16:58:14.447: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3030 pod-service-account-3ffd2768-96a1-11e9-8bcb-526dc0a539dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:58:14.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3030" for this suite.
Jun 24 16:58:20.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:58:20.821: INFO: namespace svcaccounts-3030 deletion completed in 6.103401274s

• [SLOW TEST:9.483 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:58:20.822: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 24 16:58:26.940: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:26.944: INFO: Pod pod-with-poststart-http-hook still exists
Jun 24 16:58:28.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:28.949: INFO: Pod pod-with-poststart-http-hook still exists
Jun 24 16:58:30.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:30.949: INFO: Pod pod-with-poststart-http-hook still exists
Jun 24 16:58:32.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:32.948: INFO: Pod pod-with-poststart-http-hook still exists
Jun 24 16:58:34.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:34.950: INFO: Pod pod-with-poststart-http-hook still exists
Jun 24 16:58:36.945: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 24 16:58:36.948: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:58:36.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8508" for this suite.
Jun 24 16:58:58.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:58:59.055: INFO: namespace container-lifecycle-hook-8508 deletion completed in 22.102036773s

• [SLOW TEST:38.233 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:58:59.056: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 16:59:01.149: INFO: Waiting up to 5m0s for pod "client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd" in namespace "pods-5372" to be "success or failure"
Jun 24 16:59:01.154: INFO: Pod "client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.703563ms
Jun 24 16:59:03.158: INFO: Pod "client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009554915s
STEP: Saw pod success
Jun 24 16:59:03.158: INFO: Pod "client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:59:03.162: INFO: Trying to get logs from node minion pod client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd container env3cont: <nil>
STEP: delete the pod
Jun 24 16:59:03.182: INFO: Waiting for pod client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:59:03.188: INFO: Pod client-envvars-5d567d36-96a1-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:59:03.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5372" for this suite.
Jun 24 16:59:49.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:59:49.293: INFO: namespace pods-5372 deletion completed in 46.095106244s

• [SLOW TEST:50.237 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:59:49.293: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 16:59:49.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd" in namespace "downward-api-584" to be "success or failure"
Jun 24 16:59:49.347: INFO: Pod "downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744816ms
Jun 24 16:59:51.353: INFO: Pod "downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009249408s
STEP: Saw pod success
Jun 24 16:59:51.353: INFO: Pod "downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 16:59:51.356: INFO: Trying to get logs from node minion pod downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 16:59:51.378: INFO: Waiting for pod downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd to disappear
Jun 24 16:59:51.381: INFO: Pod downwardapi-volume-7a0fb947-96a1-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 16:59:51.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-584" for this suite.
Jun 24 16:59:57.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 16:59:57.483: INFO: namespace downward-api-584 deletion completed in 6.09824452s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 16:59:57.485: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1810
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jun 24 16:59:57.530: INFO: Found 0 stateful pods, waiting for 3
Jun 24 17:00:07.535: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 17:00:07.535: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 17:00:07.535: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 17:00:07.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1810 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:00:07.875: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:00:07.875: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:00:07.875: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 24 17:00:17.909: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 24 17:00:27.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1810 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:00:28.208: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 17:00:28.208: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 17:00:28.208: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 17:00:38.230: INFO: Waiting for StatefulSet statefulset-1810/ss2 to complete update
Jun 24 17:00:38.230: INFO: Waiting for Pod statefulset-1810/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 24 17:00:48.239: INFO: Waiting for StatefulSet statefulset-1810/ss2 to complete update
STEP: Rolling back to a previous revision
Jun 24 17:00:58.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1810 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:00:58.512: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:00:58.512: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:00:58.512: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 17:01:08.546: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 24 17:01:18.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1810 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:01:18.839: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 17:01:18.839: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 17:01:18.839: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 17:01:18.863: INFO: Waiting for StatefulSet statefulset-1810/ss2 to complete update
Jun 24 17:01:18.863: INFO: Waiting for Pod statefulset-1810/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 24 17:01:18.863: INFO: Waiting for Pod statefulset-1810/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 24 17:01:18.863: INFO: Waiting for Pod statefulset-1810/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 24 17:01:28.871: INFO: Waiting for StatefulSet statefulset-1810/ss2 to complete update
Jun 24 17:01:28.871: INFO: Waiting for Pod statefulset-1810/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 24 17:01:28.871: INFO: Waiting for Pod statefulset-1810/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 24 17:01:38.872: INFO: Deleting all statefulset in ns statefulset-1810
Jun 24 17:01:38.875: INFO: Scaling statefulset ss2 to 0
Jun 24 17:01:58.890: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 17:01:58.894: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:01:58.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1810" for this suite.
Jun 24 17:02:04.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:02:05.011: INFO: namespace statefulset-1810 deletion completed in 6.101060136s

• [SLOW TEST:127.526 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:02:05.012: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 17:02:05.067: INFO: (0) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.630649ms)
Jun 24 17:02:05.072: INFO: (1) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.546897ms)
Jun 24 17:02:05.077: INFO: (2) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.491235ms)
Jun 24 17:02:05.081: INFO: (3) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.69942ms)
Jun 24 17:02:05.086: INFO: (4) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.297904ms)
Jun 24 17:02:05.090: INFO: (5) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.312217ms)
Jun 24 17:02:05.095: INFO: (6) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.655956ms)
Jun 24 17:02:05.100: INFO: (7) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.464892ms)
Jun 24 17:02:05.105: INFO: (8) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.761172ms)
Jun 24 17:02:05.110: INFO: (9) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.325749ms)
Jun 24 17:02:05.117: INFO: (10) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.539258ms)
Jun 24 17:02:05.121: INFO: (11) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.362518ms)
Jun 24 17:02:05.126: INFO: (12) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.593372ms)
Jun 24 17:02:05.131: INFO: (13) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.020507ms)
Jun 24 17:02:05.136: INFO: (14) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.753851ms)
Jun 24 17:02:05.140: INFO: (15) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.589737ms)
Jun 24 17:02:05.145: INFO: (16) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.340187ms)
Jun 24 17:02:05.149: INFO: (17) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.288731ms)
Jun 24 17:02:05.157: INFO: (18) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.938416ms)
Jun 24 17:02:05.162: INFO: (19) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.666672ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:02:05.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3301" for this suite.
Jun 24 17:02:11.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:02:11.271: INFO: namespace proxy-3301 deletion completed in 6.105588289s

• [SLOW TEST:6.260 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:02:11.274: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Jun 24 17:02:11.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-2124'
Jun 24 17:02:12.106: INFO: stderr: ""
Jun 24 17:02:12.106: INFO: stdout: "pod/pause created\n"
Jun 24 17:02:12.106: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun 24 17:02:12.106: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2124" to be "running and ready"
Jun 24 17:02:12.110: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063379ms
Jun 24 17:02:14.114: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008031159s
Jun 24 17:02:16.118: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.011784712s
Jun 24 17:02:16.118: INFO: Pod "pause" satisfied condition "running and ready"
Jun 24 17:02:16.118: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Jun 24 17:02:16.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 label pods pause testing-label=testing-label-value --namespace=kubectl-2124'
Jun 24 17:02:16.218: INFO: stderr: ""
Jun 24 17:02:16.218: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun 24 17:02:16.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pod pause -L testing-label --namespace=kubectl-2124'
Jun 24 17:02:16.308: INFO: stderr: ""
Jun 24 17:02:16.308: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun 24 17:02:16.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 label pods pause testing-label- --namespace=kubectl-2124'
Jun 24 17:02:16.421: INFO: stderr: ""
Jun 24 17:02:16.421: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun 24 17:02:16.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pod pause -L testing-label --namespace=kubectl-2124'
Jun 24 17:02:16.518: INFO: stderr: ""
Jun 24 17:02:16.518: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Jun 24 17:02:16.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 delete --grace-period=0 --force -f - --namespace=kubectl-2124'
Jun 24 17:02:16.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 24 17:02:16.635: INFO: stdout: "pod \"pause\" force deleted\n"
Jun 24 17:02:16.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get rc,svc -l name=pause --no-headers --namespace=kubectl-2124'
Jun 24 17:02:16.737: INFO: stderr: "No resources found.\n"
Jun 24 17:02:16.737: INFO: stdout: ""
Jun 24 17:02:16.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 get pods -l name=pause --namespace=kubectl-2124 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 24 17:02:16.831: INFO: stderr: ""
Jun 24 17:02:16.831: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:02:16.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2124" for this suite.
Jun 24 17:02:22.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:02:22.933: INFO: namespace kubectl-2124 deletion completed in 6.098098949s

• [SLOW TEST:11.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:02:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:02:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7374" for this suite.
Jun 24 17:02:53.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:02:53.156: INFO: namespace namespaces-7374 deletion completed in 6.09703579s
STEP: Destroying namespace "nsdeletetest-3737" for this suite.
Jun 24 17:02:53.159: INFO: Namespace nsdeletetest-3737 was already deleted
STEP: Destroying namespace "nsdeletetest-2753" for this suite.
Jun 24 17:02:59.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:02:59.256: INFO: namespace nsdeletetest-2753 deletion completed in 6.097704368s

• [SLOW TEST:36.323 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:02:59.257: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 24 17:02:59.296: INFO: Waiting up to 5m0s for pod "pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd" in namespace "emptydir-6349" to be "success or failure"
Jun 24 17:02:59.299: INFO: Pod "pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.902033ms
Jun 24 17:03:01.303: INFO: Pod "pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00699444s
Jun 24 17:03:03.307: INFO: Pod "pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011131624s
STEP: Saw pod success
Jun 24 17:03:03.307: INFO: Pod "pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 17:03:03.311: INFO: Trying to get logs from node minion pod pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd container test-container: <nil>
STEP: delete the pod
Jun 24 17:03:03.353: INFO: Waiting for pod pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd to disappear
Jun 24 17:03:03.357: INFO: Pod pod-eb49dbb7-96a1-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:03:03.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6349" for this suite.
Jun 24 17:03:09.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:03:09.452: INFO: namespace emptydir-6349 deletion completed in 6.090261978s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:03:09.452: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jun 24 17:03:14.030: INFO: Successfully updated pod "annotationupdatef15e27be-96a1-11e9-8bcb-526dc0a539dd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:03:16.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1893" for this suite.
Jun 24 17:03:38.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:03:38.162: INFO: namespace projected-1893 deletion completed in 22.095989045s

• [SLOW TEST:28.709 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:03:38.163: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jun 24 17:03:38.211: INFO: Conformance test suite needs a cluster with at least 2 nodes.
Jun 24 17:03:38.211: INFO: Create a RollingUpdate DaemonSet
Jun 24 17:03:38.215: INFO: Check that daemon pods launch on every node of the cluster
Jun 24 17:03:38.219: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:38.222: INFO: Number of nodes with available pods: 0
Jun 24 17:03:38.223: INFO: Node minion is running more than one daemon pod
Jun 24 17:03:39.228: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:39.234: INFO: Number of nodes with available pods: 0
Jun 24 17:03:39.234: INFO: Node minion is running more than one daemon pod
Jun 24 17:03:40.228: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:40.232: INFO: Number of nodes with available pods: 0
Jun 24 17:03:40.232: INFO: Node minion is running more than one daemon pod
Jun 24 17:03:41.227: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:41.230: INFO: Number of nodes with available pods: 1
Jun 24 17:03:41.230: INFO: Number of running nodes: 1, number of available pods: 1
Jun 24 17:03:41.230: INFO: Update the DaemonSet to trigger a rollout
Jun 24 17:03:41.239: INFO: Updating DaemonSet daemon-set
Jun 24 17:03:47.266: INFO: Roll back the DaemonSet before rollout is complete
Jun 24 17:03:47.274: INFO: Updating DaemonSet daemon-set
Jun 24 17:03:47.274: INFO: Make sure DaemonSet rollback is complete
Jun 24 17:03:47.290: INFO: Wrong image for pod: daemon-set-b6m2n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jun 24 17:03:47.290: INFO: Pod daemon-set-b6m2n is not available
Jun 24 17:03:47.299: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:48.303: INFO: Wrong image for pod: daemon-set-b6m2n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jun 24 17:03:48.303: INFO: Pod daemon-set-b6m2n is not available
Jun 24 17:03:48.310: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:49.305: INFO: Wrong image for pod: daemon-set-b6m2n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jun 24 17:03:49.305: INFO: Pod daemon-set-b6m2n is not available
Jun 24 17:03:49.309: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 24 17:03:50.304: INFO: Pod daemon-set-4dxgh is not available
Jun 24 17:03:50.307: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1557, will wait for the garbage collector to delete the pods
Jun 24 17:03:50.374: INFO: Deleting DaemonSet.extensions daemon-set took: 6.509641ms
Jun 24 17:03:50.674: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.292681ms
Jun 24 17:03:54.877: INFO: Number of nodes with available pods: 0
Jun 24 17:03:54.877: INFO: Number of running nodes: 0, number of available pods: 0
Jun 24 17:03:54.880: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1557/daemonsets","resourceVersion":"19827"},"items":null}

Jun 24 17:03:54.883: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1557/pods","resourceVersion":"19827"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:03:54.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1557" for this suite.
Jun 24 17:04:00.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:04:00.996: INFO: namespace daemonsets-1557 deletion completed in 6.099682814s

• [SLOW TEST:22.833 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:04:00.998: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun 24 17:04:01.039: INFO: Pod name pod-release: Found 0 pods out of 1
Jun 24 17:04:06.043: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:04:07.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6991" for this suite.
Jun 24 17:04:13.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:04:13.178: INFO: namespace replication-controller-6991 deletion completed in 6.104178149s

• [SLOW TEST:12.181 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:04:13.179: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jun 24 17:04:13.230: INFO: Waiting up to 5m0s for pod "downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd" in namespace "projected-6480" to be "success or failure"
Jun 24 17:04:13.233: INFO: Pod "downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595442ms
Jun 24 17:04:15.237: INFO: Pod "downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006786779s
STEP: Saw pod success
Jun 24 17:04:15.237: INFO: Pod "downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 17:04:15.241: INFO: Trying to get logs from node minion pod downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd container client-container: <nil>
STEP: delete the pod
Jun 24 17:04:15.271: INFO: Waiting for pod downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd to disappear
Jun 24 17:04:15.275: INFO: Pod downwardapi-volume-175b70fc-96a2-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:04:15.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6480" for this suite.
Jun 24 17:04:21.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:04:21.378: INFO: namespace projected-6480 deletion completed in 6.09733561s

• [SLOW TEST:8.199 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:04:21.378: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 24 17:04:21.425: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 24 17:04:21.436: INFO: Waiting for terminating namespaces to be deleted...
Jun 24 17:04:21.438: INFO: 
Logging pods the kubelet thinks is on node minion before test
Jun 24 17:04:21.448: INFO: weave-net-p4t4q from kube-system started at 2019-06-24 15:29:30 +0000 UTC (2 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container weave ready: true, restart count 0
Jun 24 17:04:21.448: INFO: 	Container weave-npc ready: true, restart count 0
Jun 24 17:04:21.448: INFO: kubernetes-dashboard-6c7466966c-v95zd from kube-system started at 2019-06-24 15:30:10 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 24 17:04:21.448: INFO: weave-scope-app-5bcb7f46b9-pv6gl from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container app ready: true, restart count 0
Jun 24 17:04:21.448: INFO: weave-scope-agent-mmtsr from weave started at 2019-06-24 15:30:48 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container agent ready: true, restart count 0
Jun 24 17:04:21.448: INFO: sonobuoy-systemd-logs-daemon-set-7e1461ca4731443f-8ql79 from heptio-sonobuoy started at 2019-06-24 15:31:43 +0000 UTC (2 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jun 24 17:04:21.448: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 24 17:04:21.448: INFO: kube-proxy-d8w54 from kube-system started at 2019-06-24 15:29:46 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 24 17:04:21.448: INFO: nginx-proxy-minion from kube-system started at <nil> (0 container statuses recorded)
Jun 24 17:04:21.448: INFO: coredns-97c4b444f-9954l from kube-system started at 2019-06-24 15:30:06 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container coredns ready: true, restart count 0
Jun 24 17:04:21.448: INFO: nodelocaldns-vmsgk from kube-system started at 2019-06-24 15:30:09 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container node-cache ready: true, restart count 0
Jun 24 17:04:21.448: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-24 15:31:39 +0000 UTC (1 container statuses recorded)
Jun 24 17:04:21.448: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node minion
Jun 24 17:04:21.473: INFO: Pod sonobuoy requesting resource cpu=0m on Node minion
Jun 24 17:04:21.473: INFO: Pod sonobuoy-systemd-logs-daemon-set-7e1461ca4731443f-8ql79 requesting resource cpu=0m on Node minion
Jun 24 17:04:21.473: INFO: Pod coredns-97c4b444f-9954l requesting resource cpu=100m on Node minion
Jun 24 17:04:21.473: INFO: Pod kube-proxy-d8w54 requesting resource cpu=0m on Node minion
Jun 24 17:04:21.473: INFO: Pod kubernetes-dashboard-6c7466966c-v95zd requesting resource cpu=50m on Node minion
Jun 24 17:04:21.473: INFO: Pod nginx-proxy-minion requesting resource cpu=25m on Node minion
Jun 24 17:04:21.473: INFO: Pod nodelocaldns-vmsgk requesting resource cpu=100m on Node minion
Jun 24 17:04:21.473: INFO: Pod weave-net-p4t4q requesting resource cpu=20m on Node minion
Jun 24 17:04:21.473: INFO: Pod weave-scope-agent-mmtsr requesting resource cpu=0m on Node minion
Jun 24 17:04:21.473: INFO: Pod weave-scope-app-5bcb7f46b9-pv6gl requesting resource cpu=0m on Node minion
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd.15ab31436d939875], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2480/filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd to minion]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd.15ab3143a38390f7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd.15ab3143a8887283], Reason = [Created], Message = [Created container filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd.15ab3143b642b9af], Reason = [Started], Message = [Started container filler-pod-1c461c52-96a2-11e9-8bcb-526dc0a539dd]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15ab3143e5c13c73], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node minion
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:04:24.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2480" for this suite.
Jun 24 17:04:30.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:04:30.635: INFO: namespace sched-pred-2480 deletion completed in 6.108082831s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.257 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:04:30.635: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Jun 24 17:04:31.259: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 12
	[quantile=0.9] = 157
	[quantile=0.99] = 157
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 213684
	[quantile=0.9] = 221723
	[quantile=0.99] = 221723
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 8
	[quantile=0.99] = 40
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 14
	[quantile=0.9] = 28
	[quantile=0.99] = 74
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 36
	[quantile=0.99] = 48
For namespace_queue_latency_sum:
	[] = 10340
For namespace_queue_latency_count:
	[] = 536
For namespace_retries:
	[] = 546
For namespace_work_duration:
	[quantile=0.5] = 163838
	[quantile=0.9] = 258773
	[quantile=0.99] = 607269
For namespace_work_duration_sum:
	[] = 82014988
For namespace_work_duration_count:
	[] = 536
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:04:31.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1485" for this suite.
Jun 24 17:04:37.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:04:37.374: INFO: namespace gc-1485 deletion completed in 6.107839617s

• [SLOW TEST:6.739 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:04:37.374: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1449
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1449
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1449
Jun 24 17:04:37.435: INFO: Found 0 stateful pods, waiting for 1
Jun 24 17:04:47.439: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 24 17:04:47.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:04:47.723: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:04:47.723: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:04:47.723: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 17:04:47.727: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 24 17:04:57.732: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 17:04:57.732: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 17:04:57.746: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999566s
Jun 24 17:04:58.750: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996477703s
Jun 24 17:04:59.754: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992267118s
Jun 24 17:05:00.759: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988330921s
Jun 24 17:05:01.763: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983746866s
Jun 24 17:05:02.767: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979315919s
Jun 24 17:05:03.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974950754s
Jun 24 17:05:04.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970929397s
Jun 24 17:05:05.780: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966480488s
Jun 24 17:05:06.784: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.038237ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1449
Jun 24 17:05:07.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:08.051: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 17:05:08.051: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 17:05:08.051: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 17:05:08.057: INFO: Found 1 stateful pods, waiting for 3
Jun 24 17:05:18.061: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 17:05:18.061: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 24 17:05:18.061: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 24 17:05:18.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:05:18.342: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:05:18.343: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:05:18.343: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 17:05:18.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:05:18.622: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:05:18.622: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:05:18.622: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 17:05:18.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 24 17:05:18.902: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jun 24 17:05:18.902: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 24 17:05:18.902: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 24 17:05:18.902: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 17:05:18.905: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun 24 17:05:28.914: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 17:05:28.914: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 17:05:28.914: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 24 17:05:28.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999436s
Jun 24 17:05:29.937: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990973117s
Jun 24 17:05:30.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986214514s
Jun 24 17:05:31.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981357839s
Jun 24 17:05:32.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976598272s
Jun 24 17:05:33.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972006214s
Jun 24 17:05:34.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967174666s
Jun 24 17:05:35.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955382849s
Jun 24 17:05:36.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950359359s
Jun 24 17:05:37.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.471694ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1449
Jun 24 17:05:38.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:39.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 17:05:39.285: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 17:05:39.285: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 17:05:39.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:39.557: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jun 24 17:05:39.557: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 24 17:05:39.557: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 24 17:05:39.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:39.728: INFO: rc: 126
Jun 24 17:05:39.728: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> cannot exec in a stopped state: unknown
 command terminated with exit code 126
 [] <nil> 0xc001a21770 exit status 126 <nil> <nil> true [0xc000172af8 0xc000172be0 0xc000172d98] [0xc000172af8 0xc000172be0 0xc000172d98] [0xc000172b78 0xc000172d50] [0x9c00a0 0x9c00a0] 0xc002659920 <nil>}:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126

Jun 24 17:05:49.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:49.824: INFO: rc: 1
Jun 24 17:05:49.824: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ef4e70 exit status 1 <nil> <nil> true [0xc000010950 0xc0000109a8 0xc000010a88] [0xc000010950 0xc0000109a8 0xc000010a88] [0xc000010998 0xc000010a00] [0x9c00a0 0x9c00a0] 0xc0017344e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:05:59.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:05:59.919: INFO: rc: 1
Jun 24 17:05:59.919: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c311d0 exit status 1 <nil> <nil> true [0xc0015f4028 0xc0015f4040 0xc0015f4058] [0xc0015f4028 0xc0015f4040 0xc0015f4058] [0xc0015f4038 0xc0015f4050] [0x9c00a0 0x9c00a0] 0xc003418c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:06:09.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:06:10.014: INFO: rc: 1
Jun 24 17:06:10.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ef5200 exit status 1 <nil> <nil> true [0xc000010b00 0xc000010bb0 0xc000010c10] [0xc000010b00 0xc000010bb0 0xc000010c10] [0xc000010ba0 0xc000010bf0] [0x9c00a0 0x9c00a0] 0xc001734840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:06:20.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:06:20.128: INFO: rc: 1
Jun 24 17:06:20.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a21aa0 exit status 1 <nil> <nil> true [0xc000172e08 0xc000172f48 0xc000173108] [0xc000172e08 0xc000172f48 0xc000173108] [0xc000172e98 0xc000173078] [0x9c00a0 0x9c00a0] 0xc002659ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:06:30.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:06:30.221: INFO: rc: 1
Jun 24 17:06:30.222: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c31500 exit status 1 <nil> <nil> true [0xc0015f4060 0xc0015f4078 0xc0015f4090] [0xc0015f4060 0xc0015f4078 0xc0015f4090] [0xc0015f4070 0xc0015f4088] [0x9c00a0 0x9c00a0] 0xc003419320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:06:40.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:06:40.317: INFO: rc: 1
Jun 24 17:06:40.317: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a21fb0 exit status 1 <nil> <nil> true [0xc000173158 0xc0001732b8 0xc0001733a8] [0xc000173158 0xc0001732b8 0xc0001733a8] [0xc0001732a8 0xc000173318] [0x9c00a0 0x9c00a0] 0xc003232060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:06:50.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:06:50.409: INFO: rc: 1
Jun 24 17:06:50.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002664780 exit status 1 <nil> <nil> true [0xc001a8a028 0xc001a8a040 0xc001a8a058] [0xc001a8a028 0xc001a8a040 0xc001a8a058] [0xc001a8a038 0xc001a8a050] [0x9c00a0 0x9c00a0] 0xc00259e300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:00.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:00.500: INFO: rc: 1
Jun 24 17:07:00.500: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c31890 exit status 1 <nil> <nil> true [0xc0015f4098 0xc0015f40b0 0xc0015f40c8] [0xc0015f4098 0xc0015f40b0 0xc0015f40c8] [0xc0015f40a8 0xc0015f40c0] [0x9c00a0 0x9c00a0] 0xc0034199e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:10.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:10.591: INFO: rc: 1
Jun 24 17:07:10.591: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c31bf0 exit status 1 <nil> <nil> true [0xc0015f40d0 0xc0015f40e8 0xc0015f4100] [0xc0015f40d0 0xc0015f40e8 0xc0015f4100] [0xc0015f40e0 0xc0015f40f8] [0x9c00a0 0x9c00a0] 0xc0014ac0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:20.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:20.681: INFO: rc: 1
Jun 24 17:07:20.681: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002de2420 exit status 1 <nil> <nil> true [0xc0001733d0 0xc000173450 0xc000173530] [0xc0001733d0 0xc000173450 0xc000173530] [0xc0001733f8 0xc000173510] [0x9c00a0 0x9c00a0] 0xc003232480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:30.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:30.772: INFO: rc: 1
Jun 24 17:07:30.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c31f50 exit status 1 <nil> <nil> true [0xc0015f4108 0xc0015f4120 0xc0015f4138] [0xc0015f4108 0xc0015f4120 0xc0015f4138] [0xc0015f4118 0xc0015f4130] [0x9c00a0 0x9c00a0] 0xc0014ac660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:40.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:40.859: INFO: rc: 1
Jun 24 17:07:40.860: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a20300 exit status 1 <nil> <nil> true [0xc0015f4008 0xc0015f4020 0xc0015f4038] [0xc0015f4008 0xc0015f4020 0xc0015f4038] [0xc0015f4018 0xc0015f4030] [0x9c00a0 0x9c00a0] 0xc0034185a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:07:50.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:07:50.956: INFO: rc: 1
Jun 24 17:07:50.956: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c30300 exit status 1 <nil> <nil> true [0xc000172000 0xc000172148 0xc000172298] [0xc000172000 0xc000172148 0xc000172298] [0xc000172100 0xc000172240] [0x9c00a0 0x9c00a0] 0xc002658960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:00.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:01.051: INFO: rc: 1
Jun 24 17:08:01.052: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c30660 exit status 1 <nil> <nil> true [0xc000172370 0xc0001723e0 0xc000172ae8] [0xc000172370 0xc0001723e0 0xc000172ae8] [0xc000172390 0xc000172a98] [0x9c00a0 0x9c00a0] 0xc0026590e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:11.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:11.142: INFO: rc: 1
Jun 24 17:08:11.142: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c30990 exit status 1 <nil> <nil> true [0xc000172af8 0xc000172be0 0xc000172d98] [0xc000172af8 0xc000172be0 0xc000172d98] [0xc000172b78 0xc000172d50] [0x9c00a0 0x9c00a0] 0xc0026596e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:21.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:21.236: INFO: rc: 1
Jun 24 17:08:21.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c30cf0 exit status 1 <nil> <nil> true [0xc000172e08 0xc000172f48 0xc000173108] [0xc000172e08 0xc000172f48 0xc000173108] [0xc000172e98 0xc000173078] [0x9c00a0 0x9c00a0] 0xc002659aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:31.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:31.324: INFO: rc: 1
Jun 24 17:08:31.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a20660 exit status 1 <nil> <nil> true [0xc0015f4040 0xc0015f4058 0xc0015f4070] [0xc0015f4040 0xc0015f4058 0xc0015f4070] [0xc0015f4050 0xc0015f4068] [0x9c00a0 0x9c00a0] 0xc003418c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:41.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:41.414: INFO: rc: 1
Jun 24 17:08:41.414: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c31080 exit status 1 <nil> <nil> true [0xc000173158 0xc0001732b8 0xc0001733a8] [0xc000173158 0xc0001732b8 0xc0001733a8] [0xc0001732a8 0xc000173318] [0x9c00a0 0x9c00a0] 0xc002659e60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:08:51.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:08:51.503: INFO: rc: 1
Jun 24 17:08:51.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a20e40 exit status 1 <nil> <nil> true [0xc0015f4078 0xc0015f4090 0xc0015f40a8] [0xc0015f4078 0xc0015f4090 0xc0015f40a8] [0xc0015f4088 0xc0015f40a0] [0x9c00a0 0x9c00a0] 0xc003419320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:01.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:01.613: INFO: rc: 1
Jun 24 17:09:01.613: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002de2480 exit status 1 <nil> <nil> true [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000100b8 0xc0000106c8 0xc0000107e8] [0xc0000105b0 0xc000010730] [0x9c00a0 0x9c00a0] 0xc0014ac4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:11.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:11.712: INFO: rc: 1
Jun 24 17:09:11.712: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c313e0 exit status 1 <nil> <nil> true [0xc0001733d0 0xc000173450 0xc000173530] [0xc0001733d0 0xc000173450 0xc000173530] [0xc0001733f8 0xc000173510] [0x9c00a0 0x9c00a0] 0xc003232240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:21.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:21.800: INFO: rc: 1
Jun 24 17:09:21.801: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002de27e0 exit status 1 <nil> <nil> true [0xc000010878 0xc000010950 0xc0000109a8] [0xc000010878 0xc000010950 0xc0000109a8] [0xc0000108f8 0xc000010998] [0x9c00a0 0x9c00a0] 0xc0014acb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:31.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:31.889: INFO: rc: 1
Jun 24 17:09:31.889: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ef4300 exit status 1 <nil> <nil> true [0xc001a8a000 0xc001a8a018 0xc001a8a030] [0xc001a8a000 0xc001a8a018 0xc001a8a030] [0xc001a8a010 0xc001a8a028] [0x9c00a0 0x9c00a0] 0xc0017342a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:41.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:41.993: INFO: rc: 1
Jun 24 17:09:41.993: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a20330 exit status 1 <nil> <nil> true [0xc0015f4008 0xc0015f4020 0xc0015f4038] [0xc0015f4008 0xc0015f4020 0xc0015f4038] [0xc0015f4018 0xc0015f4030] [0x9c00a0 0x9c00a0] 0xc002658960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:09:51.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:09:52.093: INFO: rc: 1
Jun 24 17:09:52.093: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c30330 exit status 1 <nil> <nil> true [0xc000172000 0xc000172148 0xc000172298] [0xc000172000 0xc000172148 0xc000172298] [0xc000172100 0xc000172240] [0x9c00a0 0x9c00a0] 0xc0034185a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:10:02.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:10:02.182: INFO: rc: 1
Jun 24 17:10:02.183: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a206c0 exit status 1 <nil> <nil> true [0xc0015f4040 0xc0015f4058 0xc0015f4070] [0xc0015f4040 0xc0015f4058 0xc0015f4070] [0xc0015f4050 0xc0015f4068] [0x9c00a0 0x9c00a0] 0xc0026590e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:10:12.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:10:12.277: INFO: rc: 1
Jun 24 17:10:12.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a20ea0 exit status 1 <nil> <nil> true [0xc0015f4078 0xc0015f4090 0xc0015f40a8] [0xc0015f4078 0xc0015f4090 0xc0015f40a8] [0xc0015f4088 0xc0015f40a0] [0x9c00a0 0x9c00a0] 0xc0026596e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:10:22.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:10:22.371: INFO: rc: 1
Jun 24 17:10:22.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a211d0 exit status 1 <nil> <nil> true [0xc0015f40b0 0xc0015f40c8 0xc0015f40e0] [0xc0015f40b0 0xc0015f40c8 0xc0015f40e0] [0xc0015f40c0 0xc0015f40d8] [0x9c00a0 0x9c00a0] 0xc002659aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:10:32.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:10:32.465: INFO: rc: 1
Jun 24 17:10:32.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002de2420 exit status 1 <nil> <nil> true [0xc001a8a000 0xc001a8a018 0xc001a8a030] [0xc001a8a000 0xc001a8a018 0xc001a8a030] [0xc001a8a010 0xc001a8a028] [0x9c00a0 0x9c00a0] 0xc003232360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun 24 17:10:42.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 exec --namespace=statefulset-1449 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 24 17:10:42.555: INFO: rc: 1
Jun 24 17:10:42.555: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jun 24 17:10:42.555: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 24 17:10:42.569: INFO: Deleting all statefulset in ns statefulset-1449
Jun 24 17:10:42.571: INFO: Scaling statefulset ss to 0
Jun 24 17:10:42.578: INFO: Waiting for statefulset status.replicas updated to 0
Jun 24 17:10:42.580: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:10:42.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1449" for this suite.
Jun 24 17:10:48.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:10:48.703: INFO: namespace statefulset-1449 deletion completed in 6.110047248s

• [SLOW TEST:371.329 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:10:48.703: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-gjp5
STEP: Creating a pod to test atomic-volume-subpath
Jun 24 17:10:48.769: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gjp5" in namespace "subpath-5030" to be "success or failure"
Jun 24 17:10:48.773: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.267023ms
Jun 24 17:10:50.777: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007562462s
Jun 24 17:10:52.781: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 4.011422271s
Jun 24 17:10:54.785: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 6.015794552s
Jun 24 17:10:56.789: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 8.01979322s
Jun 24 17:10:58.793: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 10.023961624s
Jun 24 17:11:00.798: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 12.02850197s
Jun 24 17:11:02.802: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 14.032435178s
Jun 24 17:11:04.806: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 16.036648412s
Jun 24 17:11:06.811: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 18.041119371s
Jun 24 17:11:08.815: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Running", Reason="", readiness=true. Elapsed: 20.045587652s
Jun 24 17:11:10.819: INFO: Pod "pod-subpath-test-secret-gjp5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.049826554s
STEP: Saw pod success
Jun 24 17:11:10.819: INFO: Pod "pod-subpath-test-secret-gjp5" satisfied condition "success or failure"
Jun 24 17:11:10.823: INFO: Trying to get logs from node minion pod pod-subpath-test-secret-gjp5 container test-container-subpath-secret-gjp5: <nil>
STEP: delete the pod
Jun 24 17:11:10.848: INFO: Waiting for pod pod-subpath-test-secret-gjp5 to disappear
Jun 24 17:11:10.851: INFO: Pod pod-subpath-test-secret-gjp5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-gjp5
Jun 24 17:11:10.851: INFO: Deleting pod "pod-subpath-test-secret-gjp5" in namespace "subpath-5030"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:11:10.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5030" for this suite.
Jun 24 17:11:16.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:11:16.960: INFO: namespace subpath-5030 deletion completed in 6.103429223s

• [SLOW TEST:28.257 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:11:16.961: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jun 24 17:11:16.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 create -f - --namespace=kubectl-6522'
Jun 24 17:11:17.286: INFO: stderr: ""
Jun 24 17:11:17.286: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 24 17:11:18.290: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 17:11:18.290: INFO: Found 0 / 1
Jun 24 17:11:19.290: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 17:11:19.290: INFO: Found 1 / 1
Jun 24 17:11:19.290: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun 24 17:11:19.294: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 17:11:19.294: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 24 17:11:19.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766262415 patch pod redis-master-vf49g --namespace=kubectl-6522 -p {"metadata":{"annotations":{"x":"y"}}}'
Jun 24 17:11:19.408: INFO: stderr: ""
Jun 24 17:11:19.408: INFO: stdout: "pod/redis-master-vf49g patched\n"
STEP: checking annotations
Jun 24 17:11:19.412: INFO: Selector matched 1 pods for map[app:redis]
Jun 24 17:11:19.412: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:11:19.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6522" for this suite.
Jun 24 17:11:41.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:11:41.510: INFO: namespace kubectl-6522 deletion completed in 22.093152762s

• [SLOW TEST:24.549 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:11:41.511: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jun 24 17:11:41.539: INFO: PodSpec: initContainers in spec.initContainers
Jun 24 17:12:26.771: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2292ce71-96a3-11e9-8bcb-526dc0a539dd", GenerateName:"", Namespace:"init-container-2374", SelfLink:"/api/v1/namespaces/init-container-2374/pods/pod-init-2292ce71-96a3-11e9-8bcb-526dc0a539dd", UID:"22934f42-96a3-11e9-b70d-fa163ef83c94", ResourceVersion:"21056", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63696993101, loc:(*time.Location)(0x8a1a0e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"539294377"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wc5nr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0031b1200), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wc5nr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wc5nr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wc5nr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0023f6ff8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"minion", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00259f080), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023f7080)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023f70a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0023f70a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0023f70ac)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696993101, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696993101, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696993101, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696993101, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.0.12", PodIP:"10.251.128.5", StartTime:(*v1.Time)(0xc0031c8980), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e8ca10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e8ce70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://86a0b131993267ad96453dadaa67ad07da8fae275201c3d696d3655e364ce96f"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0031c89c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0031c89a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:12:26.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2374" for this suite.
Jun 24 17:12:48.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:12:48.872: INFO: namespace init-container-2374 deletion completed in 22.089850305s

• [SLOW TEST:67.361 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jun 24 17:12:48.873: INFO: >>> kubeConfig: /tmp/kubeconfig-766262415
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-4abc9106-96a3-11e9-8bcb-526dc0a539dd
STEP: Creating a pod to test consume secrets
Jun 24 17:12:48.932: INFO: Waiting up to 5m0s for pod "pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd" in namespace "secrets-8268" to be "success or failure"
Jun 24 17:12:48.940: INFO: Pod "pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.089796ms
Jun 24 17:12:50.944: INFO: Pod "pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012510775s
STEP: Saw pod success
Jun 24 17:12:50.945: INFO: Pod "pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd" satisfied condition "success or failure"
Jun 24 17:12:50.950: INFO: Trying to get logs from node minion pod pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd container secret-volume-test: <nil>
STEP: delete the pod
Jun 24 17:12:50.976: INFO: Waiting for pod pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd to disappear
Jun 24 17:12:50.988: INFO: Pod pod-secrets-4abd1326-96a3-11e9-8bcb-526dc0a539dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jun 24 17:12:50.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8268" for this suite.
Jun 24 17:12:57.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 24 17:12:57.098: INFO: namespace secrets-8268 deletion completed in 6.105188411s

• [SLOW TEST:8.225 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSJun 24 17:12:57.098: INFO: Running AfterSuite actions on all nodes
Jun 24 17:12:57.098: INFO: Running AfterSuite actions on node 1
Jun 24 17:12:57.098: INFO: Skipping dumping logs from cluster

Ran 204 of 3585 Specs in 6053.359 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3381 Skipped PASS

Ginkgo ran 1 suite in 1h40m55.09247126s
Test Suite Passed
